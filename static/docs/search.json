[{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to torch","title":"Contributing to torch","text":"Many thanks wanting contribute torch! welcome kinds contributions, correcting typos via bug fixes feature additions.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to torch","text":"fix typos, spelling mistakes, grammatical errors, need make changes source .R file question, generated .Rd file. Thereafter, run tools/document.R regenerate documentation. (See Workflow .)","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"filing-bugs","dir":"","previous_headings":"","what":"Filing bugs","title":"Contributing to torch","text":"find bug torch, please open issue . Please provide detailed information reproduce bug. great also provide reprex.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"feature-requests","dir":"","previous_headings":"","what":"Feature requests","title":"Contributing to torch","text":"Feel free open issues , add feature-request tag. Also try searching ’s already open issue feature-request – case ’s better comment upvote instead opening new one.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Contributing to torch","text":"welcome contributed examples. Feel free open PR new examples. examples placed vignettes/examples folder. examples consist .R file .Rmd name just renders code. See mnist-mlp.R mnist-mlp.Rmd example. ’s important one can run example without manually downloading dataset/file. also add entry _pkgdown.yaml file example.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"code-contributions","dir":"","previous_headings":"","what":"Code contributions","title":"Contributing to torch","text":"many open issues github repo. ’s one item want work , can comment ask directions.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Code contributions","what":"Code style","title":"Contributing to torch","text":"New R code follow tidyverse style guide. can use styler package apply styles, simply run tools/style.sh script, also formats code removes whitespace. Please don’t re-style code nothing PR. New C/C++ code follow Google style guide. can use clang-format apply styles, simply run tools/style.sh, also formats code removes whitespace. Please don’t re-style code nothing PR. use roxygen2, Markdown syntax, build documentation package. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"requirements","dir":"","previous_headings":"Code contributions","what":"Requirements","title":"Contributing to torch","text":"R installation R Tools compilation (Windows) devtools package CMake compile lantern binaries","code":""},{"path":"https://torch.mlverse.org/docs/CONTRIBUTING.html","id":"workflow","dir":"","previous_headings":"Code contributions","what":"Workflow","title":"Contributing to torch","text":"use devtools toolchain development, steps must done upfront. first time clone repository, run: first download LibTorch copy binaries deps folder working directory, , compile lantern binaries . command must run everytime modify lantern code, .e., code lives lantern/src. can run load torch, test interactively. Alternatively, run execute test suite. Finally, ’s important update documentation. Please always use custom tools/document.R script instead devtools::document(), need patch roxygen2 avoid running examples CRAN. ’re looking forward contributions!","code":"source(\"tools/buildlantern.R\") devtools::load_all() devtools::test()"},{"path":"https://torch.mlverse.org/docs/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2020 Daniel Falbel Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/amp.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Automatic Mixed Precision","text":"define model random training data showcase enabled AMP torch: Now let’s define model: train model without mixed precision can : enabled step 1. mixed precision, ie, allowing model run operations half precision possible, one simply run model computations (including loss computation) inside with_autocast context. additionally enable gradient scaling now introduce cuda_amp_grad_scaler() object use scale loss calling backward() also use wrap calls optimizer, can ‘unscale’ gradients actually updating weights. training loop now implemented :","code":"batch_size <- 512 # Try, for example, 128, 256, 513. in_size <- 4096 out_size <- 4096 num_layers <- 3 num_batches <- 50 epochs <- 3  # Creates data in default precision. # The same data is used for both default and mixed precision trials below. # You don't need to manually change inputs' dtype when enabling mixed precision. data <- lapply(1:num_batches, function(x) torch_randn(batch_size, in_size, device=\"cuda\")) targets <- lapply(1:num_batches, function(x) torch_randn(batch_size, out_size, device=\"cuda\")) make_model <- function(in_size, out_size, num_layers) {   layers <- list()   for (i in seq_len(num_layers-1)) {     layers <- c(layers, list(nn_linear(in_size, in_size), nn_relu()))   }   layers <- c(layers, list(nn_linear(in_size, out_size)))   nn_sequential(!!!layers)$cuda() } loss_fn <- nn_mse_loss()$cuda() net <- make_model(in_size, out_size, num_layers) opt <- optim_sgd(net$parameters, lr=0.1)  for (epoch in seq_len(epochs)) {   for (i in seq_along(data)) {          output <- net(data[[i]])     loss <- loss_fn(output, targets[[i]])        loss$backward()     opt$step()     opt$zero_grad()   } } loss_fn <- nn_mse_loss()$cuda() net <- make_model(in_size, out_size, num_layers) opt <- optim_sgd(net$parameters, lr=0.1)  for (epoch in seq_len(epochs)) {   for (i in seq_along(data)) {     with_autocast(device_type = \"cuda\", {       output <- net(data[[i]])       loss <- loss_fn(output, targets[[i]])       })          loss$backward()     opt$step()     opt$zero_grad()   } } loss_fn <- nn_mse_loss()$cuda() net <- make_model(in_size, out_size, num_layers) opt <- optim_sgd(net$parameters, lr=0.1) scaler <- cuda_amp_grad_scaler()  for (epoch in seq_len(epochs)) {   for (i in seq_along(data)) {     with_autocast(device_type = \"cuda\", {       output <- net(data[[i]])       loss <- loss_fn(output, targets[[i]])       })          scaler$scale(loss)$backward()     scaler$step(opt)     scaler$update()     opt$zero_grad()   } }"},{"path":"https://torch.mlverse.org/docs/articles/amp.html","id":"benchmark","dir":"Articles","previous_headings":"","what":"Benchmark","title":"Automatic Mixed Precision","text":"now write simple function allows us quickly switch feature can benchmark AMP:","code":"run <- function(autocast, scale) {   loss_fn <- nn_mse_loss()$cuda()   net <- make_model(in_size, out_size, num_layers)   opt <- optim_sgd(net$parameters, lr=0.1)   scaler <- cuda_amp_grad_scaler(enabled = scale)      for (epoch in seq_len(epochs)) {     for (i in seq_along(data)) {       with_autocast(enabled = autocast, device_type = \"cuda\", {         output <- net(data[[i]])         loss <- loss_fn(output, targets[[i]])         })              scaler$scale(loss)$backward()       scaler$step(opt)       scaler$update()       opt$zero_grad()     }   }   loss$item() }   system.time({run(autocast = FALSE, scale = FALSE)}) #>    user  system elapsed  #>   3.967   1.644   5.621 system.time({run(autocast = TRUE, scale = FALSE)}) #>    user  system elapsed  #>   1.857   0.591   2.462 system.time({run(autocast = TRUE, scale = TRUE)}) #>    user  system elapsed  #>   3.434   0.114   3.550"},{"path":"https://torch.mlverse.org/docs/articles/distributions.html","id":"basic-univariate-distributions","dir":"Articles","previous_headings":"","what":"Basic univariate distributions","title":"Distributions","text":"Let’s start create new instance normal distribution: can draw samples : , draw multiple samples: can evaluate log probability values: , evaluate multiple log probabilities:","code":"n <- distr_normal(loc = 0, scale = 1) n #> torch_Normal () n$sample() #> torch_tensor #>  0.6614 #> [ CPUFloatType{1} ] n$sample(3) #> torch_tensor #>  0.2669 #>  0.0617 #>  0.6213 #> [ CPUFloatType{3,1} ] n$log_prob(0) #> torch_tensor #> -0.9189 #> [ CPUFloatType{1} ] log(dnorm(0)) # equivalent R code #> [1] -0.9189385 n$log_prob(c(0, 2, 4)) #> torch_tensor #> -0.9189 #> -2.9189 #> -8.9189 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/articles/distributions.html","id":"multiple-distributions","dir":"Articles","previous_headings":"","what":"Multiple distributions","title":"Distributions","text":"distribution can take tensor ’s parameters: object represents 3 independent Bernoulli distributions, one element tensor. can sample single observation: , batch n observations:","code":"b <- distr_bernoulli(probs = torch_tensor(c(0.25, 0.5, 0.75))) b #> torch_Bernoulli () b$sample() #> torch_tensor #>  0 #>  1 #>  1 #> [ CPUFloatType{3} ] b$sample(6) #> torch_tensor #>  0  0  1 #>  0  1  1 #>  0  0  1 #>  0  1  1 #>  0  1  1 #>  0  0  1 #> [ CPUFloatType{6,3} ]"},{"path":"https://torch.mlverse.org/docs/articles/distributions.html","id":"using-distributions-within-models","dir":"Articles","previous_headings":"","what":"Using distributions within models","title":"Distributions","text":"log_prob method distributions can differentiated, thus, distributions can used train models torch. Let’s implement Gaussian linear model, first let’s simulate data plot:  can now define model: can now train model : can see parameter estimates : quickly compare glm() function:","code":"x <- torch_randn(100, 1) y <- 2*x + 1 + torch_randn(100, 1) plot(as.numeric(x), as.numeric(y)) GaussianLinear <- nn_module(   initialize = function() {     # this linear predictor will estimate the mean of the normal distribution     self$linear <- nn_linear(1, 1)     # this parameter will hold the estimate of the variability     self$scale <- nn_parameter(torch_ones(1))   },   forward = function(x) {     # we estimate the mean     loc <- self$linear(x)     # return a normal distribution     distr_normal(loc, self$scale)   } )  model <- GaussianLinear() opt <- optim_sgd(model$parameters, lr = 0.1)  for (i in 1:100) {   opt$zero_grad()   d <- model(x)   loss <- torch_mean(-d$log_prob(y))   loss$backward()   opt$step()   if (i %% 10 == 0)     cat(\"iter: \", i, \" loss: \", loss$item(), \"\\n\") } #> iter:  10  loss:  1.975726  #> iter:  20  loss:  1.790831  #> iter:  30  loss:  1.64495  #> iter:  40  loss:  1.532009  #> iter:  50  loss:  1.478054  #> iter:  60  loss:  1.465937  #> iter:  70  loss:  1.464229  #> iter:  80  loss:  1.464002  #> iter:  90  loss:  1.463971  #> iter:  100  loss:  1.463966 model$parameters #> $linear.weight #> torch_tensor #>  2.1256 #> [ CPUFloatType{1,1} ][ requires_grad = TRUE ] #>  #> $linear.bias #> torch_tensor #>  1.1215 #> [ CPUFloatType{1} ][ requires_grad = TRUE ] #>  #> $scale #> torch_tensor #>  1.0461 #> [ CPUFloatType{1} ][ requires_grad = TRUE ] summary(glm(as.numeric(y) ~ as.numeric(x))) #>  #> Call: #> glm(formula = as.numeric(y) ~ as.numeric(x)) #>  #> Coefficients: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept)     1.1226     0.1057   10.62   <2e-16 *** #> as.numeric(x)   2.1259     0.1009   21.08   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for gaussian family taken to be 1.116565) #>  #>     Null deviance: 605.56  on 99  degrees of freedom #> Residual deviance: 109.42  on 98  degrees of freedom #> AIC: 298.79 #>  #> Number of Fisher Scoring iterations: 2"},{"path":"https://torch.mlverse.org/docs/articles/extending-autograd.html","id":"note","dir":"Articles","previous_headings":"","what":"Note","title":"Extending Autograd","text":"’s user’s responsibility use special functions forward’s ctx properly order ensure new autograd_function works properly autograd engine. save_for_backward() must used saving input ouput forward used later backward. mark_dirty() must used mark input modified inplace forward function. mark_non_differentiable() must used tell engine output differentiable.","code":""},{"path":"https://torch.mlverse.org/docs/articles/extending-autograd.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Extending Autograd","text":"can find code linear function: , give additional example function parametrized non-Tensor arguments:","code":"linear <- autograd_function(   forward = function(ctx, input, weight, bias = NULL) {     ctx$save_for_backward(input = input, weight = weight, bias = bias)     output <- input$mm(weight$t())     if (!is.null(bias))       output <- output + bias$unsqueeze(0)$expand_as(output)          output   },   backward = function(ctx, grad_output) {          s <- ctx$saved_variables          grads <- list(       input = NULL,       weight = NULL,       bias = NULL     )          if (ctx$needs_input_grad$input)       grads$input <- grad_output$mm(s$weight)          if (ctx$needs_input_grad$weight)       grads$weight <- grad_output$t()$mm(s$input)          if (!is.null(s$bias) && ctx$needs_input_grad$bias)       grads$bias <- grad_output$sum(dim = 0)          grads   } ) mul_constant <- autograd_function(   forward = function(ctx, tensor, constant) {     ctx$save_for_backward(constant = constant)     tensor * constant   },   backward = function(ctx, grad_output) {     v <- ctx$saved_variables     list(       tensor = grad_output * v$constant     )   } ) x <- torch_tensor(1, requires_grad = TRUE) o <- mul_constant(x, 2) o$backward() x$grad #> torch_tensor #>  2 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"single-element-indexing","dir":"Articles","previous_headings":"","what":"Single element indexing","title":"Indexing tensors","text":"Single element indexing 1-D tensors works mostly expected. Like R, 1-based. Unlike R though, accepts negative indices indexing end array. (R, negative indices used remove elements.) can also subset matrices higher dimensions arrays using syntax: Note one indexes multidimensional tensor fewer indices dimensions, torch’s behaviour differs R, flattens array. torch, missing indices considered complete slices :.","code":"x <- torch_tensor(1:10) x[1] #> torch_tensor #> 1 #> [ CPULongType{} ] x[-1] #> torch_tensor #> 10 #> [ CPULongType{} ] x <- x$reshape(shape = c(2,5)) x #> torch_tensor #>   1   2   3   4   5 #>   6   7   8   9  10 #> [ CPULongType{2,5} ] x[1,3] #> torch_tensor #> 3 #> [ CPULongType{} ] x[1,-1] #> torch_tensor #> 5 #> [ CPULongType{} ] x[1] #> torch_tensor #>  1 #>  2 #>  3 #>  4 #>  5 #> [ CPULongType{5} ]"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"slicing-and-striding","dir":"Articles","previous_headings":"","what":"Slicing and striding","title":"Indexing tensors","text":"possible slice stride arrays extract sub-arrays number dimensions, different sizes original. best illustrated examples: can also use 1:10:2 syntax means: range 1 10, take every second item. example: Another special syntax N, meaning size specified dimension. Note: slicing behavior relies Non Standard Evaluation. requires expression passed [ exactly resulting R vector. allow dynamic dynamic indices, can create new slice using slc function. example: equivalent :","code":"x <- torch_tensor(1:10) x #> torch_tensor #>   1 #>   2 #>   3 #>   4 #>   5 #>   6 #>   7 #>   8 #>   9 #>  10 #> [ CPULongType{10} ] x[2:5] #> torch_tensor #>  2 #>  3 #>  4 #>  5 #> [ CPULongType{4} ] x[1:(-7)] #> torch_tensor #>  1 #>  2 #>  3 #>  4 #> [ CPULongType{4} ] x[1:5:2] #> torch_tensor #>  1 #>  3 #>  5 #> [ CPULongType{3} ] x[5:N] #> torch_tensor #>   5 #>   6 #>   7 #>   8 #>   9 #>  10 #> [ CPULongType{6} ] x[1:5:2] #> torch_tensor #>  1 #>  3 #>  5 #> [ CPULongType{3} ] x[slc(start = 1, end = 5, step = 2)] #> torch_tensor #>  1 #>  3 #>  5 #> [ CPULongType{3} ]"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"getting-the-complete-dimension","dir":"Articles","previous_headings":"","what":"Getting the complete dimension","title":"Indexing tensors","text":"Like R, can take elements dimension leaving index empty. Consider matrix: following syntax give first row: give first 2 columns:","code":"x <- torch_randn(2, 3) x #> torch_tensor #> -1.1594 -1.9351  1.0987 #> -0.2400  0.9302  0.4572 #> [ CPUFloatType{2,3} ] x[1,] #> torch_tensor #> -1.1594 #> -1.9351 #>  1.0987 #> [ CPUFloatType{3} ] x[,1:2] #> torch_tensor #> -1.1594 -1.9351 #> -0.2400  0.9302 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"dropping-dimensions","dir":"Articles","previous_headings":"","what":"Dropping dimensions","title":"Indexing tensors","text":"default, indexing single integer, dimension dropped avoid singleton dimension: can optionally use drop = FALSE argument avoid dropping dimension.","code":"x <- torch_randn(2, 3) x[1,]$shape #> [1] 3 x[1,,drop = FALSE]$shape #> [1] 1 3"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"adding-a-new-dimension","dir":"Articles","previous_headings":"","what":"Adding a new dimension","title":"Indexing tensors","text":"’s possible add new dimension tensor using index-like syntax: can also use NULL instead newaxis:","code":"x <- torch_tensor(c(10)) x$shape #> [1] 1 x[, newaxis]$shape #> [1] 1 1 x[, newaxis, newaxis]$shape #> [1] 1 1 1 x[,NULL]$shape #> [1] 1 1"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"dealing-with-variable-number-of-indices","dir":"Articles","previous_headings":"","what":"Dealing with variable number of indices","title":"Indexing tensors","text":"Sometimes don’t know many dimensions tensor , know last available dimension, first one. subsume others, can use ..:","code":"z <- torch_tensor(1:125)$reshape(c(5,5,5)) z[1,..] #> torch_tensor #>   1   2   3   4   5 #>   6   7   8   9  10 #>  11  12  13  14  15 #>  16  17  18  19  20 #>  21  22  23  24  25 #> [ CPULongType{5,5} ] z[..,1] #> torch_tensor #>    1    6   11   16   21 #>   26   31   36   41   46 #>   51   56   61   66   71 #>   76   81   86   91   96 #>  101  106  111  116  121 #> [ CPULongType{5,5} ]"},{"path":"https://torch.mlverse.org/docs/articles/indexing.html","id":"indexing-with-vectors","dir":"Articles","previous_headings":"","what":"Indexing with vectors","title":"Indexing tensors","text":"Vector indexing also supported care must taken regarding performance , general much less performant slice based indexing. Note: Starting version 0.5.0, vector indexing torch follows R semantics, prior behavior similar numpy’s advanced indexing. use old behavior, consider using ?torch_index, ?torch_index_put torch_index_put_. can also use boolean vectors, example: examples also work index long boolean tensors, instead R vectors. ’s also possible index multi-dimensional boolean tensors:","code":"x <- torch_randn(4,4) x[c(1,3), c(1,3)] #> torch_tensor #>  0.6781 -0.5159 #> -1.0444 -1.0188 #> [ CPUFloatType{2,2} ] x[c(TRUE, FALSE, TRUE, FALSE), c(TRUE, FALSE, TRUE, FALSE)] #> torch_tensor #>  0.6781 -0.5159 #> -1.0444 -1.0188 #> [ CPUFloatType{2,2} ] x <- torch_tensor(rbind(   c(1,2,3),   c(4,5,6) )) x[x>3] #> torch_tensor #>  4 #>  5 #>  6 #> [ CPUFloatType{3} ]"},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"cpu","dir":"Articles","previous_headings":"Windows","what":"CPU","title":"Installation","text":"don’t GPU want install CPU version torch, can install : Windows distributions don’t Visual Studio runtime pre-installed observe error like: See instructions install .","code":"install.packages(\"torch\") Error in cpp_lantern_init(normalizePath(install_path())): C:\\Users\\User\\Documents\\R\\R-4.0.2\\library\\torch\\deps\\lantern.dll - The specified module could not be found."},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"gpu","dir":"Articles","previous_headings":"Windows","what":"GPU","title":"Installation","text":"torch specific requirements terms CUDA CUDNN versions supports. recomment installing torch using pre-built binaries. See (#pre-built) information. Since version 0.1.1 torch supports GPU installation Windows. order use GPU’s torch need : CUDA compatible NVIDIA GPU. can find CUDA compatible GPU . properly installed NVIDIA CUDA toolkit version 11.7. CUDA v11.7, follow installation instructions . Note: version CUDA toolkit must match exactly ’s mentioed . installed cuDNN - version compatible CUDA v11.7. Follow installation instructions available . installed pre-requisites can install torch : followed default installation locations detect CUDA software installed automatically download GPU enabled Lantern binaries. can also specify CUDA env var something like Sys.setenv(CUDA=\"11.7\") want force specific version CUDA toolkit.","code":"install.packages(\"torch\")"},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"cpu-1","dir":"Articles","previous_headings":"MacOS","what":"CPU","title":"Installation","text":"support CPU builds torch MacOS. MacOS can install torch :","code":"install.packages(\"torch\")"},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"gpu-1","dir":"Articles","previous_headings":"MacOS","what":"GPU","title":"Installation","text":"Apple Silicon architecture support GPU MPS:","code":"install.packages(\"torch\")"},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"cpu-2","dir":"Articles","previous_headings":"Linux","what":"CPU","title":"Installation","text":"install cpu version torch can run:","code":"install.packages(\"torch\")"},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"gpu-2","dir":"Articles","previous_headings":"Linux","what":"GPU","title":"Installation","text":"torch specific requirements terms CUDA CUDNN versions supports. recomment installing torch using pre-built binaries. See (#pre-built) information. install GPU version torch linux must verify : NVIDIA CUDA compatible GPU. can find CUDA compatible GPU . correctly installed NVIDIA CUDA Toolkit versions 11.6 11.7, follow instructions . installed cuDNN (version compatible CUDA version). Follow installation instructions available . installed pre-requisites can install torch : followed default installation locations detect CUDA software installed automatically download GPU enabled Lantern binaries. can also specify CUDA env var something like Sys.setenv(CUDA=\"11.7\") want force specific version CUDA toolkit.","code":"install.packages(\"torch\")"},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"pre-built","dir":"Articles","previous_headings":"","what":"Installing from pre-built binaries","title":"Installation","text":"torch v0.9.1.9000 ’s now possible install torch pre-built package binaries CRAN like repository hosted Google Cloud Storage. currently provide pre-built binaries CPU (macOS, Linux Windows) GPU (Windows Linux). Packages provided CRAN-like repository bundles necessary execution, including CUDA CUDNN case GPU builds. means installing agree included software licenses. See PyTorch’s LICENSE CUDA libraries EULA. installing pre-built binaries, don’t need manually install CUDA cuDNN. CUDA installed, doesn’t need match installation ‘kind’ chosen . install pre-built binaries, can use following:","code":"options(timeout = 600) # increasing timeout is recommended since we will be downloading a 2GB file. # For Windows and Linux: \"cpu\", \"cu117\" are the only currently supported # For MacOS the supported are: \"cpu-intel\" or \"cpu-m1\" kind <- \"cu118\" version <- available.packages()[\"torch\",\"Version\"] options(repos = c(   torch = sprintf(\"https://torch-cdn.mlverse.org/packages/%s/%s/\", kind, version),   CRAN = \"https://cloud.r-project.org\" # or any other from which you want to install the other R dependencies. )) install.packages(\"torch\", type = \"binary\")"},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"large-file-download-timeout","dir":"Articles","previous_headings":"Troubleshooting","what":"Large file download timeout","title":"Installation","text":"encounter timeout library download, , downloads end-warning : means encounter download timeout. , increase timeout value install_torch() like","code":"Warning messages: 1: In utils::download.file(library_url, temp_file) :   downloaded length 44901568 != reported length 141774525 2: In utils::download.file(library_url, temp_file) :   URL '...': Timeout of 60 seconds was reached 3: Failed to install Torch, manually run install_torch(). download from 'https://download.pytorch.org/libtorch/cpu/libtorch-macos-1.7.1.zip' failed install_torch(timeout = 600)"},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"file-based-download","dir":"Articles","previous_headings":"Troubleshooting","what":"File based download","title":"Installation","text":"cases reach download servers machine intend install torch , last resort install Torch Lantern library files. done 3 steps : 1- get download URLs files. 2- save files machine filesystem. use /tmp/ example . 3- install torch files","code":"get_install_libs_url() # then after making both files available into /tmp/ Sys.setenv(TORCH_URL=\"/tmp/libtorch-v1.13.1.zip\") Sys.setenv(LANTERN_URL=\"/tmp/lantern-0.9.1.9001+cpu+arm64-Darwin.zip\") torch::install_torch()"},{"path":"https://torch.mlverse.org/docs/articles/installation.html","id":"installing-older-versions","dir":"Articles","previous_headings":"Troubleshooting","what":"Installing older versions","title":"Installation","text":"v0.13.0 torch shifted using Google Cloud Storage service AWS S3 storage service required Lantern binaries. keep files GCS bucket long possible, might need remove point time. files backed new AWS S3 bucket using file structure, torch tries download URL starting https://storage.googleapis.com/torch-lantern-builds, now replace https://torch-cdn.mlverse.org. torch versions v0.10.0 v0.12.0 (included), able set environment variable LANTERN_BASE_URL=https://torch-cdn.mlverse.org/binaries/ point new address binaries. older versions torch, might need manually download file new address extract expected TORCH_HOME directory. Feel free open issue GitHub need help .","code":""},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"datasets-and-data-loaders","dir":"Articles","previous_headings":"","what":"Datasets and data loaders","title":"Loading data","text":"Central data ingestion preprocessing datasets data loaders. dataset object holds data use, data loader object load data dataset providing way access subsets data. using datasets data loaders process clearly organizing data passing components torch package, model training. Built torch premade datasets commonly used machine learning, MNIST handwriting dataset (mnist_dataset()). prebuilt datasets relate image recognition natural language processing. example use MNIST dataset dataloader. First, minst_dataset() function used create ds Dataset object. dataloader dl created query data. Finally, dataloader used coro::loop() iterate batches data: See vignettes/examples/mnist-cnn.R complete example. common situation unique set data isn’t included package ’ll need make custom Dataset subclass using dataset() function. custom Dataset subclass abstract R6 container data. need know information particular dataset, iterate . minimum, using dataset() create custom Dataset class ’ll want define following: name - convenience, keep track type data initialize - member function defining create object class. parameters, objects class , can give specific parameters usually different objects different data. .getitem - member function called dataloader goes pull new batch data. can include preprocessing function needed. Note function called extremely frequently, ’s advantageous make fast. .length - return amount data dataset, helpful users.","code":"# Create a dataset from included data ds <- mnist_dataset(   dir,    download = TRUE,    transform = function(x) {     x <- x$to(dtype = torch_float())/256     x[newaxis,..]   } )  # Create the loader to query the data in batches dl <- dataloader(ds, batch_size = 32, shuffle = TRUE)  coro::loop(for (b in dl)) { # use the data from each batch `b` here # ... })"},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"example-of-using-a-custom-dataset","dir":"Articles","previous_headings":"","what":"Example of using a custom Dataset","title":"Loading data","text":"may sound complicated base logic steps–complexity often comes data involved preprocessing . show create Dataset class train Allison Horst's penguins. addition, number helper functions can defined. , assume penguins already loaded, preprocessing consists removing lines NA values, transforming factors numbers starting 0, converting R data types torch tensors. .getitem, essentially decide data going used: variables besides species go x, predictor, species constitute y, target. Predictor target returned list, accessed batch[[1]] batch[[2]] training. Let’s create dataset , query ’s length, look first item: able iterate tuxes, need data loader (override default batch size 1): Calling .length() data loader (opposed dataset) return number batches : can create iterator inspect first batch: train network, can use coro::loop() iterate batches.","code":"library(palmerpenguins) library(magrittr)  penguins #> # A tibble: 344 × 8 #>    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g #>    <fct>   <fct>              <dbl>         <dbl>             <int>       <int> #>  1 Adelie  Torgersen           39.1          18.7               181        3750 #>  2 Adelie  Torgersen           39.5          17.4               186        3800 #>  3 Adelie  Torgersen           40.3          18                 195        3250 #>  4 Adelie  Torgersen           NA            NA                  NA          NA #>  5 Adelie  Torgersen           36.7          19.3               193        3450 #>  6 Adelie  Torgersen           39.3          20.6               190        3650 #>  7 Adelie  Torgersen           38.9          17.8               181        3625 #>  8 Adelie  Torgersen           39.2          19.6               195        4675 #>  9 Adelie  Torgersen           34.1          18.1               193        3475 #> 10 Adelie  Torgersen           42            20.2               190        4250 #> # ℹ 334 more rows #> # ℹ 2 more variables: sex <fct>, year <int> penguins_dataset <- dataset(      name = \"penguins_dataset\",      initialize = function() {     self$data <- self$prepare_penguin_data()   },      .getitem = function(index) {          x <- self$data[index, 2:-1]     y <- self$data[index, 1]$to(torch_long())          list(x, y)   },      .length = function() {     self$data$size()[[1]]   },      prepare_penguin_data = function() {          input <- na.omit(penguins)      # conveniently, the categorical data are already factors     input$species <- as.numeric(input$species)     input$island <- as.numeric(input$island)     input$sex <- as.numeric(input$sex)          input <- as.matrix(input)     torch_tensor(input)   } ) tuxes <- penguins_dataset() tuxes$.length() #> [1] 333 tuxes$.getitem(1) #> [[1]] #> torch_tensor #>     3.0000 #>    39.1000 #>    18.7000 #>   181.0000 #>  3750.0000 #>     2.0000 #>  2007.0000 #> [ CPUFloatType{7} ] #>  #> [[2]] #> torch_tensor #> 1 #> [ CPULongType{} ] dl <- tuxes %>% dataloader(batch_size = 8) dl$.length() #> [1] 42 iter <- dl$.iter() b <- iter$.next() b #> [[1]] #> torch_tensor #>     3.0000    39.1000    18.7000   181.0000  3750.0000     2.0000  2007.0000 #>     3.0000    39.5000    17.4000   186.0000  3800.0000     1.0000  2007.0000 #>     3.0000    40.3000    18.0000   195.0000  3250.0000     1.0000  2007.0000 #>     3.0000    36.7000    19.3000   193.0000  3450.0000     1.0000  2007.0000 #>     3.0000    39.3000    20.6000   190.0000  3650.0000     2.0000  2007.0000 #>     3.0000    38.9000    17.8000   181.0000  3625.0000     1.0000  2007.0000 #>     3.0000    39.2000    19.6000   195.0000  4675.0000     2.0000  2007.0000 #>     3.0000    41.1000    17.6000   182.0000  3200.0000     1.0000  2007.0000 #> [ CPUFloatType{8,7} ] #>  #> [[2]] #> torch_tensor #>  1 #>  1 #>  1 #>  1 #>  1 #>  1 #>  1 #>  1 #> [ CPULongType{8} ]"},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"training-with-data-loaders","dir":"Articles","previous_headings":"Example of using a custom Dataset","what":"Training with data loaders","title":"Loading data","text":"example network simple. (reality, want treat island categorical variable , either one-hot-encode embed .) still need optimizer: ’re ready train: example trained deep learning model using dataset() define custom class loaded batches data loader. using dataset data loader able write code split data preprocessing setup model training .","code":"net <- nn_module(   \"PenguinNet\",   initialize = function() {     self$fc1 <- nn_linear(7, 32)     self$fc2 <- nn_linear(32, 3)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2() %>%        nnf_log_softmax(dim = 1)   } )  model <- net() optimizer <- optim_sgd(model$parameters, lr = 0.01) for (epoch in 1:10) {      l <- c()      coro::loop(for (b in dl) {     optimizer$zero_grad()     output <- model(b[[1]])     loss <- nnf_nll_loss(output, b[[2]])     loss$backward()     optimizer$step()     l <- c(l, loss$item())   })      cat(sprintf(\"Loss at epoch %d: %3f\\n\", epoch, mean(l))) } #> Loss at epoch 1: 560.068096 #> Loss at epoch 2: 2.068251 #> Loss at epoch 3: 2.068251 #> Loss at epoch 4: 2.068251 #> Loss at epoch 5: 2.068251 #> Loss at epoch 6: 2.068251 #> Loss at epoch 7: 2.068251 #> Loss at epoch 8: 2.068251 #> Loss at epoch 9: 2.068251 #> Loss at epoch 10: 2.068251"},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"notes-on-efficiency","dir":"Articles","previous_headings":"","what":"Notes on efficiency","title":"Loading data","text":"using datasets data loaders may find certain conditions code running slowly ’d expect. situations overhead using dataloaders datasets can impact overall performance. may change time R/C++ integration Torch improves, now workarounds:","code":""},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"use--getbatch-instead-of--getitem","dir":"Articles","previous_headings":"Notes on efficiency","what":"Use .getbatch() instead of .getitem()","title":"Loading data","text":"default dataloader use .getitem() member function pull single datapoint individually. can speed switching using .getbatch() pull datapoints batch : many instances change exactly replace just .getitem .getbatch since often .getitem function written handle vectors indices. penguins example .getitem function used index select rows, work fine vector instead","code":"penguins_dataset_batching <- dataset(      name = \"penguins_dataset_batching\",      initialize = function() {     self$data <- self$prepare_penguin_data()   },      # the only change is that this went from .getitem to .getbatch   .getbatch = function(index) {          x <- self$data[index, 2:-1]     y <- self$data[index, 1]$to(torch_long())          list(x, y)   },      .length = function() {     self$data$size()[[1]]   },      prepare_penguin_data = function() {          input <- na.omit(penguins)      # conveniently, the categorical data are already factors     input$species <- as.numeric(input$species)     input$island <- as.numeric(input$island)     input$sex <- as.numeric(input$sex)          input <- as.matrix(input)     torch_tensor(input)   } )"},{"path":"https://torch.mlverse.org/docs/articles/loading-data.html","id":"remove-dataset-dataloader-and-manually-define-the-function-calls","dir":"Articles","previous_headings":"Notes on efficiency","what":"Remove dataset dataloader and manually define the function calls","title":"Loading data","text":"switching .getbatch provide benefit expecting also remove dataset entirely manually pass data. point trading readability code convenience speed.","code":"input <- na.omit(penguins)  # conveniently, the categorical data are already factors input$species <- as.numeric(input$species) input$island <- as.numeric(input$island) input$sex <- as.numeric(input$sex)  input <- as.matrix(input) input <- torch_tensor(input)  data_x <- input[, 2:-1] data_y <- input[, 1]$to(torch_long())  batch_size <- 8 num_data_points <- data_y$size(1) num_batches <- floor(num_data_points/batch_size)  for(epoch in 1:10){    # rearrange the data each epoch   permute <- torch_randperm(num_data_points) + 1L   data_x <- data_x[permute]   data_y <- data_y[permute]      # manually loop through the batches   for(batch_idx in 1:num_batches){      # here index is a vector of the indices in the batch     index <- (batch_size*(batch_idx-1) + 1):(batch_idx*batch_size)          x <- data_x[index]     y <- data_y[index]$to(torch_long())      optimizer$zero_grad()     output <- model(x)     loss <- nnf_nll_loss(output, y)     loss$backward()     optimizer$step()     l <- c(l, loss$item())   }      cat(sprintf(\"Loss at epoch %d: %3f\\n\", epoch, mean(l))) }"},{"path":"https://torch.mlverse.org/docs/articles/memory-management.html","id":"cpu","dir":"Articles","previous_headings":"","what":"CPU","title":"Memory management","text":"CPU, torch possibly call R garbage collector two moments: Every 4GB memory allocated LibTorch make call R garbage collector cleans dangling tensors. 4GB threshold can controled setting option torch.threshold_call_gc, example using: option must set calling library(torch) calling torch function first time, setting applied torch starts . torch fails allocating enough memory creating new tensor, garbage collector called allocation retried. Note: OS’s (specially UNIX based) ’s hard allocation fail ’s large, system tries use swap. much swaping used ’s possible system hangs completely. R session hanging, convinced enough memory operations, try setting lower value torch.threshold_call_gc option, call GC often make sure tensors quickly released memory. Note though, calling GC often adds lot overhead, probably slow program execution.","code":"options(torch.threshold_call_gc = 4000)"},{"path":"https://torch.mlverse.org/docs/articles/memory-management.html","id":"cuda","dir":"Articles","previous_headings":"","what":"CUDA","title":"Memory management","text":"CUDA memory tends scarcer CPU memory, also, allocation must faster otherwise allocation overhead can counterbalance speed GPU. make allocations fast avoid segmentation, LibTorch uses caching allocator manage GPU memory, ie. LibTorch allocated CUDA memory won’t give back operation system, instead reuses memory future allocations. means nvidia-smi nvtop report amount memory used tensors, memory LibTorch reserved OS. can use torch::cuda_memory_summary() query exactly memory used LibTorch. Like CPU allocator, torch’s CUDA allocator also call R garbage collector situations cleanup tensors might dangling. torch’s implementation R garbage collector called whenever reusing cached block fails. case, GC called retry getting new block. However, unlike CPU case, allocations failures rare, reusing block common programs LibTorch never reserves large chunk memory, causing GC called almost every allocation (calling GC time consuming). fix , torch allocator call faster GC moments make full collection others. don’t make collection current reserved memory (cached memory) divided total GPU memory smaller 20%. can controlled torch.cuda_allocator_reserved_rate default 0.2. make full collection current allocated memory (memory used tensors) divided total device memory larger 80%. can controlled via torch.cuda_allocator_allocated_rate default 0.8. make full collection current allocated memory larger divided current reserved memory larger 80%. controlled torch.cuda_allocator_allocated_reserved_rate default 0.8. cases light collection made. Equivalent calling gc(full = FALSE) R. options can help tuning allocation performance depending program running. Besides R specific options can set LibTorch options via environment variables described . behavior caching allocator can controlled via environment variable PYTORCH_CUDA_ALLOC_CONF. format PYTORCH_CUDA_ALLOC_CONF=<option>:<value>,<option2><value2>... Available options: max_split_size_mb prevents allocator splitting blocks larger size (MB). can help prevent fragmentation may allow borderline workloads complete without running memory. Performance cost can range ‘zero’ ‘substatial’ depending allocation patterns. Default value unlimited, .e. blocks can split. memory_stats() memory_summary() methods useful tuning. option used last resort workload aborting due ‘memory’ showing large amount inactive split blocks. roundup_power2_divisions helps rounding requested allocation size nearest power-2 division making better use blocks. current CUDACachingAllocator, sizes rounded multiple blocks size 512, works fine smaller sizes. However, can inefficient large near-allocations go different size blocks re-use blocks minimized. might create lots unused blocks waste GPU memory capacity. option enables rounding allocation size nearest power-2 division. example, need round-size 1200 number divisions 4, size 1200 lies 1024 2048 4 divisions , values 1024, 1280, 1536, 1792. , allocation size 1200 rounded 1280 nearest ceiling power-2 division. garbage_collection_threshold helps actively reclaiming unused GPU memory avoid triggering expensive sync--reclaim-operation (release_cached_blocks), can unfavorable latency-critical GPU applications (e.g., servers). Upon setting threshold (e.g., 0.8), allocator start reclaiming GPU memory blocks GPU memory capacity usage exceeds threshold (.e., 80% total memory allocated GPU application). algorithm prefers free old & unused blocks first avoid freeing blocks actively reused. threshold value greater 0.0 less 1.0. Notice garbage collector refered R garbage collector LibTorch’s collector, releases memory cache OS.","code":""},{"path":"https://torch.mlverse.org/docs/articles/memory-management.html","id":"mps","dir":"Articles","previous_headings":"","what":"MPS","title":"Memory management","text":"Memory management MPS devices similar strategy used CUDA devices, except ’s currently configuration tuning possible. R garbage collector called whenever ’s available memory GPU thus, possibly deleting Tensors. Allocation retried fails, OOM error raised.","code":""},{"path":"https://torch.mlverse.org/docs/articles/modifying-source-code.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Modifying torch source code","text":"torch R package composed multiple abstraction layers R code finally calls LibTorch code. Depending part code want modify might need different build requirements setting . special requirements project , ’s always possible use standard devtools tools work torch. guide intended contributors torch codebase quickly get set able modify source code without spending much time understanding internals. torch R package composed following layers, going top : R code calling torch_ functions. R code calling cpp_torch_ functions. Rcpp (C++) code calling lantern_torch_ functions. Lantern (C++) code calling LibTorch functions. Depending function 2, 3 4. might auto-generated (via tools/torchgen) package . next sections explain contribute code depending layer modifying.","code":""},{"path":"https://torch.mlverse.org/docs/articles/modifying-source-code.html","id":"r-source-code","dir":"Articles","previous_headings":"","what":"R source code","title":"Modifying torch source code","text":"Modifying R source code simplest case shouldn’t required contributors tools standard R development toolbox (like RTools Windows C++ compiler MacOS). standard devtools just work . Ie, can clone project GitHub, modify R source code, including documentation run devtools::load_all() first time run devtools::load_all(), torch installation prompt appear LibTorch lantern binaries downloaded installed inside inst directory installation. Subsequent calls work expected. Note loading torch twice without restarting R session causes session crash. Unbfortunatelly don’t know yet fix bug ’s related problems correctly unloading shared libraries. restart session calling devtools::load_all() . Also note functions might call devtools::load_all() internally, like eg. devtools::test() devtools::document(). Also, running Build Check RStudio pane fail, calls Rcpp::CompileAttributes without calling Makevars file instructions, required torch work correctly. use devtools::check() pass argument devtools::check(document=FALSE). reason described .","code":""},{"path":"https://torch.mlverse.org/docs/articles/modifying-source-code.html","id":"documentation","dir":"Articles","previous_headings":"R source code","what":"Documentation","title":"Modifying torch source code","text":"torch registers roxygen2 roclets handle examples sessions roxygen2 documentation. Unfortunately unaware method automatically register roclets without messing DESCRIPTION’s collate field. recommended way update documentation torch using tools/document.R script. can either call source(\"tools/document.R\") , recommended, run: terminal. advantage since devtools::document() called internally calls pkgload::load_all(), won’t crash R session forget restart session (see note ).","code":"Rscript tools/document.R"},{"path":"https://torch.mlverse.org/docs/articles/modifying-source-code.html","id":"rcpp-code","dir":"Articles","previous_headings":"","what":"Rcpp code","title":"Modifying torch source code","text":"Modifying Rcpp source code src similar modifying C++ R packages. pay attention calling lantern_* functions though. lantern_* functions return void* leak referring objects correctly freed use. best way handle always assign variable correct type defined inst/include/torch_types.h specially defined C++ namespace torch {}. use kind objects also gain ability return R without write custom Rcpp code implemented SEXP() operator.","code":""},{"path":"https://torch.mlverse.org/docs/articles/modifying-source-code.html","id":"lantern-code","dir":"Articles","previous_headings":"","what":"Lantern code","title":"Modifying torch source code","text":"order modify Lantern source code first need make sure environment variable BUILD_LANTERN set 1. avoid forgetting set can add .Renviron using, eg usethis::edit_r_environ(). flag trigger configure file call lantern target Makevars. Building lantern requires CMake path. can install CMake major platforms following instructions install page. BUILD_LANTERN=1 run devtools::load_all(), Lantern compiled part workflow. see new directory called build-lantern package directory containing files related Lantern build. Lantern source code located src/lantern/src. lantern CMakeLists file located src/lantern/CMakeLists.txt. can also take look lantern target src/Makevars.get sense CMake commands called building Lantern source. default, rebuilding Lantern incremental, ie, calling devtools::load_all() rebuild modified parts Lantern code. Depending extend modifications Lantern source code might need completely clean build directory, can simply removing build-lantern directory.","code":""},{"path":"https://torch.mlverse.org/docs/articles/python-to-r.html","id":"loading-models-saved-in-python","dir":"Articles","previous_headings":"","what":"Loading models saved in python","title":"Python to R","text":"Currently way load models python rewrite model architecture R. parameter names must identical. complete example Python R shown . extension Serialization vignette. artificial neural net implemented Python. Note final line uses torch.save(). saved .pth object can load R. example use case training model Python using Shiny develop GUI predictions trained model.","code":"import torch import numpy as np  #Make up data  madeUpData_x = np.random.rand(1000,100) madeUpData_y = np.random.rand(1000)  #Convert to categorical madeUpData_y = madeUpData_y.round()  train_py_X = torch.from_numpy(madeUpData_x).float()  train_py_Y = torch.from_numpy(madeUpData_y).float()  #Note that this class must be replicated identically in R class simpleMLP(torch.nn.Module):     def __init__(self):         super(simpleMLP, self).__init__()         self.modelFit = torch.nn.Sequential(             torch.nn.Linear(100,20),             torch.nn.ReLU(),             torch.nn.Linear(20,1),             torch.nn.Sigmoid())                  def forward(self, x):         x =self.modelFit(x)          return x  model = simpleMLP()   def modelTrainer(data_X,data_Y,model):     criterion = torch.nn.BCELoss()     optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)      for epoch in range(100):          optimizer.zero_grad()          yhat = model(data_X)          loss = criterion(yhat,data_Y.unsqueeze(1))          loss.backward()         optimizer.step()  modelTrainer(data_X = train_py_X,data_Y = train_py_Y,model = model)  #----------------------------------------------------------------- #save the model   #Note that model.state_dict() comes out as an ordered dictionary #The code below converts to a dictionary stateDict = dict(model.state_dict())  #Note the argument _use_new_zipfile_serialization torch.save(stateDict,f=\"path/babyTest.pth\",            _use_new_zipfile_serialization=True) library(torch)  #Make up some test data #note that proper installation of torch will yield no errors when we run #this code y <- torch_tensor(array(runif(8),dim = c(2,2,2)),dtype = torch_float64())  #Note the identical names between the Python class definition and our #class definition simpleMLP <- torch::nn_module(   \"simpleMLP\",   initialize = function(){          self$modelFit <- nn_sequential(nn_linear(100,20),                                    nn_relu(),                                    nn_linear(20,1),                                    nn_sigmoid())        },   forward = function(x){     self$modelFit(x)     } )   model <- simpleMLP()  state_dict <- torch::load_state_dict(\"p/babyTest.pth\") model$load_state_dict(state_dict)  #Note that the dtype set in R has to match the made up data from Python #More generally if reading new data into R you must ensure that it matches the  #dtype that the model was trained with in Python newData = torch_tensor(array(rnorm(n=1000),dim=c(10,100)),dtype=torch_float32())  predictMe <- model(newData)"},{"path":"https://torch.mlverse.org/docs/articles/serialization.html","id":"saving-tensors","dir":"Articles","previous_headings":"","what":"Saving tensors","title":"Serialization","text":"can save object type torch_tensor disk using:","code":"x <- torch_randn(10, 10) torch_save(x, \"tensor.pt\") x_ <- torch_load(\"tensor.pt\")  torch_allclose(x, x_) #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/articles/serialization.html","id":"saving-modules","dir":"Articles","previous_headings":"","what":"Saving modules","title":"Serialization","text":"torch_save torch_load functions also work nn_modules objects. saving nn_module, object serialized including model structure ’s state.","code":"module <- nn_module(   \"my_module\",   initialize = function() {     self$fc1 <- nn_linear(10, 10)     self$fc2 <- nn_linear(10, 1)   },   forward = function(x) {     x %>%        self$fc1() %>%        self$fc2()   } )  model <- module() torch_save(model, \"model.pt\") model_ <- torch_load(\"model.pt\")  # input tensor x <- torch_randn(50, 10) torch_allclose(model(x), model_(x)) #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/articles/serialization.html","id":"loading-models-saved-in-python","dir":"Articles","previous_headings":"","what":"Loading models saved in python","title":"Serialization","text":"Currently way load models python rewrite model architecture R. parameter names must identical. can save PyTorch model state_dict using: can reload state dict R reload model : can find working examples torchvision. example AlexNet model.","code":"torch.save(model, fpath, _use_new_zipfile_serialization=True) state_dict <- load_state_dict(fpath) model <- Model() model$load_state_dict(state_dict)"},{"path":"https://torch.mlverse.org/docs/articles/serialization.html","id":"saving-optimizer-state","dir":"Articles","previous_headings":"","what":"Saving optimizer state","title":"Serialization","text":"can save state optimizers can continue training exact position. order use state_dict() load_state_dict() methods optimizer combined torch_save:","code":"model <- nn_linear(1, 1) opt <- optim_adam(model$parameters)  train_x <- torch_randn(100, 1) train_y <- torch_randn(100, 1)  loss <- nnf_mse_loss(model(train_x), train_y) loss$backward() opt$step() #> NULL # Now let's save the optimizer state tmp <- tempfile() torch_save(opt$state_dict(), tmp)  # And now let's create a new optimizer and load back opt2 <- optim_adam(model$parameters) opt2$load_state_dict(torch_load(tmp))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"numpy_t","dir":"Articles > Tensor","previous_headings":"","what":"numpy_T","title":"Tensor objects","text":"Tensor dimensions reversed. n number dimensions x, x$numpy_T() equivalent x$permute(n, n-1, ..., 1).","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"abs","dir":"Articles > Tensor","previous_headings":"","what":"abs","title":"Tensor objects","text":"abs() -> Tensor See ?torch_abs","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"abs_","dir":"Articles > Tensor","previous_headings":"","what":"abs_","title":"Tensor objects","text":"abs_() -> Tensor -place version $abs","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"absolute","dir":"Articles > Tensor","previous_headings":"","what":"absolute","title":"Tensor objects","text":"absolute() -> Tensor Alias [$abs()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"absolute_","dir":"Articles > Tensor","previous_headings":"","what":"absolute_","title":"Tensor objects","text":"absolute_() -> Tensor -place version $absolute Alias [$abs_()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"acos","dir":"Articles > Tensor","previous_headings":"","what":"acos","title":"Tensor objects","text":"acos() -> Tensor See ?torch_acos","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"acos_","dir":"Articles > Tensor","previous_headings":"","what":"acos_","title":"Tensor objects","text":"acos_() -> Tensor -place version $acos","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"acosh","dir":"Articles > Tensor","previous_headings":"","what":"acosh","title":"Tensor objects","text":"acosh() -> Tensor See ?torch_acosh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"acosh_","dir":"Articles > Tensor","previous_headings":"","what":"acosh_","title":"Tensor objects","text":"acosh_() -> Tensor -place version $acosh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"add","dir":"Articles > Tensor","previous_headings":"","what":"add","title":"Tensor objects","text":"add(, *, alpha=1) -> Tensor Add scalar tensor self tensor. alpha specified, element scaled alpha used. tensor, shape must broadcastable shape underlying tensor See ?torch_add","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"add_","dir":"Articles > Tensor","previous_headings":"","what":"add_","title":"Tensor objects","text":"add_(, *, alpha=1) -> Tensor -place version $add","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addbmm","dir":"Articles > Tensor","previous_headings":"","what":"addbmm","title":"Tensor objects","text":"addbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor See ?torch_addbmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addbmm_","dir":"Articles > Tensor","previous_headings":"","what":"addbmm_","title":"Tensor objects","text":"addbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor -place version $addbmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addcdiv","dir":"Articles > Tensor","previous_headings":"","what":"addcdiv","title":"Tensor objects","text":"addcdiv(tensor1, tensor2, *, value=1) -> Tensor See ?torch_addcdiv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addcdiv_","dir":"Articles > Tensor","previous_headings":"","what":"addcdiv_","title":"Tensor objects","text":"addcdiv_(tensor1, tensor2, *, value=1) -> Tensor -place version $addcdiv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addcmul","dir":"Articles > Tensor","previous_headings":"","what":"addcmul","title":"Tensor objects","text":"addcmul(tensor1, tensor2, *, value=1) -> Tensor See ?torch_addcmul","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addcmul_","dir":"Articles > Tensor","previous_headings":"","what":"addcmul_","title":"Tensor objects","text":"addcmul_(tensor1, tensor2, *, value=1) -> Tensor -place version $addcmul","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addmm","dir":"Articles > Tensor","previous_headings":"","what":"addmm","title":"Tensor objects","text":"addmm(mat1, mat2, *, beta=1, alpha=1) -> Tensor See ?torch_addmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addmm_","dir":"Articles > Tensor","previous_headings":"","what":"addmm_","title":"Tensor objects","text":"addmm_(mat1, mat2, *, beta=1, alpha=1) -> Tensor -place version $addmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addmv","dir":"Articles > Tensor","previous_headings":"","what":"addmv","title":"Tensor objects","text":"addmv(mat, vec, *, beta=1, alpha=1) -> Tensor See ?torch_addmv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addmv_","dir":"Articles > Tensor","previous_headings":"","what":"addmv_","title":"Tensor objects","text":"addmv_(mat, vec, *, beta=1, alpha=1) -> Tensor -place version $addmv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addr","dir":"Articles > Tensor","previous_headings":"","what":"addr","title":"Tensor objects","text":"addr(vec1, vec2, *, beta=1, alpha=1) -> Tensor See ?torch_addr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"addr_","dir":"Articles > Tensor","previous_headings":"","what":"addr_","title":"Tensor objects","text":"addr_(vec1, vec2, *, beta=1, alpha=1) -> Tensor -place version $addr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"align_as","dir":"Articles > Tensor","previous_headings":"","what":"align_as","title":"Tensor objects","text":"align_as() -> Tensor Permutes dimensions self tensor match dimension order tensor, adding size-one dims new names. operation useful explicit broadcasting names (see examples). dims self must named order use method. resulting tensor view original tensor. dimension names self must present $names. may contain named dimensions self$names; output tensor size-one dimension new names. align tensor specific order, use $align_to.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples","dir":"Articles > Tensor","previous_headings":"align_as","what":"Examples:","title":"Tensor objects","text":"","code":"# Example 1: Applying a mask mask <- torch_randint(low = 0, high = 2, size = c(127, 128), dtype=torch_bool())$refine_names(c('W', 'H')) imgs <- torch_randn(32, 128, 127, 3, names=c('N', 'H', 'W', 'C')) imgs$masked_fill_(mask$align_as(imgs), 0)  # Example 2: Applying a per-channel-scale scale_channels <- function(input, scale) {   scale <- scale$refine_names(\"C\")   input * scale$align_as(input) }  num_channels <- 3 scale <- torch_randn(num_channels, names='C') imgs <- torch_rand(32, 128, 128, num_channels, names=c('N', 'H', 'W', 'C')) more_imgs = torch_rand(32, num_channels, 128, 128, names=c('N', 'C', 'H', 'W')) videos = torch_randn(3, num_channels, 128, 128, 128, names=c('N', 'C', 'H', 'W', 'D'))  # scale_channels is agnostic to the dimension order of the input scale_channels(imgs, scale) scale_channels(more_imgs, scale) scale_channels(videos, scale)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning","dir":"Articles > Tensor","previous_headings":"align_as","what":"Warning:","title":"Tensor objects","text":"named tensor API experimental subject change.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"align_to","dir":"Articles > Tensor","previous_headings":"","what":"align_to","title":"Tensor objects","text":"Permutes dimensions self tensor match order specified names, adding size-one dims new names. dims self must named order use method. resulting tensor view original tensor. dimension names self must present names. names may contain additional names self$names; output tensor size-one dimension new names.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments","dir":"Articles > Tensor","previous_headings":"align_to","what":"Arguments:","title":"Tensor objects","text":"names (iterable str): desired dimension ordering output tensor. May contain one Ellipsis expanded unmentioned dim names self.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-1","dir":"Articles > Tensor","previous_headings":"align_to > Examples:","what":"Warning:","title":"Tensor objects","text":"named tensor API experimental subject change.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"all","dir":"Articles > Tensor","previous_headings":"","what":"all","title":"Tensor objects","text":"() -> bool Returns TRUE elements tensor TRUE, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-2","dir":"Articles > Tensor","previous_headings":"all","what":"Examples:","title":"Tensor objects","text":"(dim, keepdim=FALSE, =NULL) -> Tensor Returns TRUE elements row tensor given dimension dim TRUE, FALSE otherwise. keepdim TRUE, output tensor size input except dimension dim size 1. Otherwise, dim squeezed (see ?torch_squeeze()), resulting output tensor 1 fewer dimension input.","code":"a <- torch_rand(1, 2)$to(dtype = torch_bool()) a a$all()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-1","dir":"Articles > Tensor","previous_headings":"all","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension reduce keepdim (bool): whether output tensor dim retained (Tensor, optional): output tensor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-3","dir":"Articles > Tensor","previous_headings":"all","what":"Examples:","title":"Tensor objects","text":"","code":"a <- torch_rand(4, 2)$to(dtype = torch_bool()) a a$all(dim=2) a$all(dim=1)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"allclose","dir":"Articles > Tensor","previous_headings":"","what":"allclose","title":"Tensor objects","text":"allclose(, rtol=1e-05, atol=1e-08, equal_nan=FALSE) -> Tensor See ?torch_allclose","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"angle","dir":"Articles > Tensor","previous_headings":"","what":"angle","title":"Tensor objects","text":"angle() -> Tensor See ?torch_angle","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"any","dir":"Articles > Tensor","previous_headings":"","what":"any","title":"Tensor objects","text":"() -> bool Returns TRUE elements tensor TRUE, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-4","dir":"Articles > Tensor","previous_headings":"any","what":"Examples:","title":"Tensor objects","text":"(dim, keepdim=FALSE, =NULL) -> Tensor Returns TRUE elements row tensor given dimension dim TRUE, FALSE otherwise. keepdim TRUE, output tensor size input except dimension dim size 1. Otherwise, dim squeezed (see ?torch_squeeze()), resulting output tensor 1 fewer dimension input.","code":"a <- torch_rand(1, 2)$to(dtype = torch_bool()) a a$any()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-2","dir":"Articles > Tensor","previous_headings":"any","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension reduce keepdim (bool): whether output tensor dim retained (Tensor, optional): output tensor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-5","dir":"Articles > Tensor","previous_headings":"any","what":"Examples:","title":"Tensor objects","text":"","code":"a <- torch_randn(4, 2) < 0 a a$any(2) a$any(1)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"apply_","dir":"Articles > Tensor","previous_headings":"","what":"apply_","title":"Tensor objects","text":"apply_(callable) -> Tensor Applies function callable element tensor, replacing element value returned callable.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note","dir":"Articles > Tensor","previous_headings":"apply_","what":"Note:","title":"Tensor objects","text":"function works CPU tensors used code sections require high performance.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"argmax","dir":"Articles > Tensor","previous_headings":"","what":"argmax","title":"Tensor objects","text":"argmax(dim=NULL, keepdim=FALSE) -> LongTensor See ?torch_argmax","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"argmin","dir":"Articles > Tensor","previous_headings":"","what":"argmin","title":"Tensor objects","text":"argmin(dim=NULL, keepdim=FALSE) -> LongTensor See ?torch_argmin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"argsort","dir":"Articles > Tensor","previous_headings":"","what":"argsort","title":"Tensor objects","text":"argsort(dim=-1, descending=FALSE) -> LongTensor See ?torch_argsort","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"as_strided","dir":"Articles > Tensor","previous_headings":"","what":"as_strided","title":"Tensor objects","text":"as_strided(size, stride, storage_offset=0) -> Tensor See [torch_as_strided()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"as_subclass","dir":"Articles > Tensor","previous_headings":"","what":"as_subclass","title":"Tensor objects","text":"as_subclass(cls) -> Tensor Makes cls instance data pointer self. Changes output mirror changes self, output stays attached autograd graph. cls must subclass Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"asin","dir":"Articles > Tensor","previous_headings":"","what":"asin","title":"Tensor objects","text":"asin() -> Tensor See ?torch_asin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"asin_","dir":"Articles > Tensor","previous_headings":"","what":"asin_","title":"Tensor objects","text":"asin_() -> Tensor -place version $asin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"asinh","dir":"Articles > Tensor","previous_headings":"","what":"asinh","title":"Tensor objects","text":"asinh() -> Tensor See ?torch_asinh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"asinh_","dir":"Articles > Tensor","previous_headings":"","what":"asinh_","title":"Tensor objects","text":"asinh_() -> Tensor -place version $asinh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atan","dir":"Articles > Tensor","previous_headings":"","what":"atan","title":"Tensor objects","text":"atan() -> Tensor See ?torch_atan","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atan2","dir":"Articles > Tensor","previous_headings":"","what":"atan2","title":"Tensor objects","text":"atan2() -> Tensor See [torch_atan2()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atan2_","dir":"Articles > Tensor","previous_headings":"","what":"atan2_","title":"Tensor objects","text":"atan2_() -> Tensor -place version $atan2","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atan_","dir":"Articles > Tensor","previous_headings":"","what":"atan_","title":"Tensor objects","text":"atan_() -> Tensor -place version $atan","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atanh","dir":"Articles > Tensor","previous_headings":"","what":"atanh","title":"Tensor objects","text":"atanh() -> Tensor See ?torch_atanh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"atanh_","dir":"Articles > Tensor","previous_headings":"","what":"atanh_","title":"Tensor objects","text":"-place version $atanh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"backward","dir":"Articles > Tensor","previous_headings":"","what":"backward","title":"Tensor objects","text":"Computes gradient current tensor w.r.t. graph leaves. graph differentiated using chain rule. tensor non-scalar (.e. data one element) requires gradient, function additionally requires specifying gradient. tensor matching type location, contains gradient differentiated function w.r.t. self. function accumulates gradients leaves - might need zero $grad attributes set NULL calling . See Default gradient layouts<default-grad-layouts> details memory layout accumulated gradients.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-3","dir":"Articles > Tensor","previous_headings":"backward","what":"Arguments:","title":"Tensor objects","text":"gradient (Tensor NULL): Gradient w.r.t. tensor. tensor, automatically converted Tensor require grad unless create_graph TRUE. NULL values can specified scalar Tensors ones don’t require grad. NULL value acceptable argument optional. retain_graph (bool, optional): FALSE, graph used compute grads freed. Note nearly cases setting option TRUE needed often can worked around much efficient way. Defaults value create_graph. create_graph (bool, optional): TRUE, graph derivative constructed, allowing compute higher order derivative products. Defaults FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"baddbmm","dir":"Articles > Tensor","previous_headings":"","what":"baddbmm","title":"Tensor objects","text":"baddbmm(batch1, batch2, *, beta=1, alpha=1) -> Tensor See ?torch_baddbmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"baddbmm_","dir":"Articles > Tensor","previous_headings":"","what":"baddbmm_","title":"Tensor objects","text":"baddbmm_(batch1, batch2, *, beta=1, alpha=1) -> Tensor -place version $baddbmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bernoulli","dir":"Articles > Tensor","previous_headings":"","what":"bernoulli","title":"Tensor objects","text":"bernoulli(*, generator=NULL) -> Tensor Returns result tensor \\(\\texttt{result[]}\\) independently sampled \\(\\text{Bernoulli}(\\texttt{self[]})\\). self must floating point dtype, result dtype. See ?torch_bernoulli","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bernoulli_","dir":"Articles > Tensor","previous_headings":"","what":"bernoulli_","title":"Tensor objects","text":"bernoulli_(p=0.5, *, generator=NULL) -> Tensor Fills location self independent sample \\(\\text{Bernoulli}(\\texttt{p})\\). self can integral dtype. bernoulli_(p_tensor, *, generator=NULL) -> Tensor p_tensor tensor containing probabilities used drawing binary random number. \\(\\text{}^{th}\\) element self tensor set value sampled \\(\\text{Bernoulli}(\\texttt{p\\_tensor[]})\\). self can integral dtype, p_tensor must floating point dtype. See also $bernoulli ?torch_bernoulli","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bfloat16","dir":"Articles > Tensor","previous_headings":"","what":"bfloat16","title":"Tensor objects","text":"bfloat16(memory_format=torch_preserve_format) -> Tensor self$bfloat16() equivalent self$(torch_bfloat16). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-4","dir":"Articles > Tensor","previous_headings":"bfloat16","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bincount","dir":"Articles > Tensor","previous_headings":"","what":"bincount","title":"Tensor objects","text":"bincount(weights=NULL, minlength=0) -> Tensor See ?torch_bincount","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_and","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_and","title":"Tensor objects","text":"bitwise_and() -> Tensor See [torch_bitwise_and()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_and_","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_and_","title":"Tensor objects","text":"bitwise_and_() -> Tensor -place version $bitwise_and","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_not","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_not","title":"Tensor objects","text":"bitwise_not() -> Tensor See [torch_bitwise_not()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_not_","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_not_","title":"Tensor objects","text":"bitwise_not_() -> Tensor -place version $bitwise_not","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_or","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_or","title":"Tensor objects","text":"bitwise_or() -> Tensor See [torch_bitwise_or()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_or_","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_or_","title":"Tensor objects","text":"bitwise_or_() -> Tensor -place version $bitwise_or","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_xor","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_xor","title":"Tensor objects","text":"bitwise_xor() -> Tensor See [torch_bitwise_xor()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bitwise_xor_","dir":"Articles > Tensor","previous_headings":"","what":"bitwise_xor_","title":"Tensor objects","text":"bitwise_xor_() -> Tensor -place version $bitwise_xor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bmm","dir":"Articles > Tensor","previous_headings":"","what":"bmm","title":"Tensor objects","text":"bmm(batch2) -> Tensor See ?torch_bmm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"bool","dir":"Articles > Tensor","previous_headings":"","what":"bool","title":"Tensor objects","text":"bool(memory_format=torch_preserve_format) -> Tensor self$bool() equivalent self$(torch_bool). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-5","dir":"Articles > Tensor","previous_headings":"bool","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"byte","dir":"Articles > Tensor","previous_headings":"","what":"byte","title":"Tensor objects","text":"byte(memory_format=torch_preserve_format) -> Tensor self$byte() equivalent self$(torch_uint8). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-6","dir":"Articles > Tensor","previous_headings":"byte","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cauchy_","dir":"Articles > Tensor","previous_headings":"","what":"cauchy_","title":"Tensor objects","text":"cauchy_(median=0, sigma=1, *, generator=NULL) -> Tensor Fills tensor numbers drawn Cauchy distribution: \\[ f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2} \\]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ceil","dir":"Articles > Tensor","previous_headings":"","what":"ceil","title":"Tensor objects","text":"ceil() -> Tensor See ?torch_ceil","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ceil_","dir":"Articles > Tensor","previous_headings":"","what":"ceil_","title":"Tensor objects","text":"ceil_() -> Tensor -place version $ceil","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"char","dir":"Articles > Tensor","previous_headings":"","what":"char","title":"Tensor objects","text":"char(memory_format=torch_preserve_format) -> Tensor self$char() equivalent self$(torch_int8). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-7","dir":"Articles > Tensor","previous_headings":"char","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cholesky","dir":"Articles > Tensor","previous_headings":"","what":"cholesky","title":"Tensor objects","text":"cholesky(upper=FALSE) -> Tensor See ?torch_cholesky","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cholesky_inverse","dir":"Articles > Tensor","previous_headings":"","what":"cholesky_inverse","title":"Tensor objects","text":"cholesky_inverse(upper=FALSE) -> Tensor See [torch_cholesky_inverse()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cholesky_solve","dir":"Articles > Tensor","previous_headings":"","what":"cholesky_solve","title":"Tensor objects","text":"cholesky_solve(input2, upper=FALSE) -> Tensor See [torch_cholesky_solve()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"chunk","dir":"Articles > Tensor","previous_headings":"","what":"chunk","title":"Tensor objects","text":"chunk(chunks, dim=0) -> List Tensors See ?torch_chunk","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"clamp","dir":"Articles > Tensor","previous_headings":"","what":"clamp","title":"Tensor objects","text":"clamp(min, max) -> Tensor See ?torch_clamp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"clamp_","dir":"Articles > Tensor","previous_headings":"","what":"clamp_","title":"Tensor objects","text":"clamp_(min, max) -> Tensor -place version $clamp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"clone","dir":"Articles > Tensor","previous_headings":"","what":"clone","title":"Tensor objects","text":"clone(memory_format=torch_preserve_format()) -> Tensor Returns copy self tensor. copy size data type self.","code":"x <- torch_tensor(1) y <- x$clone()  x$add_(1) y"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-1","dir":"Articles > Tensor","previous_headings":"clone","what":"Note:","title":"Tensor objects","text":"Unlike copy_(), function recorded computation graph. Gradients propagating cloned tensor propagate original tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-8","dir":"Articles > Tensor","previous_headings":"clone","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"conj","dir":"Articles > Tensor","previous_headings":"","what":"conj","title":"Tensor objects","text":"conj() -> Tensor See ?torch_conj","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"contiguous","dir":"Articles > Tensor","previous_headings":"","what":"contiguous","title":"Tensor objects","text":"contiguous(memory_format=torch_contiguous_format) -> Tensor Returns contiguous memory tensor containing data self tensor. self tensor already specified memory format, function returns self tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-9","dir":"Articles > Tensor","previous_headings":"contiguous","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_contiguous_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"copy_","dir":"Articles > Tensor","previous_headings":"","what":"copy_","title":"Tensor objects","text":"copy_(src, non_blocking=FALSE) -> Tensor Copies elements src self tensor returns self. src tensor must broadcastable self tensor. may different data type reside different device.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-10","dir":"Articles > Tensor","previous_headings":"copy_","what":"Arguments:","title":"Tensor objects","text":"src (Tensor): source tensor copy non_blocking (bool): TRUE copy CPU GPU, copy may occur asynchronously respect host. cases, argument effect.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cos","dir":"Articles > Tensor","previous_headings":"","what":"cos","title":"Tensor objects","text":"cos() -> Tensor See ?torch_cos","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cos_","dir":"Articles > Tensor","previous_headings":"","what":"cos_","title":"Tensor objects","text":"cos_() -> Tensor -place version $cos","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cosh","dir":"Articles > Tensor","previous_headings":"","what":"cosh","title":"Tensor objects","text":"cosh() -> Tensor See ?torch_cosh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cosh_","dir":"Articles > Tensor","previous_headings":"","what":"cosh_","title":"Tensor objects","text":"cosh_() -> Tensor -place version $cosh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cpu","dir":"Articles > Tensor","previous_headings":"","what":"cpu","title":"Tensor objects","text":"cpu(memory_format=torch_preserve_format) -> Tensor Returns copy object CPU memory. object already CPU memory correct device, copy performed original object returned.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-11","dir":"Articles > Tensor","previous_headings":"cpu","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cross","dir":"Articles > Tensor","previous_headings":"","what":"cross","title":"Tensor objects","text":"cross(, dim=-1) -> Tensor See ?torch_cross","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cuda","dir":"Articles > Tensor","previous_headings":"","what":"cuda","title":"Tensor objects","text":"cuda(device=NULL, non_blocking=FALSE, memory_format=torch_preserve_format) -> Tensor Returns copy object CUDA memory. object already CUDA memory correct device, copy performed original object returned.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-12","dir":"Articles > Tensor","previous_headings":"cuda","what":"Arguments:","title":"Tensor objects","text":"device (torch_device): destination GPU device. Defaults current CUDA device. non_blocking (bool): TRUE source pinned memory, copy asynchronous respect host. Otherwise, argument effect. Default: FALSE. memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cummax","dir":"Articles > Tensor","previous_headings":"","what":"cummax","title":"Tensor objects","text":"cummax(dim) -> (Tensor, Tensor) See ?torch_cummax","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cummin","dir":"Articles > Tensor","previous_headings":"","what":"cummin","title":"Tensor objects","text":"cummin(dim) -> (Tensor, Tensor) See ?torch_cummin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cumprod","dir":"Articles > Tensor","previous_headings":"","what":"cumprod","title":"Tensor objects","text":"cumprod(dim, dtype=NULL) -> Tensor See ?torch_cumprod","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"cumsum","dir":"Articles > Tensor","previous_headings":"","what":"cumsum","title":"Tensor objects","text":"cumsum(dim, dtype=NULL) -> Tensor See ?torch_cumsum","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"data_ptr","dir":"Articles > Tensor","previous_headings":"","what":"data_ptr","title":"Tensor objects","text":"data_ptr() -> int Returns address first element self tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"deg2rad","dir":"Articles > Tensor","previous_headings":"","what":"deg2rad","title":"Tensor objects","text":"deg2rad() -> Tensor See [torch_deg2rad()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"deg2rad_","dir":"Articles > Tensor","previous_headings":"","what":"deg2rad_","title":"Tensor objects","text":"deg2rad_() -> Tensor -place version $deg2rad","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"dense_dim","dir":"Articles > Tensor","previous_headings":"","what":"dense_dim","title":"Tensor objects","text":"dense_dim() -> int self sparse COO tensor (.e., torch_sparse_coo layout), returns number dense dimensions. Otherwise, throws error. See also $sparse_dim.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"dequantize","dir":"Articles > Tensor","previous_headings":"","what":"dequantize","title":"Tensor objects","text":"dequantize() -> Tensor Given quantized Tensor, dequantize return dequantized float Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"det","dir":"Articles > Tensor","previous_headings":"","what":"det","title":"Tensor objects","text":"det() -> Tensor See ?torch_det","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"detach","dir":"Articles > Tensor","previous_headings":"","what":"detach","title":"Tensor objects","text":"Returns new Tensor, detached current graph. result never require gradient.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-2","dir":"Articles > Tensor","previous_headings":"detach","what":"Note:","title":"Tensor objects","text":"Returned Tensor shares storage original one. -place modifications either seen, may trigger errors correctness checks. IMPORTANT NOTE: Previously, -place size / stride / storage changes (resize_ / resize_as_ / set_ / transpose_) returned tensor also update original tensor. Now, -place changes update original tensor anymore, instead trigger error. sparse tensors: -place indices / values changes (zero_ / copy_ / add_) returned tensor update original tensor anymore, instead trigger error.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"detach_","dir":"Articles > Tensor","previous_headings":"","what":"detach_","title":"Tensor objects","text":"Detaches Tensor graph created , making leaf. Views detached -place.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"device","dir":"Articles > Tensor","previous_headings":"","what":"device","title":"Tensor objects","text":"torch_device Tensor .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"diag","dir":"Articles > Tensor","previous_headings":"","what":"diag","title":"Tensor objects","text":"diag(diagonal=0) -> Tensor See ?torch_diag","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"diag_embed","dir":"Articles > Tensor","previous_headings":"","what":"diag_embed","title":"Tensor objects","text":"diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor See [torch_diag_embed()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"diagflat","dir":"Articles > Tensor","previous_headings":"","what":"diagflat","title":"Tensor objects","text":"diagflat(offset=0) -> Tensor See ?torch_diagflat","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"diagonal","dir":"Articles > Tensor","previous_headings":"","what":"diagonal","title":"Tensor objects","text":"diagonal(offset=0, dim1=0, dim2=1) -> Tensor See ?torch_diagonal","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"digamma","dir":"Articles > Tensor","previous_headings":"","what":"digamma","title":"Tensor objects","text":"digamma() -> Tensor See ?torch_digamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"digamma_","dir":"Articles > Tensor","previous_headings":"","what":"digamma_","title":"Tensor objects","text":"digamma_() -> Tensor -place version $digamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"dim","dir":"Articles > Tensor","previous_headings":"","what":"dim","title":"Tensor objects","text":"dim() -> int Returns number dimensions self tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"dist","dir":"Articles > Tensor","previous_headings":"","what":"dist","title":"Tensor objects","text":"dist(, p=2) -> Tensor See ?torch_dist","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"div","dir":"Articles > Tensor","previous_headings":"","what":"div","title":"Tensor objects","text":"div(value) -> Tensor See ?torch_div","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"div_","dir":"Articles > Tensor","previous_headings":"","what":"div_","title":"Tensor objects","text":"div_(value) -> Tensor -place version $div","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"dot","dir":"Articles > Tensor","previous_headings":"","what":"dot","title":"Tensor objects","text":"dot(tensor2) -> Tensor See ?torch_dot","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"double","dir":"Articles > Tensor","previous_headings":"","what":"double","title":"Tensor objects","text":"double(memory_format=torch_preserve_format) -> Tensor self$double() equivalent self$(torch_float64). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-13","dir":"Articles > Tensor","previous_headings":"double","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"eig","dir":"Articles > Tensor","previous_headings":"","what":"eig","title":"Tensor objects","text":"eig(eigenvectors=FALSE) -> (Tensor, Tensor) See ?torch_eig","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"element_size","dir":"Articles > Tensor","previous_headings":"","what":"element_size","title":"Tensor objects","text":"element_size() -> int Returns size bytes individual element.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-6","dir":"Articles > Tensor","previous_headings":"element_size","what":"Examples:","title":"Tensor objects","text":"","code":"torch_tensor(c(1))$element_size()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"eq","dir":"Articles > Tensor","previous_headings":"","what":"eq","title":"Tensor objects","text":"eq() -> Tensor See ?torch_eq","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"eq_","dir":"Articles > Tensor","previous_headings":"","what":"eq_","title":"Tensor objects","text":"eq_() -> Tensor -place version $eq","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"equal","dir":"Articles > Tensor","previous_headings":"","what":"equal","title":"Tensor objects","text":"equal() -> bool See ?torch_equal","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erf","dir":"Articles > Tensor","previous_headings":"","what":"erf","title":"Tensor objects","text":"erf() -> Tensor See ?torch_erf","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erf_","dir":"Articles > Tensor","previous_headings":"","what":"erf_","title":"Tensor objects","text":"erf_() -> Tensor -place version $erf","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erfc","dir":"Articles > Tensor","previous_headings":"","what":"erfc","title":"Tensor objects","text":"erfc() -> Tensor See ?torch_erfc","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erfc_","dir":"Articles > Tensor","previous_headings":"","what":"erfc_","title":"Tensor objects","text":"erfc_() -> Tensor -place version $erfc","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erfinv","dir":"Articles > Tensor","previous_headings":"","what":"erfinv","title":"Tensor objects","text":"erfinv() -> Tensor See ?torch_erfinv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"erfinv_","dir":"Articles > Tensor","previous_headings":"","what":"erfinv_","title":"Tensor objects","text":"erfinv_() -> Tensor -place version $erfinv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"exp","dir":"Articles > Tensor","previous_headings":"","what":"exp","title":"Tensor objects","text":"exp() -> Tensor See ?torch_exp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"exp_","dir":"Articles > Tensor","previous_headings":"","what":"exp_","title":"Tensor objects","text":"exp_() -> Tensor -place version $exp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"expand","dir":"Articles > Tensor","previous_headings":"","what":"expand","title":"Tensor objects","text":"expand(*sizes) -> Tensor Returns new view self tensor singleton dimensions expanded larger size. Passing -1 size dimension means changing size dimension. Tensor can also expanded larger number dimensions, new ones appended front. new dimensions, size set -1. Expanding tensor allocate new memory, creates new view existing tensor dimension size one expanded larger size setting stride 0. dimension size 1 can expanded arbitrary value without allocating new memory.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-14","dir":"Articles > Tensor","previous_headings":"expand","what":"Arguments:","title":"Tensor objects","text":"sizes (torch_Size int…): desired expanded size","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-2","dir":"Articles > Tensor","previous_headings":"expand","what":"Warning:","title":"Tensor objects","text":"one element expanded tensor may refer single memory location. result, -place operations (especially ones vectorized) may result incorrect behavior. need write tensors, please clone first.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-7","dir":"Articles > Tensor","previous_headings":"expand","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(matrix(c(1,2,3), ncol = 1)) x$size() x$expand(c(3, 4)) x$expand(c(-1, 4))  # -1 means not changing the size of that dimension"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"expand_as","dir":"Articles > Tensor","previous_headings":"","what":"expand_as","title":"Tensor objects","text":"expand_as() -> Tensor Expand tensor size . self$expand_as() equivalent self$expand(.size()). Please see $expand information expand.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-15","dir":"Articles > Tensor","previous_headings":"expand_as","what":"Arguments:","title":"Tensor objects","text":"(`$): result tensor size .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"expm1","dir":"Articles > Tensor","previous_headings":"","what":"expm1","title":"Tensor objects","text":"expm1() -> Tensor See [torch_expm1()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"expm1_","dir":"Articles > Tensor","previous_headings":"","what":"expm1_","title":"Tensor objects","text":"expm1_() -> Tensor -place version $expm1","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"exponential_","dir":"Articles > Tensor","previous_headings":"","what":"exponential_","title":"Tensor objects","text":"exponential_(lambd=1, *, generator=NULL) -> Tensor Fills self tensor elements drawn exponential distribution: \\[ f(x) = \\lambda e^{-\\lambda x} \\]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fft","dir":"Articles > Tensor","previous_headings":"","what":"fft","title":"Tensor objects","text":"fft(signal_ndim, normalized=FALSE) -> Tensor See ?torch_fft","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fill_","dir":"Articles > Tensor","previous_headings":"","what":"fill_","title":"Tensor objects","text":"fill_(value) -> Tensor Fills self tensor specified value.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fill_diagonal_","dir":"Articles > Tensor","previous_headings":"","what":"fill_diagonal_","title":"Tensor objects","text":"fill_diagonal_(fill_value, wrap=FALSE) -> Tensor Fill main diagonal tensor least 2-dimensions. dims>2, dimensions input must equal length. function modifies input tensor -place, returns input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-16","dir":"Articles > Tensor","previous_headings":"fill_diagonal_","what":"Arguments:","title":"Tensor objects","text":"fill_value (Scalar): fill value wrap (bool): diagonal ‘wrapped’ N columns tall matrices.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-8","dir":"Articles > Tensor","previous_headings":"fill_diagonal_","what":"Examples:","title":"Tensor objects","text":"","code":"a <- torch_zeros(3, 3) a$fill_diagonal_(5) b <- torch_zeros(7, 3) b$fill_diagonal_(5) c <- torch_zeros(7, 3) c$fill_diagonal_(5, wrap=TRUE)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"flatten","dir":"Articles > Tensor","previous_headings":"","what":"flatten","title":"Tensor objects","text":"flatten(input, start_dim=0, end_dim=-1) -> Tensor see ?torch_flatten","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"flip","dir":"Articles > Tensor","previous_headings":"","what":"flip","title":"Tensor objects","text":"flip(dims) -> Tensor See ?torch_flip","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fliplr","dir":"Articles > Tensor","previous_headings":"","what":"fliplr","title":"Tensor objects","text":"fliplr() -> Tensor See ?torch_fliplr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"flipud","dir":"Articles > Tensor","previous_headings":"","what":"flipud","title":"Tensor objects","text":"flipud() -> Tensor See ?torch_flipud","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"float","dir":"Articles > Tensor","previous_headings":"","what":"float","title":"Tensor objects","text":"float(memory_format=torch_preserve_format) -> Tensor self$float() equivalent self$(torch_float32). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-17","dir":"Articles > Tensor","previous_headings":"float","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"floor","dir":"Articles > Tensor","previous_headings":"","what":"floor","title":"Tensor objects","text":"floor() -> Tensor See ?torch_floor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"floor_","dir":"Articles > Tensor","previous_headings":"","what":"floor_","title":"Tensor objects","text":"floor_() -> Tensor -place version $floor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"floor_divide","dir":"Articles > Tensor","previous_headings":"","what":"floor_divide","title":"Tensor objects","text":"floor_divide(value) -> Tensor See [torch_floor_divide()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"floor_divide_","dir":"Articles > Tensor","previous_headings":"","what":"floor_divide_","title":"Tensor objects","text":"floor_divide_(value) -> Tensor -place version $floor_divide","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fmod","dir":"Articles > Tensor","previous_headings":"","what":"fmod","title":"Tensor objects","text":"fmod(divisor) -> Tensor See ?torch_fmod","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"fmod_","dir":"Articles > Tensor","previous_headings":"","what":"fmod_","title":"Tensor objects","text":"fmod_(divisor) -> Tensor -place version $fmod","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"frac","dir":"Articles > Tensor","previous_headings":"","what":"frac","title":"Tensor objects","text":"frac() -> Tensor See ?torch_frac","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"frac_","dir":"Articles > Tensor","previous_headings":"","what":"frac_","title":"Tensor objects","text":"frac_() -> Tensor -place version $frac","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"gather","dir":"Articles > Tensor","previous_headings":"","what":"gather","title":"Tensor objects","text":"gather(dim, index) -> Tensor See ?torch_gather","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ge","dir":"Articles > Tensor","previous_headings":"","what":"ge","title":"Tensor objects","text":"ge() -> Tensor See ?torch_ge","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ge_","dir":"Articles > Tensor","previous_headings":"","what":"ge_","title":"Tensor objects","text":"ge_() -> Tensor -place version $ge","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"geometric_","dir":"Articles > Tensor","previous_headings":"","what":"geometric_","title":"Tensor objects","text":"geometric_(p, *, generator=NULL) -> Tensor Fills self tensor elements drawn geometric distribution: \\[ f(X=k) = p^{k - 1} (1 - p) \\]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"geqrf","dir":"Articles > Tensor","previous_headings":"","what":"geqrf","title":"Tensor objects","text":"geqrf() -> (Tensor, Tensor) See ?torch_geqrf","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ger","dir":"Articles > Tensor","previous_headings":"","what":"ger","title":"Tensor objects","text":"ger(vec2) -> Tensor See ?torch_ger","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"get_device","dir":"Articles > Tensor","previous_headings":"","what":"get_device","title":"Tensor objects","text":"get_device() -> Device ordinal (Integer) CUDA tensors, function returns device ordinal GPU tensor resides. CPU tensors, error thrown.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-9","dir":"Articles > Tensor","previous_headings":"get_device","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_randn(3, 4, 5, device='cuda:0') x$get_device() x$cpu()$get_device()  # RuntimeError: get_device is not implemented for type torch_FloatTensor"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"grad","dir":"Articles > Tensor","previous_headings":"","what":"grad","title":"Tensor objects","text":"attribute NULL default becomes Tensor first time call backward computes gradients self. attribute contain gradients computed future calls [backward()] accumulate (add) gradients .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"gt","dir":"Articles > Tensor","previous_headings":"","what":"gt","title":"Tensor objects","text":"gt() -> Tensor See ?torch_gt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"gt_","dir":"Articles > Tensor","previous_headings":"","what":"gt_","title":"Tensor objects","text":"gt_() -> Tensor -place version $gt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"half","dir":"Articles > Tensor","previous_headings":"","what":"half","title":"Tensor objects","text":"half(memory_format=torch_preserve_format) -> Tensor self$half() equivalent self$(torch_float16). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-18","dir":"Articles > Tensor","previous_headings":"half","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"hardshrink","dir":"Articles > Tensor","previous_headings":"","what":"hardshrink","title":"Tensor objects","text":"hardshrink(lambd=0.5) -> Tensor See [torch_nn.functional.hardshrink()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"has_names","dir":"Articles > Tensor","previous_headings":"","what":"has_names","title":"Tensor objects","text":"TRUE tensor’s dimensions named. Otherwise, FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"histc","dir":"Articles > Tensor","previous_headings":"","what":"histc","title":"Tensor objects","text":"histc(bins=100, min=0, max=0) -> Tensor See ?torch_histc","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ifft","dir":"Articles > Tensor","previous_headings":"","what":"ifft","title":"Tensor objects","text":"ifft(signal_ndim, normalized=FALSE) -> Tensor See ?torch_ifft","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"imag","dir":"Articles > Tensor","previous_headings":"","what":"imag","title":"Tensor objects","text":"Returns new tensor containing imaginary values self tensor. returned tensor self share underlying storage.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-3","dir":"Articles > Tensor","previous_headings":"imag","what":"Warning:","title":"Tensor objects","text":"[imag()] supported tensors complex dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-10","dir":"Articles > Tensor","previous_headings":"imag","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_randn(4, dtype=torch_cfloat()) x x$imag"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_add","dir":"Articles > Tensor","previous_headings":"","what":"index_add","title":"Tensor objects","text":"index_add(tensor1, dim, index, tensor2) -> Tensor --place version $index_add_. tensor1 corresponds self $index_add_.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_add_","dir":"Articles > Tensor","previous_headings":"","what":"index_add_","title":"Tensor objects","text":"index_add_(dim, index, tensor) -> Tensor Accumulate elements tensor self tensor adding indices order given index. example, dim == 0 index[] == j,  th row tensor added j th row self. dim th dimension tensor must size length index (must vector), dimensions must match self, error raised.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-3","dir":"Articles > Tensor","previous_headings":"index_add_","what":"Note:","title":"Tensor objects","text":"circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch_backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-19","dir":"Articles > Tensor","previous_headings":"index_add_","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension along index index (LongTensor): indices tensor select tensor (Tensor): tensor containing values add","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-11","dir":"Articles > Tensor","previous_headings":"index_add_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_ones(5, 3) t <- torch_tensor(matrix(1:9, ncol = 3), dtype=torch_float()) index <- torch_tensor(c(1L, 4L, 3L)) x$index_add_(1, index, t)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_copy","dir":"Articles > Tensor","previous_headings":"","what":"index_copy","title":"Tensor objects","text":"index_copy(tensor1, dim, index, tensor2) -> Tensor --place version $index_copy_. tensor1 corresponds self $index_copy_.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_copy_","dir":"Articles > Tensor","previous_headings":"","what":"index_copy_","title":"Tensor objects","text":"index_copy_(dim, index, tensor) -> Tensor Copies elements tensor self tensor selecting indices order given index. example, dim == 0 index[] == j,  th row tensor copied j th row self. dim th dimension tensor must size length index (must vector), dimensions must match self, error raised.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-20","dir":"Articles > Tensor","previous_headings":"index_copy_","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension along index index (LongTensor): indices tensor select tensor (Tensor): tensor containing values copy","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-12","dir":"Articles > Tensor","previous_headings":"index_copy_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_zeros(5, 3) t <- torch_tensor(matrix(1:9, ncol = 3), dtype=torch_float()) index <- torch_tensor(c(1, 5, 3)) x$index_copy_(1, index, t)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_fill","dir":"Articles > Tensor","previous_headings":"","what":"index_fill","title":"Tensor objects","text":"index_fill(tensor1, dim, index, value) -> Tensor --place version $index_fill_. tensor1 corresponds self $index_fill_.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_fill_","dir":"Articles > Tensor","previous_headings":"","what":"index_fill_","title":"Tensor objects","text":"index_fill_(dim, index, val) -> Tensor Fills elements self tensor value val selecting indices order given index.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-21","dir":"Articles > Tensor","previous_headings":"index_fill_","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension along index index (LongTensor): indices self tensor fill val (float): value fill ","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-13","dir":"Articles > Tensor","previous_headings":"index_fill_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(matrix(1:9, ncol = 3), dtype=torch_float()) index <- torch_tensor(c(1, 3), dtype = torch_long()) x$index_fill_(1, index, -1)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_put","dir":"Articles > Tensor","previous_headings":"","what":"index_put","title":"Tensor objects","text":"index_put(tensor1, indices, value, accumulate=FALSE) -> Tensor -place version $index_put_. tensor1 corresponds self $index_put_.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_put_","dir":"Articles > Tensor","previous_headings":"","what":"index_put_","title":"Tensor objects","text":"index_put_(indices, value, accumulate=FALSE) -> Tensor Puts values tensor value tensor self using indices specified indices (tuple Tensors). expression tensor.index_put_(indices, value) equivalent tensor[indices] = value. Returns self. accumulate TRUE, elements value added self. accumulate FALSE, behavior undefined indices contain duplicate elements.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-22","dir":"Articles > Tensor","previous_headings":"index_put_","what":"Arguments:","title":"Tensor objects","text":"indices (tuple LongTensor): tensors used index self. value (Tensor): tensor dtype self. accumulate (bool): whether accumulate self","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"index_select","dir":"Articles > Tensor","previous_headings":"","what":"index_select","title":"Tensor objects","text":"index_select(dim, index) -> Tensor See [torch_index_select()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"indices","dir":"Articles > Tensor","previous_headings":"","what":"indices","title":"Tensor objects","text":"indices() -> Tensor self sparse COO tensor (.e., torch_sparse_coo layout), returns view contained indices tensor. Otherwise, throws error. See also Tensor.values.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-4","dir":"Articles > Tensor","previous_headings":"indices","what":"Note:","title":"Tensor objects","text":"method can called coalesced sparse tensor. See Tensor.coalesce details.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"int","dir":"Articles > Tensor","previous_headings":"","what":"int","title":"Tensor objects","text":"int(memory_format=torch_preserve_format) -> Tensor self$int() equivalent self$(torch_int32). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-23","dir":"Articles > Tensor","previous_headings":"int","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"int_repr","dir":"Articles > Tensor","previous_headings":"","what":"int_repr","title":"Tensor objects","text":"int_repr() -> Tensor Given quantized Tensor, self$int_repr() returns CPU Tensor uint8_t data type stores underlying uint8_t values given Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"inverse","dir":"Articles > Tensor","previous_headings":"","what":"inverse","title":"Tensor objects","text":"inverse() -> Tensor See ?torch_inverse","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"irfft","dir":"Articles > Tensor","previous_headings":"","what":"irfft","title":"Tensor objects","text":"irfft(signal_ndim, normalized=FALSE, onesided=TRUE, signal_sizes=NULL) -> Tensor See ?torch_irfft","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_complex","dir":"Articles > Tensor","previous_headings":"","what":"is_complex","title":"Tensor objects","text":"is_complex() -> bool Returns TRUE data type self complex data type.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_contiguous","dir":"Articles > Tensor","previous_headings":"","what":"is_contiguous","title":"Tensor objects","text":"is_contiguous(memory_format=torch_contiguous_format) -> bool Returns TRUE self tensor contiguous memory order specified memory format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-24","dir":"Articles > Tensor","previous_headings":"is_contiguous","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): Specifies memory allocation order. Default: torch_contiguous_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_cuda","dir":"Articles > Tensor","previous_headings":"","what":"is_cuda","title":"Tensor objects","text":"TRUE Tensor stored GPU, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_floating_point","dir":"Articles > Tensor","previous_headings":"","what":"is_floating_point","title":"Tensor objects","text":"is_floating_point() -> bool Returns TRUE data type self floating point data type.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_leaf","dir":"Articles > Tensor","previous_headings":"","what":"is_leaf","title":"Tensor objects","text":"Tensors requires_grad FALSE leaf Tensors convention. Tensors requires_grad TRUE, leaf Tensors created user. means result operation grad_fn NULL. leaf Tensors grad populated call [backward()]. get grad populated non-leaf Tensors, can use [retain_grad()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-14","dir":"Articles > Tensor","previous_headings":"is_leaf","what":"Examples:","title":"Tensor objects","text":"","code":"a <- torch_rand(10, requires_grad=TRUE) a$is_leaf  # b <- torch_rand(10, requires_grad=TRUE)$cuda() # b$is_leaf() # FALSE # b was created by the operation that cast a cpu Tensor into a cuda Tensor  c <- torch_rand(10, requires_grad=TRUE) + 2 c$is_leaf # c was created by the addition operation  # d <- torch_rand(10)$cuda() # d$is_leaf() # TRUE # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)  # e <- torch_rand(10)$cuda()$requires_grad_() # e$is_leaf() # TRUE # e requires gradients and has no operations creating it  # f <- torch_rand(10, requires_grad=TRUE, device=\"cuda\") # f$is_leaf # TRUE # f requires grad, has no operation creating it"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_meta","dir":"Articles > Tensor","previous_headings":"","what":"is_meta","title":"Tensor objects","text":"TRUE Tensor meta tensor, FALSE otherwise. Meta tensors like normal tensors, carry data.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_pinned","dir":"Articles > Tensor","previous_headings":"","what":"is_pinned","title":"Tensor objects","text":"Returns true tensor resides pinned memory.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_quantized","dir":"Articles > Tensor","previous_headings":"","what":"is_quantized","title":"Tensor objects","text":"TRUE Tensor quantized, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_set_to","dir":"Articles > Tensor","previous_headings":"","what":"is_set_to","title":"Tensor objects","text":"is_set_to(tensor) -> bool Returns TRUE object refers THTensor object Torch C API given tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_shared","dir":"Articles > Tensor","previous_headings":"","what":"is_shared","title":"Tensor objects","text":"Checks tensor shared memory. always TRUE CUDA tensors.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"is_signed","dir":"Articles > Tensor","previous_headings":"","what":"is_signed","title":"Tensor objects","text":"is_signed() -> bool Returns TRUE data type self signed data type.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"isclose","dir":"Articles > Tensor","previous_headings":"","what":"isclose","title":"Tensor objects","text":"isclose(, rtol=1e-05, atol=1e-08, equal_nan=FALSE) -> Tensor See ?torch_isclose","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"isfinite","dir":"Articles > Tensor","previous_headings":"","what":"isfinite","title":"Tensor objects","text":"isfinite() -> Tensor See ?torch_isfinite","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"isinf","dir":"Articles > Tensor","previous_headings":"","what":"isinf","title":"Tensor objects","text":"isinf() -> Tensor See ?torch_isinf","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"isnan","dir":"Articles > Tensor","previous_headings":"","what":"isnan","title":"Tensor objects","text":"isnan() -> Tensor See ?torch_isnan","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"istft","dir":"Articles > Tensor","previous_headings":"","what":"istft","title":"Tensor objects","text":"See ?torch_istft ## item item() -> number Returns value tensor standard Python number. works tensors one element. cases, see $tolist. operation differentiable.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-15","dir":"Articles > Tensor","previous_headings":"istft","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(1.0) x$item()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"kthvalue","dir":"Articles > Tensor","previous_headings":"","what":"kthvalue","title":"Tensor objects","text":"kthvalue(k, dim=NULL, keepdim=FALSE) -> (Tensor, LongTensor) See ?torch_kthvalue","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"le","dir":"Articles > Tensor","previous_headings":"","what":"le","title":"Tensor objects","text":"le() -> Tensor See ?torch_le","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"le_","dir":"Articles > Tensor","previous_headings":"","what":"le_","title":"Tensor objects","text":"le_() -> Tensor -place version $le","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lerp","dir":"Articles > Tensor","previous_headings":"","what":"lerp","title":"Tensor objects","text":"lerp(end, weight) -> Tensor See ?torch_lerp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lerp_","dir":"Articles > Tensor","previous_headings":"","what":"lerp_","title":"Tensor objects","text":"lerp_(end, weight) -> Tensor -place version $lerp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lgamma","dir":"Articles > Tensor","previous_headings":"","what":"lgamma","title":"Tensor objects","text":"lgamma() -> Tensor See ?torch_lgamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lgamma_","dir":"Articles > Tensor","previous_headings":"","what":"lgamma_","title":"Tensor objects","text":"lgamma_() -> Tensor -place version $lgamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log","dir":"Articles > Tensor","previous_headings":"","what":"log","title":"Tensor objects","text":"log() -> Tensor See ?torch_log","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log10","dir":"Articles > Tensor","previous_headings":"","what":"log10","title":"Tensor objects","text":"log10() -> Tensor See [torch_log10()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log10_","dir":"Articles > Tensor","previous_headings":"","what":"log10_","title":"Tensor objects","text":"log10_() -> Tensor -place version $log10","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log1p","dir":"Articles > Tensor","previous_headings":"","what":"log1p","title":"Tensor objects","text":"log1p() -> Tensor See [torch_log1p()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log1p_","dir":"Articles > Tensor","previous_headings":"","what":"log1p_","title":"Tensor objects","text":"log1p_() -> Tensor -place version $log1p","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log2","dir":"Articles > Tensor","previous_headings":"","what":"log2","title":"Tensor objects","text":"log2() -> Tensor See [torch_log2()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log2_","dir":"Articles > Tensor","previous_headings":"","what":"log2_","title":"Tensor objects","text":"log2_() -> Tensor -place version $log2","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log_","dir":"Articles > Tensor","previous_headings":"","what":"log_","title":"Tensor objects","text":"log_() -> Tensor -place version $log","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"log_normal_","dir":"Articles > Tensor","previous_headings":"","what":"log_normal_","title":"Tensor objects","text":"log_normal_(mean=1, std=2, *, generator=NULL) Fills self tensor numbers samples log-normal distribution parameterized given mean \\mu standard deviation \\sigma. Note mean std mean standard deviation underlying normal distribution, returned distribution: \\[ f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}} \\]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logaddexp","dir":"Articles > Tensor","previous_headings":"","what":"logaddexp","title":"Tensor objects","text":"logaddexp() -> Tensor See ?torch_logaddexp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logaddexp2","dir":"Articles > Tensor","previous_headings":"","what":"logaddexp2","title":"Tensor objects","text":"logaddexp2() -> Tensor See [torch_logaddexp2()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logcumsumexp","dir":"Articles > Tensor","previous_headings":"","what":"logcumsumexp","title":"Tensor objects","text":"logcumsumexp(dim) -> Tensor See ?torch_logcumsumexp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logdet","dir":"Articles > Tensor","previous_headings":"","what":"logdet","title":"Tensor objects","text":"logdet() -> Tensor See ?torch_logdet","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_and","dir":"Articles > Tensor","previous_headings":"","what":"logical_and","title":"Tensor objects","text":"logical_and() -> Tensor See [torch_logical_and()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_and_","dir":"Articles > Tensor","previous_headings":"","what":"logical_and_","title":"Tensor objects","text":"logical_and_() -> Tensor -place version $logical_and","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_not","dir":"Articles > Tensor","previous_headings":"","what":"logical_not","title":"Tensor objects","text":"logical_not() -> Tensor See [torch_logical_not()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_not_","dir":"Articles > Tensor","previous_headings":"","what":"logical_not_","title":"Tensor objects","text":"logical_not_() -> Tensor -place version $logical_not","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_or","dir":"Articles > Tensor","previous_headings":"","what":"logical_or","title":"Tensor objects","text":"logical_or() -> Tensor See [torch_logical_or()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_or_","dir":"Articles > Tensor","previous_headings":"","what":"logical_or_","title":"Tensor objects","text":"logical_or_() -> Tensor -place version $logical_or","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_xor","dir":"Articles > Tensor","previous_headings":"","what":"logical_xor","title":"Tensor objects","text":"logical_xor() -> Tensor See [torch_logical_xor()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logical_xor_","dir":"Articles > Tensor","previous_headings":"","what":"logical_xor_","title":"Tensor objects","text":"logical_xor_() -> Tensor -place version $logical_xor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"logsumexp","dir":"Articles > Tensor","previous_headings":"","what":"logsumexp","title":"Tensor objects","text":"logsumexp(dim, keepdim=FALSE) -> Tensor See ?torch_logsumexp","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"long","dir":"Articles > Tensor","previous_headings":"","what":"long","title":"Tensor objects","text":"long(memory_format=torch_preserve_format) -> Tensor self$long() equivalent self$(torch_int64). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-25","dir":"Articles > Tensor","previous_headings":"long","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lstsq","dir":"Articles > Tensor","previous_headings":"","what":"lstsq","title":"Tensor objects","text":"lstsq() -> (Tensor, Tensor) See ?torch_lstsq","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lt","dir":"Articles > Tensor","previous_headings":"","what":"lt","title":"Tensor objects","text":"lt() -> Tensor See ?torch_lt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lt_","dir":"Articles > Tensor","previous_headings":"","what":"lt_","title":"Tensor objects","text":"lt_() -> Tensor -place version $lt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"lu","dir":"Articles > Tensor","previous_headings":"","what":"lu","title":"Tensor objects","text":"See ?torch_lu ## lu_solve lu_solve(LU_data, LU_pivots) -> Tensor See [torch_lu_solve()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"map_","dir":"Articles > Tensor","previous_headings":"","what":"map_","title":"Tensor objects","text":"map_(tensor, callable) Applies callable element self tensor given tensor stores results self tensor. self tensor given tensor must broadcastable. callable signature: callable(, b) -> number","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"masked_fill","dir":"Articles > Tensor","previous_headings":"","what":"masked_fill","title":"Tensor objects","text":"masked_fill(mask, value) -> Tensor --place version $masked_fill_","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"masked_fill_","dir":"Articles > Tensor","previous_headings":"","what":"masked_fill_","title":"Tensor objects","text":"masked_fill_(mask, value) Fills elements self tensor value mask TRUE. shape mask must broadcastable <broadcasting-semantics> shape underlying tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-26","dir":"Articles > Tensor","previous_headings":"masked_fill_","what":"Arguments:","title":"Tensor objects","text":"mask (BoolTensor): boolean mask value (float): value fill ","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"masked_scatter","dir":"Articles > Tensor","previous_headings":"","what":"masked_scatter","title":"Tensor objects","text":"masked_scatter(mask, tensor) -> Tensor --place version $masked_scatter_","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"masked_scatter_","dir":"Articles > Tensor","previous_headings":"","what":"masked_scatter_","title":"Tensor objects","text":"masked_scatter_(mask, source) Copies elements source self tensor positions mask TRUE. shape mask must :ref:broadcastable <broadcasting-semantics> shape underlying tensor. source least many elements number ones mask","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-27","dir":"Articles > Tensor","previous_headings":"masked_scatter_","what":"Arguments:","title":"Tensor objects","text":"mask (BoolTensor): boolean mask source (Tensor): tensor copy ","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-5","dir":"Articles > Tensor","previous_headings":"masked_scatter_","what":"Note:","title":"Tensor objects","text":"mask operates self tensor, given source tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"masked_select","dir":"Articles > Tensor","previous_headings":"","what":"masked_select","title":"Tensor objects","text":"masked_select(mask) -> Tensor See [torch_masked_select()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"matmul","dir":"Articles > Tensor","previous_headings":"","what":"matmul","title":"Tensor objects","text":"matmul(tensor2) -> Tensor See ?torch_matmul","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"matrix_power","dir":"Articles > Tensor","previous_headings":"","what":"matrix_power","title":"Tensor objects","text":"matrix_power(n) -> Tensor See [torch_matrix_power()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"max","dir":"Articles > Tensor","previous_headings":"","what":"max","title":"Tensor objects","text":"max(dim=NULL, keepdim=FALSE) -> Tensor (Tensor, Tensor) See ?torch_max","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mean","dir":"Articles > Tensor","previous_headings":"","what":"mean","title":"Tensor objects","text":"mean(dim=NULL, keepdim=FALSE) -> Tensor (Tensor, Tensor) See ?torch_mean","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"median","dir":"Articles > Tensor","previous_headings":"","what":"median","title":"Tensor objects","text":"median(dim=NULL, keepdim=FALSE) -> (Tensor, LongTensor) See ?torch_median","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"min","dir":"Articles > Tensor","previous_headings":"","what":"min","title":"Tensor objects","text":"min(dim=NULL, keepdim=FALSE) -> Tensor (Tensor, Tensor) See ?torch_min","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mm","dir":"Articles > Tensor","previous_headings":"","what":"mm","title":"Tensor objects","text":"mm(mat2) -> Tensor See ?torch_mm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mode","dir":"Articles > Tensor","previous_headings":"","what":"mode","title":"Tensor objects","text":"mode(dim=NULL, keepdim=FALSE) -> (Tensor, LongTensor) See ?torch_mode","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mul","dir":"Articles > Tensor","previous_headings":"","what":"mul","title":"Tensor objects","text":"mul(value) -> Tensor See ?torch_mul","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mul_","dir":"Articles > Tensor","previous_headings":"","what":"mul_","title":"Tensor objects","text":"mul_(value) -place version $mul","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"multinomial","dir":"Articles > Tensor","previous_headings":"","what":"multinomial","title":"Tensor objects","text":"multinomial(num_samples, replacement=FALSE, *, generator=NULL) -> Tensor See ?torch_multinomial","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mv","dir":"Articles > Tensor","previous_headings":"","what":"mv","title":"Tensor objects","text":"mv(vec) -> Tensor See ?torch_mv","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mvlgamma","dir":"Articles > Tensor","previous_headings":"","what":"mvlgamma","title":"Tensor objects","text":"mvlgamma(p) -> Tensor See ?torch_mvlgamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"mvlgamma_","dir":"Articles > Tensor","previous_headings":"","what":"mvlgamma_","title":"Tensor objects","text":"mvlgamma_(p) -> Tensor -place version $mvlgamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"names","dir":"Articles > Tensor","previous_headings":"","what":"names","title":"Tensor objects","text":"Stores names tensor’s dimensions. names[idx] corresponds name tensor dimension idx. Names either string dimension named NULL dimension unnamed. Dimension names may contain characters underscore. Furthermore, dimension name must valid Python variable name (.e., start underscore). Tensors may two named dimensions name.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-4","dir":"Articles > Tensor","previous_headings":"names","what":"Warning:","title":"Tensor objects","text":"named tensor API experimental subject change.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"narrow","dir":"Articles > Tensor","previous_headings":"","what":"narrow","title":"Tensor objects","text":"narrow(dimension, start, length) -> Tensor See ?torch_narrow","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-16","dir":"Articles > Tensor","previous_headings":"narrow","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(matrix(1:9, ncol = 3)) x$narrow(1, 1, 3) x$narrow(1, 1, 2)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"narrow_copy","dir":"Articles > Tensor","previous_headings":"","what":"narrow_copy","title":"Tensor objects","text":"narrow_copy(dimension, start, length) -> Tensor Tensor.narrow except returning copy rather shared storage. primarily sparse tensors, shared-storage narrow method. Calling narrow_copy` withdimemsion > self\\(sparse_dim()`` return copy relevant dense dimension narrowed, ``self\\)shape`` updated accordingly.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ndim","dir":"Articles > Tensor","previous_headings":"","what":"ndim","title":"Tensor objects","text":"Alias $dim()","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ndimension","dir":"Articles > Tensor","previous_headings":"","what":"ndimension","title":"Tensor objects","text":"ndimension() -> int Alias $dim()","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ne","dir":"Articles > Tensor","previous_headings":"","what":"ne","title":"Tensor objects","text":"ne() -> Tensor See ?torch_ne","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ne_","dir":"Articles > Tensor","previous_headings":"","what":"ne_","title":"Tensor objects","text":"ne_() -> Tensor -place version $ne","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"neg","dir":"Articles > Tensor","previous_headings":"","what":"neg","title":"Tensor objects","text":"neg() -> Tensor See ?torch_neg","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"neg_","dir":"Articles > Tensor","previous_headings":"","what":"neg_","title":"Tensor objects","text":"neg_() -> Tensor -place version $neg","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"nelement","dir":"Articles > Tensor","previous_headings":"","what":"nelement","title":"Tensor objects","text":"nelement() -> int Alias $numel","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"new_empty","dir":"Articles > Tensor","previous_headings":"","what":"new_empty","title":"Tensor objects","text":"new_empty(size, dtype=NULL, device=NULL, requires_grad=FALSE) -> Tensor Returns Tensor size size filled uninitialized data. default, returned Tensor torch_dtype torch_device tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-28","dir":"Articles > Tensor","previous_headings":"new_empty","what":"Arguments:","title":"Tensor objects","text":"dtype (torch_dtype, optional): desired type returned tensor. Default: NULL, torch_dtype tensor. device (torch_device, optional): desired device returned tensor. Default: NULL, torch_device tensor. requires_grad (bool, optional): autograd record operations returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-17","dir":"Articles > Tensor","previous_headings":"new_empty","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_ones(5) tensor$new_empty(c(2, 3))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"new_full","dir":"Articles > Tensor","previous_headings":"","what":"new_full","title":"Tensor objects","text":"new_full(size, fill_value, dtype=NULL, device=NULL, requires_grad=FALSE) -> Tensor Returns Tensor size size filled fill_value. default, returned Tensor torch_dtype torch_device tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-29","dir":"Articles > Tensor","previous_headings":"new_full","what":"Arguments:","title":"Tensor objects","text":"fill_value (scalar): number fill output tensor . dtype (torch_dtype, optional): desired type returned tensor. Default: NULL, torch_dtype tensor. device (torch_device, optional): desired device returned tensor. Default: NULL, torch_device tensor. requires_grad (bool, optional): autograd record operations returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-18","dir":"Articles > Tensor","previous_headings":"new_full","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_ones(c(2), dtype=torch_float64()) tensor$new_full(c(3, 4), 3.141592)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"new_ones","dir":"Articles > Tensor","previous_headings":"","what":"new_ones","title":"Tensor objects","text":"new_ones(size, dtype=NULL, device=NULL, requires_grad=FALSE) -> Tensor Returns Tensor size size filled 1. default, returned Tensor torch_dtype torch_device tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-30","dir":"Articles > Tensor","previous_headings":"new_ones","what":"Arguments:","title":"Tensor objects","text":"size (int…): list, tuple, torch_Size integers defining shape output tensor. dtype (torch_dtype, optional): desired type returned tensor. Default: NULL, torch_dtype tensor. device (torch_device, optional): desired device returned tensor. Default: NULL, torch_device tensor. requires_grad (bool, optional): autograd record operations returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-19","dir":"Articles > Tensor","previous_headings":"new_ones","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_tensor(c(2), dtype=torch_int32()) tensor$new_ones(c(2, 3))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"new_tensor","dir":"Articles > Tensor","previous_headings":"","what":"new_tensor","title":"Tensor objects","text":"new_tensor(data, dtype=NULL, device=NULL, requires_grad=FALSE) -> Tensor Returns new Tensor data tensor data. default, returned Tensor torch_dtype torch_device tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-5","dir":"Articles > Tensor","previous_headings":"new_tensor","what":"Warning:","title":"Tensor objects","text":"new_tensor always copies data(). Tensordata` want avoid copy, use [\\(requires_grad_()] [\\)detach()]. numpy array want avoid copy, use [torch_from_numpy()]. data tensor x, [new_tensor()()] reads ‘data’ whatever passed, constructs leaf variable. Therefore tensor$new_tensor(x) equivalent x$clone()$detach() tensor$new_tensor(x, requires_grad=TRUE) equivalent x$clone()$detach()$requires_grad_(TRUE). equivalents using clone() detach() recommended.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-31","dir":"Articles > Tensor","previous_headings":"new_tensor","what":"Arguments:","title":"Tensor objects","text":"data (array_like): returned Tensor copies data. dtype (torch_dtype, optional): desired type returned tensor. Default: NULL, torch_dtype tensor. device (torch_device, optional): desired device returned tensor. Default: NULL, torch_device tensor. requires_grad (bool, optional): autograd record operations returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-20","dir":"Articles > Tensor","previous_headings":"new_tensor","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_ones(c(2), dtype=torch_int8) data <- matrix(1:4, ncol = 2) tensor$new_tensor(data)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"new_zeros","dir":"Articles > Tensor","previous_headings":"","what":"new_zeros","title":"Tensor objects","text":"new_zeros(size, dtype=NULL, device=NULL, requires_grad=FALSE) -> Tensor Returns Tensor size size filled 0. default, returned Tensor torch_dtype torch_device tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-32","dir":"Articles > Tensor","previous_headings":"new_zeros","what":"Arguments:","title":"Tensor objects","text":"size (int…): list, tuple, torch_Size integers defining shape output tensor. dtype (torch_dtype, optional): desired type returned tensor. Default: NULL, torch_dtype tensor. device (torch_device, optional): desired device returned tensor. Default: NULL, torch_device tensor. requires_grad (bool, optional): autograd record operations returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-21","dir":"Articles > Tensor","previous_headings":"new_zeros","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_tensor(c(1), dtype=torch_float64()) tensor$new_zeros(c(2, 3))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"nonzero","dir":"Articles > Tensor","previous_headings":"","what":"nonzero","title":"Tensor objects","text":"nonzero() -> LongTensor See ?torch_nonzero","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"norm","dir":"Articles > Tensor","previous_headings":"","what":"norm","title":"Tensor objects","text":"See ?torch_norm ## normal_ normal_(mean=0, std=1, *, generator=NULL) -> Tensor Fills self tensor elements samples normal distribution parameterized mean std.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"numel","dir":"Articles > Tensor","previous_headings":"","what":"numel","title":"Tensor objects","text":"numel() -> int See ?torch_numel","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"numpy","dir":"Articles > Tensor","previous_headings":"","what":"numpy","title":"Tensor objects","text":"numpy() -> numpy.ndarray Returns self tensor NumPy :class:ndarray. tensor returned ndarray share underlying storage. Changes self tensor reflected :class:ndarray vice versa.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"orgqr","dir":"Articles > Tensor","previous_headings":"","what":"orgqr","title":"Tensor objects","text":"orgqr(input2) -> Tensor See ?torch_orgqr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"ormqr","dir":"Articles > Tensor","previous_headings":"","what":"ormqr","title":"Tensor objects","text":"ormqr(input2, input3, left=TRUE, transpose=FALSE) -> Tensor See ?torch_ormqr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"permute","dir":"Articles > Tensor","previous_headings":"","what":"permute","title":"Tensor objects","text":"permute(*dims) -> Tensor Returns view original tensor dimensions permuted.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-33","dir":"Articles > Tensor","previous_headings":"permute","what":"Arguments:","title":"Tensor objects","text":"dims (int…): desired ordering dimensions","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-22","dir":"Articles > Tensor","previous_headings":"permute","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_randn(2, 3, 5) x$size() x$permute(c(3, 1, 2))$size()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"pin_memory","dir":"Articles > Tensor","previous_headings":"","what":"pin_memory","title":"Tensor objects","text":"pin_memory() -> Tensor Copies tensor pinned memory, ’s already pinned.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"pinverse","dir":"Articles > Tensor","previous_headings":"","what":"pinverse","title":"Tensor objects","text":"pinverse() -> Tensor See ?torch_pinverse","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"polygamma","dir":"Articles > Tensor","previous_headings":"","what":"polygamma","title":"Tensor objects","text":"polygamma(n) -> Tensor See ?torch_polygamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"polygamma_","dir":"Articles > Tensor","previous_headings":"","what":"polygamma_","title":"Tensor objects","text":"polygamma_(n) -> Tensor -place version $polygamma","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"pow","dir":"Articles > Tensor","previous_headings":"","what":"pow","title":"Tensor objects","text":"pow(exponent) -> Tensor See ?torch_pow","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"pow_","dir":"Articles > Tensor","previous_headings":"","what":"pow_","title":"Tensor objects","text":"pow_(exponent) -> Tensor -place version $pow","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"prod","dir":"Articles > Tensor","previous_headings":"","what":"prod","title":"Tensor objects","text":"prod(dim=NULL, keepdim=FALSE, dtype=NULL) -> Tensor See ?torch_prod","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"put_","dir":"Articles > Tensor","previous_headings":"","what":"put_","title":"Tensor objects","text":"put_(indices, tensor, accumulate=FALSE) -> Tensor Copies elements tensor positions specified indices. purpose indexing, self tensor treated 1-D tensor. accumulate TRUE, elements tensor added self. accumulate FALSE, behavior undefined indices contain duplicate elements.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-34","dir":"Articles > Tensor","previous_headings":"put_","what":"Arguments:","title":"Tensor objects","text":"indices (LongTensor): indices self tensor (Tensor): tensor containing values copy accumulate (bool): whether accumulate self","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-23","dir":"Articles > Tensor","previous_headings":"put_","what":"Examples:","title":"Tensor objects","text":"","code":"src <- torch_tensor(matrix(3:8, ncol = 3)) src$put_(torch_tensor(1:2), torch_tensor(9:10))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"q_per_channel_axis","dir":"Articles > Tensor","previous_headings":"","what":"q_per_channel_axis","title":"Tensor objects","text":"q_per_channel_axis() -> int Given Tensor quantized linear (affine) per-channel quantization, returns index dimension per-channel quantization applied.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"q_per_channel_scales","dir":"Articles > Tensor","previous_headings":"","what":"q_per_channel_scales","title":"Tensor objects","text":"q_per_channel_scales() -> Tensor Given Tensor quantized linear (affine) per-channel quantization, returns Tensor scales underlying quantizer. number elements matches corresponding dimensions (q_per_channel_axis) tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"q_per_channel_zero_points","dir":"Articles > Tensor","previous_headings":"","what":"q_per_channel_zero_points","title":"Tensor objects","text":"q_per_channel_zero_points() -> Tensor Given Tensor quantized linear (affine) per-channel quantization, returns tensor zero_points underlying quantizer. number elements matches corresponding dimensions (q_per_channel_axis) tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"q_scale","dir":"Articles > Tensor","previous_headings":"","what":"q_scale","title":"Tensor objects","text":"q_scale() -> float Given Tensor quantized linear(affine) quantization, returns scale underlying quantizer().","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"q_zero_point","dir":"Articles > Tensor","previous_headings":"","what":"q_zero_point","title":"Tensor objects","text":"q_zero_point() -> int Given Tensor quantized linear(affine) quantization, returns zero_point underlying quantizer().","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"qr","dir":"Articles > Tensor","previous_headings":"","what":"qr","title":"Tensor objects","text":"qr(=TRUE) -> (Tensor, Tensor) See ?torch_qr","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"qscheme","dir":"Articles > Tensor","previous_headings":"","what":"qscheme","title":"Tensor objects","text":"qscheme() -> torch_qscheme Returns quantization scheme given QTensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rad2deg","dir":"Articles > Tensor","previous_headings":"","what":"rad2deg","title":"Tensor objects","text":"rad2deg() -> Tensor See [torch_rad2deg()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rad2deg_","dir":"Articles > Tensor","previous_headings":"","what":"rad2deg_","title":"Tensor objects","text":"rad2deg_() -> Tensor -place version $rad2deg","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"random_","dir":"Articles > Tensor","previous_headings":"","what":"random_","title":"Tensor objects","text":"random_(=0, =NULL, *, generator=NULL) -> Tensor Fills self tensor numbers sampled discrete uniform distribution [, - 1]. specified, values usually bounded self tensor’s data type. However, floating point types, unspecified, range [0, 2^mantissa] ensure every value representable. example, torch_tensor(1, dtype=torch_double).random_() uniform [0, 2^53].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"real","dir":"Articles > Tensor","previous_headings":"","what":"real","title":"Tensor objects","text":"Returns new tensor containing real values self tensor. returned tensor self share underlying storage.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-6","dir":"Articles > Tensor","previous_headings":"real","what":"Warning:","title":"Tensor objects","text":"[real()] supported tensors complex dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-24","dir":"Articles > Tensor","previous_headings":"real","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_randn(4, dtype=torch_cfloat()) x x$real"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"reciprocal","dir":"Articles > Tensor","previous_headings":"","what":"reciprocal","title":"Tensor objects","text":"reciprocal() -> Tensor See ?torch_reciprocal","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"reciprocal_","dir":"Articles > Tensor","previous_headings":"","what":"reciprocal_","title":"Tensor objects","text":"reciprocal_() -> Tensor -place version $reciprocal","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"record_stream","dir":"Articles > Tensor","previous_headings":"","what":"record_stream","title":"Tensor objects","text":"record_stream(stream) Ensures tensor memory reused another tensor current work queued stream complete.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-6","dir":"Articles > Tensor","previous_headings":"record_stream","what":"Note:","title":"Tensor objects","text":"caching allocator aware stream tensor allocated. Due awareness, already correctly manages life cycle tensors one stream. tensor used stream different stream origin, allocator might reuse memory unexpectedly. Calling method lets allocator know streams used tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"refine_names","dir":"Articles > Tensor","previous_headings":"","what":"refine_names","title":"Tensor objects","text":"Refines dimension names self according names. Refining special case renaming “lifts” unnamed dimensions. NULL dim can refined name; named dim can refined name. named tensors can coexist unnamed tensors, refining names gives nice way write named-tensor-aware code works named unnamed tensors. names may contain one Ellipsis (...). Ellipsis expanded greedily; expanded -place fill names length self$dim() using names corresponding indices self$names.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-35","dir":"Articles > Tensor","previous_headings":"refine_names","what":"Arguments:","title":"Tensor objects","text":"names (iterable str): desired names output tensor. May contain one Ellipsis.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-25","dir":"Articles > Tensor","previous_headings":"refine_names","what":"Examples:","title":"Tensor objects","text":"","code":"imgs <- torch_randn(32, 3, 128, 128) named_imgs <- imgs$refine_names(c('N', 'C', 'H', 'W')) named_imgs$names"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"register_hook","dir":"Articles > Tensor","previous_headings":"","what":"register_hook","title":"Tensor objects","text":"Registers backward hook. hook called every time gradient respect Tensor computed. hook following signature:: hook(grad) -> Tensor NULL hook modify argument, can optionally return new gradient used place grad. function returns handle method handle$remove() removes hook module.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"example","dir":"Articles > Tensor","previous_headings":"register_hook","what":"Example","title":"Tensor objects","text":"","code":"v <- torch_tensor(c(0., 0., 0.), requires_grad=TRUE) h <- v$register_hook(function(grad) grad * 2)  # double the gradient v$backward(torch_tensor(c(1., 2., 3.))) v$grad h$remove()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"remainder","dir":"Articles > Tensor","previous_headings":"","what":"remainder","title":"Tensor objects","text":"remainder(divisor) -> Tensor See ?torch_remainder","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"remainder_","dir":"Articles > Tensor","previous_headings":"","what":"remainder_","title":"Tensor objects","text":"remainder_(divisor) -> Tensor -place version $remainder","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rename","dir":"Articles > Tensor","previous_headings":"","what":"rename","title":"Tensor objects","text":"Renames dimension names self. two main usages: self$rename(**rename_map) returns view tensor dims renamed specified mapping rename_map. self$rename(*names) returns view tensor, renaming dimensions positionally using names. Use self$rename(NULL) drop names tensor. One specify positional args names keyword args rename_map.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-26","dir":"Articles > Tensor","previous_headings":"rename","what":"Examples:","title":"Tensor objects","text":"","code":"imgs <- torch_rand(2, 3, 5, 7, names=c('N', 'C', 'H', 'W')) renamed_imgs <- imgs$rename(c(\"Batch\", \"Channels\", \"Height\", \"Width\"))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rename_","dir":"Articles > Tensor","previous_headings":"","what":"rename_","title":"Tensor objects","text":"-place version $rename.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"renorm","dir":"Articles > Tensor","previous_headings":"","what":"renorm","title":"Tensor objects","text":"renorm(p, dim, maxnorm) -> Tensor See ?torch_renorm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"renorm_","dir":"Articles > Tensor","previous_headings":"","what":"renorm_","title":"Tensor objects","text":"renorm_(p, dim, maxnorm) -> Tensor -place version $renorm","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"repeat","dir":"Articles > Tensor","previous_headings":"","what":"repeat","title":"Tensor objects","text":"repeat(*sizes) -> Tensor Repeats tensor along specified dimensions. Unlike $expand, function copies tensor’s data.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-36","dir":"Articles > Tensor","previous_headings":"repeat","what":"Arguments:","title":"Tensor objects","text":"sizes (torch_Size int…): number times repeat tensor along dimension","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-27","dir":"Articles > Tensor","previous_headings":"repeat","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(c(1, 2, 3)) x$`repeat`(c(4, 2)) x$`repeat`(c(4, 2, 1))$size()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"repeat_interleave","dir":"Articles > Tensor","previous_headings":"","what":"repeat_interleave","title":"Tensor objects","text":"repeat_interleave(repeats, dim=NULL) -> Tensor See [torch_repeat_interleave()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"requires_grad","dir":"Articles > Tensor","previous_headings":"","what":"requires_grad","title":"Tensor objects","text":"TRUE gradients need computed Tensor, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-7","dir":"Articles > Tensor","previous_headings":"requires_grad","what":"Note:","title":"Tensor objects","text":"fact gradients need computed Tensor mean grad attribute populated, see is_leaf details.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"requires_grad_","dir":"Articles > Tensor","previous_headings":"","what":"requires_grad_","title":"Tensor objects","text":"requires_grad_(requires_grad=TRUE) -> Tensor Change autograd record operations tensor: sets tensor’s requires_grad attribute -place. Returns tensor. [requires_grad_()]’s main use case tell autograd begin recording operations Tensor tensor. tensor requires_grad=FALSE (obtained DataLoader, required preprocessing initialization), tensor.requires_grad_() makes autograd begin record operations tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-37","dir":"Articles > Tensor","previous_headings":"requires_grad_","what":"Arguments:","title":"Tensor objects","text":"requires_grad (bool): autograd record operations tensor. Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-28","dir":"Articles > Tensor","previous_headings":"requires_grad_","what":"Examples:","title":"Tensor objects","text":"","code":"# Let's say we want to preprocess some saved weights and use # the result as new weights. saved_weights <- c(0.1, 0.2, 0.3, 0.25) loaded_weights <- torch_tensor(saved_weights) weights <- preprocess(loaded_weights)  # some function weights  # Now, start to record operations done to weights weights$requires_grad_() out <- weights$pow(2)$sum() out$backward() weights$grad"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"reshape","dir":"Articles > Tensor","previous_headings":"","what":"reshape","title":"Tensor objects","text":"reshape(*shape) -> Tensor Returns tensor data number elements self specified shape. method returns view shape compatible current shape. See $view possible return view. See ?torch_reshape","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-38","dir":"Articles > Tensor","previous_headings":"reshape","what":"Arguments:","title":"Tensor objects","text":"shape (tuple ints int…): desired shape","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"reshape_as","dir":"Articles > Tensor","previous_headings":"","what":"reshape_as","title":"Tensor objects","text":"reshape_as() -> Tensor Returns tensor shape . self$reshape_as() equivalent self$reshape(.sizes()). method returns view .sizes() compatible current shape. See $view possible return view. Please see reshape information reshape.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-39","dir":"Articles > Tensor","previous_headings":"reshape_as","what":"Arguments:","title":"Tensor objects","text":"(`$): result tensor shape .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"resize_","dir":"Articles > Tensor","previous_headings":"","what":"resize_","title":"Tensor objects","text":"resize_(*sizes, memory_format=torch_contiguous_format) -> Tensor Resizes self tensor specified size. number elements larger current storage size, underlying storage resized fit new number elements. number elements smaller, underlying storage changed. Existing elements preserved new memory uninitialized.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"warning-7","dir":"Articles > Tensor","previous_headings":"resize_","what":"Warning:","title":"Tensor objects","text":"low-level method. storage reinterpreted C-contiguous, ignoring current strides (unless target size equals current size, case tensor left unchanged). purposes, instead want use $view(), checks contiguity, $reshape(), copies data needed. change size -place custom strides, see $set_().","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-40","dir":"Articles > Tensor","previous_headings":"resize_","what":"Arguments:","title":"Tensor objects","text":"sizes (torch_Size int…): desired size memory_format (torch_memory_format, optional): desired memory format Tensor. Default: torch_contiguous_format. Note memory format self going unaffected self$size() matches sizes.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-29","dir":"Articles > Tensor","previous_headings":"resize_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(matrix(1:6, ncol = 2)) x$resize_(c(2, 2))"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"resize_as_","dir":"Articles > Tensor","previous_headings":"","what":"resize_as_","title":"Tensor objects","text":"resize_as_(tensor, memory_format=torch_contiguous_format) -> Tensor Resizes self tensor size specified tensor. equivalent self$resize_(tensor.size()).","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-41","dir":"Articles > Tensor","previous_headings":"resize_as_","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format Tensor. Default: torch_contiguous_format. Note memory format self going unaffected self$size() matches tensor.size().","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"retain_grad","dir":"Articles > Tensor","previous_headings":"","what":"retain_grad","title":"Tensor objects","text":"Enables $grad attribute non-leaf Tensors.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rfft","dir":"Articles > Tensor","previous_headings":"","what":"rfft","title":"Tensor objects","text":"rfft(signal_ndim, normalized=FALSE, onesided=TRUE) -> Tensor See ?torch_rfft","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"roll","dir":"Articles > Tensor","previous_headings":"","what":"roll","title":"Tensor objects","text":"roll(shifts, dims) -> Tensor See ?torch_roll","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rot90","dir":"Articles > Tensor","previous_headings":"","what":"rot90","title":"Tensor objects","text":"rot90(k, dims) -> Tensor See [torch_rot90()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"round","dir":"Articles > Tensor","previous_headings":"","what":"round","title":"Tensor objects","text":"round() -> Tensor See ?torch_round","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"round_","dir":"Articles > Tensor","previous_headings":"","what":"round_","title":"Tensor objects","text":"round_() -> Tensor -place version $round","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rsqrt","dir":"Articles > Tensor","previous_headings":"","what":"rsqrt","title":"Tensor objects","text":"rsqrt() -> Tensor See ?torch_rsqrt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"rsqrt_","dir":"Articles > Tensor","previous_headings":"","what":"rsqrt_","title":"Tensor objects","text":"rsqrt_() -> Tensor -place version $rsqrt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"scatter","dir":"Articles > Tensor","previous_headings":"","what":"scatter","title":"Tensor objects","text":"scatter(dim, index, src) -> Tensor --place version $scatter_","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"scatter_","dir":"Articles > Tensor","previous_headings":"","what":"scatter_","title":"Tensor objects","text":"scatter_(dim, index, src) -> Tensor Writes values tensor src self indices specified index tensor. value src, output index specified index src dimension != dim corresponding value index dimension = dim. 3-D tensor, self updated : reverse operation manner described $gather. self, index src (Tensor) number dimensions. also required index.size(d) <= src.size(d) dimensions d, index.size(d) <= self$size(d) dimensions d != dim. Moreover, $gather, values index must 0 self$size(dim) - 1 inclusive, values row along specified dimension dim must unique.","code":"self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0 self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1 self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-42","dir":"Articles > Tensor","previous_headings":"scatter_","what":"Arguments:","title":"Tensor objects","text":"dim (int): axis along index index (LongTensor): indices elements scatter, can either empty size src. empty, operation returns identity src (Tensor): source element(s) scatter, incase value specified value (float): source element(s) scatter, incase src specified","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-30","dir":"Articles > Tensor","previous_headings":"scatter_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_rand(2, 5) x torch_zeros(3, 5)$scatter_(         1,          torch_tensor(rbind(c(2, 3, 3, 1, 1), c(3, 1, 1, 2, 3)), x) )  z <- torch_zeros(2, 4)$scatter_(         2,          torch_tensor(matrix(3:4, ncol = 1)), 1.23 )"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"scatter_add","dir":"Articles > Tensor","previous_headings":"","what":"scatter_add","title":"Tensor objects","text":"scatter_add(dim, index, src) -> Tensor --place version $scatter_add_","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"scatter_add_","dir":"Articles > Tensor","previous_headings":"","what":"scatter_add_","title":"Tensor objects","text":"scatter_add_(dim, index, src) -> Tensor Adds values tensor self indices specified index tensor similar fashion ~$scatter_. value src, added index self specified index src dimension != dim corresponding value index dimension = dim. 3-D tensor, self updated :: self, index src number dimensions. also required index.size(d) <= src.size(d) dimensions d, index.size(d) <= self$size(d) dimensions d != dim.","code":"self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0 self[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1 self[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-8","dir":"Articles > Tensor","previous_headings":"scatter_add_","what":"Note:","title":"Tensor objects","text":"circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch_backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-43","dir":"Articles > Tensor","previous_headings":"scatter_add_","what":"Arguments:","title":"Tensor objects","text":"dim (int): axis along index index (LongTensor): indices elements scatter add, can either empty size src. empty, operation returns identity. src (Tensor): source elements scatter add","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-31","dir":"Articles > Tensor","previous_headings":"scatter_add_","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_rand(2, 5) x torch_ones(3, 5)$scatter_add_(1, torch_tensor(rbind(c(0, 1, 2, 0, 0), c(2, 0, 0, 1, 2))), x)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"select","dir":"Articles > Tensor","previous_headings":"","what":"select","title":"Tensor objects","text":"select(dim, index) -> Tensor Slices self tensor along selected dimension given index. function returns view original tensor given dimension removed.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-44","dir":"Articles > Tensor","previous_headings":"select","what":"Arguments:","title":"Tensor objects","text":"dim (int): dimension slice index (int): index select ","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-9","dir":"Articles > Tensor","previous_headings":"select","what":"Note:","title":"Tensor objects","text":"select equivalent slicing. example, tensor$select(0, index) equivalent tensor[index] tensor$select(2, index) equivalent tensor[:,:,index].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"set_","dir":"Articles > Tensor","previous_headings":"","what":"set_","title":"Tensor objects","text":"set_(source=NULL, storage_offset=0, size=NULL, stride=NULL) -> Tensor Sets underlying storage, size, strides. source tensor, self tensor share storage size strides source. Changes elements one tensor reflected .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-45","dir":"Articles > Tensor","previous_headings":"set_","what":"Arguments:","title":"Tensor objects","text":"source (Tensor Storage): tensor storage use storage_offset (int, optional): offset storage size (torch_Size, optional): desired size. Defaults size source. stride (tuple, optional): desired stride. Defaults C-contiguous strides.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"share_memory_","dir":"Articles > Tensor","previous_headings":"","what":"share_memory_","title":"Tensor objects","text":"Moves underlying storage shared memory. -op underlying storage already shared memory CUDA tensors. Tensors shared memory resized.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"short","dir":"Articles > Tensor","previous_headings":"","what":"short","title":"Tensor objects","text":"short(memory_format=torch_preserve_format) -> Tensor self$short() equivalent self$(torch_int16). See [()].","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-46","dir":"Articles > Tensor","previous_headings":"short","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sigmoid","dir":"Articles > Tensor","previous_headings":"","what":"sigmoid","title":"Tensor objects","text":"sigmoid() -> Tensor See ?torch_sigmoid","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sigmoid_","dir":"Articles > Tensor","previous_headings":"","what":"sigmoid_","title":"Tensor objects","text":"sigmoid_() -> Tensor -place version $sigmoid","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sign","dir":"Articles > Tensor","previous_headings":"","what":"sign","title":"Tensor objects","text":"sign() -> Tensor See ?torch_sign","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sign_","dir":"Articles > Tensor","previous_headings":"","what":"sign_","title":"Tensor objects","text":"sign_() -> Tensor -place version $sign","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sin","dir":"Articles > Tensor","previous_headings":"","what":"sin","title":"Tensor objects","text":"sin() -> Tensor See ?torch_sin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sin_","dir":"Articles > Tensor","previous_headings":"","what":"sin_","title":"Tensor objects","text":"sin_() -> Tensor -place version $sin","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sinh","dir":"Articles > Tensor","previous_headings":"","what":"sinh","title":"Tensor objects","text":"sinh() -> Tensor See ?torch_sinh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sinh_","dir":"Articles > Tensor","previous_headings":"","what":"sinh_","title":"Tensor objects","text":"sinh_() -> Tensor -place version $sinh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"size","dir":"Articles > Tensor","previous_headings":"","what":"size","title":"Tensor objects","text":"size() -> torch_Size Returns size self tensor. returned value subclass tuple.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-32","dir":"Articles > Tensor","previous_headings":"size","what":"Examples:","title":"Tensor objects","text":"","code":"torch_empty(3, 4, 5)$size()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"slogdet","dir":"Articles > Tensor","previous_headings":"","what":"slogdet","title":"Tensor objects","text":"slogdet() -> (Tensor, Tensor) See ?torch_slogdet","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sort","dir":"Articles > Tensor","previous_headings":"","what":"sort","title":"Tensor objects","text":"sort(dim=-1, descending=FALSE) -> (Tensor, LongTensor) See ?torch_sort","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sparse_dim","dir":"Articles > Tensor","previous_headings":"","what":"sparse_dim","title":"Tensor objects","text":"sparse_dim() -> int self sparse COO tensor (.e., torch_sparse_coo layout), returns number sparse dimensions. Otherwise, throws error. See also Tensor.dense_dim.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sparse_mask","dir":"Articles > Tensor","previous_headings":"","what":"sparse_mask","title":"Tensor objects","text":"sparse_mask(input, mask) -> Tensor Returns new SparseTensor values Tensor input filtered indices mask values ignored. input mask must shape.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-47","dir":"Articles > Tensor","previous_headings":"sparse_mask","what":"Arguments:","title":"Tensor objects","text":"input (Tensor): input Tensor mask (SparseTensor): SparseTensor filter input based indices","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"split","dir":"Articles > Tensor","previous_headings":"","what":"split","title":"Tensor objects","text":"See ?torch_split","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sqrt","dir":"Articles > Tensor","previous_headings":"","what":"sqrt","title":"Tensor objects","text":"sqrt() -> Tensor See ?torch_sqrt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sqrt_","dir":"Articles > Tensor","previous_headings":"","what":"sqrt_","title":"Tensor objects","text":"sqrt_() -> Tensor -place version $sqrt","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"square","dir":"Articles > Tensor","previous_headings":"","what":"square","title":"Tensor objects","text":"square() -> Tensor See ?torch_square","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"square_","dir":"Articles > Tensor","previous_headings":"","what":"square_","title":"Tensor objects","text":"square_() -> Tensor -place version $square","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"squeeze","dir":"Articles > Tensor","previous_headings":"","what":"squeeze","title":"Tensor objects","text":"squeeze(dim=NULL) -> Tensor See ?torch_squeeze","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"squeeze_","dir":"Articles > Tensor","previous_headings":"","what":"squeeze_","title":"Tensor objects","text":"squeeze_(dim=NULL) -> Tensor -place version $squeeze","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"std","dir":"Articles > Tensor","previous_headings":"","what":"std","title":"Tensor objects","text":"std(dim=NULL, unbiased=TRUE, keepdim=FALSE) -> Tensor See ?torch_std","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"stft","dir":"Articles > Tensor","previous_headings":"","what":"stft","title":"Tensor objects","text":"See ?torch_stft","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"storage","dir":"Articles > Tensor","previous_headings":"","what":"storage","title":"Tensor objects","text":"storage() -> torch_Storage Returns underlying storage.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"storage_offset","dir":"Articles > Tensor","previous_headings":"","what":"storage_offset","title":"Tensor objects","text":"storage_offset() -> int Returns self tensor’s offset underlying storage terms number storage elements (bytes).","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-33","dir":"Articles > Tensor","previous_headings":"storage_offset","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(c(1, 2, 3, 4, 5)) x$storage_offset() x[3:N]$storage_offset()"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"storage_type","dir":"Articles > Tensor","previous_headings":"","what":"storage_type","title":"Tensor objects","text":"storage_type() -> type Returns type underlying storage.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"stride","dir":"Articles > Tensor","previous_headings":"","what":"stride","title":"Tensor objects","text":"stride(dim) -> tuple int Returns stride self tensor. Stride jump necessary go one element next one specified dimension dim. tuple strides returned argument passed . Otherwise, integer value returned stride particular dimension dim.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-48","dir":"Articles > Tensor","previous_headings":"stride","what":"Arguments:","title":"Tensor objects","text":"dim (int, optional): desired dimension stride required","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-34","dir":"Articles > Tensor","previous_headings":"stride","what":"Examples:","title":"Tensor objects","text":"","code":"x <- torch_tensor(matrix(1:10, nrow = 2)) x$stride() x$stride(1) x$stride(-1)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sub","dir":"Articles > Tensor","previous_headings":"","what":"sub","title":"Tensor objects","text":"sub(, *, alpha=1) -> Tensor Subtracts scalar tensor self tensor. alpha specified, element scaled alpha used. tensor, shape must broadcastable <broadcasting-semantics> shape underlying tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sub_","dir":"Articles > Tensor","previous_headings":"","what":"sub_","title":"Tensor objects","text":"sub_(, *, alpha=1) -> Tensor -place version $sub","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sum","dir":"Articles > Tensor","previous_headings":"","what":"sum","title":"Tensor objects","text":"sum(dim=NULL, keepdim=FALSE, dtype=NULL) -> Tensor See ?torch_sum","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"sum_to_size","dir":"Articles > Tensor","previous_headings":"","what":"sum_to_size","title":"Tensor objects","text":"sum_to_size(*size) -> Tensor Sum tensor size. size must broadcastable tensor size.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-49","dir":"Articles > Tensor","previous_headings":"sum_to_size","what":"Arguments:","title":"Tensor objects","text":"size (int…): sequence integers defining shape output tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"svd","dir":"Articles > Tensor","previous_headings":"","what":"svd","title":"Tensor objects","text":"svd(=TRUE, compute_uv=TRUE) -> (Tensor, Tensor, Tensor) See ?torch_svd","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"t","dir":"Articles > Tensor","previous_headings":"","what":"t","title":"Tensor objects","text":"t() -> Tensor See ?torch_t","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"t_","dir":"Articles > Tensor","previous_headings":"","what":"t_","title":"Tensor objects","text":"t_() -> Tensor -place version $t","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"take","dir":"Articles > Tensor","previous_headings":"","what":"take","title":"Tensor objects","text":"take(indices) -> Tensor See ?torch_take","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tan","dir":"Articles > Tensor","previous_headings":"","what":"tan","title":"Tensor objects","text":"tan() -> Tensor See ?torch_tan","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tan_","dir":"Articles > Tensor","previous_headings":"","what":"tan_","title":"Tensor objects","text":"tan_() -> Tensor -place version $tan","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tanh","dir":"Articles > Tensor","previous_headings":"","what":"tanh","title":"Tensor objects","text":"tanh() -> Tensor See ?torch_tanh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tanh_","dir":"Articles > Tensor","previous_headings":"","what":"tanh_","title":"Tensor objects","text":"tanh_() -> Tensor -place version $tanh","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"to","dir":"Articles > Tensor","previous_headings":"","what":"to","title":"Tensor objects","text":"(*args, **kwargs) -> Tensor Performs Tensor dtype /device conversion. torch_dtype :class:torch_device inferred arguments self$(*args, **kwargs).","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-10","dir":"Articles > Tensor","previous_headings":"to","what":"Note:","title":"Tensor objects","text":"self Tensor already correct torch_dtype :class:torch_device, self returned. Otherwise, returned tensor copy self desired torch_dtype :class:torch_device. ways call : (dtype, non_blocking=FALSE, copy=FALSE, memory_format=torch_preserve_format) -> Tensor Returns Tensor specified dtype","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-50","dir":"Articles > Tensor","previous_headings":"to","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format. (device=NULL, dtype=NULL, non_blocking=FALSE, copy=FALSE, memory_format=torch_preserve_format) -> Tensor Returns Tensor specified device (optional) dtype. dtype NULL inferred self$dtype. non_blocking, tries convert asynchronously respect host possible, e.g., converting CPU Tensor pinned memory CUDA Tensor. copy set, new Tensor created even Tensor already matches desired conversion.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-51","dir":"Articles > Tensor","previous_headings":"to","what":"Arguments:","title":"Tensor objects","text":"memory_format (torch_memory_format, optional): desired memory format returned Tensor. Default: torch_preserve_format. function:: (, non_blocking=FALSE, copy=FALSE) -> Tensor Returns Tensor torch_dtype :class:torch_device Tensor . non_blocking, tries convert asynchronously respect host possible, e.g., converting CPU Tensor pinned memory CUDA Tensor. copy set, new Tensor created even Tensor already matches desired conversion.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"examples-35","dir":"Articles > Tensor","previous_headings":"to","what":"Examples:","title":"Tensor objects","text":"","code":"tensor <- torch_randn(2, 2)  # Initially dtype=float32, device=cpu tensor$to(dtype = torch_float64())  other <- torch_randn(1, dtype=torch_float64()) tensor$to(other = other, non_blocking=TRUE)"},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"to_mkldnn","dir":"Articles > Tensor","previous_headings":"","what":"to_mkldnn","title":"Tensor objects","text":"to_mkldnn() -> Tensor Returns copy tensor torch_mkldnn layout.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"to_sparse","dir":"Articles > Tensor","previous_headings":"","what":"to_sparse","title":"Tensor objects","text":"to_sparse(sparseDims) -> Tensor Returns sparse copy tensor. PyTorch supports sparse tensors coordinate format <sparse-docs>.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-52","dir":"Articles > Tensor","previous_headings":"to_sparse","what":"Arguments:","title":"Tensor objects","text":"sparseDims (int, optional): number sparse dimensions include new sparse tensor","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tolist","dir":"Articles > Tensor","previous_headings":"","what":"tolist","title":"Tensor objects","text":"tolist() -> list number Returns tensor (nested) list. scalars, standard Python number returned, just like $item. Tensors automatically moved CPU first necessary. operation differentiable.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"topk","dir":"Articles > Tensor","previous_headings":"","what":"topk","title":"Tensor objects","text":"topk(k, dim=NULL, largest=TRUE, sorted=TRUE) -> (Tensor, LongTensor) See ?torch_topk","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"trace","dir":"Articles > Tensor","previous_headings":"","what":"trace","title":"Tensor objects","text":"trace() -> Tensor See ?torch_trace","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"transpose","dir":"Articles > Tensor","previous_headings":"","what":"transpose","title":"Tensor objects","text":"transpose(dim0, dim1) -> Tensor See ?torch_transpose","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"transpose_","dir":"Articles > Tensor","previous_headings":"","what":"transpose_","title":"Tensor objects","text":"transpose_(dim0, dim1) -> Tensor -place version $transpose","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"triangular_solve","dir":"Articles > Tensor","previous_headings":"","what":"triangular_solve","title":"Tensor objects","text":"triangular_solve(, upper=TRUE, transpose=FALSE, unitriangular=FALSE) -> (Tensor, Tensor) See [torch_triangular_solve()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tril","dir":"Articles > Tensor","previous_headings":"","what":"tril","title":"Tensor objects","text":"tril(k=0) -> Tensor See ?torch_tril","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"tril_","dir":"Articles > Tensor","previous_headings":"","what":"tril_","title":"Tensor objects","text":"tril_(k=0) -> Tensor -place version $tril","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"triu","dir":"Articles > Tensor","previous_headings":"","what":"triu","title":"Tensor objects","text":"triu(k=0) -> Tensor See ?torch_triu","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"triu_","dir":"Articles > Tensor","previous_headings":"","what":"triu_","title":"Tensor objects","text":"triu_(k=0) -> Tensor -place version $triu","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"true_divide","dir":"Articles > Tensor","previous_headings":"","what":"true_divide","title":"Tensor objects","text":"true_divide(value) -> Tensor See [torch_true_divide()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"true_divide_","dir":"Articles > Tensor","previous_headings":"","what":"true_divide_","title":"Tensor objects","text":"true_divide_(value) -> Tensor -place version $true_divide_","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"trunc","dir":"Articles > Tensor","previous_headings":"","what":"trunc","title":"Tensor objects","text":"trunc() -> Tensor See ?torch_trunc","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"trunc_","dir":"Articles > Tensor","previous_headings":"","what":"trunc_","title":"Tensor objects","text":"trunc_() -> Tensor -place version $trunc","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"type","dir":"Articles > Tensor","previous_headings":"","what":"type","title":"Tensor objects","text":"type(dtype=NULL, non_blocking=FALSE, **kwargs) -> str Tensor Returns type dtype provided, else casts object specified type. already correct type, copy performed original object returned.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-53","dir":"Articles > Tensor","previous_headings":"type","what":"Arguments:","title":"Tensor objects","text":"dtype (type string): desired type non_blocking (bool): TRUE, source pinned memory destination GPU vice versa, copy performed asynchronously respect host. Otherwise, argument effect. **kwargs: compatibility, may contain key async place non_blocking argument. async arg deprecated.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"type_as","dir":"Articles > Tensor","previous_headings":"","what":"type_as","title":"Tensor objects","text":"type_as(tensor) -> Tensor Returns tensor cast type given tensor. -op tensor already correct type. equivalent self$type(tensor.type())","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-54","dir":"Articles > Tensor","previous_headings":"type_as","what":"Arguments:","title":"Tensor objects","text":"tensor (Tensor): tensor desired type","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unbind","dir":"Articles > Tensor","previous_headings":"","what":"unbind","title":"Tensor objects","text":"unbind(dim=0) -> seq See ?torch_unbind","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unflatten","dir":"Articles > Tensor","previous_headings":"","what":"unflatten","title":"Tensor objects","text":"Unflattens named dimension dim, viewing shape specified namedshape.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-55","dir":"Articles > Tensor","previous_headings":"unflatten","what":"Arguments:","title":"Tensor objects","text":"namedshape: (iterable (name, size) tuples).","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unfold","dir":"Articles > Tensor","previous_headings":"","what":"unfold","title":"Tensor objects","text":"unfold(dimension, size, step) -> Tensor Returns view original tensor contains slices size size self tensor dimension dimension. Step two slices given step. sizedim size dimension dimension self, size dimension dimension returned tensor (sizedim - size) / step + 1. additional dimension size size appended returned tensor.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-56","dir":"Articles > Tensor","previous_headings":"unfold","what":"Arguments:","title":"Tensor objects","text":"dimension (int): dimension unfolding happens size (int): size slice unfolded step (int): step slice","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"uniform_","dir":"Articles > Tensor","previous_headings":"","what":"uniform_","title":"Tensor objects","text":"uniform_(=0, =1) -> Tensor Fills self tensor numbers sampled continuous uniform distribution: \\[ P(x) = \\dfrac{1}{\\text{} - \\text{}} \\]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unique","dir":"Articles > Tensor","previous_headings":"","what":"unique","title":"Tensor objects","text":"Returns unique elements input tensor. See ?torch_unique","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unique_consecutive","dir":"Articles > Tensor","previous_headings":"","what":"unique_consecutive","title":"Tensor objects","text":"Eliminates first element every consecutive group equivalent elements. See [torch_unique_consecutive()]","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unsqueeze","dir":"Articles > Tensor","previous_headings":"","what":"unsqueeze","title":"Tensor objects","text":"unsqueeze(dim) -> Tensor See ?torch_unsqueeze","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"unsqueeze_","dir":"Articles > Tensor","previous_headings":"","what":"unsqueeze_","title":"Tensor objects","text":"unsqueeze_(dim) -> Tensor -place version $unsqueeze","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"values","dir":"Articles > Tensor","previous_headings":"","what":"values","title":"Tensor objects","text":"values() -> Tensor self sparse COO tensor (.e., torch_sparse_coo layout), returns view contained values tensor. Otherwise, throws error.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"note-11","dir":"Articles > Tensor","previous_headings":"values","what":"Note:","title":"Tensor objects","text":"method can called coalesced sparse tensor. See Tensor$coalesce details.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"var","dir":"Articles > Tensor","previous_headings":"","what":"var","title":"Tensor objects","text":"var(dim=NULL, unbiased=TRUE, keepdim=FALSE) -> Tensor See ?torch_var","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"view","dir":"Articles > Tensor","previous_headings":"","what":"view","title":"Tensor objects","text":"view(*shape) -> Tensor Returns new tensor data self tensor different shape. returned tensor shares data must number elements, may different size. tensor viewed, new view size must compatible original size stride, .e., new view dimension must either subspace original dimension, span across original dimensions d, d+1, \\dots, d+k satisfy following contiguity-like condition \\forall = d, \\dots, d+k-1, \\[ \\text{stride}[] = \\text{stride}[+1] \\times \\text{size}[+1] \\] Otherwise, possible view self tensor shape without copying (e.g., via contiguous). unclear whether view can performed, advisable use :meth:reshape, returns view shapes compatible, copies (equivalent calling contiguous) otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-57","dir":"Articles > Tensor","previous_headings":"view","what":"Arguments:","title":"Tensor objects","text":"shape (torch_Size int…): desired size","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"view_as","dir":"Articles > Tensor","previous_headings":"","what":"view_as","title":"Tensor objects","text":"view_as() -> Tensor View tensor size . self$view_as() equivalent self$view(.size()). Please see $view information view.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"arguments-58","dir":"Articles > Tensor","previous_headings":"view_as","what":"Arguments:","title":"Tensor objects","text":"(`$): result tensor size .","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"where","dir":"Articles > Tensor","previous_headings":"","what":"where","title":"Tensor objects","text":"(condition, y) -> Tensor self$(condition, y) equivalent torch_where(condition, self, y). See ?torch_where","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor/index.html","id":"zero_","dir":"Articles > Tensor","previous_headings":"","what":"zero_","title":"Tensor objects","text":"zero_() -> Tensor Fills self tensor zeros.","code":""},{"path":"https://torch.mlverse.org/docs/articles/tensor-creation.html","id":"from-r-objects","dir":"Articles","previous_headings":"","what":"From R objects","title":"Creating tensors","text":"can create tensors R objects using torch_tensor function. torch_tensor function takes R vector, matrix array creates equivalent torch_tensor. can see examples : default, create tensors cpu device, converting R datatype corresponding torch dtype. Note currently, numeric boolean types supported. can always modify dtype device converting R object torch tensor. example: options available creating tensor : requires_grad: boolean indicating want autograd record operations automatic differentiation. pin_memory: – set, tensor returned allocated pinned memory. Works CPU tensors. options available functions can used create new tensors, including factory functions listed next section.","code":"torch_tensor(c(1,2,3)) #> torch_tensor #>  1 #>  2 #>  3 #> [ CPUFloatType{3} ] # conform to row-major indexing used in torch torch_tensor(matrix(1:10, ncol = 5, nrow = 2, byrow = TRUE)) #> torch_tensor #>   1   2   3   4   5 #>   6   7   8   9  10 #> [ CPULongType{2,5} ] torch_tensor(array(runif(12), dim = c(2, 2, 3))) #> torch_tensor #> (1,.,.) =  #>   0.6008  0.4978  0.8746 #>   0.0074  0.7329  0.0342 #>  #> (2,.,.) =  #>   0.1572  0.2898  0.1749 #>   0.4664  0.7725  0.3204 #> [ CPUFloatType{2,2,3} ] torch_tensor(1, dtype = torch_long()) #> torch_tensor #>  1 #> [ CPULongType{1} ] torch_tensor(1, device = \"cpu\", dtype = torch_float64()) #> torch_tensor #>  1 #> [ CPUDoubleType{1} ]"},{"path":"https://torch.mlverse.org/docs/articles/tensor-creation.html","id":"using-creation-functions","dir":"Articles","previous_headings":"","what":"Using creation functions","title":"Creating tensors","text":"can also use torch_* functions listed create torch tensors using algorithm. example, torch_randn function create tensors using normal distribution mean 0 standard deviation 1. can use ... argument pass size dimensions. example, code create normally distributed tensor shape 5x3. Another example torch_ones, creates tensor filled ones. full list functions can used bulk-create tensors torch: torch_arange: Returns tensor sequence integers, torch_empty: Returns tensor uninitialized values, torch_eye: Returns identity matrix, torch_full: Returns tensor filled single value, torch_linspace: Returns tensor values linearly spaced interval, torch_logspace: Returns tensor values logarithmically spaced interval, torch_ones: Returns tensor filled ones, torch_rand: Returns tensor filled values drawn uniform distribution [0, 1). torch_randint: Returns tensor integers randomly drawn interval, torch_randn: Returns tensor filled values drawn unit normal distribution, torch_randperm: Returns tensor filled random permutation integers interval, torch_zeros: Returns tensor filled zeros.","code":"x <- torch_randn(5, 3) x #> torch_tensor #>  0.8893  0.0678  0.1857 #>  2.8248 -1.0283 -2.1778 #> -1.9115 -0.3700 -0.5116 #>  0.6165  0.7820  0.5383 #> -0.4962 -0.7342 -0.2521 #> [ CPUFloatType{5,3} ] x <- torch_ones(2, 4, dtype = torch_int64(), device = \"cpu\") x #> torch_tensor #>  1  1  1  1 #>  1  1  1  1 #> [ CPULongType{2,4} ]"},{"path":"https://torch.mlverse.org/docs/articles/tensor-creation.html","id":"conversion","dir":"Articles","previous_headings":"","what":"Conversion","title":"Creating tensors","text":"tensor exists can convert dtypes move different device method. example: can also copy tensor GPU using:","code":"x <- torch_tensor(1) y <- x$to(dtype = torch_int32()) x #> torch_tensor #>  1 #> [ CPUFloatType{1} ] y #> torch_tensor #>  1 #> [ CPUIntType{1} ] x <- torch_tensor(1) y <- x$cuda())"},{"path":[]},{"path":"https://torch.mlverse.org/docs/articles/torchscript.html","id":"tracing","dir":"Articles","previous_headings":"Creating TorchScript programs","what":"Tracing","title":"TorchScript","text":"TorchScript programs can created R using tracing. using tracing, code automatically converted subset Python recording actual operators tensors simply executing discarding surrounding R code. Currently tracing supported way create TorchScript programs R code. example, let’s use jit_trace function create TorchScript program. pass regular R function example inputs. jit_trace function executed R function example input recorded torch operations occurred execution create graph. graph call intermediate representation TorchScript programs, can inspected : traced function can now invoked regular R function: ’s also possible trace nn_modules() defined R, example: using jit_trace nn_module forward method traced. can use jit_trace_module function pass example inputs methods. Traced modules look like normal nn_modules(), can called way:","code":"fn <- function(x) {   torch_relu(x) }  traced_fn <- jit_trace(fn, torch_tensor(c(-1, 0, 1))) traced_fn$graph #> graph(%0 : Float(3, strides=[1], requires_grad=0, device=cpu)): #>   %1 : Float(3, strides=[1], requires_grad=0, device=cpu) = aten::relu(%0) #>   return (%1) traced_fn(torch_randn(3)) #> torch_tensor #>  0.0000 #>  0.7543 #>  0.0000 #> [ CPUFloatType{3} ] module <- nn_module(   initialize = function() {     self$linear1 <- nn_linear(10, 10)     self$linear2 <- nn_linear(10, 1)   },   forward = function(x) {     x %>%        self$linear1() %>%        nnf_relu() %>%        self$linear2()   } ) traced_module <- jit_trace(module(), torch_randn(10, 10)) traced_module(torch_randn(3, 10)) #> torch_tensor #> 0.01 * #>  5.6937 #>   3.3835 #>   4.8311 #> [ CPUFloatType{3,1} ][ grad_fn = <AddmmBackward0> ]"},{"path":"https://torch.mlverse.org/docs/articles/torchscript.html","id":"limitations-of-tracing","dir":"Articles","previous_headings":"Creating TorchScript programs > Tracing","what":"Limitations of tracing","title":"TorchScript","text":"Tracing record control flow like -statements loops. control flow constant across module, fine often inlines control flow decisions. sometimes control flow actually part model . instance, recurrent network loop (possibly dynamic) length input sequence. example: returned ScriptModule, operations different behaviors training eval modes always behave mode tracing, matter mode ScriptModule . example: Tracing proegrams can take tensors lists tensors input return tensors lists tensors. example:","code":"# fn does does an operation for each dimension of a tensor fn <- function(x) {   x %>%      torch_unbind(dim = 1) %>%      lapply(function(x) x$sum()) %>%      torch_stack(dim = 1) } # we trace using as an example a tensor with size (10, 5, 5) traced_fn <- jit_trace(fn, torch_randn(10, 5, 5)) # applying it with a tensor with different size returns an error. traced_fn(torch_randn(11, 5, 5)) #> Error in cpp_call_traced_fn(ptr, inputs): The following operation failed in the TorchScript interpreter. #> Traceback of TorchScript (most recent call last): #> RuntimeError: Expected 10 elements in a list but found 11 traced_dropout <- jit_trace(nn_dropout(), torch_ones(5,5)) traced_dropout(torch_ones(3,3)) #> torch_tensor #>  2  0  0 #>  2  0  0 #>  2  0  2 #> [ CPUFloatType{3,3} ] traced_dropout$eval() # even after setting to eval mode, dropout is applied traced_dropout(torch_ones(3,3)) #> torch_tensor #>  0  2  0 #>  2  0  2 #>  0  2  2 #> [ CPUFloatType{3,3} ] fn <- function(x, y) {   x + y } jit_trace(fn, torch_tensor(1), 1) #> Error in cpp_trace_function(tr_fn, list(...), .compilation_unit, strict, : Only tensors or (possibly nested) dict or tuples of tensors can be inputs to traced functions. Got float #> Exception raised from addInput at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/frontend/tracer.cpp:422 (most recent call first): #> frame #0: c10::Error::Error(c10::SourceLocation, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>) + 81 (0x105089ca1 in libc10.dylib) #> frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 98 (0x105088342 in libc10.dylib) #> frame #2: torch::jit::tracer::addInput(std::__1::shared_ptr<torch::jit::tracer::TracingState> const&, c10::IValue const&, c10::Type::SingletonOrSharedTypePtr<c10::Type> const&, torch::jit::Value*) + 6052 (0x1270ce564 in libtorch_cpu.dylib) #> frame #3: torch::jit::tracer::addInput(std::__1::shared_ptr<torch::jit::tracer::TracingState> const&, c10::IValue const&, c10::Type::SingletonOrSharedTypePtr<c10::Type> const&, torch::jit::Value*) + 4445 (0x1270cdf1d in libtorch_cpu.dylib) #> frame #4: torch::jit::tracer::trace(std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue>>, std::__1::function<std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue>> (std::__1::vector<c10::IValue, std::__1::allocator<c10::IValue>>)> const&, std::__1::function<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> (at::Tensor const&)>, bool, bool, torch::jit::Module*, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>>> const&) + 826 (0x1270cb59a in libtorch_cpu.dylib) #> frame #5: _lantern_trace_fn + 597 (0x109b5fb35 in liblantern.dylib) #> frame #6: cpp_trace_function(Rcpp::Function_Impl<Rcpp::PreserveStorage>, XPtrTorchStack, XPtrTorchCompilationUnit, XPtrTorchstring, bool, XPtrTorchScriptModule, bool, bool) + 566 (0x107d05176 in torchpkg.so) #> frame #7: _torch_cpp_trace_function + 719 (0x107b3facf in torchpkg.so) #> frame #8: R_doDotCall + 13245 (0x102395a3d in libR.dylib) #> frame #9: bcEval_loop + 146643 (0x1023fd6d3 in libR.dylib) #> frame #10: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #11: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #12: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #13: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #14: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #15: do_eval + 1253 (0x1023d20e5 in libR.dylib) #> frame #16: bcEval_loop + 44476 (0x1023e47bc in libR.dylib) #> frame #17: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #18: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #19: forcePromise + 230 (0x1023cb5a6 in libR.dylib) #> frame #20: Rf_eval + 634 (0x1023caafa in libR.dylib) #> frame #21: do_withVisible + 57 (0x1023d2479 in libR.dylib) #> frame #22: do_internal + 362 (0x10244a0aa in libR.dylib) #> frame #23: bcEval_loop + 45103 (0x1023e4a2f in libR.dylib) #> frame #24: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #25: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #26: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #27: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #28: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #29: do_begin + 429 (0x1023cffad in libR.dylib) #> frame #30: Rf_eval + 990 (0x1023cac5e in libR.dylib) #> frame #31: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #32: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #33: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #34: do_docall + 615 (0x10235b827 in libR.dylib) #> frame #35: bcEval_loop + 44476 (0x1023e47bc in libR.dylib) #> frame #36: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #37: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #38: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #39: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #40: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #41: do_docall + 615 (0x10235b827 in libR.dylib) #> frame #42: bcEval_loop + 44476 (0x1023e47bc in libR.dylib) #> frame #43: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #44: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #45: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #46: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #47: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #48: forcePromise + 230 (0x1023cb5a6 in libR.dylib) #> frame #49: bcEval_loop + 19496 (0x1023de628 in libR.dylib) #> frame #50: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #51: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #52: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #53: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #54: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> frame #55: do_begin + 429 (0x1023cffad in libR.dylib) #> frame #56: Rf_eval + 990 (0x1023cac5e in libR.dylib) #> frame #57: forcePromise + 230 (0x1023cb5a6 in libR.dylib) #> frame #58: bcEval_loop + 19496 (0x1023de628 in libR.dylib) #> frame #59: bcEval + 628 (0x1023cb374 in libR.dylib) #> frame #60: Rf_eval + 506 (0x1023caa7a in libR.dylib) #> frame #61: R_execClosure + 761 (0x1023cd5b9 in libR.dylib) #> frame #62: applyClosure_core + 128 (0x1023cc6c0 in libR.dylib) #> frame #63: Rf_eval + 1189 (0x1023cad25 in libR.dylib) #> :"},{"path":"https://torch.mlverse.org/docs/articles/torchscript.html","id":"compiling-torchscript","dir":"Articles","previous_headings":"Creating TorchScript programs","what":"Compiling TorchScript","title":"TorchScript","text":"’s also possible create TorchScript programs compiling TorchScript code. TorchScript code looks lot like standard python code. example:","code":"tr <- jit_compile(\" def fn (x: Tensor):   return torch.relu(x)  \") tr$fn(torch_tensor(c(-1, 0, 1))) #> torch_tensor #>  0 #>  0 #>  1 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/articles/torchscript.html","id":"serializing-and-loading","dir":"Articles","previous_headings":"","what":"Serializing and loading","title":"TorchScript","text":"TorchScript programs can serialized using jit_save function loaded back disk jit_load. example: Loaded programs can executed usual: Note can load TorchScript programs created libraries different torch R. Eg, TorchScript program can created PyTorch torch.jit.trace torch.jit.script, run R. R objects automatically converted TorchScript counterpart following Types table document. However, sometimes ’s necessary make type annotations jit_tuple() jit_scalar() disambiguate conversion.","code":"fn <- function(x) {   torch_relu(x) } tr_fn <- jit_trace(fn, torch_tensor(1)) jit_save(tr_fn, \"path.pt\") loaded <- jit_load(\"path.pt\") loaded(torch_tensor(c(-1, 0, 1))) #> torch_tensor #>  0 #>  0 #>  1 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/articles/torchscript.html","id":"types","dir":"Articles","previous_headings":"","what":"Types","title":"TorchScript","text":"following table lists TorchScript types convert back R.","code":""},{"path":"https://torch.mlverse.org/docs/articles/using-autograd.html","id":"automatic-differentiation-with-autograd","dir":"Articles","previous_headings":"","what":"Automatic differentiation with autograd","title":"Using autograd","text":"Torch uses module called autograd record operations performed tensors, store done obtain respective gradients. actions stored functions, functions applied order gradient output (normally, loss) respect tensors calculated: starting output node propagating gradients back network. form reverse mode automatic differentiation. users, can see bit implementation. prerequisite “recording” happen, tensors created requires_grad = TRUE. E.g. clear, tensor respect gradients calculated – normally, tensor representing weight bias, input data 1. now perform operation tensor, assigning result y find y now non-empty grad_fn tells torch compute gradient y respect x: Actual computation gradients triggered calling backward() output tensor. executed, x now non-empty field grad stores gradient y respect x: longer chain computations, can peek torch builds graph backward operations. slightly complex example. call retain_grad() y z just demonstration purposes; default, intermediate gradients – course computed – aren’t stored, order save memory. Starting $grad_fn, can follow graph back leaf nodes: calling $backward(), tensors graph respective gradients created. Without calls retain_grad , z$grad y$grad empty: Thus acquainted autograd, ’re ready modify example.","code":"x <- torch_ones(2,2, requires_grad = TRUE) y <- x$mean() y$grad_fn #> MeanBackward0 y$backward() x$grad #> torch_tensor #>  0.2500  0.2500 #>  0.2500  0.2500 #> [ CPUFloatType{2,2} ] x1 <- torch_ones(2,2, requires_grad = TRUE) x2 <- torch_tensor(1.1, requires_grad = TRUE) y <- x1 * (x2 + 2) y$retain_grad() z <- y$pow(2) * 3 z$retain_grad() out <- z$mean() # how to compute the gradient for mean, the last operation executed out$grad_fn #> MeanBackward0 # how to compute the gradient for the multiplication by 3 in z = y$pow(2) * 3 out$grad_fn$next_functions #> [[1]] #> MulBackward1 # how to compute the gradient for pow in z = y.pow(2) * 3 out$grad_fn$next_functions[[1]]$next_functions #> [[1]] #> PowBackward0 # how to compute the gradient for the multiplication in y = x * (x + 2) out$grad_fn$next_functions[[1]]$next_functions[[1]]$next_functions #> [[1]] #> MulBackward0 # how to compute the gradient for the two branches of y = x * (x + 2), # where the left branch is a leaf node (AccumulateGrad for x1) out$grad_fn$next_functions[[1]]$next_functions[[1]]$next_functions[[1]]$next_functions #> [[1]] #> torch::autograd::AccumulateGrad #>  #> [[2]] #> AddBackward1 # here we arrive at the other leaf node (AccumulateGrad for x2) out$grad_fn$next_functions[[1]]$next_functions[[1]]$next_functions[[1]]$next_functions[[2]]$next_functions #> [[1]] #> torch::autograd::AccumulateGrad out$backward() z$grad #> torch_tensor #>  0.2500  0.2500 #>  0.2500  0.2500 #> [ CPUFloatType{2,2} ] y$grad #> torch_tensor #>  4.6500  4.6500 #>  4.6500  4.6500 #> [ CPUFloatType{2,2} ] x2$grad #> torch_tensor #>  18.6000 #> [ CPUFloatType{1} ] x1$grad #> torch_tensor #>  14.4150  14.4150 #>  14.4150  14.4150 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/articles/using-autograd.html","id":"the-simple-network-now-using-autograd","dir":"Articles","previous_headings":"","what":"The simple network, now using autograd","title":"Using autograd","text":"single new line calling loss$backward(), now number lines (manual backprop) gone: still manually compute forward pass, still manually update weights. last two chapters section, ’ll see parts logic can made modular reusable, well.","code":"### generate training data ----------------------------------------------------- # input dimensionality (number of input features) d_in <- 3 # output dimensionality (number of predicted features) d_out <- 1 # number of observations in training set n <- 100 # create random data x <- torch_randn(n, d_in) y <- x[,1]*0.2 - x[..,2]*1.3 - x[..,3]*0.5 + torch_randn(n) y <- y$unsqueeze(dim = 1) ### initialize weights --------------------------------------------------------- # dimensionality of hidden layer d_hidden <- 32 # weights connecting input to hidden layer w1 <- torch_randn(d_in, d_hidden, requires_grad = TRUE) # weights connecting hidden to output layer w2 <- torch_randn(d_hidden, d_out, requires_grad = TRUE) # hidden layer bias b1 <- torch_zeros(1, d_hidden, requires_grad = TRUE) # output layer bias b2 <- torch_zeros(1, d_out,requires_grad = TRUE) ### network parameters --------------------------------------------------------- learning_rate <- 1e-4 ### training loop -------------------------------------------------------------- for (t in 1:200) {      ### -------- Forward pass --------      y_pred <- x$mm(w1)$add(b1)$clamp(min = 0)$mm(w2)$add(b2)     ### -------- compute loss --------      loss <- (y_pred - y)$pow(2)$mean()     if (t %% 10 == 0) cat(t, as_array(loss), \"\\n\")     ### -------- Backpropagation --------      # compute the gradient of loss with respect to all tensors with requires_grad = True.     loss$backward()       ### -------- Update weights --------           # Wrap in torch.no_grad() because this is a part we DON'T want to record for automatic gradient computation     with_no_grad({              w1$sub_(learning_rate * w1$grad)       w2$sub_(learning_rate * w2$grad)       b1$sub_(learning_rate * b1$grad)       b2$sub_(learning_rate * b2$grad)              # Zero the gradients after every pass, because they'd accumulate otherwise       w1$grad$zero_()       w2$grad$zero_()       b1$grad$zero_()       b2$grad$zero_()          })      } #> 10 59.5981  #> 20 54.32401  #> 30 49.66991  #> 40 45.58003  #> 50 41.95185  #> 60 38.72104  #> 70 35.83778  #> 80 33.25837  #> 90 30.9521  #> 100 28.87896  #> 110 27.00857  #> 120 25.31741  #> 130 23.78777  #> 140 22.40333  #> 150 21.1463  #> 160 20.00305  #> 170 18.96302  #> 180 18.01377  #> 190 17.14516  #> 200 16.34873"},{"path":"https://torch.mlverse.org/docs/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Falbel. Author, maintainer, copyright holder. Javier Luraschi. Author. Dmitriy Selivanov. Contributor. Athos Damiani. Contributor. Christophe Regouby. Contributor. Krzysztof Joachimiak. Contributor. Hamada S. Badr. Contributor. Sebastian Fischer. Contributor. RStudio. Copyright holder.","code":""},{"path":"https://torch.mlverse.org/docs/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Falbel D, Luraschi J (2024). torch: Tensors Neural Networks 'GPU' Acceleration. R package version 0.13.0, https://github.com/mlverse/torch, https://torch.mlverse.org/docs.","code":"@Manual{,   title = {torch: Tensors and Neural Networks with 'GPU' Acceleration},   author = {Daniel Falbel and Javier Luraschi},   year = {2024},   note = {R package version 0.13.0, https://github.com/mlverse/torch},   url = {https://torch.mlverse.org/docs}, }"},{"path":[]},{"path":"https://torch.mlverse.org/docs/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tensors and Neural Networks with GPU Acceleration","text":"torch can installed CRAN : can also install development version : first package load additional software installed. See also full installation guide .","code":"install.packages(\"torch\") remotes::install_github(\"mlverse/torch\")"},{"path":"https://torch.mlverse.org/docs/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Tensors and Neural Networks with GPU Acceleration","text":"can create torch tensors R objects torch_tensor function convert back R objects as_array.","code":"library(torch) x <- array(runif(8), dim = c(2, 2, 2)) y <- torch_tensor(x, dtype = torch_float64()) y #> torch_tensor #> (1,.,.) =  #>   0.6192  0.5800 #>   0.2488  0.3681 #>  #> (2,.,.) =  #>   0.0042  0.9206 #>   0.4388  0.5664 #> [ CPUDoubleType{2,2,2} ] identical(x, as_array(y)) #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/index.html","id":"simple-autograd-example","dir":"","previous_headings":"Examples","what":"Simple Autograd Example","title":"Tensors and Neural Networks with GPU Acceleration","text":"following snippet let torch, using autograd feature, calculate derivatives:","code":"x <- torch_tensor(1, requires_grad = TRUE) w <- torch_tensor(2, requires_grad = TRUE) b <- torch_tensor(3, requires_grad = TRUE) y <- w * x + b y$backward() x$grad #> torch_tensor #>  2 #> [ CPUFloatType{1} ] w$grad #> torch_tensor #>  1 #> [ CPUFloatType{1} ] b$grad #> torch_tensor #>  1 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tensors and Neural Networks with GPU Acceleration","text":"matter current skills ’s possible contribute torch development. See contributing guide information.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":null,"dir":"Reference","previous_headings":"","what":"Class representing the context. — AutogradContext","title":"Class representing the context. — AutogradContext","text":"Class representing context. Class representing context.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Class representing the context. — AutogradContext","text":"ptr (Dev related) pointer context c++ object.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Class representing the context. — AutogradContext","text":"needs_input_grad boolean listing arguments forward whether require_grad. saved_variables list objects saved backward via save_for_backward.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Class representing the context. — AutogradContext","text":"AutogradContext$new() AutogradContext$save_for_backward() AutogradContext$mark_non_differentiable() AutogradContext$mark_dirty() AutogradContext$clone()","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Class representing the context. — AutogradContext","text":"(Dev related) Initializes context. user related.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class representing the context. — AutogradContext","text":"","code":"AutogradContext$new(   ptr,   env,   argument_names = NULL,   argument_needs_grad = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class representing the context. — AutogradContext","text":"ptr pointer c++ object env environment encloses forward backward argument_names names forward arguments argument_needs_grad whether argument forward needs grad.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"method-save-for-backward-","dir":"Reference","previous_headings":"","what":"Method save_for_backward()","title":"Class representing the context. — AutogradContext","text":"Saves given objects future call backward(). called , inside forward() method. Later, saved objects can accessed saved_variables attribute. returning user, check made ensure weren’t used -place operation modified content. Arguments can also kind R object.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Class representing the context. — AutogradContext","text":"","code":"AutogradContext$save_for_backward(...)"},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class representing the context. — AutogradContext","text":"... kind R object saved backward pass. common pass named arguments.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"method-mark-non-differentiable-","dir":"Reference","previous_headings":"","what":"Method mark_non_differentiable()","title":"Class representing the context. — AutogradContext","text":"Marks outputs non-differentiable. called , inside forward() method, arguments outputs. mark outputs requiring gradients, increasing efficiency backward computation. still need accept gradient output backward(), ’s always going zero tensor shape shape corresponding output. used e.g. indices returned max Function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Class representing the context. — AutogradContext","text":"","code":"AutogradContext$mark_non_differentiable(...)"},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class representing the context. — AutogradContext","text":"... non-differentiable outputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"method-mark-dirty-","dir":"Reference","previous_headings":"","what":"Method mark_dirty()","title":"Class representing the context. — AutogradContext","text":"Marks given tensors modified -place operation. called , inside forward() method, arguments inputs. Every tensor ’s modified -place call forward() given function, ensure correctness checks. doesn’t matter whether function called modification.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Class representing the context. — AutogradContext","text":"","code":"AutogradContext$mark_dirty(...)"},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class representing the context. — AutogradContext","text":"... tensors modified -place.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Class representing the context. — AutogradContext","text":"objects class cloneable method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Class representing the context. — AutogradContext","text":"","code":"AutogradContext$clone(deep = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/AutogradContext.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class representing the context. — AutogradContext","text":"deep Whether make deep clone.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Abstract base class for constraints. — Constraint","title":"Abstract base class for constraints. — Constraint","text":"Abstract base class constraints. Abstract base class constraints.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Abstract base class for constraints. — Constraint","text":"constraint object represents region variable valid, e.g. within variable can optimized.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Abstract base class for constraints. — Constraint","text":"Constraint$check() Constraint$print() Constraint$clone()","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"method-check-","dir":"Reference","previous_headings":"","what":"Method check()","title":"Abstract base class for constraints. — Constraint","text":"Returns byte tensor sample_shape + batch_shape indicating whether event value satisfies constraint.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Abstract base class for constraints. — Constraint","text":"","code":"Constraint$check(value)"},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Abstract base class for constraints. — Constraint","text":"value event value checked.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"Abstract base class for constraints. — Constraint","text":"Define print method constraints,","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Abstract base class for constraints. — Constraint","text":"","code":"Constraint$print()"},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Abstract base class for constraints. — Constraint","text":"objects class cloneable method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Abstract base class for constraints. — Constraint","text":"","code":"Constraint$clone(deep = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/Constraint.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Abstract base class for constraints. — Constraint","text":"deep Whether make deep clone.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic R6 class representing distributions — Distribution","title":"Generic R6 class representing distributions — Distribution","text":"Distribution abstract base class probability distributions. Note: Python, adding torch.Size objects works concatenation Try example: torch.Size((2, 1)) + torch.Size((1,))","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Generic R6 class representing distributions — Distribution","text":".validate_args whether validate arguments has_rsample whether rsample has_enumerate_support whether enumerate support","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"active-bindings","dir":"Reference","previous_headings":"","what":"Active bindings","title":"Generic R6 class representing distributions — Distribution","text":"batch_shape Returns shape parameters batched. event_shape Returns shape single sample (without batching). Returns dictionary argument names torch_Constraint objects satisfied argument distribution. Args tensors need appear dict. support Returns torch_Constraint object representing distribution's support. mean Returns mean distribution variance Returns variance distribution stddev Returns standard deviation distribution TODO: consider different message","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Generic R6 class representing distributions — Distribution","text":"Distribution$new() Distribution$expand() Distribution$sample() Distribution$rsample() Distribution$log_prob() Distribution$cdf() Distribution$icdf() Distribution$enumerate_support() Distribution$entropy() Distribution$perplexity() Distribution$.extended_shape() Distribution$.validate_sample() Distribution$print() Distribution$clone()","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Generic R6 class representing distributions — Distribution","text":"Initializes distribution class.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$new(batch_shape = NULL, event_shape = NULL, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"batch_shape shape parameters batched. event_shape shape single sample (without batching). validate_args whether validate arguments . Validation can time consuming might want disable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-expand-","dir":"Reference","previous_headings":"","what":"Method expand()","title":"Generic R6 class representing distributions — Distribution","text":"Returns new distribution instance (populates existing instance provided derived class) batch dimensions expanded batch_shape. method calls expand distribution’s parameters. , allocate new memory expanded distribution instance. Additionally, repeat args checking parameter broadcasting initialize, instance first created.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$expand(batch_shape, .instance = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"batch_shape desired expanded size. .instance new instance provided subclasses need override expand.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-sample-","dir":"Reference","previous_headings":"","what":"Method sample()","title":"Generic R6 class representing distributions — Distribution","text":"Generates sample_shape shaped sample sample_shape shaped batch samples distribution parameters batched.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$sample(sample_shape = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"sample_shape shape want sample.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-rsample-","dir":"Reference","previous_headings":"","what":"Method rsample()","title":"Generic R6 class representing distributions — Distribution","text":"Generates sample_shape shaped reparameterized sample sample_shape shaped batch reparameterized samples distribution parameters batched.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$rsample(sample_shape = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"sample_shape shape want sample.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-log-prob-","dir":"Reference","previous_headings":"","what":"Method log_prob()","title":"Generic R6 class representing distributions — Distribution","text":"Returns log probability density/mass function evaluated value.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$log_prob(value)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"value values evaluate density .","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-cdf-","dir":"Reference","previous_headings":"","what":"Method cdf()","title":"Generic R6 class representing distributions — Distribution","text":"Returns cumulative density/mass function evaluated value.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$cdf(value)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"value values evaluate density .","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-icdf-","dir":"Reference","previous_headings":"","what":"Method icdf()","title":"Generic R6 class representing distributions — Distribution","text":"Returns inverse cumulative density/mass function evaluated value. @description Returns tensor containing values supported discrete distribution. result enumerate dimension 0, shape result (cardinality,) + batch_shape + event_shape (event_shape = ()univariate distributions). Note enumerates batched tensors lock-steplist(c(0, 0), c(1, 1), ...). expand=FALSE, enumeration happens along dim 0, remaining batch dimensions singleton dimensions, list(c(0), c(1), ...)`.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$icdf(value)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"value values evaluate density .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-7","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$enumerate_support(expand = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-7","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"expand (bool): whether expand support batch dims match distribution's batch_shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Generic R6 class representing distributions — Distribution","text":"Tensor iterating dimension 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-entropy-","dir":"Reference","previous_headings":"","what":"Method entropy()","title":"Generic R6 class representing distributions — Distribution","text":"Returns entropy distribution, batched batch_shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-8","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$entropy()"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Generic R6 class representing distributions — Distribution","text":"Tensor shape batch_shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-perplexity-","dir":"Reference","previous_headings":"","what":"Method perplexity()","title":"Generic R6 class representing distributions — Distribution","text":"Returns perplexity distribution, batched batch_shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-9","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$perplexity()"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"Generic R6 class representing distributions — Distribution","text":"Tensor shape batch_shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-extended-shape-","dir":"Reference","previous_headings":"","what":"Method .extended_shape()","title":"Generic R6 class representing distributions — Distribution","text":"Returns size sample returned distribution, given sample_shape. Note, batch event shapes distribution instance fixed time construction. empty, returned shape upcast (1,).","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-10","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$.extended_shape(sample_shape = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-8","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"sample_shape (torch_Size): size sample drawn.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-validate-sample-","dir":"Reference","previous_headings":"","what":"Method .validate_sample()","title":"Generic R6 class representing distributions — Distribution","text":"Argument validation distribution methods log_prob, cdf icdf. rightmost dimensions value scored via methods must agree distribution's batch event shapes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-11","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$.validate_sample(value)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-9","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"value (Tensor): tensor whose log probability computed log_prob method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-print-","dir":"Reference","previous_headings":"","what":"Method print()","title":"Generic R6 class representing distributions — Distribution","text":"Prints distribution instance.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-12","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$print()"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Generic R6 class representing distributions — Distribution","text":"objects class cloneable method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"usage-13","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic R6 class representing distributions — Distribution","text":"","code":"Distribution$clone(deep = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/Distribution.html","id":"arguments-10","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic R6 class representing distributions — Distribution","text":"deep Whether make deep clone.","code":""},{"path":"https://torch.mlverse.org/docs/reference/as_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts to array — as_array","title":"Converts to array — as_array","text":"Converts array","code":""},{"path":"https://torch.mlverse.org/docs/reference/as_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts to array — as_array","text":"","code":"as_array(x)"},{"path":"https://torch.mlverse.org/docs/reference/as_array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts to array — as_array","text":"x object converted array","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_backward.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","title":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","text":"graph differentiated using chain rule. tensors non-scalar (.e. data one element) require gradient, Jacobian-vector product computed, case function additionally requires specifying grad_tensors. sequence matching length, contains “vector” Jacobian-vector product, usually gradient differentiated function w.r.t. corresponding tensors (None acceptable value tensors don’t need gradient tensors).","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_backward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","text":"","code":"autograd_backward(   tensors,   grad_tensors = NULL,   retain_graph = create_graph,   create_graph = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/autograd_backward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","text":"tensors (list Tensor) – Tensors derivative computed. grad_tensors (list (Tensor NULL)) – “vector” Jacobian-vector product, usually gradients w.r.t. element corresponding tensors. NULLvalues can specified scalar Tensors ones don’t require grad. aNULL` value acceptable grad_tensors, argument optional. retain_graph (bool, optional) – FALSE, graph used compute grad freed. Note nearly cases setting option TRUE needed often can worked around much efficient way. Defaults value create_graph. create_graph (bool, optional) – TRUE, graph derivative constructed, allowing compute higher order derivative products. Defaults FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_backward.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","text":"function accumulates gradients leaves - might need zero calling .","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_backward.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the sum of gradients of given tensors w.r.t. graph leaves. — autograd_backward","text":"","code":"if (torch_is_installed()) { x <- torch_tensor(1, requires_grad = TRUE) y <- 2 * x  a <- torch_tensor(1, requires_grad = TRUE) b <- 3 * a  autograd_backward(list(y, b)) }"},{"path":"https://torch.mlverse.org/docs/reference/autograd_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Records operation history and defines formulas for differentiating ops. — autograd_function","title":"Records operation history and defines formulas for differentiating ops. — autograd_function","text":"Every operation performed Tensor's creates new function object, performs computation, records happened. history retained form DAG functions, edges denoting data dependencies (input <- output). , backward called, graph processed topological ordering, calling backward() methods Function object, passing returned gradients next Function's.","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Records operation history and defines formulas for differentiating ops. — autograd_function","text":"","code":"autograd_function(forward, backward)"},{"path":"https://torch.mlverse.org/docs/reference/autograd_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Records operation history and defines formulas for differentiating ops. — autograd_function","text":"forward Performs operation. must accept context ctx first argument, followed number arguments (tensors types). context can used store tensors can retrieved backward pass. See AutogradContext information context methods. backward Defines formula differentiating operation. must accept context ctx first argument, followed many outputs ad forward() returned (list()). names arguments matter passed order returned forward(). function return named list, argument gradient w.r.t given output, element returned list gradient w.r.t. corresponding input. context can used retrieve tensors saved forward pass. also attribute ctx$needs_input_grad named list booleans representing whether input needs gradient. E.g., backward() ctx$needs_input_grad$input = TRUE input argument forward() needs gradient computated w.r.t. output. See AutogradContext information context methods.","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Records operation history and defines formulas for differentiating ops. — autograd_function","text":"","code":"if (torch_is_installed()) {  exp2 <- autograd_function(   forward = function(ctx, i) {     result <- i$exp()     ctx$save_for_backward(result = result)     result   },   backward = function(ctx, grad_output) {     list(i = grad_output * ctx$saved_variable$result)   } ) }"},{"path":"https://torch.mlverse.org/docs/reference/autograd_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","title":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","text":"grad_outputs list length matching output containing “vector” Jacobian-vector product, usually pre-computed gradients w.r.t. outputs. output doesn’t require_grad, gradient can None).","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","text":"","code":"autograd_grad(   outputs,   inputs,   grad_outputs = NULL,   retain_graph = create_graph,   create_graph = FALSE,   allow_unused = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/autograd_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","text":"outputs (sequence Tensor) – outputs differentiated function. inputs (sequence Tensor) – Inputs w.r.t. gradient returned (accumulated .grad). grad_outputs (sequence Tensor) – “vector” Jacobian-vector product. Usually gradients w.r.t. output. None values can specified scalar Tensors ones don’t require grad. None value acceptable grad_tensors, argument optional. Default: None. retain_graph (bool, optional) – FALSE, graph used compute grad freed. Note nearly cases setting option TRUE needed often can worked around much efficient way. Defaults value create_graph. create_graph (bool, optional) – TRUE, graph derivative constructed, allowing compute higher order derivative products. Default: FALSE`. allow_unused (bool, optional) – FALSE, specifying inputs used computing outputs (therefore grad always zero) error. Defaults FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_grad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","text":"only_inputs TRUE, function return list gradients w.r.t specified inputs. ’s FALSE, gradient w.r.t. remaining leaves still computed, accumulated .grad attribute.","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes and returns the sum of gradients of outputs w.r.t. the inputs. — autograd_grad","text":"","code":"if (torch_is_installed()) { w <- torch_tensor(0.5, requires_grad = TRUE) b <- torch_tensor(0.9, requires_grad = TRUE) x <- torch_tensor(runif(100)) y <- 2 * x + 1 loss <- (y - (w * x + b))^2 loss <- loss$mean()  o <- autograd_grad(loss, list(w, b)) o } #> [[1]] #> torch_tensor #> -0.9935 #> [ CPUFloatType{1} ] #>  #> [[2]] #> torch_tensor #> -1.6206 #> [ CPUFloatType{1} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/autograd_set_grad_mode.html","id":null,"dir":"Reference","previous_headings":"","what":"Set grad mode — autograd_set_grad_mode","title":"Set grad mode — autograd_set_grad_mode","text":"Sets disables gradient history.","code":""},{"path":"https://torch.mlverse.org/docs/reference/autograd_set_grad_mode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set grad mode — autograd_set_grad_mode","text":"","code":"autograd_set_grad_mode(enabled)"},{"path":"https://torch.mlverse.org/docs/reference/autograd_set_grad_mode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set grad mode — autograd_set_grad_mode","text":"enabled bool wether enable disable gradient recording.","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_cudnn_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"CuDNN is available — backends_cudnn_is_available","title":"CuDNN is available — backends_cudnn_is_available","text":"CuDNN available","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_cudnn_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CuDNN is available — backends_cudnn_is_available","text":"","code":"backends_cudnn_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/backends_cudnn_version.html","id":null,"dir":"Reference","previous_headings":"","what":"CuDNN version — backends_cudnn_version","title":"CuDNN version — backends_cudnn_version","text":"CuDNN version","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_cudnn_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CuDNN version — backends_cudnn_version","text":"","code":"backends_cudnn_version()"},{"path":"https://torch.mlverse.org/docs/reference/backends_mkl_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"MKL is available — backends_mkl_is_available","title":"MKL is available — backends_mkl_is_available","text":"MKL available","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_mkl_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MKL is available — backends_mkl_is_available","text":"","code":"backends_mkl_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/backends_mkl_is_available.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MKL is available — backends_mkl_is_available","text":"Returns whether LibTorch built MKL support.","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_mkldnn_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"MKLDNN is available — backends_mkldnn_is_available","title":"MKLDNN is available — backends_mkldnn_is_available","text":"MKLDNN available","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_mkldnn_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MKLDNN is available — backends_mkldnn_is_available","text":"","code":"backends_mkldnn_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/backends_mkldnn_is_available.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MKLDNN is available — backends_mkldnn_is_available","text":"Returns whether LibTorch built MKL-DNN support.","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_mps_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"MPS is available — backends_mps_is_available","title":"MPS is available — backends_mps_is_available","text":"MPS available","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_mps_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MPS is available — backends_mps_is_available","text":"","code":"backends_mps_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/backends_mps_is_available.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MPS is available — backends_mps_is_available","text":"Returns whether LibTorch built MPS support.","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_openmp_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"OpenMP is available — backends_openmp_is_available","title":"OpenMP is available — backends_openmp_is_available","text":"OpenMP available","code":""},{"path":"https://torch.mlverse.org/docs/reference/backends_openmp_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OpenMP is available — backends_openmp_is_available","text":"","code":"backends_openmp_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/backends_openmp_is_available.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OpenMP is available — backends_openmp_is_available","text":"Returns whether LibTorch built OpenMP support.","code":""},{"path":"https://torch.mlverse.org/docs/reference/broadcast_all.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a list of values (possibly containing numbers), returns a list where each value is broadcasted based on the following rules: — broadcast_all","title":"Given a list of values (possibly containing numbers), returns a list where each value is broadcasted based on the following rules: — broadcast_all","text":"Raises value_error: values numeric instance, torch.*Tensor instance, instance implementing torch_function TODO: add has_torch_function((v,)) See: https://github.com/pytorch/pytorch/blob/master/torch/distributions/utils.py","code":""},{"path":"https://torch.mlverse.org/docs/reference/broadcast_all.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a list of values (possibly containing numbers), returns a list where each value is broadcasted based on the following rules: — broadcast_all","text":"","code":"broadcast_all(values)"},{"path":"https://torch.mlverse.org/docs/reference/broadcast_all.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a list of values (possibly containing numbers), returns a list where each value is broadcasted based on the following rules: — broadcast_all","text":"values List : torch.*Tensor instances broadcasted per _broadcasting-semantics. numeric instances (scalars) upcast tensors size type first tensor passed values.  values scalars, upcasted scalar Tensors. values (list numeric, torch.*Tensor objects implementing torch_function)","code":""},{"path":"https://torch.mlverse.org/docs/reference/call_torch_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a (Potentially Unexported) Torch Function — call_torch_function","title":"Call a (Potentially Unexported) Torch Function — call_torch_function","text":"function allows calling function prefixed torch_, including unexported functions potentially valuable uses yet user-friendly R wrapper function. Therefore, function used extreme caution. Make sure understand function expects input. may helpful read torch source code help , well documentation corresponding function Pytorch C++ API. Generally development advanced use .","code":""},{"path":"https://torch.mlverse.org/docs/reference/call_torch_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a (Potentially Unexported) Torch Function — call_torch_function","text":"","code":"call_torch_function(name, ..., quiet = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/call_torch_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a (Potentially Unexported) Torch Function — call_torch_function","text":"name Name function call string. start \"torch_\" ... list arguments pass function. Argument splicing !!! supported. quiet TRUE, suppress warnings valuable information dangers function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/call_torch_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a (Potentially Unexported) Torch Function — call_torch_function","text":"return value calling function name arguments ...","code":""},{"path":"https://torch.mlverse.org/docs/reference/call_torch_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Call a (Potentially Unexported) Torch Function — call_torch_function","text":"","code":"if (torch_is_installed()) { ## many unexported functions do 'backward' calculations (e.g. derivatives) ## These could be used as a part of custom autograd functions for example. x <- torch_randn(10, requires_grad = TRUE) y <- torch_tanh(x) ## calculate backwards gradient using standard torch method y$backward(torch_ones_like(x)) x$grad ## we can get the same result by calling the unexported `torch_tanh_backward()` ## function. The first argument is 1 to setup the Jacobian-vector product. ## see https://pytorch.org/blog/overview-of-pytorch-autograd-engine/ for details. call_torch_function(\"torch_tanh_backward\", 1, y) all.equal(call_torch_function(\"torch_tanh_backward\", 1, y, quiet = TRUE), x$grad)  } #> Warning: Because this function allows access to unexported functions, please use with caution, and #>             only if you are sure know what you are doing. Unexported functions will expect inputs that #>             are more C++-like than R-like. For example, they will expect all indexes to be 0-based instead #>             of 1-based. In addition unexported functions may be subject to removal from the API without #>             warning. Set quiet = TRUE to silence this warning. #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/clone_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Clone a torch module. — clone_module","title":"Clone a torch module. — clone_module","text":"Clones module.","code":""},{"path":"https://torch.mlverse.org/docs/reference/clone_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clone a torch module. — clone_module","text":"","code":"clone_module(module, deep = FALSE, ..., replace_values = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/clone_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clone a torch module. — clone_module","text":"module (nn_module) module clone deep (logical(1)) Whether create deep clone. ... () Additional parameters, currently unused. replace_values (logical(1)) Whether replace parameters buffers cloned values.","code":""},{"path":"https://torch.mlverse.org/docs/reference/clone_module.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clone a torch module. — clone_module","text":"","code":"if (torch_is_installed()) { clone_module(nn_linear(1, 1), deep = TRUE) # is the same as nn_linear(1, 1)$clone(deep = TRUE) } #> An `nn_module` containing 2 parameters. #>  #> ── Parameters ────────────────────────────────────────────────────────────────── #> • weight: Float [1:1, 1:1] #> • bias: Float [1:1]"},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":null,"dir":"Reference","previous_headings":"","what":"Contrib sort vertices — contrib_sort_vertices","title":"Contrib sort vertices — contrib_sort_vertices","text":"Based implementation Rotated_IoU","code":""},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contrib sort vertices — contrib_sort_vertices","text":"","code":"contrib_sort_vertices(vertices, mask, num_valid)"},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contrib sort vertices — contrib_sort_vertices","text":"vertices Tensor vertices. mask tensors containing masks. num_valid integer tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Contrib sort vertices — contrib_sort_vertices","text":"tensors CUDA device function can used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Contrib sort vertices — contrib_sort_vertices","text":"function make part official torch API.","code":""},{"path":"https://torch.mlverse.org/docs/reference/contrib_sort_vertices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contrib sort vertices — contrib_sort_vertices","text":"","code":"if (torch_is_installed()) { if (cuda_is_available()) {   v <- torch_randn(8, 1024, 24, 2)$cuda()   mean <- torch_mean(v, dim = 2, keepdim = TRUE)   v <- v - mean   m <- (torch_rand(8, 1024, 24) > 0.8)$cuda()   nv <- torch_sum(m$to(dtype = torch_int()), dim = -1)$to(dtype = torch_int())$cuda()   result <- contrib_sort_vertices(v, m, nv) } }"},{"path":"https://torch.mlverse.org/docs/reference/cuda_amp_grad_scaler.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a gradient scaler — cuda_amp_grad_scaler","title":"Creates a gradient scaler — cuda_amp_grad_scaler","text":"gradient scaler instance used perform dynamic gradient scaling avoid gradient underflow training mixed precision.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_amp_grad_scaler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a gradient scaler — cuda_amp_grad_scaler","text":"","code":"cuda_amp_grad_scaler(   init_scale = 2^16,   growth_factor = 2,   backoff_factor = 0.5,   growth_interval = 2000,   enabled = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/cuda_amp_grad_scaler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a gradient scaler — cuda_amp_grad_scaler","text":"init_scale numeric value indicating initial scale factor. growth_factor numeric value indicating growth factor. backoff_factor numeric value indicating backoff factor. growth_interval numeric value indicating growth interval. enabled logical value indicating whether gradient scaler enabled.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_amp_grad_scaler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a gradient scaler — cuda_amp_grad_scaler","text":"gradient scaler object.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_current_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the index of a currently selected device. — cuda_current_device","title":"Returns the index of a currently selected device. — cuda_current_device","text":"Returns index currently selected device.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_current_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the index of a currently selected device. — cuda_current_device","text":"","code":"cuda_current_device()"},{"path":"https://torch.mlverse.org/docs/reference/cuda_device_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the number of GPUs available. — cuda_device_count","title":"Returns the number of GPUs available. — cuda_device_count","text":"Returns number GPUs available.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_device_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the number of GPUs available. — cuda_device_count","text":"","code":"cuda_device_count()"},{"path":"https://torch.mlverse.org/docs/reference/cuda_empty_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty cache — cuda_empty_cache","title":"Empty cache — cuda_empty_cache","text":"Releases unoccupied cached memory currently held caching allocator can used GPU application visible nvidia-smi.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_empty_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty cache — cuda_empty_cache","text":"","code":"cuda_empty_cache()"},{"path":"https://torch.mlverse.org/docs/reference/cuda_empty_cache.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Empty cache — cuda_empty_cache","text":"cuda_empty_cache() doesn’t increase amount GPU memory available torch. However, may help reduce fragmentation GPU memory certain cases. See Memory management article details GPU memory management.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_get_device_capability.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the major and minor CUDA capability of device — cuda_get_device_capability","title":"Returns the major and minor CUDA capability of device — cuda_get_device_capability","text":"Returns major minor CUDA capability device","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_get_device_capability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the major and minor CUDA capability of device — cuda_get_device_capability","text":"","code":"cuda_get_device_capability(device = cuda_current_device())"},{"path":"https://torch.mlverse.org/docs/reference/cuda_get_device_capability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the major and minor CUDA capability of device — cuda_get_device_capability","text":"device Integer value CUDA device return capabilities .","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_is_available.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a bool indicating if CUDA is currently available. — cuda_is_available","title":"Returns a bool indicating if CUDA is currently available. — cuda_is_available","text":"Returns bool indicating CUDA currently available.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_is_available.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a bool indicating if CUDA is currently available. — cuda_is_available","text":"","code":"cuda_is_available()"},{"path":"https://torch.mlverse.org/docs/reference/cuda_memory_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","title":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","text":"return value function dictionary statistics, non-negative integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_memory_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","text":"","code":"cuda_memory_stats(device = cuda_current_device())  cuda_memory_summary(device = cuda_current_device())"},{"path":"https://torch.mlverse.org/docs/reference/cuda_memory_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","text":"device Integer value CUDA device return capabilities .","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_memory_stats.html","id":"core-statistics","dir":"Reference","previous_headings":"","what":"Core statistics","title":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","text":"\"allocated.{,large_pool,small_pool}.{current,peak,allocated,freed}\": number allocation requests received memory allocator. \"allocated_bytes.{,large_pool,small_pool}.{current,peak,allocated,freed}\": amount allocated memory. \"segment.{,large_pool,small_pool}.{current,peak,allocated,freed}\": number reserved segments cudaMalloc(). \"reserved_bytes.{,large_pool,small_pool}.{current,peak,allocated,freed}\": amount reserved memory. \"active.{,large_pool,small_pool}.{current,peak,allocated,freed}\": number active memory blocks. \"active_bytes.{,large_pool,small_pool}.{current,peak,allocated,freed}\": amount active memory. \"inactive_split.{,large_pool,small_pool}.{current,peak,allocated,freed}\": number inactive, non-releasable memory blocks. \"inactive_split_bytes.{,large_pool,small_pool}.{current,peak,allocated,freed}\": amount inactive, non-releasable memory. core statistics, values broken follows. Pool type: : combined statistics across memory pools. large_pool: statistics large allocation pool (October 2019, size >= 1MB allocations). small_pool: statistics small allocation pool (October 2019, size < 1MB allocations). Metric type: current: current value metric. peak: maximum value metric. allocated: historical total increase metric. freed: historical total decrease metric.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_memory_stats.html","id":"additional-metrics","dir":"Reference","previous_headings":"","what":"Additional metrics","title":"Returns a dictionary of CUDA memory allocator statistics for a given device. — cuda_memory_stats","text":"\"num_alloc_retries\": number failed cudaMalloc calls result cache flush retry. \"num_ooms\": number --memory errors thrown.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_runtime_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the CUDA runtime version — cuda_runtime_version","title":"Returns the CUDA runtime version — cuda_runtime_version","text":"Returns CUDA runtime version","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_runtime_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the CUDA runtime version — cuda_runtime_version","text":"","code":"cuda_runtime_version()"},{"path":"https://torch.mlverse.org/docs/reference/cuda_synchronize.html","id":null,"dir":"Reference","previous_headings":"","what":"Waits for all kernels in all streams on a CUDA device to complete. — cuda_synchronize","title":"Waits for all kernels in all streams on a CUDA device to complete. — cuda_synchronize","text":"Waits kernels streams CUDA device complete.","code":""},{"path":"https://torch.mlverse.org/docs/reference/cuda_synchronize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Waits for all kernels in all streams on a CUDA device to complete. — cuda_synchronize","text":"","code":"cuda_synchronize(device = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/cuda_synchronize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Waits for all kernels in all streams on a CUDA device to complete. — cuda_synchronize","text":"device device synchronize. uses current device given cuda_current_device() device specified.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. — dataloader","title":"Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. — dataloader","text":"Data loader. Combines dataset sampler, provides single- multi-process iterators dataset.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. — dataloader","text":"","code":"dataloader(   dataset,   batch_size = 1,   shuffle = FALSE,   sampler = NULL,   batch_sampler = NULL,   num_workers = 0,   collate_fn = NULL,   pin_memory = FALSE,   drop_last = FALSE,   timeout = -1,   worker_init_fn = NULL,   worker_globals = NULL,   worker_packages = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/dataloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. — dataloader","text":"dataset (Dataset): dataset load data. batch_size (int, optional): many samples per batch load (default: 1). shuffle (bool, optional): set TRUE data reshuffled every epoch (default: FALSE). sampler (Sampler, optional): defines strategy draw samples dataset. specified, shuffle must False. Custom samplers can created sampler(). batch_sampler (Sampler, optional): like sampler, returns batch indices time. Mutually exclusive batch_size, shuffle, sampler, drop_last. Custom samplers can created sampler(). num_workers (int, optional): many subprocesses use data loading. 0 means data loaded main process. (default: 0) collate_fn (callable, optional): merges list samples form mini-batch. pin_memory (bool, optional): TRUE, data loader copy tensors CUDA pinned memory returning .  data elements custom type, collate_fn returns batch custom type see example . drop_last (bool, optional): set TRUE drop last incomplete batch, dataset size divisible batch size. FALSE size dataset divisible batch size, last batch smaller. (default: FALSE) timeout (numeric, optional): positive, timeout value collecting batch workers. -1 means timeout. (default: -1) worker_init_fn (callable, optional): NULL, called worker subprocess worker id (int [1, num_workers]) input, seeding data loading. (default: NULL) worker_globals (list character vector, optional) used num_workers > 0. character vector, objects names copied global environment workers. named list, list copied attached worker global environment. Notice objects copied worker initialization. worker_packages (character vector, optional) used num_workers > 0 optional character vector naming packages loaded worker.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader.html","id":"parallel-data-loading","dir":"Reference","previous_headings":"","what":"Parallel data loading","title":"Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. — dataloader","text":"using num_workers > 0 data loading happen parallel worker. Note batches taken parallel observations. worker initialization  process happens following order: num_workers R sessions initialized. worker perform following actions: torch library loaded. random seed set using set.seed() using torch_manual_seed. packages passed worker_packages argument loaded. objects passed trough worker_globals parameters copied global environment. worker_init function ran id argument. dataset fetcher copied worker.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/dataloader_make_iter.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an iterator from a DataLoader — dataloader_make_iter","title":"Creates an iterator from a DataLoader — dataloader_make_iter","text":"Creates iterator DataLoader","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader_make_iter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an iterator from a DataLoader — dataloader_make_iter","text":"","code":"dataloader_make_iter(dataloader)"},{"path":"https://torch.mlverse.org/docs/reference/dataloader_make_iter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an iterator from a DataLoader — dataloader_make_iter","text":"dataloader dataloader object.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader_next.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the next element of a dataloader iterator — dataloader_next","title":"Get the next element of a dataloader iterator — dataloader_next","text":"Get next element dataloader iterator","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataloader_next.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the next element of a dataloader iterator — dataloader_next","text":"","code":"dataloader_next(iter, completed = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/dataloader_next.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the next element of a dataloader iterator — dataloader_next","text":"iter DataLoader iter created dataloader_make_iter. completed returned value iterator exhausted.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create an function that generates R6 instances of class dataset — dataset","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"datasets represent map keys data samples subclass class. subclasses overwrite .getitem() method, supports fetching data sample given key. Subclasses also optionally overwrite .length(), expected return size dataset (e.g. number samples) used many sampler implementations default options dataloader().","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"","code":"dataset(   name = NULL,   inherit = Dataset,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"name name dataset. also used class . inherit can optionally inherit dataset creating new dataset. ... public methods dataset class private passed R6::R6Class(). active passed R6::R6Class(). parent_env environment use parent newly-created objects.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"output function f class dataset_generator. Calling f() creates new instance R6 class dataset. R6 class stored enclosing environment f can also accessed fs attribute Dataset.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"dataloader()  default constructs index sampler yields integral indices.  make work map-style dataset non-integral indices/keys, custom sampler must provided.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset.html","id":"get-a-batch-of-observations","dir":"Reference","previous_headings":"","what":"Get a batch of observations","title":"Helper function to create an function that generates R6 instances of class dataset — dataset","text":"default datasets iterated returning observation/item individually. Often possible optimized implementation take batch observations (eg, subsetting tensor multiple indexes faster subsetting index), case can implement .getbatch method used instead .getitem getting batch observations within dataloader. .getbatch must work batches size larger equal 1 care must taken drop batch dimension queried length 1 batch index - instance using drop=FALSE. .getitem() expected include batch dimension added datalaoder. see vignette(\"loading-data\").","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset_subset.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset Subset — dataset_subset","title":"Dataset Subset — dataset_subset","text":"Subset dataset specified indices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/dataset_subset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset Subset — dataset_subset","text":"","code":"dataset_subset(dataset, indices)"},{"path":"https://torch.mlverse.org/docs/reference/dataset_subset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataset Subset — dataset_subset","text":"dataset (Dataset): whole Dataset indices (sequence): Indices whole set selected subset","code":""},{"path":"https://torch.mlverse.org/docs/reference/default_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets and sets the default floating point dtype. — torch_set_default_dtype","title":"Gets and sets the default floating point dtype. — torch_set_default_dtype","text":"Gets sets default floating point dtype.","code":""},{"path":"https://torch.mlverse.org/docs/reference/default_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets and sets the default floating point dtype. — torch_set_default_dtype","text":"","code":"torch_set_default_dtype(d)  torch_get_default_dtype()"},{"path":"https://torch.mlverse.org/docs/reference/default_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets and sets the default floating point dtype. — torch_set_default_dtype","text":"d default floating point dtype set. Initially set torch_float().","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a Bernoulli distribution parameterized by probs or logits (but not both). Samples are binary (0 or 1). They take the value 1 with probability p and 0 with probability 1 - p. — distr_bernoulli","title":"Creates a Bernoulli distribution parameterized by probs or logits (but not both). Samples are binary (0 or 1). They take the value 1 with probability p and 0 with probability 1 - p. — distr_bernoulli","text":"Creates Bernoulli distribution parameterized probs logits (). Samples binary (0 1). take value 1 probability p 0 probability 1 - p.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a Bernoulli distribution parameterized by probs or logits (but not both). Samples are binary (0 or 1). They take the value 1 with probability p and 0 with probability 1 - p. — distr_bernoulli","text":"","code":"distr_bernoulli(probs = NULL, logits = NULL, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a Bernoulli distribution parameterized by probs or logits (but not both). Samples are binary (0 or 1). They take the value 1 with probability p and 0 with probability 1 - p. — distr_bernoulli","text":"probs (numeric torch_tensor): probability sampling 1 logits (numeric torch_tensor): log-odds sampling 1 validate_args whether validate arguments .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a Bernoulli distribution parameterized by probs or logits (but not both). Samples are binary (0 or 1). They take the value 1 with probability p and 0 with probability 1 - p. — distr_bernoulli","text":"","code":"if (torch_is_installed()) { m <- distr_bernoulli(0.3) m$sample() # 30% chance 1; 70% chance 0 } #> torch_tensor #>  1 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_categorical.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","title":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","text":"Creates categorical distribution parameterized either probs logits ().","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_categorical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","text":"","code":"distr_categorical(probs = NULL, logits = NULL, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_categorical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","text":"probs (Tensor): event probabilities logits (Tensor): event log probabilities (unnormalized) validate_args Additional arguments","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_categorical.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","text":"equivalent distribution torch_multinomial() samples . Samples integers \\(\\{0, \\ldots, K-1\\}\\) K probs$size(-1). probs 1-dimensional length-K, element relative probability sampling class index. probs N-dimensional, first N-1 dimensions treated batch relative probability vectors. probs argument must non-negative, finite non-zero sum, normalized sum 1 along last dimension. attr:probs return normalized value. logits argument interpreted unnormalized log probabilities can therefore real number. likewise normalized resulting probabilities sum 1 along last dimension. attr:logits return normalized value. See also: torch_multinomial()","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_categorical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a categorical distribution parameterized by either probs or logits (but not both). — distr_categorical","text":"","code":"if (torch_is_installed()) { m <- distr_categorical(torch_tensor(c(0.25, 0.25, 0.25, 0.25))) m$sample() # equal probability of 1,2,3,4 } #> torch_tensor #> 4 #> [ CPULongType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_chi2.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a Chi2 distribution parameterized by shape parameter df. This is exactly equivalent to distr_gamma(alpha=0.5*df, beta=0.5) — distr_chi2","title":"Creates a Chi2 distribution parameterized by shape parameter df. This is exactly equivalent to distr_gamma(alpha=0.5*df, beta=0.5) — distr_chi2","text":"Creates Chi2 distribution parameterized shape parameter df. exactly equivalent distr_gamma(alpha=0.5*df, beta=0.5)","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_chi2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a Chi2 distribution parameterized by shape parameter df. This is exactly equivalent to distr_gamma(alpha=0.5*df, beta=0.5) — distr_chi2","text":"","code":"distr_chi2(df, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_chi2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a Chi2 distribution parameterized by shape parameter df. This is exactly equivalent to distr_gamma(alpha=0.5*df, beta=0.5) — distr_chi2","text":"df (float torch_tensor): shape parameter distribution validate_args whether validate arguments .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_chi2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a Chi2 distribution parameterized by shape parameter df. This is exactly equivalent to distr_gamma(alpha=0.5*df, beta=0.5) — distr_chi2","text":"","code":"if (torch_is_installed()) { m <- distr_chi2(torch_tensor(1.0)) m$sample() # Chi2 distributed with shape df=1 torch_tensor(0.1046) } #> torch_tensor #>  0.1046 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_gamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a Gamma distribution parameterized by shape concentration and rate. — distr_gamma","title":"Creates a Gamma distribution parameterized by shape concentration and rate. — distr_gamma","text":"Creates Gamma distribution parameterized shape concentration rate.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_gamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a Gamma distribution parameterized by shape concentration and rate. — distr_gamma","text":"","code":"distr_gamma(concentration, rate, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_gamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a Gamma distribution parameterized by shape concentration and rate. — distr_gamma","text":"concentration (float Tensor): shape parameter distribution (often referred alpha) rate (float Tensor): rate = 1 / scale distribution (often referred beta) validate_args whether validate arguments .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_gamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a Gamma distribution parameterized by shape concentration and rate. — distr_gamma","text":"","code":"if (torch_is_installed()) { m <- distr_gamma(torch_tensor(1.0), torch_tensor(1.0)) m$sample() # Gamma distributed with concentration=1 and rate=1 } #> torch_tensor #>  2.0188 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_mixture_same_family.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixture of components in the same family — distr_mixture_same_family","title":"Mixture of components in the same family — distr_mixture_same_family","text":"MixtureSameFamily distribution implements (batch ) mixture distribution component different parameterizations distribution type. parameterized Categorical selecting distribution\" (k component) component distribution, .e., Distribution rightmost batch shape (equal [k]) indexes (batch ) component.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_mixture_same_family.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixture of components in the same family — distr_mixture_same_family","text":"","code":"distr_mixture_same_family(   mixture_distribution,   component_distribution,   validate_args = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/distr_mixture_same_family.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixture of components in the same family — distr_mixture_same_family","text":"mixture_distribution torch_distributions.Categorical-like instance. Manages probability selecting component. number categories must match rightmost batch dimension component_distribution. Must either scalar batch_shape batch_shape matching component_distribution.batch_shape[:-1] component_distribution torch_distributions.Distribution-like instance. Right-batch dimension indexes component. validate_args Additional arguments","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_mixture_same_family.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixture of components in the same family — distr_mixture_same_family","text":"","code":"if (torch_is_installed()) { # Construct Gaussian Mixture Model in 1D consisting of 5 equally # weighted normal distributions mix <- distr_categorical(torch_ones(5)) comp <- distr_normal(torch_randn(5), torch_rand(5)) gmm <- distr_mixture_same_family(mix, comp) }"},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian distribution — distr_multivariate_normal","title":"Gaussian distribution — distr_multivariate_normal","text":"Creates multivariate normal (also called Gaussian) distribution parameterized mean vector covariance matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian distribution — distr_multivariate_normal","text":"","code":"distr_multivariate_normal(   loc,   covariance_matrix = NULL,   precision_matrix = NULL,   scale_tril = NULL,   validate_args = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian distribution — distr_multivariate_normal","text":"loc (Tensor): mean distribution covariance_matrix (Tensor): positive-definite covariance matrix precision_matrix (Tensor): positive-definite precision matrix scale_tril (Tensor): lower-triangular factor covariance, positive-valued diagonal validate_args Bool wether validate arguments .","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian distribution — distr_multivariate_normal","text":"multivariate normal distribution can parameterized either terms positive definite covariance matrix \\(\\mathbf{\\Sigma}\\) positive definite precision matrix \\(\\mathbf{\\Sigma}^{-1}\\) lower-triangular matrix \\(\\mathbf{L}\\) positive-valued diagonal entries, \\(\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top\\). triangular matrix can obtained via e.g. Cholesky decomposition covariance.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Gaussian distribution — distr_multivariate_normal","text":"one covariance_matrix precision_matrix scale_tril can specified. Using scale_tril efficient: computations internally based scale_tril. covariance_matrix precision_matrix passed instead, used compute corresponding lower triangular matrices using Cholesky decomposition.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_multivariate_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian distribution — distr_multivariate_normal","text":"","code":"if (torch_is_installed()) { m <- distr_multivariate_normal(torch_zeros(2), torch_eye(2)) m$sample() # normally distributed with mean=`[0,0]` and covariance_matrix=`I` } #> torch_tensor #>  0.2418 #>  1.1116 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","title":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","text":"Creates normal (also called Gaussian) distribution parameterized loc scale.","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","text":"","code":"distr_normal(loc, scale, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","text":"loc (float Tensor): mean distribution (often referred mu) scale (float Tensor): standard deviation distribution (often referred sigma) validate_args Additional arguments","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_normal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","text":"Object torch_Normal class","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a normal (also called Gaussian) distribution parameterized by loc and scale. — distr_normal","text":"","code":"if (torch_is_installed()) { m <- distr_normal(loc = 0, scale = 1) m$sample() # normally distributed with loc=0 and scale=1 } #> torch_tensor #>  1.3422 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/distr_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a Poisson distribution parameterized by rate, the rate parameter. — distr_poisson","title":"Creates a Poisson distribution parameterized by rate, the rate parameter. — distr_poisson","text":"Samples nonnegative integers, pmf given $$ \\mbox{rate}^{k} \\frac{e^{-\\mbox{rate}}}{k!} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/distr_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a Poisson distribution parameterized by rate, the rate parameter. — distr_poisson","text":"","code":"distr_poisson(rate, validate_args = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/distr_poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a Poisson distribution parameterized by rate, the rate parameter. — distr_poisson","text":"rate (numeric, torch_tensor): rate parameter validate_args whether validate arguments .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/distr_poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a Poisson distribution parameterized by rate, the rate parameter. — distr_poisson","text":"","code":"if (torch_is_installed()) { m <- distr_poisson(torch_tensor(4)) m$sample() } #> torch_tensor #>  5 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/enumerate.dataloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Enumerate an iterator — enumerate.dataloader","title":"Enumerate an iterator — enumerate.dataloader","text":"Enumerate iterator","code":""},{"path":"https://torch.mlverse.org/docs/reference/enumerate.dataloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enumerate an iterator — enumerate.dataloader","text":"","code":"# S3 method for dataloader enumerate(x, max_len = 1e+06, ...)"},{"path":"https://torch.mlverse.org/docs/reference/enumerate.dataloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enumerate an iterator — enumerate.dataloader","text":"x generator enumerate. max_len maximum number iterations. ... passed specific methods.","code":""},{"path":"https://torch.mlverse.org/docs/reference/enumerate.html","id":null,"dir":"Reference","previous_headings":"","what":"Enumerate an iterator — enumerate","title":"Enumerate an iterator — enumerate","text":"Enumerate iterator","code":""},{"path":"https://torch.mlverse.org/docs/reference/enumerate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enumerate an iterator — enumerate","text":"","code":"enumerate(x, ...)"},{"path":"https://torch.mlverse.org/docs/reference/enumerate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enumerate an iterator — enumerate","text":"x generator enumerate. ... passed specific methods.","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Torch — install_torch","title":"Install Torch — install_torch","text":"Installs Torch dependencies.","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Torch — install_torch","text":"","code":"install_torch(reinstall = FALSE, ..., .inform_restart = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/install_torch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install Torch — install_torch","text":"reinstall Re-install Torch even already installed? ... Currently unused. .inform_restart TRUE running interactive() session, installation print message inform user session must restarted torch work correctly.","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Install Torch — install_torch","text":"function mainly controlled environment variables can used override defaults: TORCH_HOME: installation path. default dependencies installed within package directory. Eg given system.file(package=\"torch\"). TORCH_URL: URL, path ZIP file directory containing LibTorch version. Files installed/copied TORCH_HOME directory. LANTERN_URL: TORCH_URL Lantern library. TORCH_INSTALL_DEBUG: Setting 1, shows debug log messages installation. PRECXX11ABI: Setting 1 trigger installation Pre-cxx11 ABI installation LibTorch. can useful environments older versions GLIBC like CentOS7 older Debian/Ubuntu versions. LANTERN_BASE_URL: base URL lantern files. allows passing directory lantern binaries located. filename constructed usual. TORCH_COMMIT_SHA: torch repository commit sha used querying lantern uploads. Set 'none' avoid looking build commit use latest build branch. CUDA: try automatically detect CUDA version installed system, might want manually set . can also disable CUDA installation setting 'cpu'. TORCH_R_VERSION: R torch version. unlikely need change , can useful R package installed, want install dependencies. TORCH_INSTALL environment variable can set 0 prevent auto-installing torch TORCH_LOAD set 0 avoid loading dependencies automatically. environment variables meant advanced use cases troubleshooting . timeout error occurs library archive download, length downloaded files differ reported length, increase timeout value help.","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch_from_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Install Torch from files — get_install_libs_url","title":"Install Torch from files — get_install_libs_url","text":"List Torch Lantern libraries URLs download local files order proceed  install_torch_from_file(). Installs Torch dependencies files.","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch_from_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Install Torch from files — get_install_libs_url","text":"","code":"get_install_libs_url(version = NA, type = NA)  install_torch_from_file(version = NA, type = NA, libtorch, liblantern, ...)"},{"path":"https://torch.mlverse.org/docs/reference/install_torch_from_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Install Torch from files — get_install_libs_url","text":"version used type used. function deprecated. libtorch installation archive file use Torch. Shall \"file://\" URL scheme. liblantern installation archive file use Lantern. Shall \"file://\" URL scheme. ... parameters passed \"install_torch()\"","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch_from_file.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Install Torch from files — get_install_libs_url","text":"\"install_torch()\" initiated download possible, installation archive files present local filesystem, \"install_torch_from_file()\" can used workaround installation issue. \"libtorch\" archive containing torch modules, \"liblantern\" C interface libtorch used R package. highly dependent, checked \"get_install_libs_url()\"","code":""},{"path":"https://torch.mlverse.org/docs/reference/install_torch_from_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Install Torch from files — get_install_libs_url","text":"","code":"if (torch_is_installed()) { if (FALSE) { # on a linux CPU platform  get_install_libs_url() # then after making both files available into /tmp/ Sys.setenv(TORCH_URL=\"/tmp/libtorch-v1.13.1.zip\") Sys.setenv(LANTERN_URL=\"/tmp/lantern-0.9.1.9001+cpu+arm64-Darwin.zip\") torch::install_torch() } }"},{"path":"https://torch.mlverse.org/docs/reference/is_dataloader.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if the object is a dataloader — is_dataloader","title":"Checks if the object is a dataloader — is_dataloader","text":"Checks object dataloader","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_dataloader.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if the object is a dataloader — is_dataloader","text":"","code":"is_dataloader(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_dataloader.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if the object is a dataloader — is_dataloader","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_buffer.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if the object is a nn_buffer — is_nn_buffer","title":"Checks if the object is a nn_buffer — is_nn_buffer","text":"Checks object nn_buffer","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_buffer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if the object is a nn_buffer — is_nn_buffer","text":"","code":"is_nn_buffer(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_nn_buffer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if the object is a nn_buffer — is_nn_buffer","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if the object is an nn_module — is_nn_module","title":"Checks if the object is an nn_module — is_nn_module","text":"Checks object nn_module","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if the object is an nn_module — is_nn_module","text":"","code":"is_nn_module(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_nn_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if the object is an nn_module — is_nn_module","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_parameter.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if an object is a nn_parameter — is_nn_parameter","title":"Checks if an object is a nn_parameter — is_nn_parameter","text":"Checks object nn_parameter","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_nn_parameter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if an object is a nn_parameter — is_nn_parameter","text":"","code":"is_nn_parameter(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_nn_parameter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if an object is a nn_parameter — is_nn_parameter","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_optimizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if the object is a torch optimizer — is_optimizer","title":"Checks if the object is a torch optimizer — is_optimizer","text":"Checks object torch optimizer","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_optimizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if the object is a torch optimizer — is_optimizer","text":"","code":"is_optimizer(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_optimizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if the object is a torch optimizer — is_optimizer","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if object is a device — is_torch_device","title":"Checks if object is a device — is_torch_device","text":"Checks object device","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if object is a device — is_torch_device","text":"","code":"is_torch_device(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_torch_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if object is a device — is_torch_device","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is a torch data type — is_torch_dtype","title":"Check if object is a torch data type — is_torch_dtype","text":"Check object torch data type","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is a torch data type — is_torch_dtype","text":"","code":"is_torch_dtype(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_torch_dtype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is a torch data type — is_torch_dtype","text":"x object check.","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_layout.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an object is a torch layout. — is_torch_layout","title":"Check if an object is a torch layout. — is_torch_layout","text":"Check object torch layout.","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_layout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an object is a torch layout. — is_torch_layout","text":"","code":"is_torch_layout(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_torch_layout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an object is a torch layout. — is_torch_layout","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_memory_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an object is a memory format — is_torch_memory_format","title":"Check if an object is a memory format — is_torch_memory_format","text":"Check object memory format","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_memory_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an object is a memory format — is_torch_memory_format","text":"","code":"is_torch_memory_format(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_torch_memory_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an object is a memory format — is_torch_memory_format","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_qscheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if an object is a QScheme — is_torch_qscheme","title":"Checks if an object is a QScheme — is_torch_qscheme","text":"Checks object QScheme","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_torch_qscheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if an object is a QScheme — is_torch_qscheme","text":"","code":"is_torch_qscheme(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_torch_qscheme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if an object is a QScheme — is_torch_qscheme","text":"x object check","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_undefined_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if a tensor is undefined — is_undefined_tensor","title":"Checks if a tensor is undefined — is_undefined_tensor","text":"Checks tensor undefined","code":""},{"path":"https://torch.mlverse.org/docs/reference/is_undefined_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if a tensor is undefined — is_undefined_tensor","text":"","code":"is_undefined_tensor(x)"},{"path":"https://torch.mlverse.org/docs/reference/is_undefined_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if a tensor is undefined — is_undefined_tensor","text":"x tensor check","code":""},{"path":"https://torch.mlverse.org/docs/reference/iterable_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an iterable dataset — iterable_dataset","title":"Creates an iterable dataset — iterable_dataset","text":"Creates iterable dataset","code":""},{"path":"https://torch.mlverse.org/docs/reference/iterable_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an iterable dataset — iterable_dataset","text":"","code":"iterable_dataset(   name,   inherit = IterableDataset,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/iterable_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an iterable dataset — iterable_dataset","text":"name name dataset. also used class . inherit can optionally inherit dataset creating new dataset. ... public methods dataset class private passed R6::R6Class(). active passed R6::R6Class(). parent_env environment use parent newly-created objects.","code":""},{"path":"https://torch.mlverse.org/docs/reference/iterable_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates an iterable dataset — iterable_dataset","text":"","code":"if (torch_is_installed()) { ids <- iterable_dataset(   name = \"hello\",   initialize = function(n = 5) {     self$n <- n     self$i <- 0   },   .iter = function() {     i <- 0     function() {       i <<- i + 1       if (i > self$n) {         coro::exhausted()       } else {         i       }     }   } ) coro::collect(ids()$.iter()) } #> [[1]] #> [1] 1 #>  #> [[2]] #> [1] 2 #>  #> [[3]] #> [1] 3 #>  #> [[4]] #> [1] 4 #>  #> [[5]] #> [1] 5 #>"},{"path":"https://torch.mlverse.org/docs/reference/jit_compile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile TorchScript code into a graph — jit_compile","title":"Compile TorchScript code into a graph — jit_compile","text":"See TorchScript language reference documentation write TorchScript code.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_compile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile TorchScript code into a graph — jit_compile","text":"","code":"jit_compile(source)"},{"path":"https://torch.mlverse.org/docs/reference/jit_compile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compile TorchScript code into a graph — jit_compile","text":"source valid TorchScript source code.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_compile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile TorchScript code into a graph — jit_compile","text":"","code":"if (torch_is_installed()) { comp <- jit_compile(\" def fn (x):   return torch.abs(x)  def foo (x):   return torch.sum(x)  \")  comp$fn(torch_tensor(-1)) comp$foo(torch_randn(10)) } #> torch_tensor #> -2.62729 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/jit_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads a script_function or script_module previously saved with jit_save — jit_load","title":"Loads a script_function or script_module previously saved with jit_save — jit_load","text":"Loads script_function script_module previously saved jit_save","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads a script_function or script_module previously saved with jit_save — jit_load","text":"","code":"jit_load(path, ...)"},{"path":"https://torch.mlverse.org/docs/reference/jit_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads a script_function or script_module previously saved with jit_save — jit_load","text":"path path script_function script_module serialized jit_save(). ... currently unused.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_ops.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable idiomatic access to JIT operators from R. — jit_ops","title":"Enable idiomatic access to JIT operators from R. — jit_ops","text":"Call JIT operators directly R, keeping familiar argument types argument order. Note, however, : arguments required (defaults) axis numbering (well position numbers overall) starts 0 scalars wrapped jit_scalar()","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_ops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable idiomatic access to JIT operators from R. — jit_ops","text":"","code":"jit_ops"},{"path":"https://torch.mlverse.org/docs/reference/jit_ops.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Enable idiomatic access to JIT operators from R. — jit_ops","text":"object class torch_ops length 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_ops.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enable idiomatic access to JIT operators from R. — jit_ops","text":"","code":"if (torch_is_installed()) { t1 <- torch::torch_rand(4, 5) t2 <- torch::torch_ones(5, 4) # same as torch::torch_matmul(t1, t2) jit_ops$aten$matmul(t1, t2)  # same as torch_split(torch::torch_arange(0, 3), 2, 1) jit_ops$aten$split(torch::torch_arange(0, 3), torch::jit_scalar(2L), torch::jit_scalar(0L))  } #> [[1]] #> torch_tensor #>  0 #>  1 #> [ CPUFloatType{2} ] #>  #> [[2]] #> torch_tensor #>  2 #>  3 #> [ CPUFloatType{2} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/jit_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves a script_function to a path — jit_save","title":"Saves a script_function to a path — jit_save","text":"Saves script_function path","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves a script_function to a path — jit_save","text":"","code":"jit_save(obj, path, ...)"},{"path":"https://torch.mlverse.org/docs/reference/jit_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves a script_function to a path — jit_save","text":"obj script_function save path path save serialized function. ... currently unused","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_save.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Saves a script_function to a path — jit_save","text":"","code":"if (torch_is_installed()) { fn <- function(x) {   torch_relu(x) }  input <- torch_tensor(c(-1, 0, 1)) tr_fn <- jit_trace(fn, input)  tmp <- tempfile(\"tst\", fileext = \"pt\") jit_save(tr_fn, tmp) }"},{"path":"https://torch.mlverse.org/docs/reference/jit_save_for_mobile.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves a script_function or script_module in bytecode form, to be loaded on a mobile device — jit_save_for_mobile","title":"Saves a script_function or script_module in bytecode form, to be loaded on a mobile device — jit_save_for_mobile","text":"Saves script_function script_module bytecode form, loaded mobile device","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_save_for_mobile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves a script_function or script_module in bytecode form, to be loaded on a mobile device — jit_save_for_mobile","text":"","code":"jit_save_for_mobile(obj, path, ...)"},{"path":"https://torch.mlverse.org/docs/reference/jit_save_for_mobile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves a script_function or script_module in bytecode form, to be loaded on a mobile device — jit_save_for_mobile","text":"obj script_function script_module save path path save serialized function. ... currently unused","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_save_for_mobile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Saves a script_function or script_module in bytecode form, to be loaded on a mobile device — jit_save_for_mobile","text":"","code":"if (torch_is_installed()) { fn <- function(x) {   torch_relu(x) }  input <- torch_tensor(c(-1, 0, 1)) tr_fn <- jit_trace(fn, input)  tmp <- tempfile(\"tst\", fileext = \"pt\") jit_save_for_mobile(tr_fn, tmp) }"},{"path":"https://torch.mlverse.org/docs/reference/jit_scalar.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds the 'jit_scalar' class to the input — jit_scalar","title":"Adds the 'jit_scalar' class to the input — jit_scalar","text":"Allows disambiguating length 1 vectors scalars passing jit.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_scalar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds the 'jit_scalar' class to the input — jit_scalar","text":"","code":"jit_scalar(x)"},{"path":"https://torch.mlverse.org/docs/reference/jit_scalar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds the 'jit_scalar' class to the input — jit_scalar","text":"x length 1 R vector.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Trace a function and return an executable script_function. — jit_trace","title":"Trace a function and return an executable script_function. — jit_trace","text":"Using jit_trace, can turn existing R function TorchScript script_function. must provide example inputs, run function, recording operations performed tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trace a function and return an executable script_function. — jit_trace","text":"","code":"jit_trace(func, ..., strict = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trace a function and return an executable script_function. — jit_trace","text":"func R function run example_inputs. func arguments return values must tensors (possibly nested) lists contain tensors. Can also nn_module(), case jit_trace_module() used trace module. ... example inputs passed function tracing. resulting trace can run inputs different types shapes assuming traced operations support types shapes. example_inputs may also single Tensor case automatically wrapped list. Note ... can named, order respected. strict run tracer strict mode (default: TRUE). turn want tracer record mutable container types (currently list/dict) sure container using problem constant structure get used control flow (, ) conditions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trace a function and return an executable script_function. — jit_trace","text":"script_function func function script_module func nn_module().","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trace a function and return an executable script_function. — jit_trace","text":"resulting recording standalone function produces script_function. future also support tracing nn_modules.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Trace a function and return an executable script_function. — jit_trace","text":"Scripting yet supported R.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Trace a function and return an executable script_function. — jit_trace","text":"Tracing correctly records functions modules data dependent (e.g., conditionals data tensors) untracked external dependencies (e.g., perform input/output access global variables). Tracing records operations done given function run given tensors. Therefore, returned script_function always run traced graph input. important implications module expected run different sets operations, depending input /module state. example, Tracing record control-flow like -statements loops. control-flow constant across module, fine often inlines control-flow decisions. sometimes control-flow actually part model . instance, recurrent network loop (possibly dynamic) length input sequence. returned script_function, operations different behaviors training eval modes always behave mode tracing, matter mode script_function . cases like , tracing appropriate scripting better choice. trace models, may silently get incorrect results subsequent invocations model. tracer try emit warnings something may cause incorrect trace produced.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trace a function and return an executable script_function. — jit_trace","text":"","code":"if (torch_is_installed()) { fn <- function(x) {   torch_relu(x) } input <- torch_tensor(c(-1, 0, 1)) tr_fn <- jit_trace(fn, input) tr_fn(input) } #> torch_tensor #>  0 #>  0 #>  1 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/jit_trace_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Trace a module — jit_trace_module","title":"Trace a module — jit_trace_module","text":"Trace module return executable ScriptModule optimized using just--time compilation. module passed jit_trace(), forward method run traced. jit_trace_module(), can specify named list method names example inputs trace (see inputs) argument .","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trace a module — jit_trace_module","text":"","code":"jit_trace_module(mod, ..., strict = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/jit_trace_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trace a module — jit_trace_module","text":"mod torch nn_module()  containing methods whose names specified inputs. given methods compiled part single ScriptModule. ... named list containing sample inputs indexed method names mod. inputs passed methods whose names correspond inputs keys tracing. list('forward'=example_forward_input, 'method2'=example_method2_input). strict run tracer strict mode (default: TRUE). turn want tracer record mutable container types (currently list/dict) sure container using problem constant structure get used control flow (, ) conditions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace_module.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Trace a module — jit_trace_module","text":"See jit_trace information tracing.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_trace_module.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trace a module — jit_trace_module","text":"","code":"if (torch_is_installed()) { linear <- nn_linear(10, 1) tr_linear <- jit_trace_module(linear, forward = list(torch_randn(10, 10)))  x <- torch_randn(10, 10) torch_allclose(linear(x), tr_linear(x)) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/jit_tuple.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds the 'jit_tuple' class to the input — jit_tuple","title":"Adds the 'jit_tuple' class to the input — jit_tuple","text":"Allows specifying output input must considered jit tuple instead list dictionary tracing.","code":""},{"path":"https://torch.mlverse.org/docs/reference/jit_tuple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds the 'jit_tuple' class to the input — jit_tuple","text":"","code":"jit_tuple(x)"},{"path":"https://torch.mlverse.org/docs/reference/jit_tuple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds the 'jit_tuple' class to the input — jit_tuple","text":"x list object converted tuple.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","text":"Letting   , Cholesky decomposition complex Hermitian real symmetric positive-definite matrix  defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","text":"","code":"linalg_cholesky(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting symmetric Hermitian positive-definite matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","text":"=LLHL∈Kn×n = LL^{H}\\mathrlap{\\qquad L \\\\mathbb{K}^{n \\times n}} =LLHL∈Kn×n  lower triangular matrix  conjugate transpose  complex, transpose  real-valued. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky","text":"","code":"if (torch_is_installed()) { a <- torch_eye(10) linalg_cholesky(a) } #> torch_tensor #>  1  0  0  0  0  0  0  0  0  0 #>  0  1  0  0  0  0  0  0  0  0 #>  0  0  1  0  0  0  0  0  0  0 #>  0  0  0  1  0  0  0  0  0  0 #>  0  0  0  0  1  0  0  0  0  0 #>  0  0  0  0  0  1  0  0  0  0 #>  0  0  0  0  0  0  1  0  0  0 #>  0  0  0  0  0  0  0  1  0  0 #>  0  0  0  0  0  0  0  0  1  0 #>  0  0  0  0  0  0  0  0  0  1 #> [ CPUFloatType{10,10} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky_ex.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","text":"function skips (slow) error checking error message construction linalg_cholesky(), instead directly returning LAPACK error codes part named tuple (L, info). makes function faster way check matrix positive-definite, provides opportunity handle decomposition errors gracefully performantly linalg_cholesky() . Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. Hermitian positive-definite matrix, batch matrices one Hermitian positive-definite matrix, info stores positive integer corresponding matrix. positive integer indicates order leading minor positive-definite, decomposition completed. info filled zeros indicates decomposition successful. check_errors=TRUE info contains positive integers, RuntimeError thrown.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky_ex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","text":"","code":"linalg_cholesky_ex(A, check_errors = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky_ex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","text":"(Tensor): Hermitian n \\times n matrix batch matrices size (*, n, n) * one batch dimensions. check_errors (bool, optional): controls whether check content infos. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky_ex.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","text":"CUDA device, function may synchronize device CPU. function \"experimental\" may change future PyTorch release.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_cholesky_ex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. — linalg_cholesky_ex","text":"","code":"if (torch_is_installed()) { A <- torch_randn(2, 2) out <- linalg_cholesky_ex(A) out } #> $L #> torch_tensor #> -0.8449  0.0000 #>  1.3567  1.3276 #> [ CPUFloatType{2,2} ] #>  #> $info #> torch_tensor #> 1 #> [ CPUIntType{} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"Letting   , condition number  matrix  defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"","code":"linalg_cond(A, p = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions p (2, -2), shape (*, n, n) every matrix invertible p ('fro', 'nuc', inf, -inf, 1, -1). p (int, inf, -inf, 'fro', 'nuc', optional): type matrix norm use computations (see ). Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"real-valued tensor, even complex.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"κ()=∥∥p∥−1∥p\\kappa() = \\|\\|_p\\|^{-1}\\|_pκ()=∥∥p​∥−1∥p​ condition number measures numerical stability linear system AX = B respect matrix norm. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. p defines matrix norm computed. See table 'Details' find supported norms. p one ('fro', 'nuc', inf, -inf, 1, -1), function uses linalg_norm() linalg_inv(). , case, matrix (every matrix batch) square invertible. p (2, -2), function can computed terms singular values κ2()=σ1σnκ−2()=σnσ1\\kappa_2() = \\frac{\\sigma_1}{\\sigma_n}\\qquad \\kappa_{-2}() = \\frac{\\sigma_n}{\\sigma_1}κ2​()=σn​σ1​​κ−2​()=σ1​σn​​ cases, computed using linalg_svd(). norms, matrix (every matrix batch) may shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"inputs CUDA device, function synchronizes device CPU p one ('fro', 'nuc', inf, -inf, 1, -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_cond.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the condition number of a matrix with respect to a matrix norm. — linalg_cond","text":"","code":"if (torch_is_installed()) { a <- torch_tensor(rbind(c(1., 0, -1), c(0, 1, 0), c(1, 0, 1))) linalg_cond(a) linalg_cond(a, \"fro\") } #> torch_tensor #> 3.16228 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_det.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the determinant of a square matrix. — linalg_det","title":"Computes the determinant of a square matrix. — linalg_det","text":"Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_det.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the determinant of a square matrix. — linalg_det","text":"","code":"linalg_det(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_det.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the determinant of a square matrix. — linalg_det","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_det.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the determinant of a square matrix. — linalg_det","text":"","code":"if (torch_is_installed()) { a <- torch_randn(3, 3) linalg_det(a)  a <- torch_randn(3, 3, 3) linalg_det(a) } #> torch_tensor #> -0.1705 #> -0.2190 #>  0.6716 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"Letting   , eigenvalue decomposition square matrix  (exists) defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"","code":"linalg_eig(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting diagonalizable matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"list (eigenvalues, eigenvectors) corresponds   . eigenvalues eigenvectors always complex-valued, even real. eigenvectors given columns eigenvectors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"=Vdiag⁡(Λ)V−1V∈Cn×n,Λ∈Cn = V \\operatorname{diag}(\\Lambda) V^{-1}\\mathrlap{\\qquad V \\\\mathbb{C}^{n \\times n}, \\Lambda \\\\mathbb{C}^n} =Vdiag(Λ)V−1V∈Cn×n,Λ∈Cn decomposition exists  diagonalizable_. case eigenvalues different. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"eigenvalues eigenvectors real matrix may complex.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"function assumes diagonalizable_ (example, eigenvalues different). diagonalizable, returned eigenvalues correct . eigenvectors matrix unique, continuous respect . Due lack uniqueness, different hardware software may compute different eigenvectors. non-uniqueness caused fact multiplying eigenvector non-zero number produces another set valid eigenvectors matrix. implmentation, returned eigenvectors normalized norm 1 largest real component. Gradients computed using V finite repeated eigenvalues. Furthermore, distance two eigenvalues close zero, gradient numerically unstable, depends eigenvalues  computation .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_eig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig","text":"","code":"if (torch_is_installed()) { a <- torch_randn(2, 2) wv <- linalg_eig(a) }"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"Letting   , eigenvalue decomposition complex Hermitian real symmetric matrix  defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"","code":"linalg_eigh(A, UPLO = \"L\")"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting symmetric Hermitian matrices. UPLO ('L', 'U', optional): controls whether use upper lower triangular part computations. Default: 'L'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"list (eigenvalues, eigenvectors) corresponds   . eigenvalues always real-valued, even complex. also ordered ascending order. eigenvectors dtype contain eigenvectors columns.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"=Qdiag⁡(Λ)QHQ∈Kn×n,Λ∈Rn = Q \\operatorname{diag}(\\Lambda) Q^{H}\\mathrlap{\\qquad Q \\\\mathbb{K}^{n \\times n}, \\Lambda \\\\mathbb{R}^n} =Qdiag(Λ)QHQ∈Kn×n,Λ∈Rn  conjugate transpose  complex, transpose  real-valued.  orthogonal real case unitary complex case. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. assumed Hermitian (resp. symmetric), checked internally, instead: UPLO\\ = 'L' (default), lower triangular part matrix used computation. UPLO\\ = 'U', upper triangular part matrix used. eigenvalues returned ascending order.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"eigenvalues real symmetric complex Hermitian matrices always real.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"eigenvectors symmetric matrix unique, continuous respect . Due lack uniqueness, different hardware software may compute different eigenvectors. non-uniqueness caused fact multiplying eigenvector -1 real case  complex case produces another set valid eigenvectors matrix. non-uniqueness problem even worse matrix repeated eigenvalues. case, one may multiply associated eigenvectors spanning subspace rotation matrix resulting eigenvectors valid eigenvectors. Gradients computed using eigenvectors tensor finite unique eigenvalues. Furthermore, distance two eigvalues close zero, gradient numerically unstable, depends eigenvalues  computation .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. — linalg_eigh","text":"","code":"if (torch_is_installed()) { a <- torch_randn(2, 2) linalg_eigh(a) } #> [[1]] #> torch_tensor #>  0.6851 #>  2.1951 #> [ CPUFloatType{2} ] #>  #> [[2]] #> torch_tensor #>  0.5609 -0.8279 #> -0.8279 -0.5609 #> [ CPUFloatType{2,2} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the eigenvalues of a square matrix. — linalg_eigvals","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"Letting   , eigenvalues square matrix  defined roots (counted multiplicity) polynomial p degree n given ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"","code":"linalg_eigvals(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"p(λ)=det⁡(−λIn)λ∈C p(\\lambda) = \\operatorname{det}(- \\lambda \\mathrm{}_n)\\mathrlap{\\qquad \\lambda \\\\mathbb{C}} p(λ)=det(−λIn​)λ∈C  n-dimensional identity matrix. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"eigenvalues real matrix may complex, roots real polynomial may complex. eigenvalues matrix always well-defined, even matrix diagonalizable.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the eigenvalues of a square matrix. — linalg_eigvals","text":"","code":"if (torch_is_installed()) { a <- torch_randn(2, 2) w <- linalg_eigvals(a) }"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"Letting   , eigenvalues complex Hermitian real symmetric  matrix  defined roots (counted multiplicity) polynomial p degree n given ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"","code":"linalg_eigvalsh(A, UPLO = \"L\")"},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting symmetric Hermitian matrices. UPLO ('L', 'U', optional): controls whether use upper lower triangular part computations. Default: 'L'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"real-valued tensor cointaining eigenvalues even complex. eigenvalues returned ascending order.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"p(λ)=det⁡(−λIn)λ∈R p(\\lambda) = \\operatorname{det}(- \\lambda \\mathrm{}_n)\\mathrlap{\\qquad \\lambda \\\\mathbb{R}} p(λ)=det(−λIn​)λ∈R  n-dimensional identity matrix. eigenvalues real symmetric complex Hermitian matrix always real. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. eigenvalues returned ascending order. assumed Hermitian (resp. symmetric), checked internally, instead: UPLO\\ = 'L' (default), lower triangular part matrix used computation. UPLO\\ = 'U', upper triangular part matrix used.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_eigvalsh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the eigenvalues of a complex Hermitian or real symmetric matrix. — linalg_eigvalsh","text":"","code":"if (torch_is_installed()) { a <- torch_randn(2, 2) linalg_eigvalsh(a) } #> torch_tensor #> -1.1600 #>  0.5052 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"Letting   , matrix  columns   vector  , function computes first  columns matrix","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"","code":"linalg_householder_product(A, tau)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions. tau (Tensor): tensor shape (*, k) * zero batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"H1H2...HkwithHi=Im−τiviviH H_1H_2 ... H_k \\qquad \\qquad H_i = \\mathrm{}_m - \\tau_i v_i v_i^{H} H1​H2​...Hk​withHi​=Im​−τi​vi​viH​  m-dimensional identity matrix  conjugate transpose  complex, transpose  real-valued. See Representation Orthogonal Unitary Matrices details. Supports inputs float, double, cfloat cdouble dtypes. Also supports batches matrices, inputs batches matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"function uses values strictly main diagonal . values ignored.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_householder_product.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the first n columns of a product of Householder matrices. — linalg_householder_product","text":"","code":"if (torch_is_installed()) { A <- torch_randn(2, 2) h_tau <- torch_geqrf(A) Q <- linalg_householder_product(h_tau[[1]], h_tau[[2]]) torch_allclose(Q, linalg_qr(A)[[1]]) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the inverse of a square matrix if it exists. — linalg_inv","title":"Computes the inverse of a square matrix if it exists. — linalg_inv","text":"Throws runtime_error matrix invertible.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the inverse of a square matrix if it exists. — linalg_inv","text":"","code":"linalg_inv(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the inverse of a square matrix if it exists. — linalg_inv","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting invertible matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the inverse of a square matrix if it exists. — linalg_inv","text":"Letting   , matrix , inverse matrix  (exists) defined −1A=AA−1=^{-1}= AA^{-1} = \\mathrm{}_n −1A=AA−1=​  n-dimensional identity matrix. inverse matrix exists  invertible. case, inverse unique. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. Consider using linalg_solve() possible multiplying matrix left inverse, linalg_solve(, B) == $inv() %*% B always prefered use linalg_solve() possible, faster numerically stable computing inverse explicitly.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the inverse of a square matrix if it exists. — linalg_inv","text":"","code":"if (torch_is_installed()) { A <- torch_randn(4, 4) linalg_inv(A) } #> torch_tensor #> -0.2507 -0.4972 -0.1922 -0.9363 #> -0.2006 -1.1907  3.5489  0.3504 #> -1.1944 -1.1430  3.6438 -0.8388 #> -0.4556 -0.7984  0.8755 -0.3526 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv_ex.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","title":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","text":"Returns namedtuple (inverse, info). inverse contains result inverting info stores LAPACK error codes. invertible matrix, batch matrices one invertible matrix, info stores positive integer corresponding matrix. positive integer indicates diagonal element LU decomposition input matrix exactly zero. info filled zeros indicates inversion successful. check_errors=TRUE info contains positive integers, RuntimeError thrown. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv_ex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","text":"","code":"linalg_inv_ex(A, check_errors = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv_ex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions consisting square matrices. check_errors (bool, optional): controls whether check content info. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv_ex.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","text":"CUDA device function may synchronize device CPU. function \"experimental\" may change future PyTorch release.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_inv_ex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the inverse of a square matrix if it is invertible. — linalg_inv_ex","text":"","code":"if (torch_is_installed()) { A <- torch_randn(3, 3) out <- linalg_inv_ex(A) }"},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"Letting   , least squares problem linear system   defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"","code":"linalg_lstsq(A, B, rcond = NULL, ..., driver = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"(Tensor): lhs tensor shape (*, m, n) * zero batch dimensions. B (Tensor): rhs tensor shape (*, m, k) * zero batch dimensions. rcond (float, optional): used determine effective rank . rcond = NULL, rcond set machine precision dtype times max(m, n). Default: NULL. ... currently unused. driver (str, optional): name LAPACK/MAGMA method used. NULL, 'gelsy' used CPU inputs 'gels' CUDA inputs. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"list (solution, residuals, rank, singular_values).","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"min⁡X∈Kn×k∥AX−B∥F \\min_{X \\\\mathbb{K}^{n \\times k}} \\|AX - B\\|_F X∈Kn×kmin​∥AX−B∥F​  denotes Frobenius norm. Supports inputs float, double, cfloat cdouble dtypes. Also supports batches matrices, inputs batches matrices output batch dimensions. driver chooses LAPACK/MAGMA function used. CPU inputs valid values 'gels', 'gelsy', 'gelsd, 'gelss'. CUDA input, valid driver 'gels', assumes full-rank. choose best driver CPU consider: well-conditioned (condition number large), mind precision loss. general matrix: 'gelsy' (QR pivoting) (default) full-rank: 'gels' (QR) well-conditioned. 'gelsd' (tridiagonal reduction SVD) run memory issues: 'gelss' (full SVD). See also full description drivers rcond used determine effective rank matrices driver one ('gelsy', 'gelsd', 'gelss'). case,  singular values decreasing order,  rounded zero . rcond = NULL (default), rcond set machine precision dtype . function returns solution problem extra information list four tensors (solution, residuals, rank, singular_values). inputs , B shape (*, m, n), (*, m, k) respectively, cointains solution: least squares solution. shape (*, n, k). residuals: squared residuals solutions, , . shape equal batch dimensions . computed m > n every matrix full-rank, otherwise, empty tensor. batch matrices matrix batch full rank, empty tensor returned. behavior may change future PyTorch release. rank: tensor ranks matrices . shape equal batch dimensions . computed driver one ('gelsy', 'gelsd', 'gelss'), otherwise empty tensor. singular_values: tensor singular values matrices . shape (*, min(m, n)). computed driver one ('gelsd', 'gelss'), otherwise empty tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"function computes X = $pinverse() %*% B faster numerically stable way performing computations separately.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"default value rcond may change future PyTorch release. therefore recommended use fixed value avoid potential breaking changes.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_lstsq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a solution to the least squares problem of a system of linear equations. — linalg_lstsq","text":"","code":"if (torch_is_installed()) { A <- torch_tensor(rbind(c(10, 2, 3), c(3, 10, 5), c(5, 6, 12)))$unsqueeze(1) # shape (1, 3, 3) B <- torch_stack(list(   rbind(c(2, 5, 1), c(3, 2, 1), c(5, 1, 9)),   rbind(c(4, 2, 9), c(2, 0, 3), c(2, 5, 3)) ), dim = 1) # shape (2, 3, 3) X <- linalg_lstsq(A, B)$solution # A is broadcasted to shape (2, 3, 3) }"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a matrix norm. — linalg_matrix_norm","title":"Computes a matrix norm. — linalg_matrix_norm","text":"complex valued, computes norm $abs() Support input float, double, cfloat cdouble dtypes. Also supports batches matrices: norm computed dimensions specified 2-tuple dim dimensions treated batch dimensions. output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a matrix norm. — linalg_matrix_norm","text":"","code":"linalg_matrix_norm(   A,   ord = \"fro\",   dim = c(-2, -1),   keepdim = FALSE,   dtype = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a matrix norm. — linalg_matrix_norm","text":"(Tensor): tensor two dimensions. default shape interpreted (*, m, n) * zero batch dimensions, behavior can controlled using dim. ord (int, inf, -inf, 'fro', 'nuc', optional): order norm. Default: 'fro' dim (int, Tupleint, optional): dimensions compute vector matrix norm. See behavior dim=NULL. Default: NULL keepdim (bool, optional): set TRUE, reduced dimensions retained result dimensions size one. Default: FALSE dtype dtype (torch_dtype, optional): specified, input tensor cast dtype performing operation, returned tensor's type dtype. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes a matrix norm. — linalg_matrix_norm","text":"ord defines norm computed. following norms supported:","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a matrix norm. — linalg_matrix_norm","text":"","code":"if (torch_is_installed()) { a <- torch_arange(0, 8, dtype = torch_float())$reshape(c(3, 3)) linalg_matrix_norm(a) linalg_matrix_norm(a, ord = -1) b <- a$expand(c(2, -1, -1)) linalg_matrix_norm(b) linalg_matrix_norm(b, dim = c(1, 3)) } #> torch_tensor #>   3.1623 #>  10.0000 #>  17.2627 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_power.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","title":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","text":"Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_power.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","text":"","code":"linalg_matrix_power(A, n)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_power.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","text":"(Tensor): tensor shape (*, m, m) * zero batch dimensions. n (int): exponent.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_power.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","text":"n=0, returns identity matrix (batch) shape . n negative, returns inverse matrix (invertible) raised power abs(n).","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_power.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the n-th power of a square matrix for an integer n. — linalg_matrix_power","text":"","code":"if (torch_is_installed()) { A <- torch_randn(3, 3) linalg_matrix_power(A, 0) } #> torch_tensor #>  1  0  0 #>  0  1  0 #>  0  0  1 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the numerical rank of a matrix. — linalg_matrix_rank","title":"Computes the numerical rank of a matrix. — linalg_matrix_rank","text":"matrix rank computed number singular values (eigenvalues absolute value hermitian = TRUE) greater specified tol threshold.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the numerical rank of a matrix. — linalg_matrix_rank","text":"","code":"linalg_matrix_rank(   A,   ...,   atol = NULL,   rtol = NULL,   tol = NULL,   hermitian = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the numerical rank of a matrix. — linalg_matrix_rank","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions. ... currently used. atol absolute tolerance value. NULL ’s considered zero. rtol relative tolerance value. See value takes NULL. tol (float, Tensor, optional): tolerance value. See value takes NULL. Default: NULL. hermitian (bool, optional): indicates whether Hermitian complex symmetric real. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_rank.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the numerical rank of a matrix. — linalg_matrix_rank","text":"Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. hermitian = TRUE, assumed Hermitian complex symmetric real, checked internally. Instead, just lower triangular part matrix used computations. tol specified matrix dimensions (m, n), tolerance set tol=σ1max⁡(m,n)ε tol = \\sigma_1 \\max(m, n) \\varepsilon tol=σ1​max(m,n)ε  largest singular value (eigenvalue absolute value hermitian = TRUE),  epsilon value dtype (see torch_finfo()). batch matrices, tol computed way every element batch.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_matrix_rank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the numerical rank of a matrix. — linalg_matrix_rank","text":"","code":"if (torch_is_installed()) { a <- torch_eye(10) linalg_matrix_rank(a) } #> torch_tensor #> 10 #> [ CPULongType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficiently multiplies two or more matrices — linalg_multi_dot","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"Efficiently multiplies two matrices reordering multiplications fewest arithmetic operations performed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"","code":"linalg_multi_dot(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"tensors (Sequence[Tensor]): two tensors multiply. first last tensors may 1D 2D. Every tensor must 2D.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"Supports inputs float, double, cfloat cdouble dtypes. function support batched inputs. Every tensor tensors must 2D, except first last may 1D. first tensor 1D vector shape (n,) treated row vector shape (1, n), similarly last tensor 1D vector shape (n,) treated column vector shape (n, 1). first last tensors matrices, output matrix. However, either 1D vector, output 1D vector.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"function implemented chaining torch_mm() calls computing optimal matrix multiplication order. cost multiplying two matrices shapes (, b) (b, c) * b * c. Given matrices , B, C shapes (10, 100), (100, 5), (5, 50) respectively, can calculate cost different multiplication orders follows: cost⁡((AB)C)=10×100×5+10×5×50=7500 cost⁡((BC))=10×100×50+100×5×50=75000 \\begin{align*} \\operatorname{cost}((AB)C) &= 10 \\times 100 \\times 5 + 10 \\times 5 \\times 50 = 7500 \\ \\operatorname{cost}((BC)) &= 10 \\times 100 \\times 50 + 100 \\times 5 \\times 50 = 75000 \\end{align*} cost((AB)C)​=10×100×5+10×5×50=7500 cost((BC))​=10×100×50+100×5×50=75000​ case, multiplying B first followed C 10 times faster.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_multi_dot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Efficiently multiplies two or more matrices — linalg_multi_dot","text":"","code":"if (torch_is_installed()) {  linalg_multi_dot(list(torch_tensor(c(1, 2)), torch_tensor(c(2, 3)))) } #> torch_tensor #> 8 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a vector or matrix norm. — linalg_norm","title":"Computes a vector or matrix norm. — linalg_norm","text":"complex valued, computes norm $abs() Supports input float, double, cfloat cdouble dtypes. Whether function computes vector matrix norm determined follows:","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a vector or matrix norm. — linalg_norm","text":"","code":"linalg_norm(A, ord = NULL, dim = NULL, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a vector or matrix norm. — linalg_norm","text":"(Tensor): tensor shape (*, n) (*, m, n) * zero batch dimensions ord (int, float, inf, -inf, 'fro', 'nuc', optional): order norm. Default: NULL dim (int, Tupleint, optional): dimensions compute vector matrix norm. See behavior dim=NULL. Default: NULL keepdim (bool, optional): set TRUE, reduced dimensions retained result dimensions size one. Default: FALSE dtype dtype (torch_dtype, optional): specified, input tensor cast dtype performing operation, returned tensor's type dtype. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes a vector or matrix norm. — linalg_norm","text":"dim int, vector norm computed. dim 2-tuple, matrix norm computed. dim=NULL ord=NULL, flattened 1D 2-norm resulting vector computed. dim=NULL ord!=NULL, must 1D 2D. ord defines norm computed. following norms supported:","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a vector or matrix norm. — linalg_norm","text":"","code":"if (torch_is_installed()) { a <- torch_arange(0, 8, dtype = torch_float()) - 4 a b <- a$reshape(c(3, 3)) b  linalg_norm(a) linalg_norm(b) } #> torch_tensor #> 7.74597 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"pseudoinverse may defined algebraically_ computationally convenient understand SVD_ Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"","code":"linalg_pinv(A, rcond = NULL, hermitian = FALSE, atol = NULL, rtol = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions. rcond (float Tensor, optional): tolerance value determine singular value zero torch_Tensor, shape must broadcastable singular values returned linalg_svd(). Alias rtol. Default: 0. hermitian (bool, optional): indicates whether Hermitian complex symmetric real. Default: FALSE. atol absolute tolerance value. NULL ’s considered zero. rtol relative tolerance value. See value takes NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"hermitian= TRUE, assumed Hermitian complex symmetric real, checked internally. Instead, just lower triangular part matrix used computations. singular values (norm eigenvalues hermitian= TRUE) specified rcond threshold treated zero discarded computation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"function uses linalg_svd() hermitian= FALSE linalg_eigh() hermitian= TRUE. CUDA inputs, function synchronizes device CPU. Consider using linalg_lstsq() possible multiplying matrix left pseudoinverse, linalg_lstsq(, B)$solution == $pinv() %*% B always prefered use linalg_lstsq() possible, faster numerically stable computing pseudoinverse explicitly.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_pinv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. — linalg_pinv","text":"","code":"if (torch_is_installed()) { A <- torch_randn(3, 5) linalg_pinv(A) } #> torch_tensor #>  0.6886  0.2109  0.0239 #>  0.0302  0.1808  0.1159 #>  0.3785  0.2301 -0.3357 #> -0.4896 -0.6582  0.2559 #> -0.1375 -0.4979  0.0205 #> [ CPUFloatType{5,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the QR decomposition of a matrix. — linalg_qr","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"Letting   , full QR decomposition matrix  defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"","code":"linalg_qr(A, mode = \"reduced\")"},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions. mode (str, optional): one 'reduced', 'complete', 'r'. Controls shape returned tensors. Default: 'reduced'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"list (Q, R).","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"=QRQ∈Km×m,R∈Km×n = QR\\mathrlap{\\qquad Q \\\\mathbb{K}^{m \\times m}, R \\\\mathbb{K}^{m \\times n}} =QRQ∈Km×m,R∈Km×n  orthogonal real case unitary complex case,  upper triangular. m > n (tall matrix), R upper triangular, last m - n rows zero. case, can drop last m - n columns Q form reduced QR decomposition: =QRQ∈Km×n,R∈Kn×n = QR\\mathrlap{\\qquad Q \\\\mathbb{K}^{m \\times n}, R \\\\mathbb{K}^{n \\times n}} =QRQ∈Km×n,R∈Kn×n reduced QR decomposition agrees full QR decomposition n >= m (wide matrix). Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. parameter mode chooses full reduced QR decomposition. shape (*, m, n), denoting k = min(m, n) mode = 'reduced' (default): Returns (Q, R) shapes (*, m, k), (*, k, n) respectively. mode = 'complete': Returns (Q, R) shapes (*, m, m), (*, m, n) respectively. mode = 'r': Computes reduced R. Returns (Q, R) Q empty R shape (*, k, n).","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_qr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the QR decomposition of a matrix. — linalg_qr","text":"","code":"if (torch_is_installed()) { a <- torch_tensor(rbind(c(12., -51, 4), c(6, 167, -68), c(-4, 24, -41))) qr <- linalg_qr(a)  torch_mm(qr[[1]], qr[[2]])$round() torch_mm(qr[[1]]$t(), qr[[1]])$round() } #> torch_tensor #>  1  0  0 #>  0  1  0 #>  0  0  1 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"complex , returns angle natural logarithm modulus determinant, , logarithmic polar decomposition determinant. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"","code":"linalg_slogdet(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"list (sign, logabsdet). logabsdet always real-valued, even complex. sign dtype .","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":"notes","dir":"Reference","previous_headings":"","what":"Notes","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"determinant can recovered sign * exp(logabsdet). matrix determinant zero, returns (0, -Inf).","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_slogdet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. — linalg_slogdet","text":"","code":"if (torch_is_installed()) { a <- torch_randn(3, 3) linalg_slogdet(a) } #> [[1]] #> torch_tensor #> -1 #> [ CPUFloatType{} ] #>  #> [[2]] #> torch_tensor #> 0.643368 #> [ CPUFloatType{} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"Letting   , function computes solution  linear system associated , defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"","code":"linalg_solve(A, B)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"(Tensor): tensor shape (*, n, n) * zero batch dimensions. B (Tensor): right-hand side tensor shape (*, n)  (*, n, k) (n,) (n, k) according rules described ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"$$   AX = B $$ system linear equations one solution  invertible_. function assumes  invertible. Supports inputs float, double, cfloat cdouble dtypes. Also supports batches matrices, inputs batches matrices output batch dimensions. Letting * zero batch dimensions, shape (*, n, n) B shape (*, n) (batch vectors) shape (*, n, k) (batch matrices \"multiple right-hand sides\"), function returns X shape (*, n) (*, n, k) respectively. Otherwise, shape (*, n, n)  B shape (n,)  (n, k), B broadcasted shape (*, n) (*, n, k) respectively. function returns solution resulting batch systems linear equations.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"function computes X = $inverse() @ B faster numerically stable way performing computations separately.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the solution of a square system of linear equations with a unique solution. — linalg_solve","text":"","code":"if (torch_is_installed()) { A <- torch_randn(3, 3) b <- torch_randn(3) x <- linalg_solve(A, b) torch_allclose(torch_matmul(A, x), b) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve_triangular.html","id":null,"dir":"Reference","previous_headings":"","what":"Triangular solve — linalg_solve_triangular","title":"Triangular solve — linalg_solve_triangular","text":"Triangular solve","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve_triangular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triangular solve — linalg_solve_triangular","text":"","code":"linalg_solve_triangular(A, B, ..., upper, left = TRUE, unitriangular = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_solve_triangular.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triangular solve — linalg_solve_triangular","text":"tensor shape (*, n, n) (*, k, k) left=TRUE) * zero batch dimensions. B right-hand side tensor shape (*, n, k) ... Currently ignored. upper whether upper lower triangular matrix. left wheter solve system AX=B XA=B unitriangular TRUE, diagonal elements assumed equal 1.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"Letting   , full SVD matrix , k = min(m,n), defined ","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"","code":"linalg_svd(A, full_matrices = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions. full_matrices (bool, optional): controls whether compute full reduced SVD, consequently, shape returned tensors U V. Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"list (U, S, V) corresponds , ,  . S always real-valued, even complex. also ordered descending order. U V dtype . left / right singular vectors given columns U rows V respectively.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"=Udiag⁡(S)VHU∈Km×m,S∈Rk,V∈Kn×n = U \\operatorname{diag}(S) V^{H} \\mathrlap{\\qquad U \\\\mathbb{K}^{m \\times m}, S \\\\mathbb{R}^k, V \\\\mathbb{K}^{n \\times n}} =Udiag(S)VHU∈Km×m,S∈Rk,V∈Kn×n ,  conjugate transpose  complex, transpose  real-valued. matrices  ,  (thus ) orthogonal real case, unitary complex case. m > n (resp. m < n) can drop last m - n (resp. n - m) columns U (resp. V) form reduced SVD: =Udiag⁡(S)VHU∈Km×k,S∈Rk,V∈Kk×n = U \\operatorname{diag}(S) V^{H} \\mathrlap{\\qquad U \\\\mathbb{K}^{m \\times k}, S \\\\mathbb{R}^k, V \\\\mathbb{K}^{k \\times n}} =Udiag(S)VHU∈Km×k,S∈Rk,V∈Kk×n . case,   also orthonormal columns. Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. returned decomposition named tuple (U, S, V) corresponds , ,  . singular values returned descending order. parameter full_matrices chooses full (default) reduced SVD.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"full_matrices=TRUE, gradients respect U[..., :, min(m, n):] Vh[..., min(m, n):, :] ignored, vectors can arbitrary bases corresponding subspaces.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"warnings","dir":"Reference","previous_headings":"","what":"Warnings","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"returned tensors U V unique, continuous respect . Due lack uniqueness, different hardware software may compute different singular vectors. non-uniqueness caused fact multiplying pair singular vectors  -1 real case  complex case produces another two valid singular vectors matrix. non-uniqueness problem even worse matrix repeated singular values. case, one may multiply associated singular vectors U V spanning subspace rotation matrix resulting vectors span subspace. Gradients computed using U V finite zero singular value repeated singular values. Furthermore, distance two singular values close zero, gradient numerically unstable, depends singular values  computation . gradient also numerically unstable small singular values, also depends computaiton .","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_svd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the singular value decomposition (SVD) of a matrix. — linalg_svd","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(5, 3) linalg_svd(a, full_matrices = FALSE) } #> [[1]] #> torch_tensor #> -0.0445  0.3368 -0.7746 #> -0.8789 -0.1809  0.1178 #> -0.0135  0.8168  0.1631 #> -0.4666  0.3359 -0.0405 #>  0.0876  0.2717  0.5983 #> [ CPUFloatType{5,3} ] #>  #> [[2]] #> torch_tensor #>  2.7608 #>  1.9651 #>  0.9611 #> [ CPUFloatType{3} ] #>  #> [[3]] #> torch_tensor #> -0.0630 -0.9964  0.0561 #>  0.9145 -0.0351  0.4031 #>  0.3997 -0.0767 -0.9134 #> [ CPUFloatType{3,3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/linalg_svdvals.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the singular values of a matrix. — linalg_svdvals","title":"Computes the singular values of a matrix. — linalg_svdvals","text":"Supports input float, double, cfloat cdouble dtypes. Also supports batches matrices, batch matrices output batch dimensions. singular values returned descending order.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svdvals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the singular values of a matrix. — linalg_svdvals","text":"","code":"linalg_svdvals(A)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_svdvals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the singular values of a matrix. — linalg_svdvals","text":"(Tensor): tensor shape (*, m, n) * zero batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_svdvals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes the singular values of a matrix. — linalg_svdvals","text":"real-valued tensor, even complex.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_svdvals.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the singular values of a matrix. — linalg_svdvals","text":"","code":"if (torch_is_installed()) { A <- torch_randn(5, 3) S <- linalg_svdvals(A) S } #> torch_tensor #>  3.1020 #>  1.3424 #>  0.9048 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"m product first ind dimensions n product rest dimensions, function expects m n equal. case, computes tensor X tensordot(, X, ind) identity matrix dimension m.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"","code":"linalg_tensorinv(A, ind = 3L)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"(Tensor): tensor invert. ind (int): index compute inverse torch_tensordot(). Default: 3.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"Supports input float, double, cfloat cdouble dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"Consider using linalg_tensorsolve() possible multiplying tensor left tensor inverse linalg_tensorsolve(, B) == torch_tensordot(linalg_tensorinv(), B)) always prefered use linalg_tensorsolve() possible, faster numerically stable computing pseudoinverse explicitly.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorinv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the multiplicative inverse of torch_tensordot() — linalg_tensorinv","text":"","code":"if (torch_is_installed()) { A <- torch_eye(4 * 6)$reshape(c(4, 6, 8, 3)) Ainv <- linalg_tensorinv(A, ind = 3) Ainv$shape B <- torch_randn(4, 6) torch_allclose(torch_tensordot(Ainv, B), linalg_tensorsolve(A, B))  A <- torch_randn(4, 4) Atensorinv <- linalg_tensorinv(A, 2) Ainv <- linalg_inv(A) torch_allclose(Atensorinv, Ainv) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorsolve.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","title":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","text":"m product first B\\ .ndim  dimensions n product rest dimensions, function expects m n equal. returned tensor x satisfies tensordot(, x, dims=x$ndim) == B.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorsolve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","text":"","code":"linalg_tensorsolve(A, B, dims = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorsolve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","text":"(Tensor): tensor solve . B (Tensor): solution dims (Tupleint, optional): dimensions moved. NULL, dimensions moved. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorsolve.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","text":"dims specified, reshaped = movedim(, dims, seq(len(dims) - $ndim + 1, 0)) Supports inputs float, double, cfloat cdouble dtypes.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_tensorsolve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the solution X to the system torch_tensordot(A, X) = B. — linalg_tensorsolve","text":"","code":"if (torch_is_installed()) { A <- torch_eye(2 * 3 * 4)$reshape(c(2 * 3, 4, 2, 3, 4)) B <- torch_randn(2 * 3, 4) X <- linalg_tensorsolve(A, B) X$shape torch_allclose(torch_tensordot(A, X, dims = X$ndim), B)  A <- torch_randn(6, 4, 4, 3, 2) B <- torch_randn(4, 3, 2) X <- linalg_tensorsolve(A, B, dims = c(1, 3)) A <- A$permute(c(2, 4, 5, 1, 3)) torch_allclose(torch_tensordot(A, X, dims = X$ndim), B, atol = 1e-6) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/linalg_vector_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a vector norm. — linalg_vector_norm","title":"Computes a vector norm. — linalg_vector_norm","text":"complex valued, computes norm $abs() Supports input float, double, cfloat cdouble dtypes. function necessarily treat multidimensonal batch vectors, instead:","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_vector_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a vector norm. — linalg_vector_norm","text":"","code":"linalg_vector_norm(A, ord = 2, dim = NULL, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/linalg_vector_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a vector norm. — linalg_vector_norm","text":"(Tensor): tensor, flattened default, behavior can controlled using dim. ord (int, float, inf, -inf, 'fro', 'nuc', optional): order norm. Default: 2 dim (int, Tupleint, optional): dimensions compute vector matrix norm. See behavior dim=NULL. Default: NULL keepdim (bool, optional): set TRUE, reduced dimensions retained result dimensions size one. Default: FALSE dtype dtype (torch_dtype, optional): specified, input tensor cast dtype performing operation, returned tensor's type dtype. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/linalg_vector_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Computes a vector norm. — linalg_vector_norm","text":"dim=NULL, flattened norm computed. dim int tuple, norm computed dimensions dimensions treated batch dimensions. behavior consistency linalg_norm(). ord defines norm computed. following norms supported:","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/linalg_vector_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a vector norm. — linalg_vector_norm","text":"","code":"if (torch_is_installed()) { a <- torch_arange(0, 8, dtype = torch_float()) - 4 a b <- a$reshape(c(3, 3)) b  linalg_vector_norm(a, ord = 3.5) linalg_vector_norm(b, ord = 3.5) } #> torch_tensor #> 5.43449 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/load_state_dict.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a state dict file — load_state_dict","title":"Load a state dict file — load_state_dict","text":"function used load models saved python. work correctly need use torch.save flag: _use_new_zipfile_serialization=True also remove nn.Parameter classes tensors dict.","code":""},{"path":"https://torch.mlverse.org/docs/reference/load_state_dict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a state dict file — load_state_dict","text":"","code":"load_state_dict(path, ..., legacy_stream = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/load_state_dict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a state dict file — load_state_dict","text":"path state dict file ... additional arguments currently used. legacy_stream TRUE state dict loaded using legacy way handling streams.","code":""},{"path":"https://torch.mlverse.org/docs/reference/load_state_dict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a state dict file — load_state_dict","text":"named list tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/load_state_dict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load a state dict file — load_state_dict","text":"might change development pytorch's C++ api.","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":null,"dir":"Reference","previous_headings":"","what":"Autocast context manager — local_autocast","title":"Autocast context manager — local_autocast","text":"Allow regions code run mixed precision. regions, ops run op-specific dtype chosen autocast improve performance maintaining accuracy.","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Autocast context manager — local_autocast","text":"","code":"local_autocast(   device_type,   dtype = NULL,   enabled = TRUE,   cache_enabled = NULL,   ...,   .env = parent.frame() )  with_autocast(   code,   ...,   device_type,   dtype = NULL,   enabled = TRUE,   cache_enabled = NULL )  set_autocast(device_type, dtype = NULL, enabled = TRUE, cache_enabled = NULL)  unset_autocast(context)"},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Autocast context manager — local_autocast","text":"device_type character string indicating whether use 'cuda' 'cpu' device dtype torch data type indicating whether use torch_float16() torch_bfloat16(). enabled logical value indicating whether autocasting enabled region. Default: TRUE cache_enabled logical value indicating whether weight cache inside autocast enabled. ... currently unused. .env environment use scoping. code code executed gradient recording. context Returned set_autocast passed unsetting .","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Autocast context manager — local_autocast","text":"entering autocast-enabled region, Tensors may type. call half() bfloat16() model(s) inputs using autocasting. autocast enabled forward pass(es) network, including loss computation(s).  Backward passes autocast recommended. Backward ops run type autocast used corresponding forward ops.","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Autocast context manager — local_autocast","text":"with_autocast(): context automatic mixed precision. set_autocast(): Set autocast context. advanced users . unset_autocast(): Unset autocast context.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/local_autocast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Autocast context manager — local_autocast","text":"","code":"if (torch_is_installed()) { x <- torch_randn(5, 5, dtype = torch_float32()) y <- torch_randn(5, 5, dtype = torch_float32())  foo <- function(x, y) {   local_autocast(device = \"cpu\")   z <- torch_mm(x, y)   w <- torch_mm(z, x)   w }  out <- foo(x, y) }"},{"path":"https://torch.mlverse.org/docs/reference/local_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Device contexts — local_device","title":"Device contexts — local_device","text":"Device contexts","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Device contexts — local_device","text":"","code":"local_device(device, ..., .env = parent.frame())  with_device(code, ..., device)"},{"path":"https://torch.mlverse.org/docs/reference/local_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Device contexts — local_device","text":"device torch device used default creating new tensors. ... currently unused. .env environment use scoping. code code evaluated modified environment.","code":""},{"path":"https://torch.mlverse.org/docs/reference/local_device.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Device contexts — local_device","text":"with_device(): Modifies default device selected context.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_cosine_annealing.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the learning rate of each parameter group using a cosine annealing schedule — lr_cosine_annealing","title":"Set the learning rate of each parameter group using a cosine annealing schedule — lr_cosine_annealing","text":"Set learning rate parameter group using cosine annealing schedule","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_cosine_annealing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the learning rate of each parameter group using a cosine annealing schedule — lr_cosine_annealing","text":"","code":"lr_cosine_annealing(   optimizer,   T_max,   eta_min = 0,   last_epoch = -1,   verbose = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/lr_cosine_annealing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the learning rate of each parameter group using a cosine annealing schedule — lr_cosine_annealing","text":"optimizer (Optimizer): Wrapped optimizer. T_max Maximum number iterations eta_min Minimum learning rate. Default: 0. last_epoch index last epoch verbose (bool): TRUE, prints message stdout update. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. — lr_lambda","title":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. — lr_lambda","text":"Sets learning rate parameter group initial lr times given function. last_epoch=-1, sets initial lr lr.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. — lr_lambda","text":"","code":"lr_lambda(optimizer, lr_lambda, last_epoch = -1, verbose = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/lr_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. — lr_lambda","text":"optimizer (Optimizer): Wrapped optimizer. lr_lambda (function list): function computes multiplicative factor given integer parameter epoch, list functions, one group optimizer.param_groups. last_epoch (int): index last epoch. Default: -1. verbose (bool): TRUE, prints message stdout update. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_lambda.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets the learning rate of each parameter group to the initial lr times a given function. When last_epoch=-1, sets initial lr as lr. — lr_lambda","text":"","code":"if (torch_is_installed()) { # Assuming optimizer has two groups. lambda1 <- function(epoch) epoch %/% 30 lambda2 <- function(epoch) 0.95^epoch if (FALSE) { scheduler <- lr_lambda(optimizer, lr_lambda = list(lambda1, lambda2)) for (epoch in 1:100) {   train(...)   validate(...)   scheduler$step() } }  }"},{"path":"https://torch.mlverse.org/docs/reference/lr_multiplicative.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. — lr_multiplicative","title":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. — lr_multiplicative","text":"Multiply learning rate parameter group factor given specified function. last_epoch=-1, sets initial lr lr.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_multiplicative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. — lr_multiplicative","text":"","code":"lr_multiplicative(optimizer, lr_lambda, last_epoch = -1, verbose = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/lr_multiplicative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. — lr_multiplicative","text":"optimizer (Optimizer): Wrapped optimizer. lr_lambda (function list): function computes multiplicative factor given integer parameter epoch, list functions, one group optimizer.param_groups. last_epoch (int): index last epoch. Default: -1. verbose (bool): TRUE, prints message stdout update. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_multiplicative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiply the learning rate of each parameter group by the factor given in the specified function. When last_epoch=-1, sets initial lr as lr. — lr_multiplicative","text":"","code":"if (torch_is_installed()) { if (FALSE) { lmbda <- function(epoch) 0.95 scheduler <- lr_multiplicative(optimizer, lr_lambda = lmbda) for (epoch in 1:100) {   train(...)   validate(...)   scheduler$step() } }  }"},{"path":"https://torch.mlverse.org/docs/reference/lr_one_cycle.html","id":null,"dir":"Reference","previous_headings":"","what":"Once cycle learning rate — lr_one_cycle","title":"Once cycle learning rate — lr_one_cycle","text":"Sets learning rate parameter group according 1cycle learning rate policy. 1cycle policy anneals learning rate initial learning rate maximum learning rate maximum learning rate minimum learning rate much lower initial learning rate.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_one_cycle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Once cycle learning rate — lr_one_cycle","text":"","code":"lr_one_cycle(   optimizer,   max_lr,   total_steps = NULL,   epochs = NULL,   steps_per_epoch = NULL,   pct_start = 0.3,   anneal_strategy = \"cos\",   cycle_momentum = TRUE,   base_momentum = 0.85,   max_momentum = 0.95,   div_factor = 25,   final_div_factor = 10000,   last_epoch = -1,   verbose = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/lr_one_cycle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Once cycle learning rate — lr_one_cycle","text":"optimizer (Optimizer): Wrapped optimizer. max_lr (float list): Upper learning rate boundaries cycle parameter group. total_steps (int): total number steps cycle. Note value provided , must inferred providing value epochs steps_per_epoch. Default: NULL epochs (int): number epochs train . used along steps_per_epoch order infer total number steps cycle value total_steps provided. Default: NULL steps_per_epoch (int): number steps per epoch train . used along epochs order infer total number steps cycle value total_steps provided. Default: NULL pct_start (float): percentage cycle (number steps) spent increasing learning rate. Default: 0.3 anneal_strategy (str): {'cos', 'linear'} Specifies annealing strategy: \"cos\" cosine annealing, \"linear\" linear annealing. Default: 'cos' cycle_momentum (bool): TRUE, momentum cycled inversely learning rate 'base_momentum' 'max_momentum'. Default: TRUE base_momentum (float list): Lower momentum boundaries cycle parameter group. Note momentum cycled inversely learning rate; peak cycle, momentum 'base_momentum' learning rate 'max_lr'. Default: 0.85 max_momentum (float list): Upper momentum boundaries cycle parameter group. Functionally, defines cycle amplitude (max_momentum - base_momentum). Note momentum cycled inversely learning rate; start cycle, momentum 'max_momentum' learning rate 'base_lr' Default: 0.95 div_factor (float): Determines initial learning rate via initial_lr = max_lr/div_factor Default: 25 final_div_factor (float): Determines minimum learning rate via min_lr = initial_lr/final_div_factor Default: 1e4 last_epoch (int): index last batch. parameter used resuming training job. Since step() invoked batch instead epoch, number represents total number batches computed, total number epochs computed. last_epoch=-1, schedule started beginning. Default: -1 verbose (bool): TRUE, prints message stdout update. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_one_cycle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Once cycle learning rate — lr_one_cycle","text":"policy initially described paper Super-Convergence: Fast Training Neural Networks Using Large Learning Rates. 1cycle learning rate policy changes learning rate every batch. step called batch used training. scheduler chainable. Note also total number steps cycle can determined one two ways (listed order precedence): value total_steps explicitly provided. number epochs (epochs) number steps per epoch (steps_per_epoch) provided. case, number total steps inferred total_steps = epochs * steps_per_epoch must either provide value total_steps provide value epochs steps_per_epoch.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_one_cycle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Once cycle learning rate — lr_one_cycle","text":"","code":"if (torch_is_installed()) { if (FALSE) { data_loader <- dataloader(...) optimizer <- optim_sgd(model$parameters, lr = 0.1, momentum = 0.9) scheduler <- lr_one_cycle(optimizer,   max_lr = 0.01, steps_per_epoch = length(data_loader),   epochs = 10 )  for (i in 1:epochs) {   coro::loop(for (batch in data_loader) {     train_batch(...)     scheduler$step()   }) } }  }"},{"path":"https://torch.mlverse.org/docs/reference/lr_reduce_on_plateau.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce learning rate on plateau — lr_reduce_on_plateau","title":"Reduce learning rate on plateau — lr_reduce_on_plateau","text":"Reduce learning rate metric stopped improving. Models often benefit reducing learning rate factor 2-10 learning stagnates. scheduler reads metrics quantity improvement seen 'patience' number epochs, learning rate reduced.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_reduce_on_plateau.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce learning rate on plateau — lr_reduce_on_plateau","text":"","code":"lr_reduce_on_plateau(   optimizer,   mode = \"min\",   factor = 0.1,   patience = 10,   threshold = 1e-04,   threshold_mode = \"rel\",   cooldown = 0,   min_lr = 0,   eps = 1e-08,   verbose = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/lr_reduce_on_plateau.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce learning rate on plateau — lr_reduce_on_plateau","text":"optimizer (Optimizer): Wrapped optimizer. mode (str): One min, max. min mode, lr reduced quantity monitored stopped decreasing; max mode reduced quantity monitored stopped increasing. Default: 'min'. factor (float): Factor learning rate reduced. new_lr <- lr * factor. Default: 0.1. patience (int): Number epochs improvement learning rate reduced. example, patience = 2, ignore first 2 epochs improvement, decrease LR 3rd epoch loss still improved . Default: 10. threshold (float):Threshold measuring new optimum, focus significant changes. Default: 1e-4. threshold_mode (str): One rel, abs. rel mode, dynamic_threshold <- best * ( 1 + threshold ) 'max' mode best * ( 1 - threshold ) min mode. abs mode, dynamic_threshold <- best + threshold max mode best - threshold min mode. Default: 'rel'. cooldown (int): Number epochs wait resuming normal operation lr reduced. Default: 0. min_lr (float list): scalar list scalars. lower bound learning rate param groups group respectively. Default: 0. eps (float): Minimal decay applied lr. difference new old lr smaller eps, update ignored. Default: 1e-8. verbose (bool): TRUE, prints message stdout update. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_reduce_on_plateau.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce learning rate on plateau — lr_reduce_on_plateau","text":"","code":"if (torch_is_installed()) { if (FALSE) {  optimizer <- optim_sgd(model$parameters(), lr=0.1, momentum=0.9) scheduler <- lr_reduce_on_plateau(optimizer, 'min') for (epoch in 1:10) {  train(...)  val_loss <- validate(...)  # note that step should be called after validate  scheduler$step(val_loss) } } }"},{"path":"https://torch.mlverse.org/docs/reference/lr_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates learning rate schedulers — lr_scheduler","title":"Creates learning rate schedulers — lr_scheduler","text":"Creates learning rate schedulers","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates learning rate schedulers — lr_scheduler","text":"","code":"lr_scheduler(   classname = NULL,   inherit = LRScheduler,   ...,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/lr_scheduler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates learning rate schedulers — lr_scheduler","text":"classname optional name learning rate scheduler inherit optional learning rate scheduler inherit ... named list methods. must implement get_lr() method take argument returns learning rates param_group optimizer. parent_env passed R6::R6Class().","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Step learning rate decay — lr_step","title":"Step learning rate decay — lr_step","text":"Decays learning rate parameter group gamma every step_size epochs. Notice decay can happen simultaneously changes learning rate outside scheduler. last_epoch=-1, sets initial lr lr.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step learning rate decay — lr_step","text":"","code":"lr_step(optimizer, step_size, gamma = 0.1, last_epoch = -1)"},{"path":"https://torch.mlverse.org/docs/reference/lr_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step learning rate decay — lr_step","text":"optimizer (Optimizer): Wrapped optimizer. step_size (int): Period learning rate decay. gamma (float): Multiplicative factor learning rate decay. Default: 0.1. last_epoch (int): index last epoch. Default: -1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/lr_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Step learning rate decay — lr_step","text":"","code":"if (torch_is_installed()) { if (FALSE) { # Assuming optimizer uses lr = 0.05 for all groups # lr = 0.05     if epoch < 30 # lr = 0.005    if 30 <= epoch < 60 # lr = 0.0005   if 60 <= epoch < 90 # ... scheduler <- lr_step(optimizer, step_size = 30, gamma = 0.1) for (epoch in 1:100) {   train(...)   validate(...)   scheduler$step() } }  }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 1D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool1d","title":"Applies a 1D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool1d","text":"output size H, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 1D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool1d","text":"","code":"nn_adaptive_avg_pool1d(output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 1D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool1d","text":"output_size target output size H","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 1D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool1d","text":"","code":"if (torch_is_installed()) { # target output size of 5 m <- nn_adaptive_avg_pool1d(5) input <- torch_randn(1, 64, 8) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 2D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool2d","title":"Applies a 2D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool2d","text":"output size H x W, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 2D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool2d","text":"","code":"nn_adaptive_avg_pool2d(output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 2D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool2d","text":"output_size target output size image form H x W. Can tuple (H, W) single H square image H x H. H W can either int, NULL means size input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 2D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool2d","text":"","code":"if (torch_is_installed()) { # target output size of 5x7 m <- nn_adaptive_avg_pool2d(c(5, 7)) input <- torch_randn(1, 64, 8, 9) output <- m(input) # target output size of 7x7 (square) m <- nn_adaptive_avg_pool2d(7) input <- torch_randn(1, 64, 10, 9) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 3D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool3d","title":"Applies a 3D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool3d","text":"output size D x H x W, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 3D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool3d","text":"","code":"nn_adaptive_avg_pool3d(output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 3D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool3d","text":"output_size target output size form D x H x W. Can tuple (D, H, W) single number D cube D x D x D. D, H W can either int, None means size input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_avg_pool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 3D adaptive average pooling over an input signal composed of several input planes. — nn_adaptive_avg_pool3d","text":"","code":"if (torch_is_installed()) { # target output size of 5x7x9 m <- nn_adaptive_avg_pool3d(c(5, 7, 9)) input <- torch_randn(1, 64, 8, 9, 10) output <- m(input) # target output size of 7x7x7 (cube) m <- nn_adaptive_avg_pool3d(7) input <- torch_randn(1, 64, 10, 9, 8) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"Efficient softmax approximation described Efficient softmax approximation GPUs Edouard Grave, Armand Joulin, Moustapha Cissé, David Grangier, Hervé Jégou","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"","code":"nn_adaptive_log_softmax_with_loss(   in_features,   n_classes,   cutoffs,   div_value = 4,   head_bias = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"in_features (int): Number features input tensor n_classes (int): Number classes dataset cutoffs (Sequence): Cutoffs used assign targets buckets div_value (float, optional): value used exponent compute sizes clusters. Default: 4.0 head_bias (bool, optional): True, adds bias term 'head' adaptive softmax. Default: False","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"NamedTuple output loss fields: output Tensor size N containing computed target log probabilities example loss Scalar representing computed negative log likelihood loss","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"Adaptive softmax approximate strategy training models large output spaces. effective label distribution highly imbalanced, example natural language modelling, word frequency distribution approximately follows Zipf's law. Adaptive softmax partitions labels several clusters, according frequency. clusters may contain different number targets . Additionally, clusters containing less frequent labels assign lower dimensional embeddings labels, speeds computation. minibatch, clusters least one target present evaluated. idea clusters accessed frequently (like first one, containing frequent labels), also cheap compute -- , contain small number assigned labels. highly recommend taking look original paper details. cutoffs ordered Sequence integers sorted increasing order. controls number clusters partitioning targets clusters. example setting cutoffs = c(10, 100, 1000) means first 10 targets assigned 'head' adaptive softmax, targets 11, 12, ..., 100 assigned first cluster, targets 101, 102, ..., 1000 assigned second cluster, targets 1001, 1002, ..., n_classes - 1 assigned last, third cluster. div_value used compute size additional cluster, given \\(\\left\\lfloor\\frac{\\mbox{\\_features}}{\\mbox{div\\_value}^{idx}}\\right\\rfloor\\), \\(idx\\) cluster index (clusters less frequent words larger indices, indices starting \\(1\\)). head_bias set True, adds bias term 'head' adaptive softmax. See paper details. Set False official implementation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"module returns NamedTuple output loss fields. See documentation details. compute log-probabilities classes, log_prob method can used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"Labels passed inputs module sorted according frequency. means frequent label represented index 0, least frequent label represented index n_classes - 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_log_softmax_with_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"AdaptiveLogSoftmaxWithLoss module — nn_adaptive_log_softmax_with_loss","text":"input: \\((N, \\mbox{\\_features})\\) target: \\((N)\\) value satisfies \\(0 <= \\mbox{target[]} <= \\mbox{n\\_classes}\\) output1: \\((N)\\) output2: Scalar","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 1D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool1d","title":"Applies a 1D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool1d","text":"output size H, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 1D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool1d","text":"","code":"nn_adaptive_max_pool1d(output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 1D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool1d","text":"output_size target output size H return_indices TRUE, return indices along outputs. Useful pass nn_max_unpool1d(). Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 1D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool1d","text":"","code":"if (torch_is_installed()) { # target output size of 5 m <- nn_adaptive_max_pool1d(5) input <- torch_randn(1, 64, 8) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 2D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool2d","title":"Applies a 2D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool2d","text":"output size H x W, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 2D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool2d","text":"","code":"nn_adaptive_max_pool2d(output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 2D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool2d","text":"output_size target output size image form H x W. Can tuple (H, W) single H square image H x H. H W can either int, None means size input. return_indices TRUE, return indices along outputs. Useful pass nn_max_unpool2d(). Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 2D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool2d","text":"","code":"if (torch_is_installed()) { # target output size of 5x7 m <- nn_adaptive_max_pool2d(c(5, 7)) input <- torch_randn(1, 64, 8, 9) output <- m(input) # target output size of 7x7 (square) m <- nn_adaptive_max_pool2d(7) input <- torch_randn(1, 64, 10, 9) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 3D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool3d","title":"Applies a 3D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool3d","text":"output size D x H x W, input size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 3D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool3d","text":"","code":"nn_adaptive_max_pool3d(output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 3D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool3d","text":"output_size target output size image form D x H x W. Can tuple (D, H, W) single D cube D x D x D. D, H W can either int, None means size input. return_indices TRUE, return indices along outputs. Useful pass nn_max_unpool3d(). Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_adaptive_max_pool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 3D adaptive max pooling over an input signal composed of several input planes. — nn_adaptive_max_pool3d","text":"","code":"if (torch_is_installed()) { # target output size of 5x7x9 m <- nn_adaptive_max_pool3d(c(5, 7, 9)) input <- torch_randn(1, 64, 8, 9, 10) output <- m(input) # target output size of 7x7x7 (cube) m <- nn_adaptive_max_pool3d(7) input <- torch_randn(1, 64, 10, 9, 8) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"simplest case, output value layer input size \\((N, C, L)\\), output \\((N, C, L_{})\\) kernel_size \\(k\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"","code":"nn_avg_pool1d(   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"kernel_size size window stride stride window. Default value kernel_size padding implicit zero padding added sides ceil_mode TRUE, use ceil instead floor compute output shape count_include_pad TRUE, include zero-padding averaging calculation","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"$$   \\mbox{}(N_i, C_j, l) = \\frac{1}{k} \\sum_{m=0}^{k-1} \\mbox{input}(N_i, C_j, \\mbox{stride} \\times l + m) $$ padding non-zero, input implicitly zero-padded sides padding number points. parameters kernel_size, stride, padding can int one-element tuple.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"Input: \\((N, C, L_{})\\) Output: \\((N, C, L_{})\\), $$   L_{} = \\left\\lfloor \\frac{L_{} +       2 \\times \\mbox{padding} - \\mbox{kernel\\_size}}{\\mbox{stride}} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 1D average pooling over an input signal composed of several input planes. — nn_avg_pool1d","text":"","code":"if (torch_is_installed()) {  # pool with window of size=3, stride=2 m <- nn_avg_pool1d(3, stride = 2) m(torch_randn(1, 1, 8)) } #> torch_tensor #> (1,.,.) =  #>   0.4693 -0.1130 -0.5694 #> [ CPUFloatType{1,1,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"simplest case, output value layer input size \\((N, C, H, W)\\), output \\((N, C, H_{}, W_{})\\) kernel_size \\((kH, kW)\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"","code":"nn_avg_pool2d(   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE,   divisor_override = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"kernel_size size window stride stride window. Default value kernel_size padding implicit zero padding added sides ceil_mode TRUE, use ceil instead floor compute output shape count_include_pad TRUE, include zero-padding averaging calculation divisor_override specified, used divisor, otherwise kernel_size used","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"$$   (N_i, C_j, h, w)  = \\frac{1}{kH * kW} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1} input(N_i, C_j, stride[0] \\times h + m, stride[1] \\times w + n) $$ padding non-zero, input implicitly zero-padded sides padding number points. parameters kernel_size, stride, padding can either : single int -- case value used height width dimension tuple two ints -- case, first int used height dimension, second int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"Input: \\((N, C, H_{}, W_{})\\) Output: \\((N, C, H_{}, W_{})\\), $$   H_{} = \\left\\lfloor\\frac{H_{}  + 2 \\times \\mbox{padding}[0] -       \\mbox{kernel\\_size}[0]}{\\mbox{stride}[0]} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{}  + 2 \\times \\mbox{padding}[1] -       \\mbox{kernel\\_size}[1]}{\\mbox{stride}[1]} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 2D average pooling over an input signal composed of several input planes. — nn_avg_pool2d","text":"","code":"if (torch_is_installed()) {  # pool of square window of size=3, stride=2 m <- nn_avg_pool2d(3, stride = 2) # pool of non-square window m <- nn_avg_pool2d(c(3, 2), stride = c(2, 1)) input <- torch_randn(20, 16, 50, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"simplest case, output value layer input size \\((N, C, D, H, W)\\), output \\((N, C, D_{}, H_{}, W_{})\\) kernel_size \\((kD, kH, kW)\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"","code":"nn_avg_pool3d(   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE,   divisor_override = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"kernel_size size window stride stride window. Default value kernel_size padding implicit zero padding added three sides ceil_mode TRUE, use ceil instead floor compute output shape count_include_pad TRUE, include zero-padding averaging calculation divisor_override specified, used divisor, otherwise kernel_size used","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"$$ \\begin{array}{ll} \\mbox{}(N_i, C_j, d, h, w) = & \\sum_{k=0}^{kD-1} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1} \\\\ & \\frac{\\mbox{input}(N_i, C_j, \\mbox{stride}[0] \\times d + k, \\mbox{stride}[1] \\times h + m, \\mbox{stride}[2] \\times w + n)}{kD \\times kH \\times kW} \\end{array} $$ padding non-zero, input implicitly zero-padded three sides padding number points. parameters kernel_size, stride can either : single int -- case value used depth, height width dimension tuple three ints -- case, first int used depth dimension, second int height dimension third int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"Input: \\((N, C, D_{}, H_{}, W_{})\\) Output: \\((N, C, D_{}, H_{}, W_{})\\), $$   D_{} = \\left\\lfloor\\frac{D_{} + 2 \\times \\mbox{padding}[0] -       \\mbox{kernel\\_size}[0]}{\\mbox{stride}[0]} + 1\\right\\rfloor $$ $$   H_{} = \\left\\lfloor\\frac{H_{} + 2 \\times \\mbox{padding}[1] -       \\mbox{kernel\\_size}[1]}{\\mbox{stride}[1]} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{} + 2 \\times \\mbox{padding}[2] -       \\mbox{kernel\\_size}[2]}{\\mbox{stride}[2]} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_avg_pool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 3D average pooling over an input signal composed of several input planes. — nn_avg_pool3d","text":"","code":"if (torch_is_installed()) {  # pool of square window of size=3, stride=2 m <- nn_avg_pool3d(3, stride = 2) # pool of non-square window m <- nn_avg_pool3d(c(3, 2, 2), stride = c(2, 1, 2)) input <- torch_randn(20, 16, 50, 44, 31) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":null,"dir":"Reference","previous_headings":"","what":"BatchNorm1D module — nn_batch_norm1d","title":"BatchNorm1D module — nn_batch_norm1d","text":"Applies Batch Normalization 2D 3D input (mini-batch 1D inputs optional additional channel dimension) described paper Batch Normalization: Accelerating Deep Network Training Reducing Internal Covariate Shift","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BatchNorm1D module — nn_batch_norm1d","text":"","code":"nn_batch_norm1d(   num_features,   eps = 1e-05,   momentum = 0.1,   affine = TRUE,   track_running_stats = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BatchNorm1D module — nn_batch_norm1d","text":"num_features \\(C\\) expected input size \\((N, C, L)\\) \\(L\\) input size \\((N, L)\\) eps value added denominator numerical stability. Default: 1e-5 momentum value used running_mean running_var computation. Can set NULL cumulative moving average (.e. simple average). Default: 0.1 affine boolean value set TRUE, module learnable affine parameters. Default: TRUE track_running_stats boolean value set TRUE, module tracks running mean variance, set FALSE, module track statistics always uses batch statistics training eval modes. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BatchNorm1D module — nn_batch_norm1d","text":"$$ y = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ mean standard-deviation calculated per-dimension mini-batches \\(\\gamma\\) \\(\\beta\\) learnable parameter vectors size C (C input size). default, elements \\(\\gamma\\) set 1 elements \\(\\beta\\) set 0. Also default, training layer keeps running estimates computed mean variance, used normalization evaluation. running estimates kept default :attr:momentum 0.1. track_running_stats set FALSE, layer keep running estimates, batch statistics instead used evaluation time well.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"BatchNorm1D module — nn_batch_norm1d","text":"momentum argument different one used optimizer classes conventional notion momentum. Mathematically, update rule running statistics \\(\\hat{x}_{\\mbox{new}} = (1 - \\mbox{momentum}) \\times \\hat{x} + \\mbox{momentum} \\times x_t\\), \\(\\hat{x}\\) estimated statistic \\(x_t\\) new observed value. Batch Normalization done C dimension, computing statistics (N, L) slices, common terminology call Temporal Batch Normalization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"BatchNorm1D module — nn_batch_norm1d","text":"Input: \\((N, C)\\) \\((N, C, L)\\) Output: \\((N, C)\\) \\((N, C, L)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BatchNorm1D module — nn_batch_norm1d","text":"","code":"if (torch_is_installed()) { # With Learnable Parameters m <- nn_batch_norm1d(100) # Without Learnable Parameters m <- nn_batch_norm1d(100, affine = FALSE) input <- torch_randn(20, 100) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":null,"dir":"Reference","previous_headings":"","what":"BatchNorm2D — nn_batch_norm2d","title":"BatchNorm2D — nn_batch_norm2d","text":"Applies Batch Normalization 4D input (mini-batch 2D inputs additional channel dimension) described paper Batch Normalization: Accelerating Deep Network Training Reducing Internal Covariate Shift.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BatchNorm2D — nn_batch_norm2d","text":"","code":"nn_batch_norm2d(   num_features,   eps = 1e-05,   momentum = 0.1,   affine = TRUE,   track_running_stats = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BatchNorm2D — nn_batch_norm2d","text":"num_features \\(C\\) expected input size \\((N, C, H, W)\\) eps value added denominator numerical stability. Default: 1e-5 momentum value used running_mean running_var computation. Can set None cumulative moving average (.e. simple average). Default: 0.1 affine boolean value set TRUE, module learnable affine parameters. Default: TRUE track_running_stats boolean value set TRUE, module tracks running mean variance, set FALSE, module track statistics uses batch statistics instead training eval modes running mean variance None. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BatchNorm2D — nn_batch_norm2d","text":"$$   y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ mean standard-deviation calculated per-dimension mini-batches \\(\\gamma\\) \\(\\beta\\) learnable parameter vectors size C (C input size). default, elements \\(\\gamma\\) set 1 elements \\(\\beta\\) set 0. standard-deviation calculated via biased estimator, equivalent torch_var(input, unbiased=FALSE). Also default, training layer keeps running estimates computed mean variance, used normalization evaluation. running estimates kept default momentum 0.1. track_running_stats set FALSE, layer keep running estimates, batch statistics instead used evaluation time well.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"BatchNorm2D — nn_batch_norm2d","text":"momentum argument different one used optimizer classes conventional notion momentum. Mathematically, update rule running statistics \\(\\hat{x}_{\\mbox{new}} = (1 - \\mbox{momentum}) \\times \\hat{x} + \\mbox{momentum} \\times x_t\\), \\(\\hat{x}\\) estimated statistic \\(x_t\\) new observed value. Batch Normalization done C dimension, computing statistics (N, H, W) slices, common terminology call Spatial Batch Normalization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"BatchNorm2D — nn_batch_norm2d","text":"Input: \\((N, C, H, W)\\) Output: \\((N, C, H, W)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BatchNorm2D — nn_batch_norm2d","text":"","code":"if (torch_is_installed()) { # With Learnable Parameters m <- nn_batch_norm2d(100) # Without Learnable Parameters m <- nn_batch_norm2d(100, affine = FALSE) input <- torch_randn(20, 100, 35, 45) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":null,"dir":"Reference","previous_headings":"","what":"BatchNorm3D — nn_batch_norm3d","title":"BatchNorm3D — nn_batch_norm3d","text":"Applies Batch Normalization 5D input (mini-batch 3D inputs additional channel dimension) described paper Batch Normalization: Accelerating Deep Network Training Reducing Internal Covariate Shift.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BatchNorm3D — nn_batch_norm3d","text":"","code":"nn_batch_norm3d(   num_features,   eps = 1e-05,   momentum = 0.1,   affine = TRUE,   track_running_stats = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BatchNorm3D — nn_batch_norm3d","text":"num_features \\(C\\) expected input size \\((N, C, D, H, W)\\) eps value added denominator numerical stability. Default: 1e-5 momentum value used running_mean running_var computation. Can set None cumulative moving average (.e. simple average). Default: 0.1 affine boolean value set TRUE, module learnable affine parameters. Default: TRUE track_running_stats boolean value set TRUE, module tracks running mean variance, set FALSE, module track statistics uses batch statistics instead training eval modes running mean variance None. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BatchNorm3D — nn_batch_norm3d","text":"$$   y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ mean standard-deviation calculated per-dimension mini-batches \\(\\gamma\\) \\(\\beta\\) learnable parameter vectors size C (C input size). default, elements \\(\\gamma\\) set 1 elements \\(\\beta\\) set 0. standard-deviation calculated via biased estimator, equivalent torch_var(input, unbiased = FALSE). Also default, training layer keeps running estimates computed mean variance, used normalization evaluation. running estimates kept default momentum 0.1. track_running_stats set FALSE, layer keep running estimates, batch statistics instead used evaluation time well.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"BatchNorm3D — nn_batch_norm3d","text":"momentum argument different one used optimizer classes conventional notion momentum. Mathematically, update rule running statistics : \\(\\hat{x}_{\\mbox{new}} = (1 - \\mbox{momentum}) \\times \\hat{x} + \\mbox{momentum} \\times x_t\\), \\(\\hat{x}\\) estimated statistic \\(x_t\\) new observed value. Batch Normalization done C dimension, computing statistics (N, D, H, W) slices, common terminology call Volumetric Batch Normalization Spatio-temporal Batch Normalization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"BatchNorm3D — nn_batch_norm3d","text":"Input: \\((N, C, D, H, W)\\) Output: \\((N, C, D, H, W)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_batch_norm3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BatchNorm3D — nn_batch_norm3d","text":"","code":"if (torch_is_installed()) { # With Learnable Parameters m <- nn_batch_norm3d(100) # Without Learnable Parameters m <- nn_batch_norm3d(100, affine = FALSE) input <- torch_randn(20, 100, 35, 45, 55) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary cross entropy loss — nn_bce_loss","title":"Binary cross entropy loss — nn_bce_loss","text":"Creates criterion measures Binary Cross Entropy target output:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary cross entropy loss — nn_bce_loss","text":"","code":"nn_bce_loss(weight = NULL, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary cross entropy loss — nn_bce_loss","text":"weight (Tensor, optional): manual rescaling weight given loss batch element. given, Tensor size nbatch. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binary cross entropy loss — nn_bce_loss","text":"unreduced (.e. reduction set 'none') loss can described : $$   \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right] $$ \\(N\\) batch size. reduction 'none' (default 'mean'), $$   \\ell(x, y) = \\left\\{ \\begin{array}{ll} \\mbox{mean}(L), & \\mbox{reduction} = \\mbox{'mean';}\\\\ \\mbox{sum}(L),  & \\mbox{reduction} = \\mbox{'sum'.} \\end{array} \\right. $$ used measuring error reconstruction example auto-encoder. Note targets \\(y\\) numbers 0 1. Notice \\(x_n\\) either 0 1, one log terms mathematically undefined loss equation. PyTorch chooses set \\(\\log (0) = -\\infty\\), since \\(\\lim_{x\\0} \\log (x) = -\\infty\\). However, infinite term loss equation desirable several reasons. one, either \\(y_n = 0\\) \\((1 - y_n) = 0\\), multiplying 0 infinity. Secondly, infinite loss value, also infinite term gradient, since \\(\\lim_{x\\0} \\frac{d}{dx} \\log (x) = \\infty\\). make BCELoss's backward method nonlinear respect \\(x_n\\), using things like linear regression straight-forward. solution BCELoss clamps log function outputs greater equal -100. way, can always finite loss value linear backward method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Binary cross entropy loss — nn_bce_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar. reduction 'none', \\((N, *)\\), shape input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binary cross entropy loss — nn_bce_loss","text":"","code":"if (torch_is_installed()) { m <- nn_sigmoid() loss <- nn_bce_loss() input <- torch_randn(3, requires_grad = TRUE) target <- torch_rand(3) output <- loss(m(input), target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"BCE with logits loss — nn_bce_with_logits_loss","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"loss combines Sigmoid layer BCELoss one single class. version numerically stable using plain Sigmoid followed BCELoss , combining operations one layer, take advantage log-sum-exp trick numerical stability.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"","code":"nn_bce_with_logits_loss(weight = NULL, reduction = \"mean\", pos_weight = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"weight (Tensor, optional): manual rescaling weight given loss batch element. given, Tensor size nbatch. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. pos_weight (Tensor, optional): weight positive examples. Must vector length equal number classes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"unreduced (.e. reduction set 'none') loss can described : $$   \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)                    + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right], $$ \\(N\\) batch size. reduction 'none' (default 'mean'), $$   \\ell(x, y) = \\begin{array}{ll} \\mbox{mean}(L), & \\mbox{reduction} = \\mbox{'mean';}\\\\ \\mbox{sum}(L),  & \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ used measuring error reconstruction example auto-encoder. Note targets t[] numbers 0 1. possible trade recall precision adding weights positive examples. case multi-label classification loss can described : $$ \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c}) + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right], $$ \\(c\\) class number (\\(c > 1\\) multi-label binary classification, \\(c = 1\\) single-label binary classification), \\(n\\) number sample batch \\(p_c\\) weight positive answer class \\(c\\). \\(p_c > 1\\) increases recall, \\(p_c < 1\\) increases precision. example, dataset contains 100 positive 300 negative examples single class, pos_weight class equal \\(\\frac{300}{100}=3\\). loss act dataset contains \\(3\\times 100=300\\) positive examples.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar. reduction 'none', \\((N, *)\\), shape input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bce_with_logits_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BCE with logits loss — nn_bce_with_logits_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_bce_with_logits_loss() input <- torch_randn(3, requires_grad = TRUE) target <- torch_empty(3)$random_(1, 2) output <- loss(input, target) output$backward()  target <- torch_ones(10, 64, dtype = torch_float32()) # 64 classes, batch size = 10 output <- torch_full(c(10, 64), 1.5) # A prediction (logit) pos_weight <- torch_ones(64) # All weights are equal to 1 criterion <- nn_bce_with_logits_loss(pos_weight = pos_weight) criterion(output, target) # -log(sigmoid(1.5)) } #> torch_tensor #> 0.201413 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Bilinear module — nn_bilinear","title":"Bilinear module — nn_bilinear","text":"Applies bilinear transformation incoming data \\(y = x_1^T x_2 + b\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bilinear module — nn_bilinear","text":"","code":"nn_bilinear(in1_features, in2_features, out_features, bias = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bilinear module — nn_bilinear","text":"in1_features size first input sample in2_features size second input sample out_features size output sample bias set FALSE, layer learn additive bias. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Bilinear module — nn_bilinear","text":"Input1: \\((N, *, H_{in1})\\) \\(H_{in1}=\\mbox{in1\\_features}\\) \\(*\\) means number additional dimensions. last dimension inputs . Input2: \\((N, *, H_{in2})\\) \\(H_{in2}=\\mbox{in2\\_features}\\). Output: \\((N, *, H_{})\\) \\(H_{}=\\mbox{\\_features}\\) last dimension shape input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Bilinear module — nn_bilinear","text":"weight: learnable weights module shape \\((\\mbox{\\_features}, \\mbox{in1\\_features}, \\mbox{in2\\_features})\\). values initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\), \\(k = \\frac{1}{\\mbox{in1\\_features}}\\) bias: learnable bias module shape \\((\\mbox{\\_features})\\). bias TRUE, values initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\), \\(k = \\frac{1}{\\mbox{in1\\_features}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_bilinear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bilinear module — nn_bilinear","text":"","code":"if (torch_is_installed()) { m <- nn_bilinear(20, 30, 50) input1 <- torch_randn(128, 20) input2 <- torch_randn(128, 30) output <- m(input1, input2) print(output$size()) } #> [1] 128  50"},{"path":"https://torch.mlverse.org/docs/reference/nn_buffer.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a nn_buffer — nn_buffer","title":"Creates a nn_buffer — nn_buffer","text":"Indicates tensor buffer nn_module","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_buffer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a nn_buffer — nn_buffer","text":"","code":"nn_buffer(x, persistent = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_buffer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a nn_buffer — nn_buffer","text":"x tensor converted nn_buffer persistent whether buffer persistent .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":null,"dir":"Reference","previous_headings":"","what":"CELU module — nn_celu","title":"CELU module — nn_celu","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CELU module — nn_celu","text":"","code":"nn_celu(alpha = 1, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CELU module — nn_celu","text":"alpha \\(\\alpha\\) value CELU formulation. Default: 1.0 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CELU module — nn_celu","text":"$$   \\mbox{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1)) $$ details can found paper Continuously Differentiable Exponential Linear Units.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"CELU module — nn_celu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_celu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CELU module — nn_celu","text":"","code":"if (torch_is_installed()) { m <- nn_celu() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_contrib_sparsemax.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparsemax activation — nn_contrib_sparsemax","title":"Sparsemax activation — nn_contrib_sparsemax","text":"Sparsemax activation module.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_contrib_sparsemax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparsemax activation — nn_contrib_sparsemax","text":"","code":"nn_contrib_sparsemax(dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_contrib_sparsemax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparsemax activation — nn_contrib_sparsemax","text":"dim dimension apply sparsemax function. (-1)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_contrib_sparsemax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sparsemax activation — nn_contrib_sparsemax","text":"SparseMax activation described 'Softmax Sparsemax: Sparse Model Attention Multi-Label Classification' implementation based aced125/sparsemax","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv1D module — nn_conv1d","title":"Conv1D module — nn_conv1d","text":"Applies 1D convolution input signal composed several input planes. simplest case, output value layer input size \\((N, C_{\\mbox{}}, L)\\) output \\((N, C_{\\mbox{}}, L_{\\mbox{}})\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv1D module — nn_conv1d","text":"","code":"nn_conv1d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   dilation = 1,   groups = 1,   bias = TRUE,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv1D module — nn_conv1d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int, tuple str, optional) – Padding added sides input. Default: 0 dilation (int tuple, optional): Spacing kernel elements. Default: 1 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): TRUE, adds learnable bias output. Default: TRUE padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conv1D module — nn_conv1d","text":"$$ \\mbox{}(N_i, C_{\\mbox{}_j}) = \\mbox{bias}(C_{\\mbox{}_j}) +   \\sum_{k = 0}^{C_{} - 1} \\mbox{weight}(C_{\\mbox{}_j}, k) \\star \\mbox{input}(N_i, k) $$ \\(\\star\\) valid cross-correlation operator, \\(N\\) batch size, \\(C\\) denotes number channels, \\(L\\) length signal sequence. stride controls stride cross-correlation, single number one-element tuple. padding controls amount implicit zero-paddings sides padding number points. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters, size \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conv1D module — nn_conv1d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation, full cross-correlation. user add proper padding. groups == in_channels out_channels == K * in_channels, K positive integer, operation also termed literature depthwise convolution. words, input size \\((N, C_{}, L_{})\\), depthwise convolution depthwise multiplier K, can constructed arguments \\((C_{\\mbox{}}=C_{}, C_{\\mbox{}}=C_{} \\times K, ..., \\mbox{groups}=C_{})\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Conv1D module — nn_conv1d","text":"Input: \\((N, C_{}, L_{})\\) Output: \\((N, C_{}, L_{})\\) $$   L_{} = \\left\\lfloor\\frac{L_{} + 2 \\times \\mbox{padding} - \\mbox{dilation}     \\times (\\mbox{kernel\\_size} - 1) - 1}{\\mbox{stride}} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Conv1D module — nn_conv1d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}}, \\mbox{kernel\\_size})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\mbox{kernel\\_size}}\\) bias (Tensor): learnable bias module shape (out_channels). bias TRUE, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\mbox{kernel\\_size}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv1D module — nn_conv1d","text":"","code":"if (torch_is_installed()) { m <- nn_conv1d(16, 33, 3, stride = 2) input <- torch_randn(20, 16, 50) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv2D module — nn_conv2d","title":"Conv2D module — nn_conv2d","text":"Applies 2D convolution input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv2D module — nn_conv2d","text":"","code":"nn_conv2d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   dilation = 1,   groups = 1,   bias = TRUE,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv2D module — nn_conv2d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int tuple string, optional): Zero-padding added sides input. controls amount padding applied input. can either string 'valid', '' tuple ints giving amount implicit padding applied sides. Default: 0 dilation (int tuple, optional): Spacing kernel elements. Default: 1 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): TRUE, adds learnable bias output. Default: TRUE padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conv2D module — nn_conv2d","text":"simplest case, output value layer input size \\((N, C_{\\mbox{}}, H, W)\\) output \\((N, C_{\\mbox{}}, H_{\\mbox{}}, W_{\\mbox{}})\\) can precisely described : $$ \\mbox{}(N_i, C_{\\mbox{}_j}) = \\mbox{bias}(C_{\\mbox{}_j}) +   \\sum_{k = 0}^{C_{\\mbox{}} - 1} \\mbox{weight}(C_{\\mbox{}_j}, k) \\star \\mbox{input}(N_i, k) $$ \\(\\star\\) valid 2D cross-correlation operator, \\(N\\) batch size, \\(C\\) denotes number channels, \\(H\\) height input planes pixels, \\(W\\) width pixels. stride controls stride cross-correlation, single number tuple. padding controls amount implicit zero-paddings sides padding number points dimension. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link_ nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters, size: \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\). parameters kernel_size, stride, padding, dilation can either : single int -- case value used height width dimension tuple two ints -- case, first int used height dimension, second int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conv2D module — nn_conv2d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation, full cross-correlation. user add proper padding. groups == in_channels out_channels == K * in_channels, K positive integer, operation also termed literature depthwise convolution. words, input size :math:(N, C_{}, H_{}, W_{}), depthwise convolution depthwise multiplier K, can constructed arguments \\((\\_channels=C_{}, \\_channels=C_{} \\times K, ..., groups=C_{})\\). circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting backends_cudnn_deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Conv2D module — nn_conv2d","text":"Input: \\((N, C_{}, H_{}, W_{})\\) Output: \\((N, C_{}, H_{}, W_{})\\) $$   H_{} = \\left\\lfloor\\frac{H_{}  + 2 \\times \\mbox{padding}[0] - \\mbox{dilation}[0]     \\times (\\mbox{kernel\\_size}[0] - 1) - 1}{\\mbox{stride}[0]} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{}  + 2 \\times \\mbox{padding}[1] - \\mbox{dilation}[1]     \\times (\\mbox{kernel\\_size}[1] - 1) - 1}{\\mbox{stride}[1]} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Conv2D module — nn_conv2d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}}\\), \\(\\mbox{kernel\\_size[0]}, \\mbox{kernel\\_size[1]})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{1}\\mbox{kernel\\_size}[]}\\) bias (Tensor): learnable bias module shape (out_channels). bias TRUE, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{1}\\mbox{kernel\\_size}[]}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv2D module — nn_conv2d","text":"","code":"if (torch_is_installed()) {  # With square kernels and equal stride m <- nn_conv2d(16, 33, 3, stride = 2) # non-square kernels and unequal stride and with padding m <- nn_conv2d(16, 33, c(3, 5), stride = c(2, 1), padding = c(4, 2)) # non-square kernels and unequal stride and with padding and dilation m <- nn_conv2d(16, 33, c(3, 5), stride = c(2, 1), padding = c(4, 2), dilation = c(3, 1)) input <- torch_randn(20, 16, 50, 100) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv3D module — nn_conv3d","title":"Conv3D module — nn_conv3d","text":"Applies 3D convolution input signal composed several input planes. simplest case, output value layer input size \\((N, C_{}, D, H, W)\\) output \\((N, C_{}, D_{}, H_{}, W_{})\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv3D module — nn_conv3d","text":"","code":"nn_conv3d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   dilation = 1,   groups = 1,   bias = TRUE,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv3D module — nn_conv3d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int, tuple str, optional): padding added six sides input. Default: 0 dilation (int tuple, optional): Spacing kernel elements. Default: 1 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): TRUE, adds learnable bias output. Default: TRUE padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Conv3D module — nn_conv3d","text":"$$   (N_i, C_{out_j}) = bias(C_{out_j}) +   \\sum_{k = 0}^{C_{} - 1} weight(C_{out_j}, k) \\star input(N_i, k) $$ \\(\\star\\) valid 3D cross-correlation operator stride controls stride cross-correlation. padding controls amount implicit zero-paddings sides padding number points dimension. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link_ nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters, size \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\). parameters kernel_size, stride, padding, dilation can either : single int -- case value used depth, height width dimension tuple three ints -- case, first int used depth dimension, second int height dimension third int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Conv3D module — nn_conv3d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation, full cross-correlation. user add proper padding. groups == in_channels out_channels == K * in_channels, K positive integer, operation also termed literature depthwise convolution. words, input size \\((N, C_{}, D_{}, H_{}, W_{})\\), depthwise convolution depthwise multiplier K, can constructed arguments \\((\\_channels=C_{}, \\_channels=C_{} \\times K, ..., groups=C_{})\\). circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch.backends.cudnn.deterministic = TRUE. Please see notes :doc:/notes/randomness background.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Conv3D module — nn_conv3d","text":"Input: \\((N, C_{}, D_{}, H_{}, W_{})\\) Output: \\((N, C_{}, D_{}, H_{}, W_{})\\) $$   D_{} = \\left\\lfloor\\frac{D_{} + 2 \\times \\mbox{padding}[0] - \\mbox{dilation}[0]     \\times (\\mbox{kernel\\_size}[0] - 1) - 1}{\\mbox{stride}[0]} + 1\\right\\rfloor  $$ $$   H_{} = \\left\\lfloor\\frac{H_{} + 2 \\times \\mbox{padding}[1] - \\mbox{dilation}[1]     \\times (\\mbox{kernel\\_size}[1] - 1) - 1}{\\mbox{stride}[1]} + 1\\right\\rfloor  $$ $$   W_{} = \\left\\lfloor\\frac{W_{} + 2 \\times \\mbox{padding}[2] - \\mbox{dilation}[2]     \\times (\\mbox{kernel\\_size}[2] - 1) - 1}{\\mbox{stride}[2]} + 1\\right\\rfloor  $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Conv3D module — nn_conv3d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}},\\) \\(\\mbox{kernel\\_size[0]}, \\mbox{kernel\\_size[1]}, \\mbox{kernel\\_size[2]})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{2}\\mbox{kernel\\_size}[]}\\) bias (Tensor):   learnable bias module shape (out_channels). bias True, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{2}\\mbox{kernel\\_size}[]}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv3D module — nn_conv3d","text":"","code":"if (torch_is_installed()) { # With square kernels and equal stride m <- nn_conv3d(16, 33, 3, stride = 2) # non-square kernels and unequal stride and with padding m <- nn_conv3d(16, 33, c(3, 5, 2), stride = c(2, 1, 1), padding = c(4, 2, 0)) input <- torch_randn(20, 16, 10, 50, 100) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":null,"dir":"Reference","previous_headings":"","what":"ConvTranspose1D — nn_conv_transpose1d","title":"ConvTranspose1D — nn_conv_transpose1d","text":"Applies 1D transposed convolution operator input image composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ConvTranspose1D — nn_conv_transpose1d","text":"","code":"nn_conv_transpose1d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   bias = TRUE,   dilation = 1,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConvTranspose1D — nn_conv_transpose1d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int tuple, optional): dilation * (kernel_size - 1) - padding zero-padding added sides input. Default: 0 output_padding (int tuple, optional): Additional size added one side output shape. Default: 0 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): True, adds learnable bias output. Default: TRUE dilation (int tuple, optional): Spacing kernel elements. Default: 1 padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ConvTranspose1D — nn_conv_transpose1d","text":"module can seen gradient Conv1d respect input. also known fractionally-strided convolution deconvolution (although actual deconvolution operation). stride controls stride cross-correlation. padding controls amount implicit zero-paddings sides dilation * (kernel_size - 1) - padding number points. See note details. output_padding controls additional size added one side output shape. See note details. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters (size \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\)).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ConvTranspose1D — nn_conv_transpose1d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation, full cross-correlation. user add proper padding. padding argument effectively adds dilation * (kernel_size - 1) - padding amount zero padding sizes input. set ~torch.nn.Conv1d ~torch.nn.ConvTranspose1d initialized parameters, inverses regard input output shapes. However, stride > 1, ~torch.nn.Conv1d maps multiple input shapes output shape. output_padding provided resolve ambiguity effectively increasing calculated output shape one side. Note output_padding used find output shape, actually add zero-padding output. circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch.backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ConvTranspose1D — nn_conv_transpose1d","text":"Input: \\((N, C_{}, L_{})\\) Output: \\((N, C_{}, L_{})\\) $$   L_{} = (L_{} - 1) \\times \\mbox{stride} - 2 \\times \\mbox{padding} + \\mbox{dilation} \\times (\\mbox{kernel\\_size} - 1) + \\mbox{output\\_padding} + 1 $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"ConvTranspose1D — nn_conv_transpose1d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}},\\) \\(\\mbox{kernel\\_size})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\mbox{kernel\\_size}}\\) bias (Tensor):   learnable bias module shape (out_channels). bias TRUE, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\mbox{kernel\\_size}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ConvTranspose1D — nn_conv_transpose1d","text":"","code":"if (torch_is_installed()) { m <- nn_conv_transpose1d(32, 16, 2) input <- torch_randn(10, 32, 2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":null,"dir":"Reference","previous_headings":"","what":"ConvTranpose2D module — nn_conv_transpose2d","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"Applies 2D transposed convolution operator input image composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"","code":"nn_conv_transpose2d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   bias = TRUE,   dilation = 1,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int tuple, optional): dilation * (kernel_size - 1) - padding zero-padding added sides dimension input. Default: 0 output_padding (int tuple, optional): Additional size added one side dimension output shape. Default: 0 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): True, adds learnable bias output. Default: True dilation (int tuple, optional): Spacing kernel elements. Default: 1 padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"module can seen gradient Conv2d respect input. also known fractionally-strided convolution deconvolution (although actual deconvolution operation). stride controls stride cross-correlation. padding controls amount implicit zero-paddings sides dilation * (kernel_size - 1) - padding number points. See note details. output_padding controls additional size added one side output shape. See note details. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link_ nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters (size \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\)). parameters kernel_size, stride, padding, output_padding can either : single int -- case value used height width dimensions tuple two ints -- case, first int used height dimension, second int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation_, full cross-correlation. user add proper padding. padding argument effectively adds dilation * (kernel_size - 1) - padding amount zero padding sizes input. set nn_conv2d nn_conv_transpose2d initialized parameters, inverses regard input output shapes. However, stride > 1, nn_conv2d maps multiple input shapes output shape. output_padding provided resolve ambiguity effectively increasing calculated output shape one side. Note output_padding used find output shape, actually add zero-padding output. circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch.backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"Input: \\((N, C_{}, H_{}, W_{})\\) Output: \\((N, C_{}, H_{}, W_{})\\) $$   H_{} = (H_{} - 1) \\times \\mbox{stride}[0] - 2 \\times \\mbox{padding}[0] + \\mbox{dilation}[0] \\times (\\mbox{kernel\\_size}[0] - 1) + \\mbox{output\\_padding}[0] + 1 $$ $$   W_{} = (W_{} - 1) \\times \\mbox{stride}[1] - 2 \\times \\mbox{padding}[1] + \\mbox{dilation}[1] \\times (\\mbox{kernel\\_size}[1] - 1) + \\mbox{output\\_padding}[1] + 1 $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}},\\) \\(\\mbox{kernel\\_size[0]}, \\mbox{kernel\\_size[1]})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{1}\\mbox{kernel\\_size}[]}\\) bias (Tensor):   learnable bias module shape (out_channels) bias True, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{1}\\mbox{kernel\\_size}[]}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ConvTranpose2D module — nn_conv_transpose2d","text":"","code":"if (torch_is_installed()) { # With square kernels and equal stride m <- nn_conv_transpose2d(16, 33, 3, stride = 2) # non-square kernels and unequal stride and with padding m <- nn_conv_transpose2d(16, 33, c(3, 5), stride = c(2, 1), padding = c(4, 2)) input <- torch_randn(20, 16, 50, 100) output <- m(input) # exact output size can be also specified as an argument input <- torch_randn(1, 16, 12, 12) downsample <- nn_conv2d(16, 16, 3, stride = 2, padding = 1) upsample <- nn_conv_transpose2d(16, 16, 3, stride = 2, padding = 1) h <- downsample(input) h$size() output <- upsample(h, output_size = input$size()) output$size() } #> [1]  1 16 12 12"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":null,"dir":"Reference","previous_headings":"","what":"ConvTranpose3D module — nn_conv_transpose3d","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"Applies 3D transposed convolution operator input image composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"","code":"nn_conv_transpose3d(   in_channels,   out_channels,   kernel_size,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   bias = TRUE,   dilation = 1,   padding_mode = \"zeros\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"in_channels (int): Number channels input image out_channels (int): Number channels produced convolution kernel_size (int tuple): Size convolving kernel stride (int tuple, optional): Stride convolution. Default: 1 padding (int tuple, optional): dilation * (kernel_size - 1) - padding zero-padding added sides dimension input. Default: 0 output_padding (int tuple, optional): Additional size added one side dimension output shape. Default: 0 output_padding (int tuple, optional): Additional size added one side dimension output shape. Default: 0 groups (int, optional): Number blocked connections input channels output channels. Default: 1 bias (bool, optional): True, adds learnable bias output. Default: True dilation (int tuple, optional): Spacing kernel elements. Default: 1 padding_mode (string, optional): 'zeros', 'reflect', 'replicate' 'circular'. Default: 'zeros'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"transposed convolution operator multiplies input value element-wise learnable kernel, sums outputs input feature planes. module can seen gradient Conv3d respect input. also known fractionally-strided convolution deconvolution (although actual deconvolution operation). stride controls stride cross-correlation. padding controls amount implicit zero-paddings sides dilation * (kernel_size - 1) - padding number points. See note details. output_padding controls additional size added one side output shape. See note details. dilation controls spacing kernel points; also known à trous algorithm. harder describe, link_ nice visualization dilation . groups controls connections inputs outputs. in_channels out_channels must divisible groups. example, groups=1, inputs convolved outputs. groups=2, operation becomes equivalent two conv layers side side, seeing half input channels, producing half output channels, subsequently concatenated. groups= in_channels, input channel convolved set filters (size \\(\\left\\lfloor\\frac{\\_channels}{\\_channels}\\right\\rfloor\\)). parameters kernel_size, stride, padding, output_padding can either : single int -- case value used depth, height width dimensions tuple three ints -- case, first int used depth dimension, second int height dimension third int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"Depending size kernel, several (last) columns input might lost, valid cross-correlation, full cross-correlation. user add proper padding. padding argument effectively adds dilation * (kernel_size - 1) - padding amount zero padding sizes input. set ~torch.nn.Conv3d ~torch.nn.ConvTranspose3d initialized parameters, inverses regard input output shapes. However, stride > 1, ~torch.nn.Conv3d maps multiple input shapes output shape. output_padding provided resolve ambiguity effectively increasing calculated output shape one side. Note output_padding used find output shape, actually add zero-padding output. circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch.backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"Input: \\((N, C_{}, D_{}, H_{}, W_{})\\) Output: \\((N, C_{}, D_{}, H_{}, W_{})\\) $$   D_{} = (D_{} - 1) \\times \\mbox{stride}[0] - 2 \\times \\mbox{padding}[0] + \\mbox{dilation}[0] \\times (\\mbox{kernel\\_size}[0] - 1) + \\mbox{output\\_padding}[0] + 1 $$ $$   H_{} = (H_{} - 1) \\times \\mbox{stride}[1] - 2 \\times \\mbox{padding}[1] + \\mbox{dilation}[1] \\times (\\mbox{kernel\\_size}[1] - 1) + \\mbox{output\\_padding}[1] + 1 $$ $$   W_{} = (W_{} - 1) \\times \\mbox{stride}[2] - 2 \\times \\mbox{padding}[2] + \\mbox{dilation}[2] \\times (\\mbox{kernel\\_size}[2] - 1) + \\mbox{output\\_padding}[2] + 1 $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"weight (Tensor): learnable weights module shape \\((\\mbox{\\_channels}, \\frac{\\mbox{\\_channels}}{\\mbox{groups}},\\) \\(\\mbox{kernel\\_size[0]}, \\mbox{kernel\\_size[1]}, \\mbox{kernel\\_size[2]})\\). values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{2}\\mbox{kernel\\_size}[]}\\) bias (Tensor):   learnable bias module shape (out_channels) bias True, values weights sampled \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{groups}{C_{\\mbox{}} * \\prod_{=0}^{2}\\mbox{kernel\\_size}[]}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_conv_transpose3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ConvTranpose3D module — nn_conv_transpose3d","text":"","code":"if (torch_is_installed()) { if (FALSE) { # With square kernels and equal stride m <- nn_conv_transpose3d(16, 33, 3, stride = 2) # non-square kernels and unequal stride and with padding m <- nn_conv_transpose3d(16, 33, c(3, 5, 2), stride = c(2, 1, 1), padding = c(0, 4, 2)) input <- torch_randn(20, 16, 10, 50, 100) output <- m(input) } }"},{"path":"https://torch.mlverse.org/docs/reference/nn_cosine_embedding_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine embedding loss — nn_cosine_embedding_loss","title":"Cosine embedding loss — nn_cosine_embedding_loss","text":"Creates criterion measures loss given input tensors \\(x_1\\), \\(x_2\\) Tensor label \\(y\\) values 1 -1. used measuring whether two inputs similar dissimilar, using cosine distance, typically used learning nonlinear embeddings semi-supervised learning. loss function sample :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cosine_embedding_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine embedding loss — nn_cosine_embedding_loss","text":"","code":"nn_cosine_embedding_loss(margin = 0, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_cosine_embedding_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine embedding loss — nn_cosine_embedding_loss","text":"margin (float, optional): number \\(-1\\) \\(1\\), \\(0\\) \\(0.5\\) suggested. margin missing, default value \\(0\\). reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cosine_embedding_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cosine embedding loss — nn_cosine_embedding_loss","text":"$$   \\mbox{loss}(x, y) =   \\begin{array}{ll} 1 - \\cos(x_1, x_2), & \\mbox{} y = 1 \\\\ \\max(0, \\cos(x_1, x_2) - \\mbox{margin}), & \\mbox{} y = -1 \\end{array} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"CrossEntropyLoss module — nn_cross_entropy_loss","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"criterion combines nn_log_softmax() nn_nll_loss() one single class. useful training classification problem C classes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"","code":"nn_cross_entropy_loss(weight = NULL, ignore_index = -100, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"weight (Tensor, optional): manual rescaling weight given class. given, Tensor size C ignore_index (int, optional): Specifies target value ignored contribute input gradient. size_average TRUE, loss averaged non-ignored targets. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"provided, optional argument weight 1D Tensor assigning weight classes. particularly useful unbalanced training set. input expected contain raw, unnormalized scores class. input Tensor size either \\((minibatch, C)\\) \\((minibatch, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) K-dimensional case (described later). criterion expects class index range \\([0, C-1]\\) target value 1D tensor size minibatch; ignore_index specified, criterion also accepts class index (index may necessarily class range). loss can described : $$   \\mbox{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right) = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right) $$ case weight argument specified: $$   \\mbox{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right) $$ losses averaged across observations minibatch. Can also used higher dimension inputs, 2D images, providing input size \\((minibatch, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\), \\(K\\) number dimensions, target appropriate shape (see ).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"Input: \\((N, C)\\) C = number classes, \\((N, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. Target: \\((N)\\) value \\(0 \\leq \\mbox{targets}[] \\leq C-1\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. Output: scalar. reduction 'none', size target: \\((N)\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CrossEntropyLoss module — nn_cross_entropy_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_cross_entropy_loss() input <- torch_randn(3, 5, requires_grad = TRUE) target <- torch_randint(low = 1, high = 5, size = 3, dtype = torch_long()) output <- loss(input, target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"The Connectionist Temporal Classification loss. — nn_ctc_loss","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"Calculates loss continuous (unsegmented) time series target sequence. CTCLoss sums probability possible alignments input target, producing loss value differentiable respect input node. alignment input target assumed \"many--one\", limits length target sequence must \\(\\leq\\) input length.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"","code":"nn_ctc_loss(blank = 0, reduction = \"mean\", zero_infinity = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"blank (int, optional): blank label. Default \\(0\\). reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': output losses divided target lengths mean batch taken. Default: 'mean' zero_infinity (bool, optional): Whether zero infinite losses associated gradients. Default: FALSE Infinite losses mainly occur inputs short aligned targets.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"order use CuDNN, following must satisfied: targets must concatenated format, input_lengths must T.  \\(blank=0\\), target_lengths \\(\\leq 256\\), integer arguments must regular implementation uses (common PyTorch) torch_long dtype. dtype torch_int32. circumstances using CUDA backend CuDNN, operator may select nondeterministic algorithm increase performance. undesirable, can try make operation deterministic (potentially performance cost) setting torch.backends.cudnn.deterministic = TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"Log_probs: Tensor size \\((T, N, C)\\), \\(T = \\mbox{input length}\\), \\(N = \\mbox{batch size}\\), \\(C = \\mbox{number classes (including blank)}\\). logarithmized probabilities outputs (e.g. obtained [nnf)log_softmax()]). Targets: Tensor size \\((N, S)\\) \\((\\mbox{sum}(\\mbox{target\\_lengths}))\\), \\(N = \\mbox{batch size}\\) \\(S = \\mbox{max target length, shape } (N, S)\\). represent target sequences. element target sequence class index. target index blank (default=0). \\((N, S)\\) form, targets padded length longest sequence, stacked. \\((\\mbox{sum}(\\mbox{target\\_lengths}))\\) form, targets assumed un-padded concatenated within 1 dimension. Input_lengths: Tuple tensor size \\((N)\\), \\(N = \\mbox{batch size}\\). represent lengths inputs (must \\(\\leq T\\)). lengths specified sequence achieve masking assumption sequences padded equal lengths. Target_lengths: Tuple tensor size \\((N)\\), \\(N = \\mbox{batch size}\\). represent lengths targets. Lengths specified sequence achieve masking assumption sequences padded equal lengths. target shape \\((N,S)\\), target_lengths effectively stop index \\(s_n\\) target sequence, target_n = targets[n,0:s_n] target batch. Lengths must \\(\\leq S\\) targets given 1d tensor concatenation individual targets, target_lengths must add total length tensor. Output: scalar. reduction 'none', \\((N)\\), \\(N = \\mbox{batch size}\\). [nnf)log_softmax()]: R:nnf)log_softmax() [n,0:s_n]: R:n,0:s_n","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":". Graves et al.: Connectionist Temporal Classification: Labelling Unsegmented Sequence Data Recurrent Neural Networks: https://www.cs.toronto.edu/~graves/icml_2006.pdf","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_ctc_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Connectionist Temporal Classification loss. — nn_ctc_loss","text":"","code":"if (torch_is_installed()) { # Target are to be padded T <- 50 # Input sequence length C <- 20 # Number of classes (including blank) N <- 16 # Batch size S <- 30 # Target sequence length of longest target in batch (padding length) S_min <- 10 # Minimum target length, for demonstration purposes  # Initialize random batch of input vectors, for *size = (T,N,C) input <- torch_randn(T, N, C)$log_softmax(2)$detach()$requires_grad_()  # Initialize random batch of targets (0 = blank, 1:C = classes) target <- torch_randint(low = 1, high = C, size = c(N, S), dtype = torch_long())  input_lengths <- torch_full(size = c(N), fill_value = TRUE, dtype = torch_long()) target_lengths <- torch_randint(low = S_min, high = S, size = c(N), dtype = torch_long()) ctc_loss <- nn_ctc_loss() loss <- ctc_loss(input, target, input_lengths, target_lengths) loss$backward()   # Target are to be un-padded T <- 50 # Input sequence length C <- 20 # Number of classes (including blank) N <- 16 # Batch size  # Initialize random batch of input vectors, for *size = (T,N,C) input <- torch_randn(T, N, C)$log_softmax(2)$detach()$requires_grad_() input_lengths <- torch_full(size = c(N), fill_value = TRUE, dtype = torch_long())  # Initialize random batch of targets (0 = blank, 1:C = classes) target_lengths <- torch_randint(low = 1, high = T, size = c(N), dtype = torch_long()) target <- torch_randint(   low = 1, high = C, size = as.integer(sum(target_lengths)),   dtype = torch_long() ) ctc_loss <- nn_ctc_loss() loss <- ctc_loss(input, target, input_lengths, target_lengths) loss$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout module — nn_dropout","title":"Dropout module — nn_dropout","text":"training, randomly zeroes elements input tensor probability p using samples Bernoulli distribution. channel zeroed independently every forward call.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout module — nn_dropout","text":"","code":"nn_dropout(p = 0.5, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout module — nn_dropout","text":"p probability element zeroed. Default: 0.5 inplace set TRUE, operation -place. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dropout module — nn_dropout","text":"proven effective technique regularization preventing co-adaptation neurons described paper Improving neural networks preventing co-adaptation feature detectors. Furthermore, outputs scaled factor :math:\\frac{1}{1-p} training. means evaluation module simply computes identity function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Dropout module — nn_dropout","text":"Input: \\((*)\\). Input can shape Output: \\((*)\\). Output shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropout module — nn_dropout","text":"","code":"if (torch_is_installed()) { m <- nn_dropout(p = 0.2) input <- torch_randn(20, 16) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout2D module — nn_dropout2d","title":"Dropout2D module — nn_dropout2d","text":"Randomly zero entire channels (channel 2D feature map, e.g., \\(j\\)-th channel \\(\\)-th sample batched input 2D tensor \\(\\mbox{input}[, j]\\)).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout2D module — nn_dropout2d","text":"","code":"nn_dropout2d(p = 0.5, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout2D module — nn_dropout2d","text":"p (float, optional): probability element zero-ed. inplace (bool, optional): set TRUE, operation -place","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dropout2D module — nn_dropout2d","text":"channel zeroed independently every forward call probability p using samples Bernoulli distribution. Usually input comes nn_conv2d modules. described paper Efficient Object Localization Using Convolutional Networks , adjacent pixels within feature maps strongly correlated (normally case early convolution layers) ..d. dropout regularize activations otherwise just result effective learning rate decrease. case, nn_dropout2d help promote independence feature maps used instead.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Dropout2D module — nn_dropout2d","text":"Input: \\((N, C, H, W)\\) Output: \\((N, C, H, W)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropout2D module — nn_dropout2d","text":"","code":"if (torch_is_installed()) { m <- nn_dropout2d(p = 0.2) input <- torch_randn(20, 16, 32, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout3D module — nn_dropout3d","title":"Dropout3D module — nn_dropout3d","text":"Randomly zero entire channels (channel 3D feature map, e.g., \\(j\\)-th channel \\(\\)-th sample batched input 3D tensor \\(\\mbox{input}[, j]\\)).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout3D module — nn_dropout3d","text":"","code":"nn_dropout3d(p = 0.5, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout3D module — nn_dropout3d","text":"p (float, optional): probability element zeroed. inplace (bool, optional): set TRUE, operation -place","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Dropout3D module — nn_dropout3d","text":"channel zeroed independently every forward call probability p using samples Bernoulli distribution. Usually input comes nn_conv2d modules. described paper Efficient Object Localization Using Convolutional Networks , adjacent pixels within feature maps strongly correlated (normally case early convolution layers) ..d. dropout regularize activations otherwise just result effective learning rate decrease. case, nn_dropout3d help promote independence feature maps used instead.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Dropout3D module — nn_dropout3d","text":"Input: \\((N, C, D, H, W)\\) Output: \\((N, C, D, H, W)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_dropout3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dropout3D module — nn_dropout3d","text":"","code":"if (torch_is_installed()) { m <- nn_dropout3d(p = 0.2) input <- torch_randn(20, 16, 4, 32, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":null,"dir":"Reference","previous_headings":"","what":"ELU module — nn_elu","title":"ELU module — nn_elu","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ELU module — nn_elu","text":"","code":"nn_elu(alpha = 1, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ELU module — nn_elu","text":"alpha \\(\\alpha\\) value ELU formulation. Default: 1.0 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ELU module — nn_elu","text":"$$   \\mbox{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ELU module — nn_elu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_elu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ELU module — nn_elu","text":"","code":"if (torch_is_installed()) { m <- nn_elu() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding module — nn_embedding","title":"Embedding module — nn_embedding","text":"simple lookup table stores embeddings fixed dictionary size. module often used store word embeddings retrieve using indices. input module list indices, output corresponding word embeddings.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding module — nn_embedding","text":"","code":"nn_embedding(   num_embeddings,   embedding_dim,   padding_idx = NULL,   max_norm = NULL,   norm_type = 2,   scale_grad_by_freq = FALSE,   sparse = FALSE,   .weight = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding module — nn_embedding","text":"num_embeddings (int): size dictionary embeddings embedding_dim (int): size embedding vector padding_idx (int, optional): given, pads output embedding vector padding_idx (initialized zeros) whenever encounters index. max_norm (float, optional): given, embedding vector norm larger max_norm renormalized norm max_norm. norm_type (float, optional): p p-norm compute max_norm option. Default 2. scale_grad_by_freq (boolean, optional): given, scale gradients inverse frequency words mini-batch. Default False. sparse (bool, optional): True, gradient w.r.t. weight matrix sparse tensor. .weight (Tensor) embeddings weights (case want set manually) See Notes details regarding sparse gradients.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Embedding module — nn_embedding","text":"Keep mind limited number optimizers support sparse gradients: currently optim.SGD (CUDA CPU), optim.SparseAdam (CUDA CPU) optim.Adagrad (CPU) padding_idx set, embedding vector padding_idx initialized zeros. However, note vector can modified afterwards, e.g., using customized initialization method, thus changing vector used pad output. gradient vector nn_embedding always zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Embedding module — nn_embedding","text":"weight (Tensor): learnable weights module shape (num_embeddings, embedding_dim) initialized \\(\\mathcal{N}(0, 1)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Embedding module — nn_embedding","text":"Input: \\((*)\\), LongTensor arbitrary shape containing indices extract Output: \\((*, H)\\), * input shape \\(H=\\mbox{embedding\\_dim}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding module — nn_embedding","text":"","code":"if (torch_is_installed()) { # an Embedding module containing 10 tensors of size 3 embedding <- nn_embedding(10, 3) # a batch of 2 samples of 4 indices each input <- torch_tensor(rbind(c(1, 2, 4, 5), c(4, 3, 2, 9)), dtype = torch_long()) embedding(input) # example with padding_idx embedding <- nn_embedding(10, 3, padding_idx = 1) input <- torch_tensor(matrix(c(1, 3, 1, 6), nrow = 1), dtype = torch_long()) embedding(input) } #> torch_tensor #> (1,.,.) =  #>   0.0000  0.0000  0.0000 #>   1.0913  0.6573  2.3777 #>   0.0000  0.0000  0.0000 #>  -0.3899 -0.0915 -1.3749 #> [ CPUFloatType{1,4,3} ][ grad_fn = <EmbeddingBackward0> ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding_bag.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding bag module — nn_embedding_bag","title":"Embedding bag module — nn_embedding_bag","text":"Computes sums, means maxes bags embeddings, without instantiating intermediate embeddings.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding_bag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding bag module — nn_embedding_bag","text":"","code":"nn_embedding_bag(   num_embeddings,   embedding_dim,   max_norm = NULL,   norm_type = 2,   scale_grad_by_freq = FALSE,   mode = \"mean\",   sparse = FALSE,   include_last_offset = FALSE,   padding_idx = NULL,   .weight = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding_bag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding bag module — nn_embedding_bag","text":"num_embeddings (int): size dictionary embeddings embedding_dim (int): size embedding vector max_norm (float, optional): given, embedding vector norm larger max_norm renormalized norm max_norm. norm_type (float, optional): p p-norm compute max_norm option. Default 2 scale_grad_by_freq (boolean, optional): given, scale gradients inverse frequency words mini-batch. Default False. mode (string, optional): \"sum\", \"mean\" \"max\". Specifies way reduce bag. \"sum\" computes weighted sum, taking per_sample_weights  consideration. \"mean\" computes average values bag, \"max\" computes max value bag. sparse (bool, optional): True, gradient w.r.t. weight matrix sparse tensor. See Notes details regarding sparse gradients. include_last_offset (bool, optional): True, offsets one additional element, last element equivalent size indices. matches CSR format. padding_idx (int, optional):  given, pads output embedding vector padding_idx (initialized zeros) whenever encounters index. .weight (Tensor, optional) embeddings weights (case want set manually)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding_bag.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Embedding bag module — nn_embedding_bag","text":"weight (Tensor): learnable weights module shape (num_embeddings, embedding_dim) initialized \\(\\mathcal{N}(0, 1)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_embedding_bag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Embedding bag module — nn_embedding_bag","text":"","code":"if (torch_is_installed()) { # an EmbeddingBag module containing 10 tensors of size 3 embedding_sum <- nn_embedding_bag(10, 3, mode = 'sum') # a batch of 2 samples of 4 indices each input <- torch_tensor(c(1, 2, 4, 5, 4, 3, 2, 9), dtype = torch_long()) offsets <- torch_tensor(c(0, 4), dtype = torch_long()) embedding_sum(input, offsets) # example with padding_idx embedding_sum <- nn_embedding_bag(10, 3, mode = 'sum', padding_idx = 1) input <- torch_tensor(c(2, 2, 2, 2, 4, 3, 2, 9), dtype = torch_long()) offsets <- torch_tensor(c(0, 4), dtype = torch_long()) embedding_sum(input, offsets) # An EmbeddingBag can be loaded from an Embedding like so embedding <- nn_embedding(10, 3, padding_idx = 2) embedding_sum <- nn_embedding_bag$from_pretrained(embedding$weight,                                                  padding_idx = embedding$padding_idx,                                                  mode='sum') }"},{"path":"https://torch.mlverse.org/docs/reference/nn_flatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Flattens a contiguous range of dims into a tensor. — nn_flatten","title":"Flattens a contiguous range of dims into a tensor. — nn_flatten","text":"use nn_sequential.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_flatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flattens a contiguous range of dims into a tensor. — nn_flatten","text":"","code":"nn_flatten(start_dim = 2, end_dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_flatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flattens a contiguous range of dims into a tensor. — nn_flatten","text":"start_dim first dim flatten (default = 2). end_dim last dim flatten (default = -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_flatten.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Flattens a contiguous range of dims into a tensor. — nn_flatten","text":"Input: (*, S_start,..., S_i, ..., S_end, *), S_i size dimension * means number dimensions including none. Output: (*, S_start*...*S_i*...S_end, *).","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_flatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flattens a contiguous range of dims into a tensor. — nn_flatten","text":"","code":"if (torch_is_installed()) { input <- torch_randn(32, 1, 5, 5) m <- nn_flatten() m(input) } #> torch_tensor #> Columns 1 to 10-0.8015 -1.0448  0.4715 -0.0156  0.7085  0.6113 -0.5675 -0.7171 -0.2615  1.2159 #>  2.3857  1.2484 -0.5993  0.3149  1.0410 -0.0031 -0.1256 -1.4730 -0.4148  0.2949 #> -0.6647  2.6382 -1.9189  1.5107  0.1844 -0.4771 -0.1499  0.6239 -0.2575  0.1938 #>  2.0218 -0.1541  0.3580 -0.6831 -0.4747  1.5348  0.7168  0.3497 -0.4437  0.5037 #>  1.5272 -1.2138 -2.3443 -0.6669  0.8383  1.6540 -0.5365  0.3552  1.8786 -1.7464 #>  0.6394 -0.0746 -0.3072 -0.5264 -0.9450  1.0271  0.0991  0.0619  0.3204 -0.2456 #>  0.0250  1.0297 -1.4002  1.7605  1.5106 -2.4053 -0.9495 -0.1437  0.0332  1.5030 #> -0.5799  0.0074  1.2746  1.4900 -1.0154  0.3608 -0.8096 -0.9809  0.0256  2.0557 #>  0.3317  0.3536  0.8048  0.7115  0.3078  1.2502  1.4476 -0.4187 -1.0832 -0.8844 #> -1.0850 -0.6192  0.1627 -1.9400 -0.6659  1.2134  0.2179  0.5830 -0.6183  0.0321 #> -1.6692  0.7485 -0.8128  1.0693 -0.9317  0.9081 -0.7930 -0.7436 -0.6327  0.9231 #>  1.7045  0.1461  0.3835  1.6954 -0.1849 -0.2247  0.6355 -0.5568  0.3298  1.1491 #>  0.1119 -0.1293 -0.1382  1.6020 -0.7861  0.8450  1.0183 -0.0673  0.3050  0.9445 #> -1.8077 -0.1964 -0.1349  1.0182  0.7130 -0.4587 -2.3798  0.3252  1.3848 -0.7724 #>  0.2489  0.5840  0.1690 -0.9544  1.1001 -0.4978 -1.2585 -0.9969  0.0469  0.6774 #> -1.7650 -0.4240 -0.3131  2.0314  1.0105  1.0466  0.2259 -0.2248  1.6021  1.5515 #> -0.8189 -0.2861 -0.1885 -0.1888  1.2369 -0.8073  1.0088  0.8614  0.9339  0.4690 #> -0.8568  1.5507 -1.4375  1.7597  0.7363 -1.4567  2.2990  1.3478  1.4151  0.4128 #>  0.1707  0.9011 -1.6190  0.0704  0.8973 -1.6506  0.3608  0.0830  1.6077 -1.5901 #> -1.0287 -0.4341  0.0636 -0.4749  0.1226 -1.1832 -0.0746  0.9812 -1.4514 -0.0938 #>  0.0018  1.7226 -0.3270  1.1839 -0.4936 -0.8200  0.0203 -0.7399  0.3987  0.4709 #>  0.1172  0.9947  0.4600  1.3165 -1.3755  0.4174 -2.3616 -1.1633 -0.0096 -1.6175 #>  0.8800 -0.6760 -0.3397  1.4769 -0.1437  1.3507  0.3871 -0.4962 -1.1812  0.5646 #> -0.3333 -0.1028 -0.1121  0.2401 -0.9883  1.6939 -0.7209  1.0521 -0.3183 -0.0213 #> -2.6093 -1.1583 -0.8108  0.3671 -0.3561  1.3556  0.1852 -0.6264  1.0287  0.8352 #>  0.8922  1.2746  0.8763 -0.0620 -0.4186 -0.4048  0.1820 -2.4252 -0.5739 -0.7585 #>  1.6924 -0.4010 -0.0632 -0.6726  1.6817  0.9732 -0.9486 -1.2342 -1.1307  1.6650 #> -1.1404  1.6418  0.8507 -1.0957 -0.4790  1.2576  2.6430  1.4992  1.5525 -1.8223 #>  0.1169 -1.0268  1.0565 -0.2669 -0.2602  1.5338 -0.1799 -0.2940 -2.9724 -0.5963 #>  0.2384  1.6367  0.3955 -0.0629  1.3515 -0.0084  1.0178 -0.1979  0.3229  0.7691 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{32,25} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","title":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","text":"Fractional MaxPooling described detail paper Fractional MaxPooling Ben Graham","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","text":"","code":"nn_fractional_max_pool2d(   kernel_size,   output_size = NULL,   output_ratio = NULL,   return_indices = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","text":"kernel_size size window take max . Can single number k (square kernel k x k) tuple (kh, kw) output_size target output size image form oH x oW. Can tuple (oH, oW) single number oH square image oH x oH output_ratio one wants output size ratio input size, option can given. number tuple range (0, 1) return_indices TRUE, return indices along outputs. Useful pass nn_max_unpool2d(). Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","text":"max-pooling operation applied \\(kH \\times kW\\) regions stochastic step size determined target output size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 2D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool2d","text":"","code":"if (torch_is_installed()) { # pool of square window of size=3, and target output size 13x12 m <- nn_fractional_max_pool2d(3, output_size = c(13, 12)) # pool of square window and target output size being half of input image size m <- nn_fractional_max_pool2d(3, output_ratio = c(0.5, 0.5)) input <- torch_randn(20, 16, 50, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","title":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","text":"Fractional MaxPooling described detail paper Fractional MaxPooling Ben Graham","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","text":"","code":"nn_fractional_max_pool3d(   kernel_size,   output_size = NULL,   output_ratio = NULL,   return_indices = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","text":"kernel_size size window take max . Can single number k (square kernel k x k x k) tuple (kt x kh x kw) output_size target output size image form oT x oH x oW. Can tuple (oT, oH, oW) single number oH square image oH x oH x oH output_ratio one wants output size ratio input size, option can given. number tuple range (0, 1) return_indices TRUE, return indices along outputs. Useful pass nn_max_unpool3d(). Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","text":"max-pooling operation applied \\(kTxkHxkW\\) regions stochastic step size determined target output size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_fractional_max_pool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 3D fractional max pooling over an input signal composed of several input planes. — nn_fractional_max_pool3d","text":"","code":"if (torch_is_installed()) { # pool of cubic window of size=3, and target output size 13x12x11 m <- nn_fractional_max_pool3d(3, output_size = c(13, 12, 11)) # pool of cubic window and target output size being half of input size m <- nn_fractional_max_pool3d(3, output_ratio = c(0.5, 0.5, 0.5)) input <- torch_randn(20, 16, 50, 32, 16) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"GELU module — nn_gelu","title":"GELU module — nn_gelu","text":"Applies Gaussian Error Linear Units function: $$\\mbox{GELU}(x) = x * \\Phi(x)$$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GELU module — nn_gelu","text":"","code":"nn_gelu(approximate = \"none\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GELU module — nn_gelu","text":"approximate gelu approximation algorithm use: 'none' 'tanh'. Default: 'none'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GELU module — nn_gelu","text":"\\(\\Phi(x)\\) Cumulative Distribution Function Gaussian Distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"GELU module — nn_gelu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gelu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GELU module — nn_gelu","text":"","code":"if (torch_is_installed()) { m <- nn_gelu() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_glu.html","id":null,"dir":"Reference","previous_headings":"","what":"GLU module — nn_glu","title":"GLU module — nn_glu","text":"Applies gated linear unit function \\({GLU}(, b)= \\otimes \\sigma(b)\\) \\(\\) first half input matrices \\(b\\) second half.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_glu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GLU module — nn_glu","text":"","code":"nn_glu(dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_glu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GLU module — nn_glu","text":"dim (int): dimension split input. Default: -1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_glu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"GLU module — nn_glu","text":"Input: \\((\\ast_1, N, \\ast_2)\\) * means, number additional dimensions Output: \\((\\ast_1, M, \\ast_2)\\) \\(M=N/2\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_glu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"GLU module — nn_glu","text":"","code":"if (torch_is_installed()) { m <- nn_glu() input <- torch_randn(4, 2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Group normalization — nn_group_norm","title":"Group normalization — nn_group_norm","text":"Applies Group Normalization mini-batch inputs described paper Group Normalization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group normalization — nn_group_norm","text":"","code":"nn_group_norm(num_groups, num_channels, eps = 1e-05, affine = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group normalization — nn_group_norm","text":"num_groups (int): number groups separate channels num_channels (int): number channels expected input eps value added denominator numerical stability. Default: 1e-5 affine boolean value set TRUE, module learnable per-channel affine parameters initialized ones (weights) zeros (biases). Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group normalization — nn_group_norm","text":"$$   y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ input channels separated num_groups groups, containing num_channels / num_groups channels. mean standard-deviation calculated separately group. \\(\\gamma\\) \\(\\beta\\) learnable per-channel affine transform parameter vectors size num_channels affine TRUE. standard-deviation calculated via biased estimator, equivalent torch_var(input, unbiased=FALSE).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Group normalization — nn_group_norm","text":"layer uses statistics computed input data training evaluation modes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Group normalization — nn_group_norm","text":"Input: \\((N, C, *)\\) \\(C=\\mbox{num\\_channels}\\) Output: \\((N, C, *)\\)` (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_group_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group normalization — nn_group_norm","text":"","code":"if (torch_is_installed()) {  input <- torch_randn(20, 6, 10, 10) # Separate 6 channels into 3 groups m <- nn_group_norm(3, 6) # Separate 6 channels into 6 groups (equivalent with [nn_instance_morm]) m <- nn_group_norm(6, 6) # Put all 6 channels into a single group (equivalent with [nn_layer_norm]) m <- nn_group_norm(1, 6) # Activating the module output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"element input sequence, layer computes following function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"","code":"nn_gru(   input_size,   hidden_size,   num_layers = 1,   bias = TRUE,   batch_first = FALSE,   dropout = 0,   bidirectional = FALSE,   ... )"},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"input_size number expected features input x hidden_size number features hidden state h num_layers Number recurrent layers. E.g., setting num_layers=2 mean stacking two GRUs together form stacked GRU, second GRU taking outputs first GRU computing final results. Default: 1 bias FALSE, layer use bias weights b_ih b_hh. Default: TRUE batch_first TRUE, input output tensors provided (batch, seq, feature). Default: FALSE dropout non-zero, introduces Dropout layer outputs GRU layer except last layer, dropout probability equal dropout. Default: 0 bidirectional TRUE, becomes bidirectional GRU. Default: FALSE ... currently unused.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"$$ \\begin{array}{ll} r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\ z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\ n_t = \\tanh(W_{} x_t + b_{} + r_t (W_{hn} h_{(t-1)}+ b_{hn})) \\\\ h_t = (1 - z_t) n_t + z_t h_{(t-1)} \\end{array} $$ \\(h_t\\) hidden state time t, \\(x_t\\) input time t, \\(h_{(t-1)}\\) hidden state previous layer time t-1 initial hidden state time 0, \\(r_t\\), \\(z_t\\), \\(n_t\\) reset, update, new gates, respectively. \\(\\sigma\\) sigmoid function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"weights biases initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{1}{\\mbox{hidden\\_size}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"Inputs: input, h_0 input shape (seq_len, batch, input_size): tensor containing features input sequence. input can also packed variable length sequence. See nn_utils_rnn_pack_padded_sequence() details. h_0 shape (num_layers * num_directions, batch, hidden_size): tensor containing initial hidden state element batch. Defaults zero provided.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"outputs","dir":"Reference","previous_headings":"","what":"Outputs","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"Outputs: output, h_n output shape (seq_len, batch, num_directions * hidden_size): tensor containing output features h_t last layer GRU, t. PackedSequence given input, output also packed sequence. unpacked case, directions can separated using output$view(c(seq_len, batch, num_directions, hidden_size)), forward backward direction 0 1 respectively. Similarly, directions can separated packed case. h_n shape (num_layers * num_directions, batch, hidden_size): tensor containing hidden state t = seq_len Like output, layers can separated using h_n$view(num_layers, num_directions, batch, hidden_size).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"weight_ih_l[k] : learnable input-hidden weights \\(\\mbox{k}^{th}\\) layer (W_ir|W_iz|W_in), shape (3*hidden_size x input_size) weight_hh_l[k] : learnable hidden-hidden weights \\(\\mbox{k}^{th}\\) layer (W_hr|W_hz|W_hn), shape (3*hidden_size x hidden_size) bias_ih_l[k] : learnable input-hidden bias \\(\\mbox{k}^{th}\\) layer (b_ir|b_iz|b_in), shape (3*hidden_size) bias_hh_l[k] : learnable hidden-hidden bias \\(\\mbox{k}^{th}\\) layer (b_hr|b_hz|b_hn), shape (3*hidden_size)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_gru.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. — nn_gru","text":"","code":"if (torch_is_installed()) {  rnn <- nn_gru(10, 20, 2) input <- torch_randn(5, 3, 10) h0 <- torch_randn(2, 3, 20) output <- rnn(input, h0) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardshwink module — nn_hardshrink","title":"Hardshwink module — nn_hardshrink","text":"Applies hard shrinkage function element-wise:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardshwink module — nn_hardshrink","text":"","code":"nn_hardshrink(lambd = 0.5)"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardshwink module — nn_hardshrink","text":"lambd \\(\\lambda\\) value Hardshrink formulation. Default: 0.5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hardshwink module — nn_hardshrink","text":"$$   \\mbox{HardShrink}(x) =   \\left\\{ \\begin{array}{ll} x, & \\mbox{ } x > \\lambda \\\\ x, & \\mbox{ } x < -\\lambda \\\\ 0, & \\mbox{ otherwise } \\end{array} \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Hardshwink module — nn_hardshrink","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardshrink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hardshwink module — nn_hardshrink","text":"","code":"if (torch_is_installed()) { m <- nn_hardshrink() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardsigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardsigmoid module — nn_hardsigmoid","title":"Hardsigmoid module — nn_hardsigmoid","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardsigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardsigmoid module — nn_hardsigmoid","text":"","code":"nn_hardsigmoid()"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardsigmoid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hardsigmoid module — nn_hardsigmoid","text":"$$ \\mbox{Hardsigmoid}(x) = \\left\\{ \\begin{array}{ll}   0 & \\mbox{~} x \\le -3, \\\\   1 & \\mbox{~} x \\ge +3, \\\\   x / 6 + 1 / 2 & \\mbox{otherwise} \\end{array} \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardsigmoid.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Hardsigmoid module — nn_hardsigmoid","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardsigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hardsigmoid module — nn_hardsigmoid","text":"","code":"if (torch_is_installed()) { m <- nn_hardsigmoid() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardswish.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardswish module — nn_hardswish","title":"Hardswish module — nn_hardswish","text":"Applies hardswish function, element-wise, described paper: Searching MobileNetV3","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardswish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardswish module — nn_hardswish","text":"","code":"nn_hardswish()"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardswish.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hardswish module — nn_hardswish","text":"$$ \\mbox{Hardswish}(x) = \\left\\{   \\begin{array}{ll}   0 & \\mbox{} x \\le -3, \\\\   x & \\mbox{} x \\ge +3, \\\\   x \\cdot (x + 3)/6 & \\mbox{otherwise}   \\end{array}   \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardswish.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Hardswish module — nn_hardswish","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardswish.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hardswish module — nn_hardswish","text":"","code":"if (torch_is_installed()) { if (FALSE) { m <- nn_hardswish() input <- torch_randn(2) output <- m(input) }  }"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardtanh module — nn_hardtanh","title":"Hardtanh module — nn_hardtanh","text":"Applies HardTanh function element-wise HardTanh defined :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardtanh module — nn_hardtanh","text":"","code":"nn_hardtanh(min_val = -1, max_val = 1, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardtanh module — nn_hardtanh","text":"min_val minimum value linear region range. Default: -1 max_val maximum value linear region range. Default: 1 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hardtanh module — nn_hardtanh","text":"$$ \\mbox{HardTanh}(x) = \\left\\{ \\begin{array}{ll}   1 & \\mbox{ } x > 1 \\\\   -1 & \\mbox{ } x < -1 \\\\   x & \\mbox{ otherwise } \\\\ \\end{array} \\right. $$ range linear region :math:[-1, 1] can adjusted using min_val max_val.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Hardtanh module — nn_hardtanh","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hardtanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hardtanh module — nn_hardtanh","text":"","code":"if (torch_is_installed()) { m <- nn_hardtanh(-2, 2) input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_hinge_embedding_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Hinge embedding loss — nn_hinge_embedding_loss","title":"Hinge embedding loss — nn_hinge_embedding_loss","text":"Measures loss given input tensor \\(x\\) labels tensor \\(y\\) (containing 1 -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hinge_embedding_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hinge embedding loss — nn_hinge_embedding_loss","text":"","code":"nn_hinge_embedding_loss(margin = 1, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_hinge_embedding_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hinge embedding loss — nn_hinge_embedding_loss","text":"margin (float, optional): default value 1. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hinge_embedding_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hinge embedding loss — nn_hinge_embedding_loss","text":"usually used measuring whether two inputs similar dissimilar, e.g. using L1 pairwise distance \\(x\\), typically used learning nonlinear embeddings semi-supervised learning. loss function \\(n\\)-th sample mini-batch $$   l_n = \\begin{array}{ll} x_n, & \\mbox{}\\; y_n = 1,\\\\ \\max \\{0, \\Delta - x_n\\}, & \\mbox{}\\; y_n = -1, \\end{array} $$ total loss functions $$   \\ell(x, y) = \\begin{array}{ll} \\mbox{mean}(L), & \\mbox{reduction} = \\mbox{'mean';}\\\\ \\mbox{sum}(L),  & \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ \\(L = \\{l_1,\\dots,l_N\\}^\\top\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_hinge_embedding_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Hinge embedding loss — nn_hinge_embedding_loss","text":"Input: \\((*)\\) \\(*\\) means, number dimensions. sum operation operates elements. Target: \\((*)\\), shape input Output: scalar. reduction 'none', shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_identity.html","id":null,"dir":"Reference","previous_headings":"","what":"Identity module — nn_identity","title":"Identity module — nn_identity","text":"placeholder identity operator argument-insensitive.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_identity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identity module — nn_identity","text":"","code":"nn_identity(...)"},{"path":"https://torch.mlverse.org/docs/reference/nn_identity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identity module — nn_identity","text":"... arguments (unused)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_identity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identity module — nn_identity","text":"","code":"if (torch_is_installed()) { m <- nn_identity(54, unused_argument1 = 0.1, unused_argument2 = FALSE) input <- torch_randn(128, 20) output <- m(input) print(output$size()) } #> [1] 128  20"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_calculate_gain.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate gain — nn_init_calculate_gain","title":"Calculate gain — nn_init_calculate_gain","text":"Return recommended gain value given nonlinearity function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_calculate_gain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate gain — nn_init_calculate_gain","text":"","code":"nn_init_calculate_gain(nonlinearity, param = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_calculate_gain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate gain — nn_init_calculate_gain","text":"nonlinearity non-linear function param optional parameter non-linear function","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_constant_.html","id":null,"dir":"Reference","previous_headings":"","what":"Constant initialization — nn_init_constant_","title":"Constant initialization — nn_init_constant_","text":"Fills input Tensor value val.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_constant_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constant initialization — nn_init_constant_","text":"","code":"nn_init_constant_(tensor, val)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_constant_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constant initialization — nn_init_constant_","text":"tensor n-dimensional Tensor val value fill tensor ","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_constant_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Constant initialization — nn_init_constant_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_constant_(w, 0.3) } #> torch_tensor #>  0.3000  0.3000  0.3000  0.3000  0.3000 #>  0.3000  0.3000  0.3000  0.3000  0.3000 #>  0.3000  0.3000  0.3000  0.3000  0.3000 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_dirac_.html","id":null,"dir":"Reference","previous_headings":"","what":"Dirac initialization — nn_init_dirac_","title":"Dirac initialization — nn_init_dirac_","text":"Fills {3, 4, 5}-dimensional input Tensor Dirac delta function. Preserves identity inputs Convolutional layers, many input channels preserved possible. case groups>1, group channels preserves identity.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_dirac_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dirac initialization — nn_init_dirac_","text":"","code":"nn_init_dirac_(tensor, groups = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_dirac_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dirac initialization — nn_init_dirac_","text":"tensor {3, 4, 5}-dimensional torch.Tensor groups (optional) number groups conv layer (default: 1)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_dirac_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dirac initialization — nn_init_dirac_","text":"","code":"if (torch_is_installed()) { if (FALSE) { w <- torch_empty(3, 16, 5, 5) nn_init_dirac_(w) }  }"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_eye_.html","id":null,"dir":"Reference","previous_headings":"","what":"Eye initialization — nn_init_eye_","title":"Eye initialization — nn_init_eye_","text":"Fills 2-dimensional input Tensor identity matrix. Preserves identity inputs Linear layers, many inputs preserved possible.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_eye_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eye initialization — nn_init_eye_","text":"","code":"nn_init_eye_(tensor)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_eye_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eye initialization — nn_init_eye_","text":"tensor 2-dimensional torch tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_eye_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eye initialization — nn_init_eye_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_eye_(w) } #> torch_tensor #>  1  0  0  0  0 #>  0  1  0  0  0 #>  0  0  1  0  0 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_normal_.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaiming normal initialization — nn_init_kaiming_normal_","title":"Kaiming normal initialization — nn_init_kaiming_normal_","text":"Fills input Tensor values according method described Delving deep rectifiers: Surpassing human-level performance ImageNet classification - , K. et al. (2015), using normal distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_normal_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaiming normal initialization — nn_init_kaiming_normal_","text":"","code":"nn_init_kaiming_normal_(   tensor,   a = 0,   mode = \"fan_in\",   nonlinearity = \"leaky_relu\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_normal_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaiming normal initialization — nn_init_kaiming_normal_","text":"tensor n-dimensional torch.Tensor negative slope rectifier used layer (used 'leaky_relu') mode either 'fan_in' (default) 'fan_out'. Choosing 'fan_in' preserves magnitude variance weights forward pass. Choosing 'fan_out' preserves magnitudes backwards pass. nonlinearity non-linear function. recommended use 'relu' 'leaky_relu' (default).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_normal_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaiming normal initialization — nn_init_kaiming_normal_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_kaiming_normal_(w, mode = \"fan_in\", nonlinearity = \"leaky_relu\") } #> torch_tensor #> -0.5483  0.6051 -0.1700  0.4698 -0.3578 #>  0.0111  0.0262  0.0239 -0.5470 -1.0493 #>  0.7398  0.0686  0.7970 -0.6537 -0.3586 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_uniform_.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaiming uniform initialization — nn_init_kaiming_uniform_","title":"Kaiming uniform initialization — nn_init_kaiming_uniform_","text":"Fills input Tensor values according method described Delving deep rectifiers: Surpassing human-level performance ImageNet classification - , K. et al. (2015), using uniform distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_uniform_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaiming uniform initialization — nn_init_kaiming_uniform_","text":"","code":"nn_init_kaiming_uniform_(   tensor,   a = 0,   mode = \"fan_in\",   nonlinearity = \"leaky_relu\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_uniform_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaiming uniform initialization — nn_init_kaiming_uniform_","text":"tensor n-dimensional torch.Tensor negative slope rectifier used layer (used 'leaky_relu') mode either 'fan_in' (default) 'fan_out'. Choosing 'fan_in' preserves magnitude variance weights forward pass. Choosing 'fan_out' preserves magnitudes backwards pass. nonlinearity non-linear function. recommended use 'relu' 'leaky_relu' (default).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_kaiming_uniform_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kaiming uniform initialization — nn_init_kaiming_uniform_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_kaiming_uniform_(w, mode = \"fan_in\", nonlinearity = \"leaky_relu\") } #> torch_tensor #>  0.6448 -0.9118 -0.6907 -0.7555  0.7679 #> -0.2540 -0.9912 -0.8890  0.7258  0.0094 #>  0.8867  0.6021 -0.3258 -0.0241  0.6353 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_normal_.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal initialization — nn_init_normal_","title":"Normal initialization — nn_init_normal_","text":"Fills input Tensor values drawn normal distribution","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_normal_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal initialization — nn_init_normal_","text":"","code":"nn_init_normal_(tensor, mean = 0, std = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_normal_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal initialization — nn_init_normal_","text":"tensor n-dimensional Tensor mean mean normal distribution std standard deviation normal distribution","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_normal_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal initialization — nn_init_normal_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_normal_(w) } #> torch_tensor #>  1.1478  0.3302  1.4379  0.8988 -0.1674 #>  0.1804  1.2466 -1.3061 -0.3345  0.2397 #>  0.5363 -1.3692 -0.2766 -1.2271 -1.0775 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_ones_.html","id":null,"dir":"Reference","previous_headings":"","what":"Ones initialization — nn_init_ones_","title":"Ones initialization — nn_init_ones_","text":"Fills input Tensor scalar value 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_ones_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ones initialization — nn_init_ones_","text":"","code":"nn_init_ones_(tensor)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_ones_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ones initialization — nn_init_ones_","text":"tensor n-dimensional Tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_ones_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ones initialization — nn_init_ones_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_ones_(w) } #> torch_tensor #>  1  1  1  1  1 #>  1  1  1  1  1 #>  1  1  1  1  1 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_orthogonal_.html","id":null,"dir":"Reference","previous_headings":"","what":"Orthogonal initialization — nn_init_orthogonal_","title":"Orthogonal initialization — nn_init_orthogonal_","text":"Fills input Tensor (semi) orthogonal matrix, described Exact solutions nonlinear dynamics learning deep linear neural networks - Saxe, . et al. (2013). input tensor must least 2 dimensions, tensors 2 dimensions trailing dimensions flattened.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_orthogonal_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orthogonal initialization — nn_init_orthogonal_","text":"","code":"nn_init_orthogonal_(tensor, gain = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_orthogonal_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orthogonal initialization — nn_init_orthogonal_","text":"tensor n-dimensional Tensor gain optional scaling factor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_orthogonal_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Orthogonal initialization — nn_init_orthogonal_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_orthogonal_(w) } #> torch_tensor #>  0.1160 -0.2048 -0.9706  0.0430  0.0257 #> -0.7007  0.1632 -0.0854  0.4108  0.5535 #>  0.0030  0.3251 -0.0535  0.7074 -0.6253 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_sparse_.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse initialization — nn_init_sparse_","title":"Sparse initialization — nn_init_sparse_","text":"Fills 2D input Tensor sparse matrix, non-zero elements drawn normal distribution described Deep learning via Hessian-free optimization - Martens, J. (2010).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_sparse_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse initialization — nn_init_sparse_","text":"","code":"nn_init_sparse_(tensor, sparsity, std = 0.01)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_sparse_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse initialization — nn_init_sparse_","text":"tensor n-dimensional Tensor sparsity fraction elements column set zero std standard deviation normal distribution used generate non-zero values","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_sparse_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse initialization — nn_init_sparse_","text":"","code":"if (torch_is_installed()) { if (FALSE) { w <- torch_empty(3, 5) nn_init_sparse_(w, sparsity = 0.1) } }"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_trunc_normal_.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated normal initialization — nn_init_trunc_normal_","title":"Truncated normal initialization — nn_init_trunc_normal_","text":"Fills input Tensor values drawn truncated normal distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_trunc_normal_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated normal initialization — nn_init_trunc_normal_","text":"","code":"nn_init_trunc_normal_(tensor, mean = 0, std = 1, a = -2, b = 2)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_trunc_normal_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated normal initialization — nn_init_trunc_normal_","text":"tensor n-dimensional Tensor mean mean normal distribution std standard deviation normal distribution minimum cutoff value b maximum cutoff value","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_trunc_normal_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated normal initialization — nn_init_trunc_normal_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_trunc_normal_(w) } #> torch_tensor #>  1.6650 -0.5936 -0.4173 -0.3491 -0.2854 #> -0.7031 -0.3730  0.4309 -0.8737  0.2055 #>  0.7119  1.1223 -1.3891  1.1680 -0.0479 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_uniform_.html","id":null,"dir":"Reference","previous_headings":"","what":"Uniform initialization — nn_init_uniform_","title":"Uniform initialization — nn_init_uniform_","text":"Fills input Tensor values drawn uniform distribution","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_uniform_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uniform initialization — nn_init_uniform_","text":"","code":"nn_init_uniform_(tensor, a = 0, b = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_uniform_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uniform initialization — nn_init_uniform_","text":"tensor n-dimensional Tensor lower bound uniform distribution b upper bound uniform distribution","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_uniform_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uniform initialization — nn_init_uniform_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_uniform_(w) } #> torch_tensor #>  0.9775  0.7917  0.6477  0.2337  0.0261 #>  0.9267  0.4705  0.3090  0.4401  0.1671 #>  0.3938  0.8689  0.3312  0.1128  0.8623 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_normal_.html","id":null,"dir":"Reference","previous_headings":"","what":"Xavier normal initialization — nn_init_xavier_normal_","title":"Xavier normal initialization — nn_init_xavier_normal_","text":"Fills input Tensor values according method described Understanding difficulty training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010), using normal distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_normal_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Xavier normal initialization — nn_init_xavier_normal_","text":"","code":"nn_init_xavier_normal_(tensor, gain = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_normal_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Xavier normal initialization — nn_init_xavier_normal_","text":"tensor n-dimensional Tensor gain optional scaling factor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_normal_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Xavier normal initialization — nn_init_xavier_normal_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_xavier_normal_(w) } #> torch_tensor #> -0.1958 -1.2098 -0.3898 -0.4418  0.3574 #> -0.2345  0.5271  0.5841 -0.1748  0.3071 #> -0.8960 -0.1640 -0.1738  0.7133  0.8885 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_uniform_.html","id":null,"dir":"Reference","previous_headings":"","what":"Xavier uniform initialization — nn_init_xavier_uniform_","title":"Xavier uniform initialization — nn_init_xavier_uniform_","text":"Fills input Tensor values according method described Understanding difficulty training deep feedforward neural networks - Glorot, X. & Bengio, Y. (2010), using uniform distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_uniform_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Xavier uniform initialization — nn_init_xavier_uniform_","text":"","code":"nn_init_xavier_uniform_(tensor, gain = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_uniform_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Xavier uniform initialization — nn_init_xavier_uniform_","text":"tensor n-dimensional Tensor gain optional scaling factor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_xavier_uniform_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Xavier uniform initialization — nn_init_xavier_uniform_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_xavier_uniform_(w) } #> torch_tensor #> -0.5071 -0.3531  0.1250  0.7562 -0.6302 #> -0.6892  0.6461  0.5584  0.7683 -0.3572 #> -0.5540 -0.8478 -0.5756  0.1296  0.1135 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_zeros_.html","id":null,"dir":"Reference","previous_headings":"","what":"Zeros initialization — nn_init_zeros_","title":"Zeros initialization — nn_init_zeros_","text":"Fills input Tensor scalar value 0","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_zeros_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zeros initialization — nn_init_zeros_","text":"","code":"nn_init_zeros_(tensor)"},{"path":"https://torch.mlverse.org/docs/reference/nn_init_zeros_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zeros initialization — nn_init_zeros_","text":"tensor n-dimensional tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_init_zeros_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zeros initialization — nn_init_zeros_","text":"","code":"if (torch_is_installed()) { w <- torch_empty(3, 5) nn_init_zeros_(w) } #> torch_tensor #>  0  0  0  0  0 #>  0  0  0  0  0 #>  0  0  0  0  0 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Kullback-Leibler divergence loss — nn_kl_div_loss","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"Kullback-Leibler divergence loss measure Kullback-Leibler divergence useful distance measure continuous distributions often useful performing direct regression space (discretely sampled) continuous output distributions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"","code":"nn_kl_div_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'batchmean' | 'sum' | 'mean'. 'none': reduction applied. 'batchmean': sum output divided batchsize. 'sum': output summed. 'mean': output divided number elements output. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"nn_nll_loss(), input given expected contain log-probabilities restricted 2D Tensor. targets interpreted probabilities default, considered log-probabilities log_target set TRUE. criterion expects target Tensor size input Tensor. unreduced (.e. reduction set 'none') loss can described : $$   l(x,y) = L = \\{ l_1,\\dots,l_N \\}, \\quad l_n = y_n \\cdot \\left( \\log y_n - x_n \\right) $$ index \\(N\\) spans dimensions input \\(L\\) shape input. reduction 'none' (default 'mean'), : $$   \\ell(x, y) = \\begin{array}{ll} \\mbox{mean}(L), & \\mbox{reduction} = \\mbox{'mean';} \\\\ \\mbox{sum}(L),  & \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ default reduction mode 'mean', losses averaged minibatch observations well dimensions. 'batchmean' mode gives correct KL divergence losses averaged batch dimension . 'mean' mode's behavior changed 'batchmean' next major release.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"reduction = 'mean' return true kl divergence value, please use reduction = 'batchmean' aligns KL math definition. next major release, 'mean' changed 'batchmean'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_kl_div_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Kullback-Leibler divergence loss — nn_kl_div_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar default. reduction 'none', \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"L1 loss — nn_l1_loss","title":"L1 loss — nn_l1_loss","text":"Creates criterion measures mean absolute error (MAE) element input \\(x\\) target \\(y\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L1 loss — nn_l1_loss","text":"","code":"nn_l1_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L1 loss — nn_l1_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L1 loss — nn_l1_loss","text":"unreduced (.e. reduction set 'none') loss can described : $$ \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = \\left| x_n - y_n \\right|, $$ \\(N\\) batch size. reduction 'none' (default 'mean'), : $$ \\ell(x, y) = \\begin{array}{ll} \\mbox{mean}(L), & \\mbox{reduction} = \\mbox{'mean';}\\\\ \\mbox{sum}(L),  & \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ \\(x\\) \\(y\\) tensors arbitrary shapes total \\(n\\) elements . sum operation still operates elements, divides \\(n\\). division \\(n\\) can avoided one sets reduction = 'sum'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"L1 loss — nn_l1_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar. reduction 'none', \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_l1_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L1 loss — nn_l1_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_l1_loss() input <- torch_randn(3, 5, requires_grad = TRUE) target <- torch_randn(3, 5) output <- loss(input, target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer normalization — nn_layer_norm","title":"Layer normalization — nn_layer_norm","text":"Applies Layer Normalization mini-batch inputs described paper Layer Normalization","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer normalization — nn_layer_norm","text":"","code":"nn_layer_norm(normalized_shape, eps = 1e-05, elementwise_affine = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer normalization — nn_layer_norm","text":"normalized_shape (int list): input shape expected input size \\([* \\times \\mbox{normalized\\_shape}[0] \\times \\mbox{normalized\\_shape}[1] \\times \\ldots \\times \\mbox{normalized\\_shape}[-1]]\\) single integer used, treated singleton list, module normalize last dimension expected specific size. eps value added denominator numerical stability. Default: 1e-5 elementwise_affine boolean value set TRUE, module learnable per-element affine parameters initialized ones (weights) zeros (biases). Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Layer normalization — nn_layer_norm","text":"$$   y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta $$ mean standard-deviation calculated separately last certain number dimensions shape specified normalized_shape. \\(\\gamma\\) \\(\\beta\\) learnable affine transform parameters normalized_shape elementwise_affine TRUE. standard-deviation calculated via biased estimator, equivalent torch_var(input, unbiased=FALSE).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Layer normalization — nn_layer_norm","text":"Unlike Batch Normalization Instance Normalization, applies scalar scale bias entire channel/plane affine option, Layer Normalization applies per-element scale bias elementwise_affine. layer uses statistics computed input data training evaluation modes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Layer normalization — nn_layer_norm","text":"Input: \\((N, *)\\) Output: \\((N, *)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_layer_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Layer normalization — nn_layer_norm","text":"","code":"if (torch_is_installed()) {  input <- torch_randn(20, 5, 10, 10) # With Learnable Parameters m <- nn_layer_norm(input$size()[-1]) # Without Learnable Parameters m <- nn_layer_norm(input$size()[-1], elementwise_affine = FALSE) # Normalize over last two dimensions m <- nn_layer_norm(c(10, 10)) # Normalize over last dimension of size 10 m <- nn_layer_norm(10) # Activating the module output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"LeakyReLU module — nn_leaky_relu","title":"LeakyReLU module — nn_leaky_relu","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LeakyReLU module — nn_leaky_relu","text":"","code":"nn_leaky_relu(negative_slope = 0.01, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LeakyReLU module — nn_leaky_relu","text":"negative_slope Controls angle negative slope. Default: 1e-2 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"LeakyReLU module — nn_leaky_relu","text":"$$   \\mbox{LeakyReLU}(x) = \\max(0, x) + \\mbox{negative\\_slope} * \\min(0, x) $$ $$   \\mbox{LeakyRELU}(x) =   \\left\\{ \\begin{array}{ll} x, & \\mbox{ } x \\geq 0 \\\\ \\mbox{negative\\_slope} \\times x, & \\mbox{ otherwise } \\end{array} \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"LeakyReLU module — nn_leaky_relu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_leaky_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LeakyReLU module — nn_leaky_relu","text":"","code":"if (torch_is_installed()) { m <- nn_leaky_relu(0.1) input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear module — nn_linear","title":"Linear module — nn_linear","text":"Applies linear transformation incoming data: y = xA^T + b","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear module — nn_linear","text":"","code":"nn_linear(in_features, out_features, bias = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear module — nn_linear","text":"in_features size input sample out_features size output sample bias set FALSE, layer learn additive bias. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Linear module — nn_linear","text":"Input: (N, *, H_in) * means number additional dimensions H_in = in_features. Output: (N, *, H_out) last dimension shape input :math:H_out = out_features.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Linear module — nn_linear","text":"weight: learnable weights module shape (out_features, in_features). values initialized \\(U(-\\sqrt{k}, \\sqrt{k})\\)s, \\(k = \\frac{1}{\\mbox{\\_features}}\\) bias: learnable bias module shape \\((\\mbox{\\_features})\\). bias TRUE, values initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{1}{\\mbox{\\_features}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear module — nn_linear","text":"","code":"if (torch_is_installed()) { m <- nn_linear(20, 30) input <- torch_randn(128, 20) output <- m(input) print(output$size()) } #> [1] 128  30"},{"path":"https://torch.mlverse.org/docs/reference/nn_log_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"LogSigmoid module — nn_log_sigmoid","title":"LogSigmoid module — nn_log_sigmoid","text":"Applies element-wise function: $$   \\mbox{LogSigmoid}(x) = \\log\\left(\\frac{ 1 }{ 1 + \\exp(-x)}\\right)  $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LogSigmoid module — nn_log_sigmoid","text":"","code":"nn_log_sigmoid()"},{"path":"https://torch.mlverse.org/docs/reference/nn_log_sigmoid.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"LogSigmoid module — nn_log_sigmoid","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LogSigmoid module — nn_log_sigmoid","text":"","code":"if (torch_is_installed()) { m <- nn_log_sigmoid() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"LogSoftmax module — nn_log_softmax","title":"LogSoftmax module — nn_log_softmax","text":"Applies \\(\\log(\\mbox{Softmax}(x))\\) function n-dimensional input Tensor. LogSoftmax formulation can simplified :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LogSoftmax module — nn_log_softmax","text":"","code":"nn_log_softmax(dim)"},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LogSoftmax module — nn_log_softmax","text":"dim (int): dimension along LogSoftmax computed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LogSoftmax module — nn_log_softmax","text":"Tensor dimension shape input values range [-inf, 0)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"LogSoftmax module — nn_log_softmax","text":"$$   \\mbox{LogSoftmax}(x_{}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"LogSoftmax module — nn_log_softmax","text":"Input: \\((*)\\) * means, number additional dimensions Output: \\((*)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_log_softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LogSoftmax module — nn_log_softmax","text":"","code":"if (torch_is_installed()) { m <- nn_log_softmax(1) input <- torch_randn(2, 3) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"window, function computed :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"","code":"nn_lp_pool1d(norm_type, kernel_size, stride = NULL, ceil_mode = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"norm_type inf one gets max pooling 0 get sum pooling ( proportional avg pooling) kernel_size single int, size window stride single int, stride window. Default value kernel_size ceil_mode TRUE, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"$$   f(X) = \\sqrt[p]{\\sum_{x \\X} x^{p}} $$ p = \\(\\infty\\), one gets Max Pooling p = 1, one gets Sum Pooling (proportional Average Pooling)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"sum power p zero, gradient function defined. implementation set gradient zero case.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"Input: \\((N, C, L_{})\\) Output: \\((N, C, L_{})\\), $$   L_{} = \\left\\lfloor\\frac{L_{} - \\mbox{kernel\\_size}}{\\mbox{stride}} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 1D power-average pooling over an input signal composed of several input planes. — nn_lp_pool1d","text":"","code":"if (torch_is_installed()) { # power-2 pool of window of length 3, with stride 2. m <- nn_lp_pool1d(2, 3, stride = 2) input <- torch_randn(20, 16, 50) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"window, function computed :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"","code":"nn_lp_pool2d(norm_type, kernel_size, stride = NULL, ceil_mode = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"norm_type inf one gets max pooling 0 get sum pooling ( proportional avg pooling) kernel_size size window stride stride window. Default value kernel_size ceil_mode TRUE, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"$$   f(X) = \\sqrt[p]{\\sum_{x \\X} x^{p}} $$ p = \\(\\infty\\), one gets Max Pooling p = 1, one gets Sum Pooling (proportional average pooling) parameters kernel_size, stride can either : single int -- case value used height width dimension tuple two ints -- case, first int used height dimension, second int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"sum power p zero, gradient function defined. implementation set gradient zero case.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"Input: \\((N, C, H_{}, W_{})\\) Output: \\((N, C, H_{}, W_{})\\), $$   H_{} = \\left\\lfloor\\frac{H_{} - \\mbox{kernel\\_size}[0]}{\\mbox{stride}[0]} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{} - \\mbox{kernel\\_size}[1]}{\\mbox{stride}[1]} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lp_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 2D power-average pooling over an input signal composed of several input planes. — nn_lp_pool2d","text":"","code":"if (torch_is_installed()) {  # power-2 pool of square window of size=3, stride=2 m <- nn_lp_pool2d(2, 3, stride = 2) # pool of non-square window of power 1.2 m <- nn_lp_pool2d(1.2, c(3, 2), stride = c(2, 1)) input <- torch_randn(20, 16, 50, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"element input sequence, layer computes following function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"","code":"nn_lstm(   input_size,   hidden_size,   num_layers = 1,   bias = TRUE,   batch_first = FALSE,   dropout = 0,   bidirectional = FALSE,   ... )"},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"input_size number expected features input x hidden_size number features hidden state h num_layers Number recurrent layers. E.g., setting num_layers=2 mean stacking two LSTMs together form stacked LSTM, second LSTM taking outputs first LSTM computing final results. Default: 1 bias FALSE, layer use bias weights b_ih b_hh. Default: TRUE batch_first TRUE, input output tensors provided (batch, seq, feature). Default: FALSE dropout non-zero, introduces Dropout layer outputs LSTM layer except last layer, dropout probability equal dropout. Default: 0 bidirectional TRUE, becomes bidirectional LSTM. Default: FALSE ... currently unused.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"$$ \\begin{array}{ll} \\\\ i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\ f_t = \\sigma(W_{} x_t + b_{} + W_{hf} h_{(t-1)} + b_{hf}) \\\\ g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\ o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\ c_t = f_t c_{(t-1)} + i_t g_t \\\\ h_t = o_t \\tanh(c_t) \\\\ \\end{array} $$ \\(h_t\\) hidden state time t, \\(c_t\\) cell state time t, \\(x_t\\) input time t, \\(h_{(t-1)}\\) hidden state previous layer time t-1 initial hidden state time 0, \\(i_t\\), \\(f_t\\), \\(g_t\\), \\(o_t\\) input, forget, cell, output gates, respectively. \\(\\sigma\\) sigmoid function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"weights biases initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{1}{\\mbox{hidden\\_size}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"Inputs: input, (h_0, c_0) input shape (seq_len, batch, input_size): tensor containing features input sequence. input can also packed variable length sequence. See nn_utils_rnn_pack_padded_sequence() nn_utils_rnn_pack_sequence() details. h_0 shape (num_layers * num_directions, batch, hidden_size): tensor containing initial hidden state element batch. c_0 shape (num_layers * num_directions, batch, hidden_size): tensor containing initial cell state element batch. (h_0, c_0) provided, h_0 c_0 default zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"outputs","dir":"Reference","previous_headings":"","what":"Outputs","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"Outputs: output, (h_n, c_n) output shape (seq_len, batch, num_directions * hidden_size): tensor containing output features (h_t) last layer LSTM, t. torch_nn.utils.rnn.PackedSequence given input, output also packed sequence. unpacked case, directions can separated using output$view(c(seq_len, batch, num_directions, hidden_size)), forward backward direction 0 1 respectively. Similarly, directions can separated packed case. h_n shape (num_layers * num_directions, batch, hidden_size): tensor containing hidden state t = seq_len. Like output, layers can separated using h_n$view(c(num_layers, num_directions, batch, hidden_size)) similarly c_n. c_n (num_layers * num_directions, batch, hidden_size): tensor containing cell state t = seq_len","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"weight_ih_l[k] : learnable input-hidden weights \\(\\mbox{k}^{th}\\) layer (W_ii|W_if|W_ig|W_io), shape (4*hidden_size x input_size) weight_hh_l[k] : learnable hidden-hidden weights \\(\\mbox{k}^{th}\\) layer (W_hi|W_hf|W_hg|W_ho), shape (4*hidden_size x hidden_size) bias_ih_l[k] : learnable input-hidden bias \\(\\mbox{k}^{th}\\) layer (b_ii|b_if|b_ig|b_io), shape (4*hidden_size) bias_hh_l[k] : learnable hidden-hidden bias \\(\\mbox{k}^{th}\\) layer (b_hi|b_hf|b_hg|b_ho), shape (4*hidden_size)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_lstm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence. — nn_lstm","text":"","code":"if (torch_is_installed()) { rnn <- nn_lstm(10, 20, 2) input <- torch_randn(5, 3, 10) h0 <- torch_randn(2, 3, 20) c0 <- torch_randn(2, 3, 20) output <- rnn(input, list(h0, c0)) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Margin ranking loss — nn_margin_ranking_loss","title":"Margin ranking loss — nn_margin_ranking_loss","text":"Creates criterion measures loss given inputs \\(x1\\), \\(x2\\), two 1D mini-batch Tensors, label 1D mini-batch tensor \\(y\\) (containing 1 -1). \\(y = 1\\) assumed first input ranked higher (larger value) second input, vice-versa \\(y = -1\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Margin ranking loss — nn_margin_ranking_loss","text":"","code":"nn_margin_ranking_loss(margin = 0, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Margin ranking loss — nn_margin_ranking_loss","text":"margin (float, optional): default value \\(0\\). reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Margin ranking loss — nn_margin_ranking_loss","text":"loss function pair samples mini-batch : $$   \\mbox{loss}(x1, x2, y) = \\max(0, -y * (x1 - x2) + \\mbox{margin}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Margin ranking loss — nn_margin_ranking_loss","text":"Input1: \\((N)\\) N batch size. Input2: \\((N)\\), shape Input1. Target: \\((N)\\), shape inputs. Output: scalar. reduction 'none', \\((N)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_margin_ranking_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Margin ranking loss — nn_margin_ranking_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_margin_ranking_loss() input1 <- torch_randn(3, requires_grad = TRUE) input2 <- torch_randn(3, requires_grad = TRUE) target <- torch_randn(3)$sign() output <- loss(input1, input2, target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"MaxPool1D module — nn_max_pool1d","title":"MaxPool1D module — nn_max_pool1d","text":"Applies 1D max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MaxPool1D module — nn_max_pool1d","text":"","code":"nn_max_pool1d(   kernel_size,   stride = NULL,   padding = 0,   dilation = 1,   return_indices = FALSE,   ceil_mode = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MaxPool1D module — nn_max_pool1d","text":"kernel_size size window take max stride stride window. Default value kernel_size padding implicit zero padding added sides dilation parameter controls stride elements window return_indices TRUE, return max indices along outputs. Useful  nn_max_unpool1d() later. ceil_mode TRUE, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MaxPool1D module — nn_max_pool1d","text":"simplest case, output value layer input size \\((N, C, L)\\) output \\((N, C, L_{})\\) can precisely described : $$   (N_i, C_j, k) = \\max_{m=0, \\ldots, \\mbox{kernel\\_size} - 1} input(N_i, C_j, stride \\times k + m) $$ padding non-zero, input implicitly zero-padded sides padding number points. dilation controls spacing kernel points. harder describe, link nice visualization dilation .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"MaxPool1D module — nn_max_pool1d","text":"Input: \\((N, C, L_{})\\) Output: \\((N, C, L_{})\\), $$   L_{} = \\left\\lfloor \\frac{L_{} + 2 \\times \\mbox{padding} - \\mbox{dilation}     \\times (\\mbox{kernel\\_size} - 1) - 1}{\\mbox{stride}} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MaxPool1D module — nn_max_pool1d","text":"","code":"if (torch_is_installed()) { # pool of size=3, stride=2 m <- nn_max_pool1d(3, stride = 2) input <- torch_randn(20, 16, 50) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"MaxPool2D module — nn_max_pool2d","title":"MaxPool2D module — nn_max_pool2d","text":"Applies 2D max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MaxPool2D module — nn_max_pool2d","text":"","code":"nn_max_pool2d(   kernel_size,   stride = NULL,   padding = 0,   dilation = 1,   return_indices = FALSE,   ceil_mode = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MaxPool2D module — nn_max_pool2d","text":"kernel_size size window take max stride stride window. Default value kernel_size padding implicit zero padding added sides dilation parameter controls stride elements window return_indices TRUE, return max indices along outputs. Useful nn_max_unpool2d() later. ceil_mode TRUE, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MaxPool2D module — nn_max_pool2d","text":"simplest case, output value layer input size \\((N, C, H, W)\\), output \\((N, C, H_{}, W_{})\\) kernel_size \\((kH, kW)\\) can precisely described : $$ \\begin{array}{ll} (N_i, C_j, h, w) ={} & \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\ & \\mbox{input}(N_i, C_j, \\mbox{stride[0]} \\times h + m,                \\mbox{stride[1]} \\times w + n) \\end{array} $$ padding non-zero, input implicitly zero-padded sides padding number points. dilation controls spacing kernel points. harder describe, link nice visualization dilation . parameters kernel_size, stride, padding, dilation can either : single int -- case value used height width dimension tuple two ints -- case, first int used height dimension, second int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"MaxPool2D module — nn_max_pool2d","text":"Input: \\((N, C, H_{}, W_{})\\) Output: \\((N, C, H_{}, W_{})\\), $$   H_{} = \\left\\lfloor\\frac{H_{} + 2 * \\mbox{padding[0]} - \\mbox{dilation[0]}     \\times (\\mbox{kernel\\_size[0]} - 1) - 1}{\\mbox{stride[0]}} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{} + 2 * \\mbox{padding[1]} - \\mbox{dilation[1]}     \\times (\\mbox{kernel\\_size[1]} - 1) - 1}{\\mbox{stride[1]}} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MaxPool2D module — nn_max_pool2d","text":"","code":"if (torch_is_installed()) { # pool of square window of size=3, stride=2 m <- nn_max_pool2d(3, stride = 2) # pool of non-square window m <- nn_max_pool2d(c(3, 2), stride = c(2, 1)) input <- torch_randn(20, 16, 50, 32) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"simplest case, output value layer input size \\((N, C, D, H, W)\\), output \\((N, C, D_{}, H_{}, W_{})\\) kernel_size \\((kD, kH, kW)\\) can precisely described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"","code":"nn_max_pool3d(   kernel_size,   stride = NULL,   padding = 0,   dilation = 1,   return_indices = FALSE,   ceil_mode = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"kernel_size size window take max stride stride window. Default value kernel_size padding implicit zero padding added three sides dilation parameter controls stride elements window return_indices TRUE, return max indices along outputs. Useful torch_nn.MaxUnpool3d later ceil_mode TRUE, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"$$ \\begin{array}{ll} \\mbox{}(N_i, C_j, d, h, w) = & \\max_{k=0, \\ldots, kD-1} \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\  & \\mbox{input}(N_i, C_j, \\mbox{stride[0]} \\times d + k, \\mbox{stride[1]} \\times h + m, \\mbox{stride[2]} \\times w + n) \\end{array} $$ padding non-zero, input implicitly zero-padded sides padding number points. dilation controls spacing kernel points. harder describe, link_ nice visualization dilation . parameters kernel_size, stride, padding, dilation can either : single int -- case value used depth, height width dimension tuple three ints -- case, first int used depth dimension, second int height dimension third int width dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"Input: \\((N, C, D_{}, H_{}, W_{})\\) Output: \\((N, C, D_{}, H_{}, W_{})\\), $$   D_{} = \\left\\lfloor\\frac{D_{} + 2 \\times \\mbox{padding}[0] - \\mbox{dilation}[0] \\times     (\\mbox{kernel\\_size}[0] - 1) - 1}{\\mbox{stride}[0]} + 1\\right\\rfloor $$ $$   H_{} = \\left\\lfloor\\frac{H_{} + 2 \\times \\mbox{padding}[1] - \\mbox{dilation}[1] \\times     (\\mbox{kernel\\_size}[1] - 1) - 1}{\\mbox{stride}[1]} + 1\\right\\rfloor $$ $$   W_{} = \\left\\lfloor\\frac{W_{} + 2 \\times \\mbox{padding}[2] - \\mbox{dilation}[2] \\times     (\\mbox{kernel\\_size}[2] - 1) - 1}{\\mbox{stride}[2]} + 1\\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_pool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Applies a 3D max pooling over an input signal composed of several input planes. — nn_max_pool3d","text":"","code":"if (torch_is_installed()) { # pool of square window of size=3, stride=2 m <- nn_max_pool3d(3, stride = 2) # pool of non-square window m <- nn_max_pool3d(c(3, 2, 2), stride = c(2, 1, 2)) input <- torch_randn(20, 16, 50, 44, 31) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"MaxPool1d fully invertible, since non-maximal values lost. MaxUnpool1d takes input output MaxPool1d including indices maximal values computes partial inverse non-maximal values set zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"","code":"nn_max_unpool1d(kernel_size, stride = NULL, padding = 0)"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"kernel_size (int tuple): Size max pooling window. stride (int tuple): Stride max pooling window. set kernel_size default. padding (int tuple): Padding added input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"MaxPool1d can map several input sizes output sizes. Hence, inversion process can get ambiguous. accommodate , can provide needed output size additional argument output_size forward call. See Inputs Example .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"input: input Tensor invert indices: indices given nn_max_pool1d() output_size (optional): targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"Input: \\((N, C, H_{})\\) Output: \\((N, C, H_{})\\), $$   H_{} = (H_{} - 1) \\times \\mbox{stride}[0] - 2 \\times \\mbox{padding}[0] + \\mbox{kernel\\_size}[0] $$ given output_size call operator","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a partial inverse of MaxPool1d. — nn_max_unpool1d","text":"","code":"if (torch_is_installed()) { pool <- nn_max_pool1d(2, stride = 2, return_indices = TRUE) unpool <- nn_max_unpool1d(2, stride = 2)  input <- torch_tensor(array(1:8 / 1, dim = c(1, 1, 8))) out <- pool(input) unpool(out[[1]], out[[2]])  # Example showcasing the use of output_size input <- torch_tensor(array(1:8 / 1, dim = c(1, 1, 8))) out <- pool(input) unpool(out[[1]], out[[2]], output_size = input$size()) unpool(out[[1]], out[[2]]) } #> torch_tensor #> (1,1,.,.) =  #>   0 #>   2 #>   0 #>   4 #>   0 #>   6 #>   0 #>   8 #> [ CPUFloatType{1,1,8,1} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"MaxPool2d fully invertible, since non-maximal values lost. MaxUnpool2d takes input output MaxPool2d including indices maximal values computes partial inverse non-maximal values set zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"","code":"nn_max_unpool2d(kernel_size, stride = NULL, padding = 0)"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"kernel_size (int tuple): Size max pooling window. stride (int tuple): Stride max pooling window. set kernel_size default. padding (int tuple): Padding added input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"MaxPool2d can map several input sizes output sizes. Hence, inversion process can get ambiguous. accommodate , can provide needed output size additional argument output_size forward call. See Inputs Example .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"input: input Tensor invert indices: indices given nn_max_pool2d() output_size (optional): targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"Input: \\((N, C, H_{}, W_{})\\) Output: \\((N, C, H_{}, W_{})\\), $$   H_{} = (H_{} - 1) \\times \\mbox{stride[0]} - 2 \\times \\mbox{padding[0]} + \\mbox{kernel\\_size[0]} $$ $$   W_{} = (W_{} - 1) \\times \\mbox{stride[1]} - 2 \\times \\mbox{padding[1]} + \\mbox{kernel\\_size[1]} $$ given output_size call operator","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a partial inverse of MaxPool2d. — nn_max_unpool2d","text":"","code":"if (torch_is_installed()) {  pool <- nn_max_pool2d(2, stride = 2, return_indices = TRUE) unpool <- nn_max_unpool2d(2, stride = 2) input <- torch_randn(1, 1, 4, 4) out <- pool(input) unpool(out[[1]], out[[2]])  # specify a different output size than input size unpool(out[[1]], out[[2]], output_size = c(1, 1, 5, 5)) } #> torch_tensor #> (1,1,.,.) =  #>   0.0000  0.0000  0.6845  0.0000  0.6537 #>   0.0000  0.0000  0.0000  0.0000  0.0000 #>   0.0000  0.0000  0.0000  1.3880  0.0000 #>   1.7067  0.0000  0.0000  0.0000  0.0000 #>   0.0000  0.0000  0.0000  0.0000  0.0000 #> [ CPUFloatType{1,1,5,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"MaxPool3d fully invertible, since non-maximal values lost. MaxUnpool3d takes input output MaxPool3d including indices maximal values computes partial inverse non-maximal values set zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"","code":"nn_max_unpool3d(kernel_size, stride = NULL, padding = 0)"},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"kernel_size (int tuple): Size max pooling window. stride (int tuple): Stride max pooling window. set kernel_size default. padding (int tuple): Padding added input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"MaxPool3d can map several input sizes output sizes. Hence, inversion process can get ambiguous. accommodate , can provide needed output size additional argument output_size forward call. See Inputs section .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"input: input Tensor invert indices: indices given nn_max_pool3d() output_size (optional): targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"Input: \\((N, C, D_{}, H_{}, W_{})\\) Output: \\((N, C, D_{}, H_{}, W_{})\\), $$   D_{} = (D_{} - 1) \\times \\mbox{stride[0]} - 2 \\times \\mbox{padding[0]} + \\mbox{kernel\\_size[0]} $$ $$   H_{} = (H_{} - 1) \\times \\mbox{stride[1]} - 2 \\times \\mbox{padding[1]} + \\mbox{kernel\\_size[1]} $$ $$   W_{} = (W_{} - 1) \\times \\mbox{stride[2]} - 2 \\times \\mbox{padding[2]} + \\mbox{kernel\\_size[2]} $$ given output_size call operator","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_max_unpool3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes a partial inverse of MaxPool3d. — nn_max_unpool3d","text":"","code":"if (torch_is_installed()) {  # pool of square window of size=3, stride=2 pool <- nn_max_pool3d(3, stride = 2, return_indices = TRUE) unpool <- nn_max_unpool3d(3, stride = 2) out <- pool(torch_randn(20, 16, 51, 33, 15)) unpooled_output <- unpool(out[[1]], out[[2]]) unpooled_output$size() } #> [1] 20 16 51 33 15"},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":null,"dir":"Reference","previous_headings":"","what":"Base class for all neural network modules. — nn_module","title":"Base class for all neural network modules. — nn_module","text":"models also subclass class.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base class for all neural network modules. — nn_module","text":"","code":"nn_module(   classname = NULL,   inherit = nn_Module,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base class for all neural network modules. — nn_module","text":"classname optional name module inherit optional module inherit ... methods implementation private passed R6::R6Class(). active passed R6::R6Class(). parent_env passed R6::R6Class().","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Base class for all neural network modules. — nn_module","text":"Modules can also contain Modules, allowing nest tree structure. can assign submodules regular attributes. expected implement initialize forward create new nn_module.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"initialize","dir":"Reference","previous_headings":"","what":"Initialize","title":"Base class for all neural network modules. — nn_module","text":"initialize function called whenever new instance nn_module created. use initialize functions define submodules parameters module. example:   initialize function can number parameters. objects assigned self$ available methods implement. Tensors wrapped nn_parameter() nn_buffer() submodules automatically tracked assigned self$. initialize function optional module defining weights, submodules buffers.","code":"initialize = function(input_size, output_size) {    self$conv1 <- nn_conv2d(input_size, output_size, 5)    self$conv2 <- nn_conv2d(output_size, output_size, 5) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"forward","dir":"Reference","previous_headings":"","what":"Forward","title":"Base class for all neural network modules. — nn_module","text":"forward method called whenever instance nn_module called. usually used implement computation module weights ad submodules defined initialize function. example:   forward function can use self$training attribute make different computations depending wether model training , example implementing dropout module.","code":"forward = function(input) {    input <- self$conv1(input)    input <- nnf_relu(input)    input <- self$conv2(input)    input <- nnf_relu(input)    input  }"},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"cloning","dir":"Reference","previous_headings":"","what":"Cloning","title":"Base class for all neural network modules. — nn_module","text":"finalize cloning module, can define private finalize_deep_clone() method. method called cloned object deep-cloning module, modules, parameters buffers already cloned.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Base class for all neural network modules. — nn_module","text":"","code":"if (torch_is_installed()) { model <- nn_module(   initialize = function() {     self$conv1 <- nn_conv2d(1, 20, 5)     self$conv2 <- nn_conv2d(20, 20, 5)   },   forward = function(input) {     input <- self$conv1(input)     input <- nnf_relu(input)     input <- self$conv2(input)     input <- nnf_relu(input)     input   } ) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_module_dict.html","id":null,"dir":"Reference","previous_headings":"","what":"Container that allows named values — nn_module_dict","title":"Container that allows named values — nn_module_dict","text":"Container allows named values","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module_dict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Container that allows named values — nn_module_dict","text":"","code":"nn_module_dict(dict)"},{"path":"https://torch.mlverse.org/docs/reference/nn_module_dict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Container that allows named values — nn_module_dict","text":"dict named list submodules saved module.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_module_dict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Container that allows named values — nn_module_dict","text":"","code":"if (torch_is_installed()) { nn_module <- nn_module(   initialize = function() {     self$dict <- nn_module_dict(list(       l1 = nn_linear(10, 20),       l2 = nn_linear(20, 10)     ))   },   forward = function(x) {     x <- self$dict$l1(x)     self$dict$l2(x)   } ) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_module_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Holds submodules in a list. — nn_module_list","title":"Holds submodules in a list. — nn_module_list","text":"nn_module_list can indexed like regular R list, modules contains properly registered, visible nn_module methods.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_module_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Holds submodules in a list. — nn_module_list","text":"","code":"nn_module_list(modules = list())"},{"path":"https://torch.mlverse.org/docs/reference/nn_module_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Holds submodules in a list. — nn_module_list","text":"modules list modules add","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_module_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Holds submodules in a list. — nn_module_list","text":"","code":"if (torch_is_installed()) {  my_module <- nn_module(   initialize = function() {     self$linears <- nn_module_list(lapply(1:10, function(x) nn_linear(10, 10)))   },   forward = function(x) {     for (i in 1:length(self$linears)) {       x <- self$linears[[i]](x)     }     x   } ) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"MSE loss — nn_mse_loss","title":"MSE loss — nn_mse_loss","text":"Creates criterion measures mean squared error (squared L2 norm) element input \\(x\\) target \\(y\\). unreduced (.e. reduction set 'none') loss can described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MSE loss — nn_mse_loss","text":"","code":"nn_mse_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MSE loss — nn_mse_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MSE loss — nn_mse_loss","text":"$$   \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = \\left( x_n - y_n \\right)^2, $$ \\(N\\) batch size. reduction 'none' (default 'mean'), : $$   \\ell(x, y) =   \\begin{array}{ll} \\mbox{mean}(L), &  \\mbox{reduction} = \\mbox{'mean';}\\\\ \\mbox{sum}(L),  &  \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ \\(x\\) \\(y\\) tensors arbitrary shapes total \\(n\\) elements . mean operation still operates elements, divides \\(n\\). division \\(n\\) can avoided one sets reduction = 'sum'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"MSE loss — nn_mse_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_mse_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MSE loss — nn_mse_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_mse_loss() input <- torch_randn(3, 5, requires_grad = TRUE) target <- torch_randn(3, 5) output <- loss(input, target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_multi_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi margin loss — nn_multi_margin_loss","title":"Multi margin loss — nn_multi_margin_loss","text":"Creates criterion optimizes multi-class classification hinge loss (margin-based loss) input \\(x\\) (2D mini-batch Tensor) output \\(y\\) (1D tensor target class indices, \\(0 \\leq y \\leq \\mbox{x.size}(1)-1\\)):","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multi_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi margin loss — nn_multi_margin_loss","text":"","code":"nn_multi_margin_loss(p = 1, margin = 1, weight = NULL, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_multi_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi margin loss — nn_multi_margin_loss","text":"p (int, optional): default value \\(1\\). \\(1\\) \\(2\\) supported values. margin (float, optional): default value \\(1\\). weight (Tensor, optional): manual rescaling weight given class. given, Tensor size C. Otherwise, treated ones. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multi_margin_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi margin loss — nn_multi_margin_loss","text":"mini-batch sample, loss terms 1D input \\(x\\) scalar output \\(y\\) : $$   \\mbox{loss}(x, y) = \\frac{\\sum_i \\max(0, \\mbox{margin} - x[y] + x[]))^p}{\\mbox{x.size}(0)} $$ \\(x \\\\left\\{0, \\; \\cdots , \\; \\mbox{x.size}(0) - 1\\right\\}\\) \\(\\neq y\\). Optionally, can give non-equal weighting classes passing 1D weight tensor constructor. loss function becomes: $$   \\mbox{loss}(x, y) = \\frac{\\sum_i \\max(0, w[y] * (\\mbox{margin} - x[y] + x[]))^p)}{\\mbox{x.size}(0)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"MultiHead attention — nn_multihead_attention","title":"MultiHead attention — nn_multihead_attention","text":"Allows model jointly attend information different representation subspaces. See reference: Attention Need","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MultiHead attention — nn_multihead_attention","text":"","code":"nn_multihead_attention(   embed_dim,   num_heads,   dropout = 0,   bias = TRUE,   add_bias_kv = FALSE,   add_zero_attn = FALSE,   kdim = NULL,   vdim = NULL,   batch_first = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MultiHead attention — nn_multihead_attention","text":"embed_dim total dimension model. num_heads parallel attention heads. Note embed_dim split across num_heads (.e. head dimension embed_dim %/% num_heads). dropout Dropout layer attn_output_weights. Default: 0.0. bias add bias module parameter. Default: True. add_bias_kv add bias key value sequences dim=0. add_zero_attn add new batch zeros key value sequences dim=1. kdim total number features key. Default: NULL vdim total number features value. Default: NULL. Note: kdim vdim NULL, set embed_dim query, key, value number features. batch_first TRUE input output tensors \\((N,   S, E)\\) instead \\((S, N, E)\\), N batch size, S sequence length, E embedding dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MultiHead attention — nn_multihead_attention","text":"$$ \\mbox{MultiHead}(Q, K, V) = \\mbox{Concat}(head_1,\\dots,head_h)W^O \\mbox{} head_i = \\mbox{Attention}(QW_i^Q, KW_i^K, VW_i^V) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"MultiHead attention — nn_multihead_attention","text":"Inputs: query: \\((L, N, E)\\) L target sequence length, N batch size, E embedding dimension. (see batch_first argument) key: \\((S, N, E)\\), S source sequence length, N batch size, E embedding dimension. (see batch_first argument) value: \\((S, N, E)\\) S source sequence length, N batch size, E embedding dimension. (see batch_first argument) key_padding_mask: \\((N, S)\\) N batch size, S source sequence length. ByteTensor provided, non-zero positions ignored position zero positions unchanged. BoolTensor provided, positions value True ignored position value False unchanged. attn_mask: 2D mask \\((L, S)\\) L target sequence length, S source sequence length. 3D mask \\((N*num_heads, L, S)\\) N batch size, L target sequence length, S source sequence length. attn_mask ensure position allowed attend unmasked positions. ByteTensor provided, non-zero positions allowed attend zero positions unchanged. BoolTensor provided, positions True allowed attend False values unchanged. FloatTensor provided, added attention weight. Outputs: attn_output: \\((L, N, E)\\) L target sequence length, N batch size, E embedding dimension. (see  batch_first argument) attn_output_weights: avg_weights TRUE (default), output attention weights averaged attention heads, giving tensor shape \\((N, L, S)\\) N batch size, L target sequence length, S source sequence length. avg_weights FALSE, attention weight tensor output -, shape \\((N, H, L, S)\\), H number attention heads.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multihead_attention.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MultiHead attention — nn_multihead_attention","text":"","code":"if (torch_is_installed()) { if (FALSE) { multihead_attn <- nn_multihead_attention(embed_dim, num_heads) out <- multihead_attn(query, key, value) attn_output <- out[[1]] attn_output_weights <- out[[2]] }  }"},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilabel margin loss — nn_multilabel_margin_loss","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"Creates criterion optimizes multi-class multi-classification hinge loss (margin-based loss) input \\(x\\) (2D mini-batch Tensor) output \\(y\\) (2D Tensor target class indices). sample mini-batch:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"","code":"nn_multilabel_margin_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"$$   \\mbox{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[]))}{\\mbox{x.size}(0)} $$ \\(x \\\\left\\{0, \\; \\cdots , \\; \\mbox{x.size}(0) - 1\\right\\}\\), \\ \\(y \\\\left\\{0, \\; \\cdots , \\; \\mbox{y.size}(0) - 1\\right\\}\\), \\ \\(0 \\leq y[j] \\leq \\mbox{x.size}(0)-1\\), \\ \\(\\neq y[j]\\) \\(\\) \\(j\\). \\(y\\) \\(x\\) must size. criterion considers contiguous block non-negative targets starts front. allows different samples variable amounts target classes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"Input: \\((C)\\) \\((N, C)\\) N batch size C number classes. Target: \\((C)\\) \\((N, C)\\), label targets padded -1 ensuring shape input. Output: scalar. reduction 'none', \\((N)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_margin_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multilabel margin loss — nn_multilabel_margin_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_multilabel_margin_loss() x <- torch_tensor(c(0.1, 0.2, 0.4, 0.8))$view(c(1, 4)) # for target y, only consider labels 4 and 1, not after label -1 y <- torch_tensor(c(4, 1, -1, 2), dtype = torch_long())$view(c(1, 4)) loss(x, y) } #> torch_tensor #> 0.85 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_soft_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","title":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","text":"Creates criterion optimizes multi-label one-versus-loss based max-entropy, input \\(x\\) target \\(y\\) size \\((N, C)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_soft_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","text":"","code":"nn_multilabel_soft_margin_loss(weight = NULL, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_soft_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","text":"weight (Tensor, optional): manual rescaling weight given class. given, Tensor size C. Otherwise, treated ones. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_soft_margin_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","text":"sample minibatch: $$   loss(x, y) = - \\frac{1}{C} * \\sum_i y[] * \\log((1 + \\exp(-x[]))^{-1}) + (1-y[]) * \\log\\left(\\frac{\\exp(-x[])}{(1 + \\exp(-x[]))}\\right) $$ \\(\\\\left\\{0, \\; \\cdots , \\; \\mbox{x.nElement}() - 1\\right\\}\\), \\(y[] \\\\left\\{0, \\; 1\\right\\}\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_multilabel_soft_margin_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Multi label soft margin loss — nn_multilabel_soft_margin_loss","text":"Input: \\((N, C)\\) N batch size C number classes. Target: \\((N, C)\\), label targets padded -1 ensuring shape input. Output: scalar. reduction 'none', \\((N)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Nll loss — nn_nll_loss","title":"Nll loss — nn_nll_loss","text":"negative log likelihood loss. useful train classification problem C classes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nll loss — nn_nll_loss","text":"","code":"nn_nll_loss(weight = NULL, ignore_index = -100, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nll loss — nn_nll_loss","text":"weight (Tensor, optional): manual rescaling weight given class. given, Tensor size C. Otherwise, treated ones. ignore_index (int, optional): Specifies target value ignored contribute input gradient. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': weighted mean output taken, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nll loss — nn_nll_loss","text":"provided, optional argument weight 1D Tensor assigning weight classes. particularly useful unbalanced training set. input given forward call expected contain log-probabilities class. input Tensor size either \\((minibatch, C)\\) \\((minibatch, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) K-dimensional case (described later). Obtaining log-probabilities neural network easily achieved adding  LogSoftmax  layer last layer network. may use CrossEntropyLoss instead, prefer add extra layer. target loss expects class index range \\([0, C-1]\\) C = number classes; ignore_index specified, loss also accepts class index (index may necessarily class range). unreduced (.e. reduction set 'none') loss can described : $$ \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - w_{y_n} x_{n,y_n}, \\quad w_{c} = \\mbox{weight}[c] \\cdot \\mbox{1}\\{c \\= \\mbox{ignore\\_index}\\}, $$ \\(x\\) input, \\(y\\) target, \\(w\\) weight, \\(N\\) batch size. reduction 'none' (default 'mean'), $$ \\ell(x, y) = \\begin{array}{ll} \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &   \\mbox{reduction} = \\mbox{'mean';}\\\\ \\sum_{n=1}^N l_n,  &   \\mbox{reduction} = \\mbox{'sum'.} \\end{array} $$ Can also used higher dimension inputs, 2D images, providing input size \\((minibatch, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\), \\(K\\) number dimensions, target appropriate shape (see ). case images, computes NLL loss per-pixel.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Nll loss — nn_nll_loss","text":"Input: \\((N, C)\\) C = number classes, \\((N, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. Target: \\((N)\\) value \\(0 \\leq \\mbox{targets}[] \\leq C-1\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. Output: scalar. reduction 'none', size target: \\((N)\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_nll_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nll loss — nn_nll_loss","text":"","code":"if (torch_is_installed()) { m <- nn_log_softmax(dim = 2) loss <- nn_nll_loss() # input is of size N x C = 3 x 5 input <- torch_randn(3, 5, requires_grad = TRUE) # each element in target has to have 0 <= value < C target <- torch_tensor(c(2, 1, 5), dtype = torch_long()) output <- loss(m(input), target) output$backward()  # 2D loss example (used, for example, with image inputs) N <- 5 C <- 4 loss <- nn_nll_loss() # input is of size N x C x height x width data <- torch_randn(N, 16, 10, 10) conv <- nn_conv2d(16, C, c(3, 3)) m <- nn_log_softmax(dim = 1) # each element in target has to have 0 <= value < C target <- torch_empty(N, 8, 8, dtype = torch_long())$random_(1, C) output <- loss(m(conv(data)), target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise distance — nn_pairwise_distance","title":"Pairwise distance — nn_pairwise_distance","text":"Computes batchwise pairwise distance vectors \\(v_1\\), \\(v_2\\) using p-norm:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise distance — nn_pairwise_distance","text":"","code":"nn_pairwise_distance(p = 2, eps = 1e-06, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise distance — nn_pairwise_distance","text":"p (real): norm degree. Default: 2 eps (float, optional): Small value avoid division zero. Default: 1e-6 keepdim (bool, optional): Determines whether keep vector dimension. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pairwise distance — nn_pairwise_distance","text":"$$  \\Vert x \\Vert _p = \\left( \\sum_{=1}^n  \\vert x_i \\vert ^ p \\right) ^ {1/p}. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Pairwise distance — nn_pairwise_distance","text":"Input1: \\((N, D)\\) D = vector dimension Input2: \\((N, D)\\), shape Input1 Output: \\((N)\\). keepdim TRUE, \\((N, 1)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_pairwise_distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pairwise distance — nn_pairwise_distance","text":"","code":"if (torch_is_installed()) { pdist <- nn_pairwise_distance(p = 2) input1 <- torch_randn(100, 128) input2 <- torch_randn(100, 128) output <- pdist(input1, input2) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_parameter.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates an nn_parameter — nn_parameter","title":"Creates an nn_parameter — nn_parameter","text":"Indicates nn_module x parameter","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_parameter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates an nn_parameter — nn_parameter","text":"","code":"nn_parameter(x, requires_grad = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_parameter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates an nn_parameter — nn_parameter","text":"x tensor want indicate parameter requires_grad whether parameter  requires_grad = TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson NLL loss — nn_poisson_nll_loss","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"Negative log likelihood loss Poisson distribution target. loss can described :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"","code":"nn_poisson_nll_loss(   log_input = TRUE,   full = FALSE,   eps = 1e-08,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"log_input (bool, optional): TRUE loss computed \\(\\exp(\\mbox{input}) - \\mbox{target}*\\mbox{input}\\), FALSE loss \\(\\mbox{input} - \\mbox{target}*\\log(\\mbox{input}+\\mbox{eps})\\). full (bool, optional): whether compute full loss, . e. add Stirling approximation term \\(\\mbox{target}*\\log(\\mbox{target}) - \\mbox{target} + 0.5 * \\log(2\\pi\\mbox{target})\\). eps (float, optional): Small value avoid evaluation \\(\\log(0)\\) log_input = FALSE. Default: 1e-8 reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"$$ \\mbox{target} \\sim \\mathrm{Poisson}(\\mbox{input}) \\mbox{loss}(\\mbox{input}, \\mbox{target}) = \\mbox{input} - \\mbox{target} * \\log(\\mbox{input}) + \\log(\\mbox{target!}) $$ last term can omitted approximated Stirling formula. approximation used target values 1. targets less equal 1 zeros added loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar default. reduction 'none', \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_poisson_nll_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson NLL loss — nn_poisson_nll_loss","text":"","code":"if (torch_is_installed()) { loss <- nn_poisson_nll_loss() log_input <- torch_randn(5, 2, requires_grad = TRUE) target <- torch_randn(5, 2) output <- loss(log_input, target) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":null,"dir":"Reference","previous_headings":"","what":"PReLU module — nn_prelu","title":"PReLU module — nn_prelu","text":"Applies element-wise function: $$   \\mbox{PReLU}(x) = \\max(0,x) + * \\min(0,x) $$ $$   \\mbox{PReLU}(x) =   \\left\\{ \\begin{array}{ll} x, & \\mbox{ } x \\geq 0 \\\\ ax, & \\mbox{ otherwise } \\end{array} \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PReLU module — nn_prelu","text":"","code":"nn_prelu(num_parameters = 1, init = 0.25)"},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PReLU module — nn_prelu","text":"num_parameters (int): number \\(\\) learn. Although takes int input, two values legitimate: 1, number channels input. Default: 1 init (float): initial value \\(\\). Default: 0.25","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PReLU module — nn_prelu","text":"\\(\\) learnable parameter. called without arguments, nn.prelu() uses single parameter \\(\\) across input channels. called nn_prelu(nChannels), separate \\(\\) used input channel.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"PReLU module — nn_prelu","text":"weight decay used learning \\(\\) good performance. Channel dim 2nd dim input. input dims < 2, channel dim number channels = 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"PReLU module — nn_prelu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"PReLU module — nn_prelu","text":"weight (Tensor): learnable weights shape (num_parameters).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prelu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PReLU module — nn_prelu","text":"","code":"if (torch_is_installed()) { m <- nn_prelu() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_prune_head.html","id":null,"dir":"Reference","previous_headings":"","what":"Prune top layer(s) of a network — nn_prune_head","title":"Prune top layer(s) of a network — nn_prune_head","text":"Prune head_size last layers nn_module order replace head, order use pruned module sequential embedding module.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prune_head.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prune top layer(s) of a network — nn_prune_head","text":"","code":"nn_prune_head(x, head_size)"},{"path":"https://torch.mlverse.org/docs/reference/nn_prune_head.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prune top layer(s) of a network — nn_prune_head","text":"x nn_network prune head_size number nn_layers prune","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prune_head.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prune top layer(s) of a network — nn_prune_head","text":"nn_sequential network top nn_layer removed","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_prune_head.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prune top layer(s) of a network — nn_prune_head","text":"","code":"if (torch_is_installed()) { if (torch_is_installed()) { x <- nn_sequential(   nn_relu(),   nn_tanh(),   nn_relu6(),   nn_relu(),   nn_linear(2,10),   nn_batch_norm1d(10),   nn_tanh(),   nn_linear(10,3) ) prune <- nn_prune_head(x, 3) prune } } #> An `nn_module` containing 30 parameters. #>  #> ── Modules ───────────────────────────────────────────────────────────────────── #> • 0: <nn_relu> #0 parameters #> • 1: <nn_tanh> #0 parameters #> • 2: <nn_relu6> #0 parameters #> • 3: <nn_relu> #0 parameters #> • 4: <nn_linear> #30 parameters"},{"path":"https://torch.mlverse.org/docs/reference/nn_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"ReLU module — nn_relu","title":"ReLU module — nn_relu","text":"Applies rectified linear unit function element-wise $$\\mbox{ReLU}(x) = (x)^+ = \\max(0, x)$$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ReLU module — nn_relu","text":"","code":"nn_relu(inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ReLU module — nn_relu","text":"inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ReLU module — nn_relu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ReLU module — nn_relu","text":"","code":"if (torch_is_installed()) { m <- nn_relu() input <- torch_randn(2) m(input) } #> torch_tensor #>  0.2521 #>  0.0000 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":null,"dir":"Reference","previous_headings":"","what":"ReLu6 module — nn_relu6","title":"ReLu6 module — nn_relu6","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ReLu6 module — nn_relu6","text":"","code":"nn_relu6(inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ReLu6 module — nn_relu6","text":"inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ReLu6 module — nn_relu6","text":"$$   \\mbox{ReLU6}(x) = \\min(\\max(0,x), 6) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"ReLu6 module — nn_relu6","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_relu6.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ReLu6 module — nn_relu6","text":"","code":"if (torch_is_installed()) { m <- nn_relu6() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":null,"dir":"Reference","previous_headings":"","what":"RNN module — nn_rnn","title":"RNN module — nn_rnn","text":"Applies multi-layer Elman RNN \\(\\tanh\\) \\(\\mbox{ReLU}\\) non-linearity input sequence.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RNN module — nn_rnn","text":"","code":"nn_rnn(   input_size,   hidden_size,   num_layers = 1,   nonlinearity = NULL,   bias = TRUE,   batch_first = FALSE,   dropout = 0,   bidirectional = FALSE,   ... )"},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RNN module — nn_rnn","text":"input_size number expected features input x hidden_size number features hidden state h num_layers Number recurrent layers. E.g., setting num_layers=2 mean stacking two RNNs together form stacked RNN, second RNN taking outputs first RNN computing final results. Default: 1 nonlinearity non-linearity use. Can either 'tanh' 'relu'. Default: 'tanh' bias FALSE, layer use bias weights b_ih b_hh. Default: TRUE batch_first TRUE, input output tensors provided (batch, seq, feature). Default: FALSE dropout non-zero, introduces Dropout layer outputs RNN layer except last layer, dropout probability equal dropout. Default: 0 bidirectional TRUE, becomes bidirectional RNN. Default: FALSE ... arguments can passed super class.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RNN module — nn_rnn","text":"element input sequence, layer computes following function: $$ h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh}) $$ \\(h_t\\) hidden state time t, \\(x_t\\) input time t, \\(h_{(t-1)}\\) hidden state previous layer time t-1 initial hidden state time 0. nonlinearity 'relu', \\(\\mbox{ReLU}\\) used instead \\(\\tanh\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"RNN module — nn_rnn","text":"input shape (seq_len, batch, input_size): tensor containing features input sequence. input can also packed variable length sequence. h_0 shape (num_layers * num_directions, batch, hidden_size): tensor containing initial hidden state element batch. Defaults zero provided. RNN bidirectional, num_directions 2, else 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"outputs","dir":"Reference","previous_headings":"","what":"Outputs","title":"RNN module — nn_rnn","text":"output shape (seq_len, batch, num_directions * hidden_size): tensor containing output features (h_t) last layer RNN, t.  :class:nn_packed_sequence given input, output also packed sequence. unpacked case, directions can separated using output$view(seq_len, batch, num_directions, hidden_size), forward backward direction 0 1 respectively. Similarly, directions can separated packed case. h_n shape (num_layers * num_directions, batch, hidden_size): tensor containing hidden state t = seq_len. Like output, layers can separated using h_n$view(num_layers, num_directions, batch, hidden_size).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"RNN module — nn_rnn","text":"Input1: \\((L, N, H_{})\\) tensor containing input features \\(H_{}=\\mbox{input\\_size}\\) L represents sequence length. Input2: \\((S, N, H_{})\\) tensor containing initial hidden state element batch. \\(H_{}=\\mbox{hidden\\_size}\\) Defaults zero provided. \\(S=\\mbox{num\\_layers} * \\mbox{num\\_directions}\\) RNN bidirectional, num_directions 2, else 1. Output1: \\((L, N, H_{})\\) \\(H_{}=\\mbox{num\\_directions} * \\mbox{hidden\\_size}\\) Output2: \\((S, N, H_{})\\) tensor containing next hidden state element batch","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"attributes","dir":"Reference","previous_headings":"","what":"Attributes","title":"RNN module — nn_rnn","text":"weight_ih_l[k]: learnable input-hidden weights k-th layer, shape (hidden_size, input_size) k = 0. Otherwise, shape (hidden_size, num_directions * hidden_size) weight_hh_l[k]: learnable hidden-hidden weights k-th layer, shape (hidden_size, hidden_size) bias_ih_l[k]: learnable input-hidden bias k-th layer, shape (hidden_size) bias_hh_l[k]: learnable hidden-hidden bias k-th layer, shape (hidden_size)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"RNN module — nn_rnn","text":"weights biases initialized \\(\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\\) \\(k = \\frac{1}{\\mbox{hidden\\_size}}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rnn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RNN module — nn_rnn","text":"","code":"if (torch_is_installed()) { rnn <- nn_rnn(10, 20, 2) input <- torch_randn(5, 3, 10) h0 <- torch_randn(2, 3, 20) rnn(input, h0) } #> [[1]] #> torch_tensor #> (1,.,.) =  #>  Columns 1 to 9  0.6194  0.1261 -0.5859 -0.5130  0.2639  0.2436  0.7532 -0.1778 -0.1698 #>  -0.7915 -0.2606  0.5423 -0.2332 -0.5692  0.0797 -0.3458 -0.2994 -0.4752 #>   0.7498 -0.1321 -0.2842  0.4756 -0.1615  0.2806  0.3849  0.2648 -0.1627 #>  #> Columns 10 to 18 -0.4432 -0.2098 -0.7064 -0.0722 -0.5759 -0.7316  0.3305 -0.2668  0.0912 #>   0.3085 -0.2419  0.3502  0.3794 -0.2719  0.7153  0.0670  0.6914  0.6160 #>  -0.0390  0.7705  0.9537  0.7160 -0.5791  0.8475 -0.8662  0.0169 -0.3920 #>  #> Columns 19 to 20 -0.1107  0.3902 #>   0.4782 -0.1679 #>  -0.9254  0.8202 #>  #> (2,.,.) =  #>  Columns 1 to 9 -0.2733  0.5807 -0.5705 -0.2137 -0.1263  0.2720  0.6784  0.3367  0.2812 #>  -0.2298  0.4555 -0.4291  0.0732  0.4738 -0.2003  0.2658  0.3731 -0.0465 #>  -0.2809  0.1940 -0.0990  0.2505 -0.0127 -0.4197  0.1765  0.8446 -0.0952 #>  #> Columns 10 to 18  0.2151  0.3480  0.2816  0.6208 -0.4694 -0.2574 -0.3221  0.7333 -0.4520 #>  -0.2748 -0.2761 -0.7137  0.4835 -0.1636 -0.6345 -0.0590  0.2484  0.0123 #>  -0.5653  0.5783 -0.5571  0.2605  0.1348 -0.0049  0.2231  0.4494  0.2747 #>  #> Columns 19 to 20  0.4467  0.2031 #>  -0.3049  0.3067 #>  -0.0243  0.4457 #>  #> (3,.,.) =  #>  Columns 1 to 9 -0.4587  0.5419 -0.3534 -0.4045 -0.4276 -0.2290  0.0918  0.5118 -0.5355 #>  -0.1085  0.3107 -0.3817 -0.3413 -0.4206 -0.2209  0.3014  0.1557 -0.1130 #>   0.2597  0.2839 -0.4300  0.1852  0.0349  0.0473  0.3646 -0.3881  0.4646 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{5,3,20} ][ grad_fn = <StackBackward0> ] #>  #> [[2]] #> torch_tensor #> (1,.,.) =  #>  Columns 1 to 9  0.0086 -0.2831 -0.5776  0.0057 -0.0709  0.6271  0.5970  0.2080  0.1378 #>   0.0209 -0.5796 -0.3668  0.0877 -0.3049  0.4987  0.4293 -0.7983 -0.5304 #>   0.2519 -0.3285  0.2158 -0.1921  0.4215  0.2205  0.2465 -0.4121 -0.2367 #>  #> Columns 10 to 18  0.8283  0.0237  0.4405  0.3959  0.7915 -0.3492 -0.5114  0.2015  0.4390 #>   0.4698 -0.1859  0.3392  0.6283  0.7378  0.7038  0.3066  0.7614 -0.0596 #>  -0.0976  0.1275  0.5496  0.4558 -0.0012  0.2623  0.1556 -0.0674 -0.4739 #>  #> Columns 19 to 20  0.4836  0.6168 #>  -0.4734  0.4156 #>  -0.2577  0.4979 #>  #> (2,.,.) =  #>  Columns 1 to 9 -0.1114  0.3486 -0.4200 -0.1580 -0.5198 -0.3118  0.2938  0.5197 -0.0018 #>   0.2732  0.4590 -0.4445  0.2851 -0.4892  0.0292  0.2732  0.1335  0.0589 #>   0.3064  0.3742 -0.6699 -0.2006 -0.5265 -0.1959  0.4728  0.1926 -0.0590 #>  #> Columns 10 to 18  0.0210  0.3693 -0.2735  0.4198 -0.6618 -0.2076 -0.0963  0.3921 -0.5134 #>   0.1978  0.4044 -0.1352  0.3989 -0.5551 -0.5138  0.0447  0.2919 -0.1836 #>  -0.1193 -0.0102  0.0760  0.4765 -0.0831 -0.3886  0.2522  0.4670 -0.1084 #>  #> Columns 19 to 20 -0.0799  0.3596 #>   0.2372  0.5238 #>   0.2247  0.4753 #> [ CPUFloatType{2,3,20} ][ grad_fn = <StackBackward0> ] #>"},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":null,"dir":"Reference","previous_headings":"","what":"RReLU module — nn_rrelu","title":"RReLU module — nn_rrelu","text":"Applies randomized leaky rectified liner unit function, element-wise, described paper:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RReLU module — nn_rrelu","text":"","code":"nn_rrelu(lower = 1/8, upper = 1/3, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RReLU module — nn_rrelu","text":"lower lower bound uniform distribution. Default: \\(\\frac{1}{8}\\) upper upper bound uniform distribution. Default: \\(\\frac{1}{3}\\) inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"RReLU module — nn_rrelu","text":"Empirical Evaluation Rectified Activations Convolutional Network. function defined : $$ \\mbox{RReLU}(x) = \\left\\{ \\begin{array}{ll} x & \\mbox{} x \\geq 0 \\\\ ax & \\mbox{ otherwise } \\end{array} \\right. $$ \\(\\) randomly sampled uniform distribution \\(\\mathcal{U}(\\mbox{lower}, \\mbox{upper})\\). See: https://arxiv.org/pdf/1505.00853.pdf","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"RReLU module — nn_rrelu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_rrelu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RReLU module — nn_rrelu","text":"","code":"if (torch_is_installed()) { m <- nn_rrelu(0.1, 0.3) input <- torch_randn(2) m(input) } #> torch_tensor #> 0.01 * #> -1.9460 #> -29.5220 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":null,"dir":"Reference","previous_headings":"","what":"SELU module — nn_selu","title":"SELU module — nn_selu","text":"Applied element-wise, :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SELU module — nn_selu","text":"","code":"nn_selu(inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SELU module — nn_selu","text":"inplace (bool, optional): can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SELU module — nn_selu","text":"$$   \\mbox{SELU}(x) = \\mbox{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))) $$ \\(\\alpha = 1.6732632423543772848170429916717\\) \\(\\mbox{scale} = 1.0507009873554804934193349852946\\). details can found paper Self-Normalizing Neural Networks.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"SELU module — nn_selu","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_selu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SELU module — nn_selu","text":"","code":"if (torch_is_installed()) { m <- nn_selu() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"A sequential container — nn_sequential","title":"A sequential container — nn_sequential","text":"sequential container. Modules added order passed constructor. See examples.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A sequential container — nn_sequential","text":"","code":"nn_sequential(...)"},{"path":"https://torch.mlverse.org/docs/reference/nn_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A sequential container — nn_sequential","text":"... sequence modules added","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A sequential container — nn_sequential","text":"","code":"if (torch_is_installed()) {  model <- nn_sequential(   nn_conv2d(1, 20, 5),   nn_relu(),   nn_conv2d(20, 64, 5),   nn_relu() ) input <- torch_randn(32, 1, 28, 28) output <- model(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid module — nn_sigmoid","title":"Sigmoid module — nn_sigmoid","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid module — nn_sigmoid","text":"","code":"nn_sigmoid()"},{"path":"https://torch.mlverse.org/docs/reference/nn_sigmoid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sigmoid module — nn_sigmoid","text":"$$   \\mbox{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_sigmoid.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Sigmoid module — nn_sigmoid","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid module — nn_sigmoid","text":"","code":"if (torch_is_installed()) { m <- nn_sigmoid() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. The SiLU function is also known as the swish function. — nn_silu","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. The SiLU function is also known as the swish function. — nn_silu","text":"Applies Sigmoid Linear Unit (SiLU) function, element-wise. SiLU function also known swish function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. The SiLU function is also known as the swish function. — nn_silu","text":"","code":"nn_silu(inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. The SiLU function is also known as the swish function. — nn_silu","text":"inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_silu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. The SiLU function is also known as the swish function. — nn_silu","text":"See Gaussian Error Linear Units (GELUs) SiLU (Sigmoid Linear Unit) originally coined, see Sigmoid-Weighted Linear Units Neural Network Function Approximation Reinforcement Learning Swish: Self-Gated Activation Function SiLU experimented later.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_smooth_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth L1 loss — nn_smooth_l1_loss","title":"Smooth L1 loss — nn_smooth_l1_loss","text":"Creates criterion uses squared term absolute element-wise error falls 1 L1 term otherwise. less sensitive outliers MSELoss cases prevents exploding gradients (e.g. see Fast R-CNN paper Ross Girshick). Also known Huber loss:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_smooth_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth L1 loss — nn_smooth_l1_loss","text":"","code":"nn_smooth_l1_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_smooth_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth L1 loss — nn_smooth_l1_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_smooth_l1_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Smooth L1 loss — nn_smooth_l1_loss","text":"$$   \\mbox{loss}(x, y) = \\frac{1}{n} \\sum_{} z_{} $$ \\(z_{}\\) given : $$   z_{} =   \\begin{array}{ll} 0.5 (x_i - y_i)^2, & \\mbox{} |x_i - y_i| < 1 \\\\ |x_i - y_i| - 0.5, & \\mbox{otherwise } \\end{array} $$ \\(x\\) \\(y\\) arbitrary shapes total \\(n\\) elements sum operation still operates elements, divides \\(n\\). division \\(n\\) can avoided sets reduction = 'sum'.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_smooth_l1_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Smooth L1 loss — nn_smooth_l1_loss","text":"Input: \\((N, *)\\) \\(*\\) means, number additional dimensions Target: \\((N, *)\\), shape input Output: scalar. reduction 'none', \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_soft_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Soft margin loss — nn_soft_margin_loss","title":"Soft margin loss — nn_soft_margin_loss","text":"Creates criterion optimizes two-class classification logistic loss input tensor \\(x\\) target tensor \\(y\\) (containing 1 -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_soft_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Soft margin loss — nn_soft_margin_loss","text":"","code":"nn_soft_margin_loss(reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nn_soft_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Soft margin loss — nn_soft_margin_loss","text":"reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_soft_margin_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Soft margin loss — nn_soft_margin_loss","text":"$$   \\mbox{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[]*x[]))}{\\mbox{x.nelement}()} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_soft_margin_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Soft margin loss — nn_soft_margin_loss","text":"Input: \\((*)\\) \\(*\\) means, number additional dimensions Target: \\((*)\\), shape input Output: scalar. reduction 'none', shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax module — nn_softmax","title":"Softmax module — nn_softmax","text":"Applies Softmax function n-dimensional input Tensor rescaling elements n-dimensional output Tensor lie range [0,1] sum 1. Softmax defined :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax module — nn_softmax","text":"","code":"nn_softmax(dim)"},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax module — nn_softmax","text":"dim (int): dimension along Softmax computed (every slice along dim sum 1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax module — nn_softmax","text":": Tensor dimension shape input values range [0, 1]","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softmax module — nn_softmax","text":"$$   \\mbox{Softmax}(x_{}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} $$ input Tensor sparse tensor unspecifed values treated -Inf.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Softmax module — nn_softmax","text":"module work directly NLLLoss, expects Log computed Softmax . Use LogSoftmax instead (faster better numerical properties).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softmax module — nn_softmax","text":"Input: \\((*)\\) * means, number additional dimensions Output: \\((*)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax module — nn_softmax","text":"","code":"if (torch_is_installed()) { m <- nn_softmax(1) input <- torch_randn(2, 3) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax2d module — nn_softmax2d","title":"Softmax2d module — nn_softmax2d","text":"Applies SoftMax features spatial location. given image Channels x Height x Width, apply Softmax location \\((Channels, h_i, w_j)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax2d module — nn_softmax2d","text":"","code":"nn_softmax2d()"},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmax2d module — nn_softmax2d","text":"Tensor dimension shape input values range [0, 1]","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax2d.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softmax2d module — nn_softmax2d","text":"Input: \\((N, C, H, W)\\) Output: \\((N, C, H, W)\\) (shape input)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmax2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmax2d module — nn_softmax2d","text":"","code":"if (torch_is_installed()) { m <- nn_softmax2d() input <- torch_randn(2, 3, 12, 13) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmin — nn_softmin","title":"Softmin — nn_softmin","text":"Applies Softmin function n-dimensional input Tensor rescaling elements n-dimensional output Tensor lie range [0, 1] sum 1. Softmin defined :","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmin — nn_softmin","text":"","code":"nn_softmin(dim)"},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmin — nn_softmin","text":"dim (int): dimension along Softmin computed (every slice along dim sum 1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Softmin — nn_softmin","text":"Tensor dimension shape input, values range [0, 1].","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softmin — nn_softmin","text":"$$   \\mbox{Softmin}(x_{}) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softmin — nn_softmin","text":"Input: \\((*)\\) * means, number additional dimensions Output: \\((*)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softmin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softmin — nn_softmin","text":"","code":"if (torch_is_installed()) { m <- nn_softmin(dim = 1) input <- torch_randn(2, 2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Softplus module — nn_softplus","title":"Softplus module — nn_softplus","text":"Applies element-wise function: $$   \\mbox{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x)) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softplus module — nn_softplus","text":"","code":"nn_softplus(beta = 1, threshold = 20)"},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softplus module — nn_softplus","text":"beta \\(\\beta\\) value Softplus formulation. Default: 1 threshold values revert linear function. Default: 20","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softplus module — nn_softplus","text":"SoftPlus smooth approximation ReLU function can used constrain output machine always positive. numerical stability implementation reverts linear function \\(input \\times \\beta > threshold\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softplus module — nn_softplus","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softplus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softplus module — nn_softplus","text":"","code":"if (torch_is_installed()) { m <- nn_softplus() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Softshrink module — nn_softshrink","title":"Softshrink module — nn_softshrink","text":"Applies soft shrinkage function elementwise:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softshrink module — nn_softshrink","text":"","code":"nn_softshrink(lambd = 0.5)"},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softshrink module — nn_softshrink","text":"lambd \\(\\lambda\\) (must less zero) value Softshrink formulation. Default: 0.5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softshrink module — nn_softshrink","text":"$$   \\mbox{SoftShrinkage}(x) =   \\left\\{ \\begin{array}{ll} x - \\lambda, & \\mbox{ } x > \\lambda \\\\ x + \\lambda, & \\mbox{ } x < -\\lambda \\\\ 0, & \\mbox{ otherwise } \\end{array} \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softshrink module — nn_softshrink","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softshrink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softshrink module — nn_softshrink","text":"","code":"if (torch_is_installed()) { m <- nn_softshrink() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_softsign.html","id":null,"dir":"Reference","previous_headings":"","what":"Softsign module — nn_softsign","title":"Softsign module — nn_softsign","text":"Applies element-wise function: $$   \\mbox{SoftSign}(x) = \\frac{x}{ 1 + |x|} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softsign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softsign module — nn_softsign","text":"","code":"nn_softsign()"},{"path":"https://torch.mlverse.org/docs/reference/nn_softsign.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Softsign module — nn_softsign","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_softsign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Softsign module — nn_softsign","text":"","code":"if (torch_is_installed()) { m <- nn_softsign() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanh module — nn_tanh","title":"Tanh module — nn_tanh","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanh module — nn_tanh","text":"","code":"nn_tanh()"},{"path":"https://torch.mlverse.org/docs/reference/nn_tanh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tanh module — nn_tanh","text":"$$   \\mbox{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanh.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Tanh module — nn_tanh","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tanh module — nn_tanh","text":"","code":"if (torch_is_installed()) { m <- nn_tanh() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_tanhshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanhshrink module — nn_tanhshrink","title":"Tanhshrink module — nn_tanhshrink","text":"Applies element-wise function:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanhshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanhshrink module — nn_tanhshrink","text":"","code":"nn_tanhshrink()"},{"path":"https://torch.mlverse.org/docs/reference/nn_tanhshrink.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tanhshrink module — nn_tanhshrink","text":"$$   \\mbox{Tanhshrink}(x) = x - \\tanh(x) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanhshrink.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Tanhshrink module — nn_tanhshrink","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_tanhshrink.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tanhshrink module — nn_tanhshrink","text":"","code":"if (torch_is_installed()) { m <- nn_tanhshrink() input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Threshold module — nn_threshold","title":"Threshold module — nn_threshold","text":"Thresholds element input Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threshold module — nn_threshold","text":"","code":"nn_threshold(threshold, value, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threshold module — nn_threshold","text":"threshold value threshold value value replace inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Threshold module — nn_threshold","text":"Threshold defined : $$   y =   \\left\\{ \\begin{array}{ll}   x, &\\mbox{ } x > \\mbox{threshold} \\\\   \\mbox{value}, &\\mbox{ otherwise }   \\end{array}   \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Threshold module — nn_threshold","text":"Input: \\((N, *)\\) * means, number additional dimensions Output: \\((N, *)\\), shape input","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Threshold module — nn_threshold","text":"","code":"if (torch_is_installed()) { m <- nn_threshold(0.1, 20) input <- torch_randn(2) output <- m(input) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Triplet margin loss — nn_triplet_margin_loss","title":"Triplet margin loss — nn_triplet_margin_loss","text":"Creates criterion measures triplet loss given input tensors \\(x1\\), \\(x2\\), \\(x3\\) margin value greater \\(0\\). used measuring relative similarity samples. triplet composed , p n (.e., anchor, positive examples negative examples respectively). shapes input tensors \\((N, D)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triplet margin loss — nn_triplet_margin_loss","text":"","code":"nn_triplet_margin_loss(   margin = 1,   p = 2,   eps = 1e-06,   swap = FALSE,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triplet margin loss — nn_triplet_margin_loss","text":"margin (float, optional): Default: \\(1\\). p (int, optional): norm degree pairwise distance. Default: \\(2\\). eps constant avoid NaN's swap (bool, optional): distance swap described detail paper Learning shallow convolutional feature descriptors triplet losses V. Balntas, E. Riba et al. Default: FALSE. reduction (string, optional): Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Triplet margin loss — nn_triplet_margin_loss","text":"distance swap described detail paper Learning shallow convolutional feature descriptors triplet losses V. Balntas, E. Riba et al. loss function sample mini-batch : $$   L(, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\} $$ $$   d(x_i, y_i) = | {\\bf x}_i - {\\bf y}_i |_p $$ See also nn_triplet_margin_with_distance_loss(), computes triplet margin loss input tensors using custom distance function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Triplet margin loss — nn_triplet_margin_loss","text":"Input: \\((N, D)\\) \\(D\\) vector dimension. Output: Tensor shape \\((N)\\) reduction 'none', scalar otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triplet margin loss — nn_triplet_margin_loss","text":"","code":"if (torch_is_installed()) { triplet_loss <- nn_triplet_margin_loss(margin = 1, p = 2) anchor <- torch_randn(100, 128, requires_grad = TRUE) positive <- torch_randn(100, 128, requires_grad = TRUE) negative <- torch_randn(100, 128, requires_grad = TRUE) output <- triplet_loss(anchor, positive, negative) output$backward() }"},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"Creates criterion measures triplet loss given input tensors \\(\\), \\(p\\), \\(n\\) (representing anchor, positive, negative examples, respectively), nonnegative, real-valued function (\"distance function\") used compute relationship anchor positive example (\"positive distance\") anchor negative example (\"negative distance\").","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"","code":"nn_triplet_margin_with_distance_loss(   distance_function = NULL,   margin = 1,   swap = FALSE,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"distance_function (callable, optional): nonnegative, real-valued function quantifies closeness two tensors. specified, nn_pairwise_distance() used.  Default: None margin (float, optional): non-negative margin representing minimum difference positive negative distances required loss 0. Larger margins penalize cases negative examples distant enough anchors, relative positives. Default: \\(1\\). swap (bool, optional): Whether use distance swap described paper Learning shallow convolutional feature descriptors triplet losses V. Balntas, E. Riba et al. TRUE, positive example closer negative example anchor , swaps positive example anchor loss computation. Default: FALSE. reduction (string, optional): Specifies (optional) reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"unreduced loss (.e., reduction set 'none') can described : $$   \\ell(, p, n) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_i = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\} $$ \\(N\\) batch size; \\(d\\) nonnegative, real-valued function quantifying closeness two tensors, referred distance_function; \\(margin\\) non-negative margin representing minimum difference positive negative distances required loss 0.  input tensors \\(N\\) elements can shape distance function can handle. reduction 'none' (default 'mean'), : $$ \\ell(x, y) = \\begin{array}{ll} \\mbox{mean}(L), &  \\mbox{reduction} = \\mbox{`mean';}\\\\             \\mbox{sum}(L),  &  \\mbox{reduction} = \\mbox{`sum'.} \\end{array} $$ See also nn_triplet_margin_loss(), computes triplet loss input tensors using \\(l_p\\) distance distance function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":"shape","dir":"Reference","previous_headings":"","what":"Shape","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"Input: \\((N, *)\\) \\(*\\) represents number additional dimensions supported distance function. Output: Tensor shape \\((N)\\) reduction 'none', scalar otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_triplet_margin_with_distance_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triplet margin with distance loss — nn_triplet_margin_with_distance_loss","text":"","code":"if (torch_is_installed()) { # Initialize embeddings embedding <- nn_embedding(1000, 128) anchor_ids <- torch_randint(1, 1000, 1, dtype = torch_long()) positive_ids <- torch_randint(1, 1000, 1, dtype = torch_long()) negative_ids <- torch_randint(1, 1000, 1, dtype = torch_long()) anchor <- embedding(anchor_ids) positive <- embedding(positive_ids) negative <- embedding(negative_ids)  # Built-in Distance Function triplet_loss <- nn_triplet_margin_with_distance_loss(   distance_function = nn_pairwise_distance() ) output <- triplet_loss(anchor, positive, negative)  # Custom Distance Function l_infinity <- function(x1, x2) {   torch_max(torch_abs(x1 - x2), dim = 1)[[1]] }  triplet_loss <- nn_triplet_margin_with_distance_loss(   distance_function = l_infinity, margin = 1.5 ) output <- triplet_loss(anchor, positive, negative)  # Custom Distance Function (Lambda) triplet_loss <- nn_triplet_margin_with_distance_loss(   distance_function = function(x, y) {     1 - nnf_cosine_similarity(x, y)   } )  output <- triplet_loss(anchor, positive, negative) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_unflatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Unflattens a tensor dim expanding it to a desired shape. For use with [nn_sequential. — nn_unflatten","title":"Unflattens a tensor dim expanding it to a desired shape. For use with [nn_sequential. — nn_unflatten","text":"Unflattens tensor dim expanding desired shape. use [nn_sequential.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_unflatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unflattens a tensor dim expanding it to a desired shape. For use with [nn_sequential. — nn_unflatten","text":"","code":"nn_unflatten(dim, unflattened_size)"},{"path":"https://torch.mlverse.org/docs/reference/nn_unflatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unflattens a tensor dim expanding it to a desired shape. For use with [nn_sequential. — nn_unflatten","text":"dim Dimension unflattened unflattened_size New shape unflattened dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_unflatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unflattens a tensor dim expanding it to a desired shape. For use with [nn_sequential. — nn_unflatten","text":"","code":"if (torch_is_installed()) { input <- torch_randn(2, 50)  m <- nn_sequential(   nn_linear(50, 50),   nn_unflatten(2, c(2, 5, 5)) ) output <- m(input) output$size() } #> [1] 2 2 5 5"},{"path":"https://torch.mlverse.org/docs/reference/nn_upsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Upsample module — nn_upsample","title":"Upsample module — nn_upsample","text":"Upsamples given multi-channel 1D (temporal), 2D (spatial) 3D (volumetric) data. input data assumed form minibatch x channels x optional depth x optional height] x width. Hence, spatial inputs, expect 4D Tensor volumetric inputs, expect 5D Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_upsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upsample module — nn_upsample","text":"","code":"nn_upsample(   size = NULL,   scale_factor = NULL,   mode = \"nearest\",   align_corners = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_upsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upsample module — nn_upsample","text":"size (int Tuple[int] Tuple[int, int] Tuple[int, int, int], optional): output spatial sizes scale_factor (float Tuple[float] Tuple[float, float] Tuple[float, float, float], optional): multiplier spatial size. match input size tuple. mode (str, optional): upsampling algorithm: one 'nearest', 'linear', 'bilinear', 'bicubic' 'trilinear'. Default: 'nearest' align_corners (bool, optional): TRUE, corner pixels input output tensors aligned, thus preserving values pixels. effect mode 'linear', 'bilinear', 'trilinear'. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_upsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Upsample module — nn_upsample","text":"algorithms available upsampling nearest neighbor linear, bilinear, bicubic trilinear 3D, 4D 5D input Tensor, respectively. One can either give scale_factor target output size calculate output size. (give , ambiguous)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_upsample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upsample module — nn_upsample","text":"","code":"if (torch_is_installed()) { input <- torch_arange(start = 1, end = 4, dtype = torch_float())$view(c(1, 1, 2, 2)) nn_upsample(scale_factor = c(2), mode = \"nearest\")(input) nn_upsample(scale_factor = c(2, 2), mode = \"nearest\")(input) } #> torch_tensor #> (1,1,.,.) =  #>   1  1  2  2 #>   1  1  2  2 #>   3  3  4  4 #>   3  3  4  4 #> [ CPUFloatType{1,1,4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_norm_.html","id":null,"dir":"Reference","previous_headings":"","what":"Clips gradient norm of an iterable of parameters. — nn_utils_clip_grad_norm_","title":"Clips gradient norm of an iterable of parameters. — nn_utils_clip_grad_norm_","text":"norm computed gradients together, concatenated single vector. Gradients modified -place.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_norm_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clips gradient norm of an iterable of parameters. — nn_utils_clip_grad_norm_","text":"","code":"nn_utils_clip_grad_norm_(parameters, max_norm, norm_type = 2)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_norm_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clips gradient norm of an iterable of parameters. — nn_utils_clip_grad_norm_","text":"parameters (IterableTensor Tensor): iterable Tensors single Tensor gradients normalized max_norm (float int): max norm gradients norm_type (float int): type used p-norm. Can Inf infinity norm.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_norm_.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clips gradient norm of an iterable of parameters. — nn_utils_clip_grad_norm_","text":"Total norm parameters (viewed single vector).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_value_.html","id":null,"dir":"Reference","previous_headings":"","what":"Clips gradient of an iterable of parameters at specified value. — nn_utils_clip_grad_value_","title":"Clips gradient of an iterable of parameters at specified value. — nn_utils_clip_grad_value_","text":"Gradients modified -place.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_value_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clips gradient of an iterable of parameters at specified value. — nn_utils_clip_grad_value_","text":"","code":"nn_utils_clip_grad_value_(parameters, clip_value)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_value_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clips gradient of an iterable of parameters at specified value. — nn_utils_clip_grad_value_","text":"parameters (Iterable(Tensor) Tensor): iterable Tensors single Tensor gradients normalized clip_value (float int): maximum allowed value gradients.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_clip_grad_value_.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Clips gradient of an iterable of parameters at specified value. — nn_utils_clip_grad_value_","text":"gradients clipped range \\(\\left[\\mbox{-clip\\_value}, \\mbox{clip\\_value}\\right]\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"input can size T x B x * T length longest sequence (equal lengths[1]), B batch size, * number dimensions (including 0). batch_first TRUE, B x T x * input expected.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"","code":"nn_utils_rnn_pack_padded_sequence(   input,   lengths,   batch_first = FALSE,   enforce_sorted = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"input (Tensor): padded batch variable length sequences. lengths (Tensor): list sequences lengths batch element. batch_first (bool, optional): TRUE, input expected B x T x * format. enforce_sorted (bool, optional): TRUE, input expected contain sequences sorted length decreasing order. FALSE, input get sorted unconditionally. Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"PackedSequence object","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"unsorted sequences, use enforce_sorted = FALSE. enforce_sorted TRUE, sequences sorted length decreasing order, .e. input[,1] longest sequence, input[,B] shortest one. enforce_sorted = TRUE necessary ONNX export.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_padded_sequence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Packs a Tensor containing padded sequences of variable length. — nn_utils_rnn_pack_padded_sequence","text":"function accepts input least two dimensions. can apply pack labels, use output RNN compute loss directly. Tensor can retrieved PackedSequence object accessing .data attribute.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"sequences list Tensors size L x *, L length sequence * number trailing dimensions, including zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"","code":"nn_utils_rnn_pack_sequence(sequences, enforce_sorted = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"sequences (list[Tensor]): list sequences decreasing length. enforce_sorted (bool, optional): TRUE, checks input contains sequences sorted length decreasing order. FALSE, condition checked. Default: TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"PackedSequence object","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"unsorted sequences, use enforce_sorted = FALSE. enforce_sorted TRUE, sequences sorted order decreasing length. enforce_sorted = TRUE necessary ONNX export.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pack_sequence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Packs a list of variable length Tensors — nn_utils_rnn_pack_sequence","text":"","code":"if (torch_is_installed()) { x <- torch_tensor(c(1, 2, 3), dtype = torch_long()) y <- torch_tensor(c(4, 5), dtype = torch_long()) z <- torch_tensor(c(6), dtype = torch_long())  p <- nn_utils_rnn_pack_sequence(list(x, y, z)) }"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"inverse operation nn_utils_rnn_pack_padded_sequence().","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"","code":"nn_utils_rnn_pad_packed_sequence(   sequence,   batch_first = FALSE,   padding_value = 0,   total_length = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"sequence (PackedSequence): batch pad batch_first (bool, optional): True, output ``B x T x *` format. padding_value (float, optional): values padded elements. total_length (int, optional): NULL, output padded length total_length. method throw ValueError total_length less max sequence length sequence.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"Tuple Tensor containing padded sequence, Tensor containing list lengths sequence batch. Batch elements re-ordered ordered originally batch passed nn_utils_rnn_pack_padded_sequence() nn_utils_rnn_pack_sequence().","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"returned Tensor's data size T x B x *, T length longest sequence B batch size. batch_first TRUE, data transposed B x T x * format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"total_length useful implement pack sequence -> recurrent network -> unpack sequence pattern nn_module wrapped ~torch.nn.DataParallel.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_packed_sequence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pads a packed batch of variable length sequences. — nn_utils_rnn_pad_packed_sequence","text":"","code":"if (torch_is_installed()) { seq <- torch_tensor(rbind(c(1, 2, 0), c(3, 0, 0), c(4, 5, 6))) lens <- c(2, 1, 3) packed <- nn_utils_rnn_pack_padded_sequence(seq, lens,   batch_first = TRUE,   enforce_sorted = FALSE ) packed nn_utils_rnn_pad_packed_sequence(packed, batch_first = TRUE) } #> [[1]] #> torch_tensor #>  1  2  0 #>  3  0  0 #>  4  5  6 #> [ CPUFloatType{3,3} ] #>  #> [[2]] #> torch_tensor #>  2 #>  1 #>  3 #> [ CPULongType{3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"pad_sequence stacks list Tensors along new dimension, pads equal length. example, input list sequences size L x * batch_first False, T x B x * otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"","code":"nn_utils_rnn_pad_sequence(sequences, batch_first = FALSE, padding_value = 0)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"sequences (list[Tensor]): list variable length sequences. batch_first (bool, optional): output B x T x * TRUE, T x B x * otherwise padding_value (float, optional): value padded elements. Default: 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"Tensor size T x B x * batch_first FALSE. Tensor size B x T x * otherwise","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"B batch size. equal number elements sequences. T length longest sequence. L length sequence. * number trailing dimensions, including none.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"function returns Tensor size T x B x * B x T x * T length longest sequence. function assumes trailing dimensions type Tensors sequences .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_rnn_pad_sequence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pad a list of variable length Tensors with padding_value — nn_utils_rnn_pad_sequence","text":"","code":"if (torch_is_installed()) { a <- torch_ones(25, 300) b <- torch_ones(22, 300) c <- torch_ones(15, 300) nn_utils_rnn_pad_sequence(list(a, b, c))$size() } #> [1]  25   3 300"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"nn_utils_weight_norm — nn_utils_weight_norm","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"Applies weight normalization parameter given module.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"original module weight_v weight_g paramters.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"Weight normalization reparameterization decouples magnitude weight tensor direction. replaces parameter specified name  (e.g. 'weight') two parameters: one specifying magnitude (e.g. 'weight_g') one specifying direction (e.g. 'weight_v').","code":"\\eqn{\\mathbf{w} = g \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}}"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"pytorch Weight normalization implemented via hook recomputes weight tensor magnitude direction every forward() call. Since torch R still support hooks, weight recomputation need done explicitly inside forward() definition trough call recompute() method. See examples. default, dim = 0, norm computed independently per output channel/plane. compute norm entire weight tensor, use dim = NULL. @references https://arxiv.org/abs/1602.07868","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"nn_utils_weight_norm$new() nn_utils_weight_norm$compute_weight() nn_utils_weight_norm$apply() nn_utils_weight_norm$call() nn_utils_weight_norm$recompute() nn_utils_weight_norm$remove() nn_utils_weight_norm$clone()","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$new(name, dim)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"name (str, optional): name weight parameter dim (int, optional): dimension compute norm","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$compute_weight(module, name = NULL, dim = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"module (Module): containing module name (str, optional): name weight parameter dim (int, optional): dimension compute norm","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$apply(module, name = NULL, dim = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"module (Module): containing module name (str, optional): name weight parameter dim (int, optional): dimension compute norm","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$call(module)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"module (Module): containing module","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$recompute(module)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"module (Module): containing module","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$remove(module, name = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"module (Module): containing module name (str, optional): name weight parameter","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"objects class cloneable method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"nn_utils_weight_norm$clone(deep = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"deep Whether make deep clone.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nn_utils_weight_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nn_utils_weight_norm — nn_utils_weight_norm","text":"","code":"if (torch_is_installed()) { x = nn_linear(in_features = 20, out_features = 40) weight_norm = nn_utils_weight_norm$new(name = 'weight', dim = 2) weight_norm$apply(x) x$weight_g$size() x$weight_v$size() x$weight  # the recompute() method recomputes the weight using g and v. It must be called # explicitly inside `forward()`. weight_norm$recompute(x)  }"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_avg_pool1d — nnf_adaptive_avg_pool1d","title":"Adaptive_avg_pool1d — nnf_adaptive_avg_pool1d","text":"Applies 1D adaptive average pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_avg_pool1d — nnf_adaptive_avg_pool1d","text":"","code":"nnf_adaptive_avg_pool1d(input, output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_avg_pool1d — nnf_adaptive_avg_pool1d","text":"input input tensor shape (minibatch , in_channels , iW) output_size target output size (single integer)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_avg_pool2d — nnf_adaptive_avg_pool2d","title":"Adaptive_avg_pool2d — nnf_adaptive_avg_pool2d","text":"Applies 2D adaptive average pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_avg_pool2d — nnf_adaptive_avg_pool2d","text":"","code":"nnf_adaptive_avg_pool2d(input, output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_avg_pool2d — nnf_adaptive_avg_pool2d","text":"input input tensor (minibatch, in_channels , iH , iW) output_size target output size (single integer double-integer tuple)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_avg_pool3d — nnf_adaptive_avg_pool3d","title":"Adaptive_avg_pool3d — nnf_adaptive_avg_pool3d","text":"Applies 3D adaptive average pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_avg_pool3d — nnf_adaptive_avg_pool3d","text":"","code":"nnf_adaptive_avg_pool3d(input, output_size)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_avg_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_avg_pool3d — nnf_adaptive_avg_pool3d","text":"input input tensor (minibatch, in_channels , * iH , iW) output_size target output size (single integer triple-integer tuple)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_max_pool1d — nnf_adaptive_max_pool1d","title":"Adaptive_max_pool1d — nnf_adaptive_max_pool1d","text":"Applies 1D adaptive max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_max_pool1d — nnf_adaptive_max_pool1d","text":"","code":"nnf_adaptive_max_pool1d(input, output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_max_pool1d — nnf_adaptive_max_pool1d","text":"input input tensor shape (minibatch , in_channels , iW) output_size target output size (single integer) return_indices whether return pooling indices. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_max_pool2d — nnf_adaptive_max_pool2d","title":"Adaptive_max_pool2d — nnf_adaptive_max_pool2d","text":"Applies 2D adaptive max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_max_pool2d — nnf_adaptive_max_pool2d","text":"","code":"nnf_adaptive_max_pool2d(input, output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_max_pool2d — nnf_adaptive_max_pool2d","text":"input input tensor (minibatch, in_channels , iH , iW) output_size target output size (single integer double-integer tuple) return_indices whether return pooling indices. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_max_pool3d — nnf_adaptive_max_pool3d","title":"Adaptive_max_pool3d — nnf_adaptive_max_pool3d","text":"Applies 3D adaptive max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_max_pool3d — nnf_adaptive_max_pool3d","text":"","code":"nnf_adaptive_max_pool3d(input, output_size, return_indices = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_adaptive_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_max_pool3d — nnf_adaptive_max_pool3d","text":"input input tensor (minibatch, in_channels , * iH , iW) output_size target output size (single integer triple-integer tuple) return_indices whether return pooling indices. Default:FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_affine_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Affine_grid — nnf_affine_grid","title":"Affine_grid — nnf_affine_grid","text":"Generates 2D 3D flow field (sampling grid), given batch affine matrices theta.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_affine_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Affine_grid — nnf_affine_grid","text":"","code":"nnf_affine_grid(theta, size, align_corners = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_affine_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Affine_grid — nnf_affine_grid","text":"theta (Tensor) input batch affine matrices shape (\\(N \\times 2 \\times 3\\)) 2D  (\\(N \\times 3 \\times 4\\)) 3D size (torch.Size) target output image size. (\\(N \\times C \\times H \\times W\\) 2D \\(N \\times C \\times D \\times H \\times W\\) 3D) Example: torch.Size((32, 3, 24, 24)) align_corners (bool, optional) True, consider -1 1 refer centers corner pixels rather image corners. Refer nnf_grid_sample() complete description. grid generated nnf_affine_grid() passed nnf_grid_sample()  setting option. Default: False","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_affine_grid.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Affine_grid — nnf_affine_grid","text":"function often used conjunction nnf_grid_sample() build Spatial Transformer Networks_ .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_alpha_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Alpha_dropout — nnf_alpha_dropout","title":"Alpha_dropout — nnf_alpha_dropout","text":"Applies alpha dropout input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_alpha_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alpha_dropout — nnf_alpha_dropout","text":"","code":"nnf_alpha_dropout(input, p = 0.5, training = FALSE, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_alpha_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Alpha_dropout — nnf_alpha_dropout","text":"input input tensor p probability element zeroed. Default: 0.5 training apply dropout TRUE. Default: TRUE inplace set TRUE, operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Avg_pool1d — nnf_avg_pool1d","title":"Avg_pool1d — nnf_avg_pool1d","text":"Applies 1D average pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Avg_pool1d — nnf_avg_pool1d","text":"","code":"nnf_avg_pool1d(   input,   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Avg_pool1d — nnf_avg_pool1d","text":"input input tensor shape (minibatch , in_channels , iW) kernel_size size window. Can single number tuple (kW,). stride stride window. Can single number tuple (sW,). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padW,). Default: 0 ceil_mode True, use ceil instead floor compute output shape. Default: FALSE count_include_pad True, include zero-padding averaging calculation. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Avg_pool2d — nnf_avg_pool2d","title":"Avg_pool2d — nnf_avg_pool2d","text":"Applies 2D average-pooling operation \\(kH * kW\\) regions step size \\(sH * sW\\) steps. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Avg_pool2d — nnf_avg_pool2d","text":"","code":"nnf_avg_pool2d(   input,   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE,   divisor_override = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Avg_pool2d — nnf_avg_pool2d","text":"input input tensor (minibatch, in_channels , iH , iW) kernel_size size pooling region. Can single number tuple (kH, kW) stride stride pooling operation. Can single number tuple (sH, sW). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padH, padW). Default: 0 ceil_mode True, use ceil instead floor formula compute output shape. Default: FALSE count_include_pad True, include zero-padding averaging calculation. Default: TRUE divisor_override specified, used divisor, otherwise size pooling region used. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Avg_pool3d — nnf_avg_pool3d","title":"Avg_pool3d — nnf_avg_pool3d","text":"Applies 3D average-pooling operation \\(kT * kH * kW\\) regions step size \\(sT * sH * sW\\) steps. number output features equal \\(\\lfloor \\frac{ \\mbox{input planes} }{sT} \\rfloor\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Avg_pool3d — nnf_avg_pool3d","text":"","code":"nnf_avg_pool3d(   input,   kernel_size,   stride = NULL,   padding = 0,   ceil_mode = FALSE,   count_include_pad = TRUE,   divisor_override = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_avg_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Avg_pool3d — nnf_avg_pool3d","text":"input input tensor (minibatch, in_channels , * iH , iW) kernel_size size pooling region. Can single number tuple (kT, kH, kW) stride stride pooling operation. Can single number tuple (sT, sH, sW). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padT, padH, padW), Default: 0 ceil_mode True, use ceil instead floor formula compute output shape count_include_pad True, include zero-padding averaging calculation divisor_override NA specified, used divisor, otherwise size pooling region used. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_batch_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch_norm — nnf_batch_norm","title":"Batch_norm — nnf_batch_norm","text":"Applies Batch Normalization channel across batch data.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_batch_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch_norm — nnf_batch_norm","text":"","code":"nnf_batch_norm(   input,   running_mean,   running_var,   weight = NULL,   bias = NULL,   training = FALSE,   momentum = 0.1,   eps = 1e-05 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_batch_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch_norm — nnf_batch_norm","text":"input input tensor running_mean running_mean tensor running_var running_var tensor weight weight tensor bias bias tensor training bool wether training. Default: FALSE momentum value used running_mean running_var computation. Can set None cumulative moving average (.e. simple average). Default: 0.1 eps value added denominator numerical stability. Default: 1e-5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_bilinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Bilinear — nnf_bilinear","title":"Bilinear — nnf_bilinear","text":"Applies bilinear transformation incoming data: \\(y = x_1 x_2 + b\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_bilinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bilinear — nnf_bilinear","text":"","code":"nnf_bilinear(input1, input2, weight, bias = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_bilinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bilinear — nnf_bilinear","text":"input1 \\((N, *, H_{in1})\\) \\(H_{in1}=\\mbox{in1\\_features}\\) \\(*\\) means number additional dimensions. last dimension inputs . input2 \\((N, *, H_{in2})\\) \\(H_{in2}=\\mbox{in2\\_features}\\) weight \\((\\mbox{\\_features}, \\mbox{in1\\_features}, \\mbox{in2\\_features})\\) bias \\((\\mbox{\\_features})\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_bilinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bilinear — nnf_bilinear","text":"output \\((N, *, H_{})\\) \\(H_{}=\\mbox{\\_features}\\) last dimension shape input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary_cross_entropy — nnf_binary_cross_entropy","title":"Binary_cross_entropy — nnf_binary_cross_entropy","text":"Function measures Binary Cross Entropy target output.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary_cross_entropy — nnf_binary_cross_entropy","text":"","code":"nnf_binary_cross_entropy(   input,   target,   weight = NULL,   reduction = c(\"mean\", \"sum\", \"none\") )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary_cross_entropy — nnf_binary_cross_entropy","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input weight (tensor) weight value. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy_with_logits.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary_cross_entropy_with_logits — nnf_binary_cross_entropy_with_logits","title":"Binary_cross_entropy_with_logits — nnf_binary_cross_entropy_with_logits","text":"Function measures Binary Cross Entropy target output logits.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy_with_logits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary_cross_entropy_with_logits — nnf_binary_cross_entropy_with_logits","text":"","code":"nnf_binary_cross_entropy_with_logits(   input,   target,   weight = NULL,   reduction = c(\"mean\", \"sum\", \"none\"),   pos_weight = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_binary_cross_entropy_with_logits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binary_cross_entropy_with_logits — nnf_binary_cross_entropy_with_logits","text":"input Tensor arbitrary shape target Tensor shape input weight (Tensor, optional) manual rescaling weight provided repeated match input tensor shape. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean' pos_weight (Tensor, optional) weight positive examples. Must vector length equal number classes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_celu.html","id":null,"dir":"Reference","previous_headings":"","what":"Celu — nnf_celu","title":"Celu — nnf_celu","text":"Applies element-wise, \\(CELU(x) = max(0,x) + min(0, \\alpha * (exp(x \\alpha) - 1))\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_celu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Celu — nnf_celu","text":"","code":"nnf_celu(input, alpha = 1, inplace = FALSE)  nnf_celu_(input, alpha = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_celu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Celu — nnf_celu","text":"input (N,*) tensor, * means, number additional dimensions alpha alpha value CELU formulation. Default: 1.0 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_contrib_sparsemax.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparsemax — nnf_contrib_sparsemax","title":"Sparsemax — nnf_contrib_sparsemax","text":"Applies SparseMax activation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_contrib_sparsemax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparsemax — nnf_contrib_sparsemax","text":"","code":"nnf_contrib_sparsemax(input, dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_contrib_sparsemax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparsemax — nnf_contrib_sparsemax","text":"input input tensor dim dimension apply sparsemax function. (-1)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_contrib_sparsemax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sparsemax — nnf_contrib_sparsemax","text":"SparseMax activation described 'Softmax Sparsemax: Sparse Model Attention Multi-Label Classification' implementation based aced125/sparsemax","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv1d — nnf_conv1d","title":"Conv1d — nnf_conv1d","text":"Applies 1D convolution input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv1d — nnf_conv1d","text":"","code":"nnf_conv1d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   dilation = 1,   groups = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv1d — nnf_conv1d","text":"input input tensor shape (minibatch, in_channels , iW) weight filters shape (out_channels, in_channels/groups , kW) bias optional bias shape (out_channels). Default: NULL stride stride convolving kernel. Can single number one-element tuple (sW,). Default: 1 padding implicit paddings sides input. Can single number one-element tuple (padW,). Default: 0 dilation spacing kernel elements. Can single number one-element tuple (dW,). Default: 1 groups split input groups, in_channels divisible number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv2d — nnf_conv2d","title":"Conv2d — nnf_conv2d","text":"Applies 2D convolution input image composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv2d — nnf_conv2d","text":"","code":"nnf_conv2d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   dilation = 1,   groups = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv2d — nnf_conv2d","text":"input input tensor shape (minibatch, in_channels, iH , iW) weight filters shape (out_channels , in_channels/groups, kH , kW) bias optional bias tensor shape (out_channels). Default: NULL stride stride convolving kernel. Can single number tuple (sH, sW). Default: 1 padding implicit paddings sides input. Can single number tuple (padH, padW). Default: 0 dilation spacing kernel elements. Can single number tuple (dH, dW). Default: 1 groups split input groups, in_channels divisible number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv3d — nnf_conv3d","title":"Conv3d — nnf_conv3d","text":"Applies 3D convolution input image composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv3d — nnf_conv3d","text":"","code":"nnf_conv3d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   dilation = 1,   groups = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv3d — nnf_conv3d","text":"input input tensor shape (minibatch, in_channels , , iH , iW) weight filters shape (out_channels , in_channels/groups, kT , kH , kW) bias optional bias tensor shape (out_channels). Default: NULL stride stride convolving kernel. Can single number tuple (sT, sH, sW). Default: 1 padding implicit paddings sides input. Can single number tuple (padT, padH, padW). Default: 0 dilation spacing kernel elements. Can single number tuple (dT, dH, dW). Default: 1 groups split input groups, in_channels divisible number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_tbc.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_tbc — nnf_conv_tbc","title":"Conv_tbc — nnf_conv_tbc","text":"Applies 1-dimensional sequence convolution input sequence. Input output dimensions (Time, Batch, Channels) - hence TBC.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_tbc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_tbc — nnf_conv_tbc","text":"","code":"nnf_conv_tbc(input, weight, bias, pad = 0)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_tbc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_tbc — nnf_conv_tbc","text":"input input tensor shape \\((\\mbox{sequence length} \\times batch \\times \\mbox{\\_channels})\\) weight filter shape (\\(\\mbox{kernel width} \\times \\mbox{\\_channels} \\times \\mbox{\\_channels}\\)) bias bias shape (\\(\\mbox{\\_channels}\\)) pad number timesteps pad. Default: 0","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose1d — nnf_conv_transpose1d","title":"Conv_transpose1d — nnf_conv_transpose1d","text":"Applies 1D transposed convolution operator input signal composed several input planes, sometimes also called \"deconvolution\".","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose1d — nnf_conv_transpose1d","text":"","code":"nnf_conv_transpose1d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   dilation = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose1d — nnf_conv_transpose1d","text":"input input tensor shape (minibatch, in_channels , iW) weight filters shape (out_channels, in_channels/groups , kW) bias optional bias shape (out_channels). Default: NULL stride stride convolving kernel. Can single number one-element tuple (sW,). Default: 1 padding implicit paddings sides input. Can single number one-element tuple (padW,). Default: 0 output_padding padding applied output groups split input groups, in_channels divisible number groups. Default: 1 dilation spacing kernel elements. Can single number one-element tuple (dW,). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose2d — nnf_conv_transpose2d","title":"Conv_transpose2d — nnf_conv_transpose2d","text":"Applies 2D transposed convolution operator input image composed several input planes, sometimes also called \"deconvolution\".","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose2d — nnf_conv_transpose2d","text":"","code":"nnf_conv_transpose2d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   dilation = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose2d — nnf_conv_transpose2d","text":"input input tensor shape (minibatch, in_channels, iH , iW) weight filters shape (out_channels , in_channels/groups, kH , kW) bias optional bias tensor shape (out_channels). Default: NULL stride stride convolving kernel. Can single number tuple (sH, sW). Default: 1 padding implicit paddings sides input. Can single number tuple (padH, padW). Default: 0 output_padding padding applied output groups split input groups, in_channels divisible number groups. Default: 1 dilation spacing kernel elements. Can single number tuple (dH, dW). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose3d — nnf_conv_transpose3d","title":"Conv_transpose3d — nnf_conv_transpose3d","text":"Applies 3D transposed convolution operator input image composed several input planes, sometimes also called \"deconvolution\"","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose3d — nnf_conv_transpose3d","text":"","code":"nnf_conv_transpose3d(   input,   weight,   bias = NULL,   stride = 1,   padding = 0,   output_padding = 0,   groups = 1,   dilation = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_conv_transpose3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose3d — nnf_conv_transpose3d","text":"input input tensor shape (minibatch, in_channels , , iH , iW) weight filters shape (out_channels , in_channels/groups, kT , kH , kW) bias optional bias tensor shape (out_channels). Default: NULL stride stride convolving kernel. Can single number tuple (sT, sH, sW). Default: 1 padding implicit paddings sides input. Can single number tuple (padT, padH, padW). Default: 0 output_padding padding applied output groups split input groups, in_channels divisible number groups. Default: 1 dilation spacing kernel elements. Can single number tuple (dT, dH, dW). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_embedding_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine_embedding_loss — nnf_cosine_embedding_loss","title":"Cosine_embedding_loss — nnf_cosine_embedding_loss","text":"Creates criterion measures loss given input tensors x_1, x_2 Tensor label y values 1 -1. used measuring whether two inputs similar dissimilar, using cosine distance, typically used learning nonlinear embeddings semi-supervised learning.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_embedding_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine_embedding_loss — nnf_cosine_embedding_loss","text":"","code":"nnf_cosine_embedding_loss(   input1,   input2,   target,   margin = 0,   reduction = c(\"mean\", \"sum\", \"none\") )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_embedding_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine_embedding_loss — nnf_cosine_embedding_loss","text":"input1 input x_1 tensor input2 input x_2 tensor target target tensor margin number -1 1 , 0 0.5 suggested. margin missing, default value 0. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine_similarity — nnf_cosine_similarity","title":"Cosine_similarity — nnf_cosine_similarity","text":"Returns cosine similarity x1 x2, computed along dim.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine_similarity — nnf_cosine_similarity","text":"","code":"nnf_cosine_similarity(x1, x2, dim = 2, eps = 1e-08)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine_similarity — nnf_cosine_similarity","text":"x1 (Tensor) First input. x2 (Tensor) Second input (size matching x1). dim (int, optional) Dimension vectors. Default: 2 eps (float, optional) Small value avoid division zero. Default: 1e-8","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cosine_similarity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cosine_similarity — nnf_cosine_similarity","text":"$$     \\mbox{similarity} = \\frac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cross_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross_entropy — nnf_cross_entropy","title":"Cross_entropy — nnf_cross_entropy","text":"criterion combines log_softmax nll_loss single function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_cross_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross_entropy — nnf_cross_entropy","text":"","code":"nnf_cross_entropy(   input,   target,   weight = NULL,   ignore_index = -100,   reduction = c(\"mean\", \"sum\", \"none\") )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_cross_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross_entropy — nnf_cross_entropy","text":"input (Tensor) \\((N, C)\\) C = number classes \\((N, C, H, W)\\) case 2D Loss, \\((N, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. target (Tensor) \\((N)\\) value \\(0 \\leq \\mbox{targets}[] \\leq C-1\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) K-dimensional loss. weight (Tensor, optional) manual rescaling weight given class. given, Tensor size C ignore_index (int, optional) Specifies target value ignored contribute input gradient. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_ctc_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Ctc_loss — nnf_ctc_loss","title":"Ctc_loss — nnf_ctc_loss","text":"Connectionist Temporal Classification loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_ctc_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ctc_loss — nnf_ctc_loss","text":"","code":"nnf_ctc_loss(   log_probs,   targets,   input_lengths,   target_lengths,   blank = 0,   reduction = c(\"mean\", \"sum\", \"none\"),   zero_infinity = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_ctc_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ctc_loss — nnf_ctc_loss","text":"log_probs \\((T, N, C)\\) C = number characters alphabet including blank, T = input length, N = batch size. logarithmized probabilities outputs (e.g. obtained nnf_log_softmax). targets \\((N, S)\\) (sum(target_lengths)). Targets blank. second form, targets assumed concatenated. input_lengths \\((N)\\). Lengths inputs (must \\(\\leq T\\)) target_lengths \\((N)\\). Lengths targets blank (int, optional) Blank label. Default \\(0\\). reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean' zero_infinity (bool, optional) Whether zero infinite losses associated gradients. Default: FALSE Infinite losses mainly occur inputs short aligned targets.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout — nnf_dropout","title":"Dropout — nnf_dropout","text":"training, randomly zeroes elements input tensor probability p using samples Bernoulli distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout — nnf_dropout","text":"","code":"nnf_dropout(input, p = 0.5, training = TRUE, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout — nnf_dropout","text":"input input tensor p probability element zeroed. Default: 0.5 training apply dropout TRUE. Default: TRUE inplace set TRUE, operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout2d — nnf_dropout2d","title":"Dropout2d — nnf_dropout2d","text":"Randomly zero entire channels (channel 2D feature map, e.g., \\(j\\)-th channel \\(\\)-th sample batched input 2D tensor \\(input[, j]\\)) input tensor). channel zeroed independently every forward call probability p using samples Bernoulli distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout2d — nnf_dropout2d","text":"","code":"nnf_dropout2d(input, p = 0.5, training = TRUE, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout2d — nnf_dropout2d","text":"input input tensor p probability channel zeroed. Default: 0.5 training apply dropout TRUE. Default: TRUE. inplace set TRUE, operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Dropout3d — nnf_dropout3d","title":"Dropout3d — nnf_dropout3d","text":"Randomly zero entire channels (channel 3D feature map, e.g., \\(j\\)-th channel \\(\\)-th sample batched input 3D tensor \\(input[, j]\\)) input tensor). channel zeroed independently every forward call probability p using samples Bernoulli distribution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dropout3d — nnf_dropout3d","text":"","code":"nnf_dropout3d(input, p = 0.5, training = TRUE, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_dropout3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dropout3d — nnf_dropout3d","text":"input input tensor p probability channel zeroed. Default: 0.5 training apply dropout TRUE. Default: TRUE. inplace set TRUE, operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_elu.html","id":null,"dir":"Reference","previous_headings":"","what":"Elu — nnf_elu","title":"Elu — nnf_elu","text":"Applies element-wise, $$ELU(x) = max(0,x) + min(0, \\alpha * (exp(x) - 1))$$.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_elu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elu — nnf_elu","text":"","code":"nnf_elu(input, alpha = 1, inplace = FALSE)  nnf_elu_(input, alpha = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_elu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elu — nnf_elu","text":"input (N,*) tensor, * means, number additional dimensions alpha alpha value ELU formulation. Default: 1.0 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_elu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elu — nnf_elu","text":"","code":"if (torch_is_installed()) { x <- torch_randn(2, 2) y <- nnf_elu(x, alpha = 1) nnf_elu_(x, alpha = 1) torch_equal(x, y) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding — nnf_embedding","title":"Embedding — nnf_embedding","text":"simple lookup table looks embeddings fixed dictionary size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding — nnf_embedding","text":"","code":"nnf_embedding(   input,   weight,   padding_idx = NULL,   max_norm = NULL,   norm_type = 2,   scale_grad_by_freq = FALSE,   sparse = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding — nnf_embedding","text":"input (LongTensor) Tensor containing indices embedding matrix weight (Tensor) embedding matrix number rows equal maximum possible index + 1, number columns equal embedding size padding_idx (int, optional) given, pads output embedding vector padding_idx (initialized zeros) whenever encounters index. max_norm (float, optional) given, embedding vector norm larger max_norm renormalized norm max_norm. Note: modify weight -place. norm_type (float, optional) p p-norm compute max_norm option. Default 2. scale_grad_by_freq (boolean, optional) given, scale gradients inverse frequency words mini-batch. Default FALSE. sparse (bool, optional) TRUE, gradient w.r.t. weight sparse tensor. See Notes nn_embedding details regarding sparse gradients.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Embedding — nnf_embedding","text":"module often used retrieve word embeddings using indices. input module list indices, embedding matrix, output corresponding word embeddings.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding_bag.html","id":null,"dir":"Reference","previous_headings":"","what":"Embedding_bag — nnf_embedding_bag","title":"Embedding_bag — nnf_embedding_bag","text":"Computes sums, means maxes bags embeddings, without instantiating intermediate embeddings.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding_bag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Embedding_bag — nnf_embedding_bag","text":"","code":"nnf_embedding_bag(   input,   weight,   offsets = NULL,   max_norm = NULL,   norm_type = 2,   scale_grad_by_freq = FALSE,   mode = \"mean\",   sparse = FALSE,   per_sample_weights = NULL,   include_last_offset = FALSE,   padding_idx = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_embedding_bag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Embedding_bag — nnf_embedding_bag","text":"input (LongTensor) Tensor containing bags indices embedding matrix weight (Tensor) embedding matrix number rows equal maximum possible index + 1, number columns equal embedding size offsets (LongTensor, optional) used input 1D. offsets determines starting index position bag (sequence) input. max_norm (float, optional) given, embedding vector norm larger max_norm renormalized norm max_norm. Note: modify weight -place. norm_type (float, optional) p p-norm compute max_norm option. Default 2. scale_grad_by_freq (boolean, optional) given, scale gradients inverse frequency words mini-batch. Default FALSE.                                            Note: option supported mode=\"max\". mode (string, optional) \"sum\", \"mean\" \"max\". Specifies way reduce bag. Default: 'mean' sparse (bool, optional) TRUE, gradient w.r.t. weight sparse tensor. See Notes nn_embedding details regarding sparse gradients. Note: option supported mode=\"max\". per_sample_weights (Tensor, optional) tensor float / double weights, NULL indicate weights taken 1. specified, per_sample_weights must exactly shape input treated offsets, NULL. include_last_offset (bool, optional) TRUE, size offsets equal number bags + 1. padding_idx (int, optional) given, pads output embedding vector padding_idx (initialized zeros) whenever encounters index.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fold.html","id":null,"dir":"Reference","previous_headings":"","what":"Fold — nnf_fold","title":"Fold — nnf_fold","text":"Combines array sliding local blocks large containing tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fold — nnf_fold","text":"","code":"nnf_fold(   input,   output_size,   kernel_size,   dilation = 1,   padding = 0,   stride = 1 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_fold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fold — nnf_fold","text":"input input tensor output_size shape spatial dimensions output (.e., output$sizes()[-c(1,2)]) kernel_size size sliding blocks dilation parameter controls stride elements within neighborhood. Default: 1 padding implicit zero padding added sides input. Default: 0 stride stride sliding blocks input spatial dimensions. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fold.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Fold — nnf_fold","text":"Currently, 4-D output tensors (batched image-like tensors) supported.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Fractional_max_pool2d — nnf_fractional_max_pool2d","title":"Fractional_max_pool2d — nnf_fractional_max_pool2d","text":"Applies 2D fractional max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fractional_max_pool2d — nnf_fractional_max_pool2d","text":"","code":"nnf_fractional_max_pool2d(   input,   kernel_size,   output_size = NULL,   output_ratio = NULL,   return_indices = FALSE,   random_samples = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fractional_max_pool2d — nnf_fractional_max_pool2d","text":"input input tensor kernel_size size window take max . Can single number \\(k\\) (square kernel \\(k * k\\)) tuple (kH, kW) output_size target output size image form \\(oH * oW\\). Can tuple (oH, oW) single number \\(oH\\) square image \\(oH * oH\\) output_ratio one wants output size ratio input size, option can given. number tuple range (0, 1) return_indices True, return indices along outputs. random_samples optional random samples.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fractional_max_pool2d — nnf_fractional_max_pool2d","text":"Fractional MaxPooling described detail paper Fractional MaxPooling_ Ben Graham max-pooling operation applied \\(kH * kW\\) regions stochastic step size determined target output size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Fractional_max_pool3d — nnf_fractional_max_pool3d","title":"Fractional_max_pool3d — nnf_fractional_max_pool3d","text":"Applies 3D fractional max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fractional_max_pool3d — nnf_fractional_max_pool3d","text":"","code":"nnf_fractional_max_pool3d(   input,   kernel_size,   output_size = NULL,   output_ratio = NULL,   return_indices = FALSE,   random_samples = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fractional_max_pool3d — nnf_fractional_max_pool3d","text":"input input tensor kernel_size size window take max . Can single number \\(k\\) (square kernel \\(k * k * k\\)) tuple (kT, kH, kW) output_size target output size form \\(oT * oH * oW\\). Can tuple (oT, oH, oW) single number \\(oH\\) cubic output \\(oH * oH * oH\\) output_ratio one wants output size ratio input size, option can given. number tuple range (0, 1) return_indices True, return indices along outputs. random_samples undocumented argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_fractional_max_pool3d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fractional_max_pool3d — nnf_fractional_max_pool3d","text":"Fractional MaxPooling described detail paper Fractional MaxPooling_ Ben Graham max-pooling operation applied \\(kT * kH * kW\\) regions stochastic step size determined target output size. number output features equal number input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_gelu.html","id":null,"dir":"Reference","previous_headings":"","what":"Gelu — nnf_gelu","title":"Gelu — nnf_gelu","text":"Gelu","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_gelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gelu — nnf_gelu","text":"","code":"nnf_gelu(input, approximate = \"none\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_gelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gelu — nnf_gelu","text":"input (N,*) tensor, * means, number additional dimensions approximate default none, applies element-wise x*pnorm(x), 'tanh', GELU estimated. See GELU info.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_gelu.html","id":"gelu-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"gelu(input) -> Tensor","title":"Gelu — nnf_gelu","text":"Applies element-wise function \\(GELU(x) = x * \\Phi(x)\\) \\(\\Phi(x)\\) Cumulative Distribution Function Gaussian Distribution. See Gaussian Error Linear Units (GELUs).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_glu.html","id":null,"dir":"Reference","previous_headings":"","what":"Glu — nnf_glu","title":"Glu — nnf_glu","text":"gated linear unit. Computes:","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_glu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glu — nnf_glu","text":"","code":"nnf_glu(input, dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_glu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glu — nnf_glu","text":"input (Tensor) input tensor dim (int) dimension split input. Default: -1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_glu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Glu — nnf_glu","text":"$$GLU(, b) = \\otimes \\sigma(b)$$ input split half along dim form b, \\(\\sigma\\) sigmoid function \\(\\otimes\\) element-wise product matrices. See Language Modeling Gated Convolutional Networks.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_grid_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Grid_sample — nnf_grid_sample","title":"Grid_sample — nnf_grid_sample","text":"Given input flow-field grid, computes output using input values pixel locations grid.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_grid_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grid_sample — nnf_grid_sample","text":"","code":"nnf_grid_sample(   input,   grid,   mode = c(\"bilinear\", \"nearest\"),   padding_mode = c(\"zeros\", \"border\", \"reflection\"),   align_corners = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_grid_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grid_sample — nnf_grid_sample","text":"input (Tensor) input shape \\((N, C, H_{\\mbox{}}, W_{\\mbox{}})\\) (4-D case)                    \\((N, C, D_{\\mbox{}}, H_{\\mbox{}}, W_{\\mbox{}})\\) (5-D case) grid (Tensor) flow-field shape \\((N, H_{\\mbox{}}, W_{\\mbox{}}, 2)\\) (4-D case)                   \\((N, D_{\\mbox{}}, H_{\\mbox{}}, W_{\\mbox{}}, 3)\\) (5-D case) mode (str) interpolation mode calculate output values 'bilinear' | 'nearest'. Default: 'bilinear' padding_mode (str) padding mode outside grid values 'zeros' | 'border' | 'reflection'. Default: 'zeros' align_corners (bool, optional) Geometrically, consider pixels input  squares rather points. set True, extrema (-1 1) considered referring center points input's corner pixels. set False, instead considered referring corner points input's corner pixels, making sampling resolution agnostic. option parallels align_corners option  nnf_interpolate(), whichever option used also used resize input image grid sampling. Default: False","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_grid_sample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Grid_sample — nnf_grid_sample","text":"Currently, spatial (4-D) volumetric (5-D) input supported. spatial (4-D) case, input shape \\((N, C, H_{\\mbox{}}, W_{\\mbox{}})\\) grid shape \\((N, H_{\\mbox{}}, W_{\\mbox{}}, 2)\\), output shape \\((N, C, H_{\\mbox{}}, W_{\\mbox{}})\\). output location output[n, :, h, w], size-2 vector grid[n, h, w] specifies input pixel locations x y, used interpolate output value output[n, :, h, w]. case 5D inputs, grid[n, d, h, w] specifies x, y, z pixel locations interpolating output[n, :, d, h, w]. mode argument specifies nearest bilinear interpolation method sample input pixels. grid specifies sampling pixel locations normalized input spatial dimensions. Therefore, values range [-1, 1]. example, values x = -1, y = -1 left-top pixel input, values  x = 1, y = 1 right-bottom pixel input. grid values outside range [-1, 1], corresponding outputs handled defined padding_mode. Options padding_mode=\"zeros\": use 0 --bound grid locations, padding_mode=\"border\": use border values --bound grid locations, padding_mode=\"reflection\": use values locations reflected border --bound grid locations. location far away border, keep reflected becoming bound, e.g., (normalized) pixel location x = -3.5 reflects border -1 becomes x' = 1.5, reflects border 1 becomes x'' = -0.5.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_grid_sample.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Grid_sample — nnf_grid_sample","text":"function often used conjunction nnf_affine_grid() build Spatial Transformer Networks_ .","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_group_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Group_norm — nnf_group_norm","title":"Group_norm — nnf_group_norm","text":"Applies Group Normalization last certain number dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_group_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group_norm — nnf_group_norm","text":"","code":"nnf_group_norm(input, num_groups, weight = NULL, bias = NULL, eps = 1e-05)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_group_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group_norm — nnf_group_norm","text":"input input tensor num_groups number groups separate channels weight weight tensor bias bias tensor eps value added denominator numerical stability. Default: 1e-5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_gumbel_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Gumbel_softmax — nnf_gumbel_softmax","title":"Gumbel_softmax — nnf_gumbel_softmax","text":"Samples Gumbel-Softmax distribution optionally discretizes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_gumbel_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gumbel_softmax — nnf_gumbel_softmax","text":"","code":"nnf_gumbel_softmax(logits, tau = 1, hard = FALSE, dim = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_gumbel_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gumbel_softmax — nnf_gumbel_softmax","text":"logits [..., num_features] unnormalized log probabilities tau non-negative scalar temperature hard True, returned samples discretized one-hot vectors,        differentiated soft sample autograd dim (int) dimension along softmax computed. Default: -1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardshrink — nnf_hardshrink","title":"Hardshrink — nnf_hardshrink","text":"Applies hard shrinkage function element-wise","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardshrink — nnf_hardshrink","text":"","code":"nnf_hardshrink(input, lambd = 0.5)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardshrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardshrink — nnf_hardshrink","text":"input (N,*) tensor, * means, number additional dimensions lambd lambda value Hardshrink formulation. Default: 0.5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardsigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardsigmoid — nnf_hardsigmoid","title":"Hardsigmoid — nnf_hardsigmoid","text":"Applies element-wise function \\(\\mbox{Hardsigmoid}(x) = \\frac{ReLU6(x + 3)}{6}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardsigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardsigmoid — nnf_hardsigmoid","text":"","code":"nnf_hardsigmoid(input, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardsigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardsigmoid — nnf_hardsigmoid","text":"input (N,*) tensor, * means, number additional dimensions inplace NA set True, operation -place. Default: False","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardswish.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardswish — nnf_hardswish","title":"Hardswish — nnf_hardswish","text":"Applies hardswish function, element-wise, described paper: Searching MobileNetV3.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardswish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardswish — nnf_hardswish","text":"","code":"nnf_hardswish(input, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardswish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardswish — nnf_hardswish","text":"input (N,*) tensor, * means, number additional dimensions inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardswish.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hardswish — nnf_hardswish","text":"$$ \\mbox{Hardswish}(x) = \\left\\{   \\begin{array}{ll}   0 & \\mbox{} x \\le -3, \\\\   x & \\mbox{} x \\ge +3, \\\\   x \\cdot (x + 3)/6 & \\mbox{otherwise}   \\end{array}   \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardtanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Hardtanh — nnf_hardtanh","title":"Hardtanh — nnf_hardtanh","text":"Applies HardTanh function element-wise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardtanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hardtanh — nnf_hardtanh","text":"","code":"nnf_hardtanh(input, min_val = -1, max_val = 1, inplace = FALSE)  nnf_hardtanh_(input, min_val = -1, max_val = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_hardtanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hardtanh — nnf_hardtanh","text":"input (N,*) tensor, * means, number additional dimensions min_val minimum value linear region range. Default: -1 max_val maximum value linear region range. Default: 1 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hinge_embedding_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Hinge_embedding_loss — nnf_hinge_embedding_loss","title":"Hinge_embedding_loss — nnf_hinge_embedding_loss","text":"Measures loss given input tensor xx labels tensor yy (containing 1 -1). usually used measuring whether two inputs similar dissimilar, e.g. using L1 pairwise distance xx , typically used learning nonlinear embeddings semi-supervised learning.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_hinge_embedding_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hinge_embedding_loss — nnf_hinge_embedding_loss","text":"","code":"nnf_hinge_embedding_loss(input, target, margin = 1, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_hinge_embedding_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hinge_embedding_loss — nnf_hinge_embedding_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input margin default value 1. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_instance_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Instance_norm — nnf_instance_norm","title":"Instance_norm — nnf_instance_norm","text":"Applies Instance Normalization channel data sample batch.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_instance_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Instance_norm — nnf_instance_norm","text":"","code":"nnf_instance_norm(   input,   running_mean = NULL,   running_var = NULL,   weight = NULL,   bias = NULL,   use_input_stats = TRUE,   momentum = 0.1,   eps = 1e-05 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_instance_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Instance_norm — nnf_instance_norm","text":"input input tensor running_mean running_mean tensor running_var running var tensor weight weight tensor bias bias tensor use_input_stats whether use input stats momentum double momentum eps eps double numerical stability","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_interpolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpolate — nnf_interpolate","title":"Interpolate — nnf_interpolate","text":"/samples input either given size given scale_factor","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_interpolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpolate — nnf_interpolate","text":"","code":"nnf_interpolate(   input,   size = NULL,   scale_factor = NULL,   mode = \"nearest\",   align_corners = FALSE,   recompute_scale_factor = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_interpolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpolate — nnf_interpolate","text":"input (Tensor) input tensor size (int Tuple[int] Tuple[int, int] Tuple[int, int, int]) output spatial size. scale_factor (float Tuple[float]) multiplier spatial size. match input size tuple. mode (str) algorithm used upsampling: 'nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear' | 'area' Default: 'nearest' align_corners (bool, optional) Geometrically, consider pixels input output squares rather points. set TRUE, input output tensors aligned center points corner pixels, preserving values corner pixels. set False, input output tensors aligned corner points corner pixels, interpolation uses edge value padding --boundary values, making operation independent input size scale_factor kept . effect mode  'linear', 'bilinear', 'bicubic' 'trilinear'.  Default: False recompute_scale_factor (bool, optional) recompute scale_factor use interpolation calculation.  scale_factor passed parameter, used compute output_size.  recompute_scale_factor ```True`` specified, new scale_factor computed based output input sizes use interpolation computation (.e. computation identical computed `output_size` passed-explicitly).  Otherwise, passed-`scale_factor` used interpolation computation.  Note `scale_factor` floating-point, recomputed scale_factor may differ one passed due rounding precision issues.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_interpolate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interpolate — nnf_interpolate","text":"algorithm used interpolation determined mode. Currently temporal, spatial volumetric sampling supported, .e. expected inputs 3-D, 4-D 5-D shape. input dimensions interpreted form: mini-batch x channels x [optional depth] x [optional height] x width. modes available resizing : nearest, linear (3D-), bilinear, bicubic (4D-), trilinear (5D-), area","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_kl_div.html","id":null,"dir":"Reference","previous_headings":"","what":"Kl_div — nnf_kl_div","title":"Kl_div — nnf_kl_div","text":"Kullback-Leibler divergence Loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_kl_div.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kl_div — nnf_kl_div","text":"","code":"nnf_kl_div(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_kl_div.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kl_div — nnf_kl_div","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"L1_loss — nnf_l1_loss","title":"L1_loss — nnf_l1_loss","text":"Function takes mean element-wise absolute value difference.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L1_loss — nnf_l1_loss","text":"","code":"nnf_l1_loss(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L1_loss — nnf_l1_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_layer_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Layer_norm — nnf_layer_norm","title":"Layer_norm — nnf_layer_norm","text":"Applies Layer Normalization last certain number dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_layer_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Layer_norm — nnf_layer_norm","text":"","code":"nnf_layer_norm(   input,   normalized_shape,   weight = NULL,   bias = NULL,   eps = 1e-05 )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_layer_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Layer_norm — nnf_layer_norm","text":"input input tensor normalized_shape input shape expected input size. single integer used, treated singleton list, module normalize last dimension expected specific size. weight weight tensor bias bias tensor eps value added denominator numerical stability. Default: 1e-5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_leaky_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Leaky_relu — nnf_leaky_relu","title":"Leaky_relu — nnf_leaky_relu","text":"Applies element-wise, \\(LeakyReLU(x) = max(0, x) + negative_slope * min(0, x)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_leaky_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leaky_relu — nnf_leaky_relu","text":"","code":"nnf_leaky_relu(input, negative_slope = 0.01, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_leaky_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leaky_relu — nnf_leaky_relu","text":"input (N,*) tensor, * means, number additional dimensions negative_slope Controls angle negative slope. Default: 1e-2 inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear — nnf_linear","title":"Linear — nnf_linear","text":"Applies linear transformation incoming data: \\(y = xA^T + b\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear — nnf_linear","text":"","code":"nnf_linear(input, weight, bias = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear — nnf_linear","text":"input \\((N, *, \\_features)\\) * means number additional dimensions weight \\((\\_features, \\_features)\\) weights tensor. bias optional tensor \\((\\_features)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_local_response_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Local_response_norm — nnf_local_response_norm","title":"Local_response_norm — nnf_local_response_norm","text":"Applies local response normalization input signal composed several input planes, channels occupy second dimension. Applies normalization across channels.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_local_response_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local_response_norm — nnf_local_response_norm","text":"","code":"nnf_local_response_norm(input, size, alpha = 1e-04, beta = 0.75, k = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_local_response_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Local_response_norm — nnf_local_response_norm","text":"input input tensor size amount neighbouring channels used normalization alpha multiplicative factor. Default: 0.0001 beta exponent. Default: 0.75 k additive factor. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_log_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Log_softmax — nnf_log_softmax","title":"Log_softmax — nnf_log_softmax","text":"Applies softmax followed logarithm.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_log_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log_softmax — nnf_log_softmax","text":"","code":"nnf_log_softmax(input, dim = NULL, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_log_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log_softmax — nnf_log_softmax","text":"input (Tensor) input dim (int) dimension along log_softmax computed. dtype (torch.dtype, optional) desired data type returned tensor. specified, input tensor casted dtype operation performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_log_softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log_softmax — nnf_log_softmax","text":"mathematically equivalent log(softmax(x)), two operations separately slower, numerically unstable. function uses alternative formulation compute output gradient correctly.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_logsigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Logsigmoid — nnf_logsigmoid","title":"Logsigmoid — nnf_logsigmoid","text":"Applies element-wise \\(LogSigmoid(x_i) = log(\\frac{1}{1 + exp(-x_i)})\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_logsigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logsigmoid — nnf_logsigmoid","text":"","code":"nnf_logsigmoid(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_logsigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logsigmoid — nnf_logsigmoid","text":"input (N,*) tensor, * means, number additional dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Lp_pool1d — nnf_lp_pool1d","title":"Lp_pool1d — nnf_lp_pool1d","text":"Applies 1D power-average pooling input signal composed several input planes. sum inputs power p zero, gradient set zero well.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lp_pool1d — nnf_lp_pool1d","text":"","code":"nnf_lp_pool1d(input, norm_type, kernel_size, stride = NULL, ceil_mode = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lp_pool1d — nnf_lp_pool1d","text":"input input tensor norm_type inf one gets max pooling 0 get sum pooling ( proportional avg pooling) kernel_size single int, size window stride single int, stride window. Default value kernel_size ceil_mode True, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Lp_pool2d — nnf_lp_pool2d","title":"Lp_pool2d — nnf_lp_pool2d","text":"Applies 2D power-average pooling input signal composed several input planes. sum inputs power p zero, gradient set zero well.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lp_pool2d — nnf_lp_pool2d","text":"","code":"nnf_lp_pool2d(input, norm_type, kernel_size, stride = NULL, ceil_mode = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_lp_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lp_pool2d — nnf_lp_pool2d","text":"input input tensor norm_type inf one gets max pooling 0 get sum pooling ( proportional avg pooling) kernel_size single int, size window stride single int, stride window. Default value kernel_size ceil_mode True, use ceil instead floor compute output shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_margin_ranking_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Margin_ranking_loss — nnf_margin_ranking_loss","title":"Margin_ranking_loss — nnf_margin_ranking_loss","text":"Creates criterion measures loss given inputs x1 , x2 , two 1D mini-batch Tensors, label 1D mini-batch tensor y (containing 1 -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_margin_ranking_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Margin_ranking_loss — nnf_margin_ranking_loss","text":"","code":"nnf_margin_ranking_loss(input1, input2, target, margin = 0, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_margin_ranking_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Margin_ranking_loss — nnf_margin_ranking_loss","text":"input1 first tensor input2 second input tensor target target tensor margin default value 00 . reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_pool1d — nnf_max_pool1d","title":"Max_pool1d — nnf_max_pool1d","text":"Applies 1D max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_pool1d — nnf_max_pool1d","text":"","code":"nnf_max_pool1d(   input,   kernel_size,   stride = NULL,   padding = 0,   dilation = 1,   ceil_mode = FALSE,   return_indices = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_pool1d — nnf_max_pool1d","text":"input input tensor shape (minibatch , in_channels , iW) kernel_size size window. Can single number tuple (kW,). stride stride window. Can single number tuple (sW,). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padW,). Default: 0 dilation controls spacing kernel points; also known à trous algorithm. ceil_mode True, use ceil instead floor compute output shape. Default: FALSE return_indices whether return indices max occurs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_pool2d — nnf_max_pool2d","title":"Max_pool2d — nnf_max_pool2d","text":"Applies 2D max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_pool2d — nnf_max_pool2d","text":"","code":"nnf_max_pool2d(   input,   kernel_size,   stride = kernel_size,   padding = 0,   dilation = 1,   ceil_mode = FALSE,   return_indices = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_pool2d — nnf_max_pool2d","text":"input input tensor (minibatch, in_channels , iH , iW) kernel_size size pooling region. Can single number tuple (kH, kW) stride stride pooling operation. Can single number tuple (sH, sW). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padH, padW). Default: 0 dilation controls spacing kernel points; also known à trous algorithm. ceil_mode True, use ceil instead floor formula compute output shape. Default: FALSE return_indices whether return indices max occurs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_pool3d — nnf_max_pool3d","title":"Max_pool3d — nnf_max_pool3d","text":"Applies 3D max pooling input signal composed several input planes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_pool3d — nnf_max_pool3d","text":"","code":"nnf_max_pool3d(   input,   kernel_size,   stride = NULL,   padding = 0,   dilation = 1,   ceil_mode = FALSE,   return_indices = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_pool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_pool3d — nnf_max_pool3d","text":"input input tensor (minibatch, in_channels , * iH , iW) kernel_size size pooling region. Can single number tuple (kT, kH, kW) stride stride pooling operation. Can single number tuple (sT, sH, sW). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padT, padH, padW), Default: 0 dilation controls spacing kernel points; also known à trous algorithm. ceil_mode True, use ceil instead floor formula compute output shape return_indices whether return indices max occurs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_unpool1d — nnf_max_unpool1d","title":"Max_unpool1d — nnf_max_unpool1d","text":"Computes partial inverse MaxPool1d.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_unpool1d — nnf_max_unpool1d","text":"","code":"nnf_max_unpool1d(   input,   indices,   kernel_size,   stride = NULL,   padding = 0,   output_size = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_unpool1d — nnf_max_unpool1d","text":"input input Tensor invert indices indices given max pool kernel_size Size max pooling window. stride Stride max pooling window. set kernel_size default. padding Padding added input output_size targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_unpool2d — nnf_max_unpool2d","title":"Max_unpool2d — nnf_max_unpool2d","text":"Computes partial inverse MaxPool2d.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_unpool2d — nnf_max_unpool2d","text":"","code":"nnf_max_unpool2d(   input,   indices,   kernel_size,   stride = NULL,   padding = 0,   output_size = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_unpool2d — nnf_max_unpool2d","text":"input input Tensor invert indices indices given max pool kernel_size Size max pooling window. stride Stride max pooling window. set kernel_size default. padding Padding added input output_size targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Max_unpool3d — nnf_max_unpool3d","title":"Max_unpool3d — nnf_max_unpool3d","text":"Computes partial inverse MaxPool3d.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Max_unpool3d — nnf_max_unpool3d","text":"","code":"nnf_max_unpool3d(   input,   indices,   kernel_size,   stride = NULL,   padding = 0,   output_size = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_max_unpool3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max_unpool3d — nnf_max_unpool3d","text":"input input Tensor invert indices indices given max pool kernel_size Size max pooling window. stride Stride max pooling window. set kernel_size default. padding Padding added input output_size targeted output size","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_mse_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Mse_loss — nnf_mse_loss","title":"Mse_loss — nnf_mse_loss","text":"Measures element-wise mean squared error.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_mse_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mse_loss — nnf_mse_loss","text":"","code":"nnf_mse_loss(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_mse_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mse_loss — nnf_mse_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_head_attention_forward.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi head attention forward — nnf_multi_head_attention_forward","title":"Multi head attention forward — nnf_multi_head_attention_forward","text":"Allows model jointly attend information different representation subspaces. See reference: Attention Need","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_head_attention_forward.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi head attention forward — nnf_multi_head_attention_forward","text":"","code":"nnf_multi_head_attention_forward(   query,   key,   value,   embed_dim_to_check,   num_heads,   in_proj_weight,   in_proj_bias,   bias_k,   bias_v,   add_zero_attn,   dropout_p,   out_proj_weight,   out_proj_bias,   training = TRUE,   key_padding_mask = NULL,   need_weights = TRUE,   attn_mask = NULL,   avg_weights = TRUE,   use_separate_proj_weight = FALSE,   q_proj_weight = NULL,   k_proj_weight = NULL,   v_proj_weight = NULL,   static_k = NULL,   static_v = NULL,   batch_first = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_head_attention_forward.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi head attention forward — nnf_multi_head_attention_forward","text":"query \\((L, N, E)\\) L target sequence length, N batch size, E embedding dimension. batch_first TRUE, first two dimensions transposed. key \\((S, N, E)\\), S source sequence length, N batch size, E embedding dimension. batch_first TRUE, first two dimensions transposed. value \\((S, N, E)\\) S source sequence length, N batch size, E embedding dimension. batch_first TRUE, first two dimensions transposed. embed_dim_to_check total dimension model. num_heads parallel attention heads. in_proj_weight input projection weight. in_proj_bias input projection bias. bias_k bias key value sequences added dim=0. bias_v currently undocumented. add_zero_attn add new batch zeros key value sequences dim=1. dropout_p probability element zeroed. out_proj_weight output projection weight. out_proj_bias output projection bias. training apply dropout TRUE. key_padding_mask \\((N, S)\\) N batch size, S source sequence length. ByteTensor provided, non-zero positions ignored position zero positions unchanged. BoolTensor provided, positions value True ignored position value False unchanged. need_weights output attn_output_weights. attn_mask 2D mask \\((L, S)\\) L target sequence length, S source sequence length. 3D mask \\((N*num_heads, L, S)\\) N batch size, L target sequence length, S source sequence length. attn_mask ensure position allowed attend unmasked positions. ByteTensor provided, non-zero positions allowed attend zero positions unchanged. BoolTensor provided, positions True allowed attend False values unchanged. FloatTensor provided, added attention weight. avg_weights Logical; whether average attn_output_weights attention heads outputting . change returned value attn_output; affects returned attention weight matrix. use_separate_proj_weight function accept proj. weights query, key, value different forms. false, in_proj_weight used, combination q_proj_weight, k_proj_weight, v_proj_weight. q_proj_weight input projection weight bias. k_proj_weight currently undocumented. v_proj_weight currently undocumented. static_k static key value used attention operators. static_v currently undocumented. batch_first Logical; whether expect query, key, value batch first parameter, return output batch first.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi_margin_loss — nnf_multi_margin_loss","title":"Multi_margin_loss — nnf_multi_margin_loss","text":"Creates criterion optimizes multi-class classification hinge loss (margin-based loss) input x (2D mini-batch Tensor) output y (1D tensor target class indices, 0 <= y <= x$size(2) - 1 ).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi_margin_loss — nnf_multi_margin_loss","text":"","code":"nnf_multi_margin_loss(   input,   target,   p = 1,   margin = 1,   weight = NULL,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_multi_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi_margin_loss — nnf_multi_margin_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input p default value 1. 1 2 supported values. margin default value 1. weight manual rescaling weight given class. given, Tensor size C. Otherwise, treated ones. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilabel_margin_loss — nnf_multilabel_margin_loss","title":"Multilabel_margin_loss — nnf_multilabel_margin_loss","text":"Creates criterion optimizes multi-class multi-classification hinge loss (margin-based loss) input x (2D mini-batch Tensor) output y (2D Tensor target class indices).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multilabel_margin_loss — nnf_multilabel_margin_loss","text":"","code":"nnf_multilabel_margin_loss(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multilabel_margin_loss — nnf_multilabel_margin_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_soft_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Multilabel_soft_margin_loss — nnf_multilabel_soft_margin_loss","title":"Multilabel_soft_margin_loss — nnf_multilabel_soft_margin_loss","text":"Creates criterion optimizes multi-label one-versus-loss based max-entropy, input x target y size (N, C).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_soft_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multilabel_soft_margin_loss — nnf_multilabel_soft_margin_loss","text":"","code":"nnf_multilabel_soft_margin_loss(   input,   target,   weight = NULL,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_soft_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multilabel_soft_margin_loss — nnf_multilabel_soft_margin_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input weight weight tensor apply loss. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_multilabel_soft_margin_loss.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Multilabel_soft_margin_loss — nnf_multilabel_soft_margin_loss","text":"takes one hot encoded target vector input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_nll_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Nll_loss — nnf_nll_loss","title":"Nll_loss — nnf_nll_loss","text":"negative log likelihood loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_nll_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nll_loss — nnf_nll_loss","text":"","code":"nnf_nll_loss(   input,   target,   weight = NULL,   ignore_index = -100,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_nll_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nll_loss — nnf_nll_loss","text":"input \\((N, C)\\) C = number classes \\((N, C, H, W)\\) case 2D Loss, \\((N, C, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) case K-dimensional loss. target \\((N)\\) value \\(0 \\leq \\mbox{targets}[] \\leq C-1\\), \\((N, d_1, d_2, ..., d_K)\\) \\(K \\geq 1\\) K-dimensional loss. weight (Tensor, optional) manual rescaling weight given class. given, Tensor size C ignore_index (int, optional) Specifies target value ignored contribute input gradient. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize — nnf_normalize","title":"Normalize — nnf_normalize","text":"Performs \\(L_p\\) normalization inputs specified dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize — nnf_normalize","text":"","code":"nnf_normalize(input, p = 2, dim = 2, eps = 1e-12, out = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize — nnf_normalize","text":"input input tensor shape p (float) exponent value norm formulation. Default: 2 dim (int) dimension reduce. Default: 1 eps (float) small value avoid division zero. Default: 1e-12 (Tensor, optional) output tensor. used,                            operation differentiable.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_normalize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize — nnf_normalize","text":"tensor input sizes \\((n_0, ..., n_{dim}, ..., n_k)\\), \\(n_{dim}\\) -element vector \\(v\\) along dimension dim transformed $$         v = \\frac{v}{\\max(\\Vert v \\Vert_p, \\epsilon)}. $$ default arguments uses Euclidean norm vectors along dimension \\(1\\) normalization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_one_hot.html","id":null,"dir":"Reference","previous_headings":"","what":"One_hot — nnf_one_hot","title":"One_hot — nnf_one_hot","text":"Takes LongTensor index values shape (*) returns tensor shape (*, num_classes) zeros everywhere except index last dimension matches corresponding value input tensor, case 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_one_hot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One_hot — nnf_one_hot","text":"","code":"nnf_one_hot(tensor, num_classes = -1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_one_hot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One_hot — nnf_one_hot","text":"tensor (LongTensor) class values shape. num_classes (int) Total number classes. set -1, number classes inferred one greater largest class value input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_one_hot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"One_hot — nnf_one_hot","text":"One-hot Wikipedia: https://en.wikipedia.org/wiki/One-hot","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pad.html","id":null,"dir":"Reference","previous_headings":"","what":"Pad — nnf_pad","title":"Pad — nnf_pad","text":"Pads tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pad — nnf_pad","text":"","code":"nnf_pad(input, pad, mode = \"constant\", value = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_pad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pad — nnf_pad","text":"input (Tensor) N-dimensional tensor pad (tuple) m-elements tuple, \\(\\frac{m}{2} \\leq\\) input dimensions \\(m\\) even. mode 'constant', 'reflect', 'replicate' 'circular'. Default: 'constant' value fill value 'constant' padding. Default: 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pad.html","id":"padding-size","dir":"Reference","previous_headings":"","what":"Padding size","title":"Pad — nnf_pad","text":"padding size pad dimensions input described starting last dimension moving forward. \\(\\left\\lfloor\\frac{\\mbox{len(pad)}}{2}\\right\\rfloor\\) dimensions input padded. example, pad last dimension input tensor, pad form \\((\\mbox{padding\\_left}, \\mbox{padding\\_right})\\); pad last 2 dimensions input tensor, use \\((\\mbox{padding\\_left}, \\mbox{padding\\_right},\\) \\(\\mbox{padding\\_top}, \\mbox{padding\\_bottom})\\); pad last 3 dimensions, use \\((\\mbox{padding\\_left}, \\mbox{padding\\_right},\\) \\(\\mbox{padding\\_top}, \\mbox{padding\\_bottom}\\) \\(\\mbox{padding\\_front}, \\mbox{padding\\_back})\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pad.html","id":"padding-mode","dir":"Reference","previous_headings":"","what":"Padding mode","title":"Pad — nnf_pad","text":"See nn_constant_pad_2d, nn_reflection_pad_2d, nn_replication_pad_2d concrete examples padding modes works. Constant padding implemented arbitrary dimensions. tensor, last 2 dimensions 4D input tensor, last dimension 3D input tensor. Reflect padding implemented padding last 2 dimensions 4D input tensor, last dimension 3D input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pairwise_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Pairwise_distance — nnf_pairwise_distance","title":"Pairwise_distance — nnf_pairwise_distance","text":"Computes batchwise pairwise distance vectors using p-norm.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pairwise_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pairwise_distance — nnf_pairwise_distance","text":"","code":"nnf_pairwise_distance(x1, x2, p = 2, eps = 1e-06, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_pairwise_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pairwise_distance — nnf_pairwise_distance","text":"x1 (Tensor) First input. x2 (Tensor) Second input (size matching x1). p norm degree. Default: 2 eps (float, optional) Small value avoid division zero. Default: 1e-8 keepdim Determines whether keep vector dimension. Default: False","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pdist.html","id":null,"dir":"Reference","previous_headings":"","what":"Pdist — nnf_pdist","title":"Pdist — nnf_pdist","text":"Computes p-norm distance every pair row vectors input. identical upper triangular portion, excluding diagonal, torch_norm(input[:, None] - input, dim=2, p=p). function faster rows contiguous.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pdist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pdist — nnf_pdist","text":"","code":"nnf_pdist(input, p = 2)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_pdist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pdist — nnf_pdist","text":"input input tensor shape \\(N \\times M\\). p p value p-norm distance calculate vector pair \\(\\[0, \\infty]\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pdist.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pdist — nnf_pdist","text":"input shape \\(N \\times M\\) output shape \\(\\frac{1}{2} N (N - 1)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pixel_shuffle.html","id":null,"dir":"Reference","previous_headings":"","what":"Pixel_shuffle — nnf_pixel_shuffle","title":"Pixel_shuffle — nnf_pixel_shuffle","text":"Rearranges elements tensor shape \\((*, C \\times r^2, H, W)\\) tensor shape \\((*, C, H \\times r, W \\times r)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_pixel_shuffle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pixel_shuffle — nnf_pixel_shuffle","text":"","code":"nnf_pixel_shuffle(input, upscale_factor)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_pixel_shuffle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pixel_shuffle — nnf_pixel_shuffle","text":"input (Tensor) input tensor upscale_factor (int) factor increase spatial resolution ","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_poisson_nll_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson_nll_loss — nnf_poisson_nll_loss","title":"Poisson_nll_loss — nnf_poisson_nll_loss","text":"Poisson negative log likelihood loss.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_poisson_nll_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson_nll_loss — nnf_poisson_nll_loss","text":"","code":"nnf_poisson_nll_loss(   input,   target,   log_input = TRUE,   full = FALSE,   eps = 1e-08,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_poisson_nll_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson_nll_loss — nnf_poisson_nll_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input log_input TRUE loss computed \\(\\exp(\\mbox{input}) - \\mbox{target} * \\mbox{input}\\), FALSE loss \\(\\mbox{input} - \\mbox{target} * \\log(\\mbox{input}+\\mbox{eps})\\). Default: TRUE. full whether compute full loss, . e. add Stirling approximation term. Default: FALSE. eps (float, optional) Small value avoid evaluation \\(\\log(0)\\) log_input=FALSE. Default: 1e-8 reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_prelu.html","id":null,"dir":"Reference","previous_headings":"","what":"Prelu — nnf_prelu","title":"Prelu — nnf_prelu","text":"Applies element-wise function \\(PReLU(x) = max(0,x) + weight * min(0,x)\\) weight learnable parameter.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_prelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prelu — nnf_prelu","text":"","code":"nnf_prelu(input, weight)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_prelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prelu — nnf_prelu","text":"input (N,*) tensor, * means, number additional dimensions weight (Tensor) learnable weights","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Relu — nnf_relu","title":"Relu — nnf_relu","text":"Applies rectified linear unit function element-wise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relu — nnf_relu","text":"","code":"nnf_relu(input, inplace = FALSE)  nnf_relu_(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relu — nnf_relu","text":"input (N,*) tensor, * means, number additional dimensions inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu6.html","id":null,"dir":"Reference","previous_headings":"","what":"Relu6 — nnf_relu6","title":"Relu6 — nnf_relu6","text":"Applies element-wise function \\(ReLU6(x) = min(max(0,x), 6)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu6.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relu6 — nnf_relu6","text":"","code":"nnf_relu6(input, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_relu6.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relu6 — nnf_relu6","text":"input (N,*) tensor, * means, number additional dimensions inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_rrelu.html","id":null,"dir":"Reference","previous_headings":"","what":"Rrelu — nnf_rrelu","title":"Rrelu — nnf_rrelu","text":"Randomized leaky ReLU.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_rrelu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rrelu — nnf_rrelu","text":"","code":"nnf_rrelu(input, lower = 1/8, upper = 1/3, training = FALSE, inplace = FALSE)  nnf_rrelu_(input, lower = 1/8, upper = 1/3, training = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_rrelu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rrelu — nnf_rrelu","text":"input (N,*) tensor, * means, number additional dimensions lower lower bound uniform distribution. Default: 1/8 upper upper bound uniform distribution. Default: 1/3 training bool wether training pass. DEfault: FALSE inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_selu.html","id":null,"dir":"Reference","previous_headings":"","what":"Selu — nnf_selu","title":"Selu — nnf_selu","text":"Applies element-wise, $$SELU(x) = scale * (max(0,x) + min(0, \\alpha * (exp(x) - 1)))$$, \\(\\alpha=1.6732632423543772848170429916717\\) \\(scale=1.0507009873554804934193349852946\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_selu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selu — nnf_selu","text":"","code":"nnf_selu(input, inplace = FALSE)  nnf_selu_(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_selu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selu — nnf_selu","text":"input (N,*) tensor, * means, number additional dimensions inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_selu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Selu — nnf_selu","text":"","code":"if (torch_is_installed()) { x <- torch_randn(2, 2) y <- nnf_selu(x) nnf_selu_(x) torch_equal(x, y) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/nnf_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid — nnf_sigmoid","title":"Sigmoid — nnf_sigmoid","text":"Applies element-wise \\(Sigmoid(x_i) = \\frac{1}{1 + exp(-x_i)}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid — nnf_sigmoid","text":"","code":"nnf_sigmoid(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid — nnf_sigmoid","text":"input (N,*) tensor, * means, number additional dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_silu.html","id":null,"dir":"Reference","previous_headings":"","what":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. See nn_silu() for more information. — nnf_silu","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. See nn_silu() for more information. — nnf_silu","text":"Applies Sigmoid Linear Unit (SiLU) function, element-wise. See nn_silu() information.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_silu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. See nn_silu() for more information. — nnf_silu","text":"","code":"nnf_silu(input, inplace = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_silu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Applies the Sigmoid Linear Unit (SiLU) function, element-wise. See nn_silu() for more information. — nnf_silu","text":"input (N,*) tensor, * means, number additional dimensions inplace can optionally operation -place. Default: FALSE","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/nnf_smooth_l1_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Smooth_l1_loss — nnf_smooth_l1_loss","title":"Smooth_l1_loss — nnf_smooth_l1_loss","text":"Function uses squared term absolute element-wise error falls 1 L1 term otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_smooth_l1_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Smooth_l1_loss — nnf_smooth_l1_loss","text":"","code":"nnf_smooth_l1_loss(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_smooth_l1_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Smooth_l1_loss — nnf_smooth_l1_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_soft_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Soft_margin_loss — nnf_soft_margin_loss","title":"Soft_margin_loss — nnf_soft_margin_loss","text":"Creates criterion optimizes two-class classification logistic loss input tensor x target tensor y (containing 1 -1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_soft_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Soft_margin_loss — nnf_soft_margin_loss","text":"","code":"nnf_soft_margin_loss(input, target, reduction = \"mean\")"},{"path":"https://torch.mlverse.org/docs/reference/nnf_soft_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Soft_margin_loss — nnf_soft_margin_loss","text":"input tensor (N,*) ** means, number additional dimensions target tensor (N,*) , shape input reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmax — nnf_softmax","title":"Softmax — nnf_softmax","text":"Applies softmax function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmax — nnf_softmax","text":"","code":"nnf_softmax(input, dim, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmax — nnf_softmax","text":"input (Tensor) input dim (int) dimension along softmax computed. dtype (torch.dtype, optional) desired data type returned tensor.      specified, input tensor casted dtype operation      performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softmax — nnf_softmax","text":"Softmax defined : $$Softmax(x_{}) = exp(x_i)/\\sum_j exp(x_j)$$ applied slices along dim, re-scale elements lie range [0, 1] sum 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmin.html","id":null,"dir":"Reference","previous_headings":"","what":"Softmin — nnf_softmin","title":"Softmin — nnf_softmin","text":"Applies softmin function.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softmin — nnf_softmin","text":"","code":"nnf_softmin(input, dim, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softmin — nnf_softmin","text":"input (Tensor) input dim (int) dimension along softmin computed (every slice        along dim sum 1). dtype (torch.dtype, optional) desired data type returned tensor.      specified, input tensor casted dtype operation      performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softmin.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softmin — nnf_softmin","text":"Note $$Softmin(x) = Softmax(-x)$$. See nnf_softmax definition mathematical formula.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softplus.html","id":null,"dir":"Reference","previous_headings":"","what":"Softplus — nnf_softplus","title":"Softplus — nnf_softplus","text":"Applies element-wise, function \\(Softplus(x) = 1/\\beta * log(1 + exp(\\beta * x))\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softplus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softplus — nnf_softplus","text":"","code":"nnf_softplus(input, beta = 1, threshold = 20)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_softplus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softplus — nnf_softplus","text":"input (N,*) tensor, * means, number additional dimensions beta beta value Softplus formulation. Default: 1 threshold values revert linear function. Default: 20","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softplus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Softplus — nnf_softplus","text":"numerical stability implementation reverts linear function \\(input * \\beta > threshold\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Softshrink — nnf_softshrink","title":"Softshrink — nnf_softshrink","text":"Applies soft shrinkage function elementwise","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softshrink — nnf_softshrink","text":"","code":"nnf_softshrink(input, lambd = 0.5)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_softshrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softshrink — nnf_softshrink","text":"input (N,*) tensor, * means, number additional dimensions lambd lambda (must less zero) value Softshrink formulation. Default: 0.5","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softsign.html","id":null,"dir":"Reference","previous_headings":"","what":"Softsign — nnf_softsign","title":"Softsign — nnf_softsign","text":"Applies element-wise, function \\(SoftSign(x) = x/(1 + |x|\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_softsign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Softsign — nnf_softsign","text":"","code":"nnf_softsign(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_softsign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Softsign — nnf_softsign","text":"input (N,*) tensor, * means, number additional dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_tanhshrink.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanhshrink — nnf_tanhshrink","title":"Tanhshrink — nnf_tanhshrink","text":"Applies element-wise, \\(Tanhshrink(x) = x - Tanh(x)\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_tanhshrink.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanhshrink — nnf_tanhshrink","text":"","code":"nnf_tanhshrink(input)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_tanhshrink.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tanhshrink — nnf_tanhshrink","text":"input (N,*) tensor, * means, number additional dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Threshold — nnf_threshold","title":"Threshold — nnf_threshold","text":"Thresholds element input Tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threshold — nnf_threshold","text":"","code":"nnf_threshold(input, threshold, value, inplace = FALSE)  nnf_threshold_(input, threshold, value)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threshold — nnf_threshold","text":"input (N,*) tensor, * means, number additional dimensions threshold value threshold value value replace inplace can optionally operation -place. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Triplet_margin_loss — nnf_triplet_margin_loss","title":"Triplet_margin_loss — nnf_triplet_margin_loss","text":"Creates criterion measures triplet loss given input tensors x1 , x2 , x3 margin value greater 0 . used measuring relative similarity samples. triplet composed , p n (.e., anchor, positive examples negative examples respectively). shapes input tensors (N, D).","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triplet_margin_loss — nnf_triplet_margin_loss","text":"","code":"nnf_triplet_margin_loss(   anchor,   positive,   negative,   margin = 1,   p = 2,   eps = 1e-06,   swap = FALSE,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triplet_margin_loss — nnf_triplet_margin_loss","text":"anchor anchor input tensor positive positive input tensor negative negative input tensor margin Default: 1. p norm degree pairwise distance. Default: 2. eps (float, optional) Small value avoid division zero. swap distance swap described detail paper Learning shallow convolutional feature descriptors triplet losses V. Balntas, E. Riba et al. Default: FALSE. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_with_distance_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Triplet margin with distance loss — nnf_triplet_margin_with_distance_loss","title":"Triplet margin with distance loss — nnf_triplet_margin_with_distance_loss","text":"See nn_triplet_margin_with_distance_loss()","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_with_distance_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triplet margin with distance loss — nnf_triplet_margin_with_distance_loss","text":"","code":"nnf_triplet_margin_with_distance_loss(   anchor,   positive,   negative,   distance_function = NULL,   margin = 1,   swap = FALSE,   reduction = \"mean\" )"},{"path":"https://torch.mlverse.org/docs/reference/nnf_triplet_margin_with_distance_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triplet margin with distance loss — nnf_triplet_margin_with_distance_loss","text":"anchor anchor input tensor positive positive input tensor negative negative input tensor distance_function (callable, optional): nonnegative, real-valued function quantifies closeness two tensors. specified, nn_pairwise_distance() used.  Default: None margin Default: 1. swap distance swap described detail paper Learning shallow convolutional feature descriptors triplet losses V. Balntas, E. Riba et al. Default: FALSE. reduction (string, optional) – Specifies reduction apply output: 'none' | 'mean' | 'sum'. 'none': reduction applied, 'mean': sum output divided number elements output, 'sum': output summed. Default: 'mean'","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_unfold.html","id":null,"dir":"Reference","previous_headings":"","what":"Unfold — nnf_unfold","title":"Unfold — nnf_unfold","text":"Extracts sliding local blocks batched input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_unfold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unfold — nnf_unfold","text":"","code":"nnf_unfold(input, kernel_size, dilation = 1, padding = 0, stride = 1)"},{"path":"https://torch.mlverse.org/docs/reference/nnf_unfold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unfold — nnf_unfold","text":"input input tensor kernel_size size sliding blocks dilation parameter controls stride elements within neighborhood. Default: 1 padding implicit zero padding added sides input. Default: 0 stride stride sliding blocks input spatial dimensions. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/nnf_unfold.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Unfold — nnf_unfold","text":"one element unfolded tensor may refer single memory location. result, -place operations (especially ones vectorized) may result incorrect behavior. need write tensor, please clone first.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":null,"dir":"Reference","previous_headings":"","what":"Adadelta optimizer — optim_adadelta","title":"Adadelta optimizer — optim_adadelta","text":"proposed ADADELTA: Adaptive Learning Rate Method","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adadelta optimizer — optim_adadelta","text":"","code":"optim_adadelta(params, lr = 1, rho = 0.9, eps = 1e-06, weight_decay = 0)"},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adadelta optimizer — optim_adadelta","text":"params (iterable): list parameters optimize list defining parameter groups lr (float, optional): learning rate (default: 1e-3) rho (float, optional): coefficient used computing running average squared gradients (default: 0.9) eps (float, optional): term added denominator improve numerical stability (default: 1e-6) weight_decay (float, optional): weight decay (L2 penalty) (default: 0)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adadelta optimizer — optim_adadelta","text":"According original paper, decaying average squared gradients computed follows: $$ E[g^2]_{t} = \\rho E[g^2]_{t- 1} + (1 - \\rho){g_{t}}^2 $$ RMS previous squared gradients time t: $$ RMS[g_{t}] = \\sqrt{E[g^2]_{t} + \\epsilon } $$ Adadelta update rule: $$  \\begin{array}{ll}  \\Delta \\theta_{t} = - \\frac{RMS [\\Delta \\theta]_{t - 1} }{RMS[g]_{t}}  \\theta_{t+1} = \\theta_{t} + \\Delta \\theta_{t} \\end{array} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Adadelta optimizer — optim_adadelta","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adadelta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adadelta optimizer — optim_adadelta","text":"","code":"if (torch_is_installed()) { if (FALSE) { optimizer <- optim_adadelta(model$parameters, lr = 0.1) optimizer$zero_grad() loss_fn(model(input), target)$backward() optimizer$step() } }"},{"path":"https://torch.mlverse.org/docs/reference/optim_adagrad.html","id":null,"dir":"Reference","previous_headings":"","what":"Adagrad optimizer — optim_adagrad","title":"Adagrad optimizer — optim_adagrad","text":"Proposed Adaptive Subgradient Methods Online Learning Stochastic Optimization","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adagrad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adagrad optimizer — optim_adagrad","text":"","code":"optim_adagrad(   params,   lr = 0.01,   lr_decay = 0,   weight_decay = 0,   initial_accumulator_value = 0,   eps = 1e-10 )"},{"path":"https://torch.mlverse.org/docs/reference/optim_adagrad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adagrad optimizer — optim_adagrad","text":"params (iterable): list parameters optimize list parameter groups lr (float, optional): learning rate (default: 1e-2) lr_decay (float, optional): learning rate decay (default: 0) weight_decay (float, optional): weight decay (L2 penalty) (default: 0) initial_accumulator_value initial value accumulator. (default: 0) Adagrad especially good optimizer sparse data. individually modifies learning rate every single parameter, dividing original learning rate value sum squares gradients. causes rarely occurring features get greater learning rates. main downside method fact learning rate may getting small fast, point model learn anymore. eps (float, optional): term added denominator improve numerical stability (default: 1e-10)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adagrad.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adagrad optimizer — optim_adagrad","text":"Update rule: $$ \\theta_{t+1} = \\theta_{t} - \\frac{\\eta }{\\sqrt{G_{t} + \\epsilon}} \\odot g_{t} $$ equation remarks quoted overview gradient descent optimization algorithms Sebastian Ruder.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adagrad.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Adagrad optimizer — optim_adagrad","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adam.html","id":null,"dir":"Reference","previous_headings":"","what":"Implements Adam algorithm. — optim_adam","title":"Implements Adam algorithm. — optim_adam","text":"proposed Adam: Method Stochastic Optimization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Implements Adam algorithm. — optim_adam","text":"","code":"optim_adam(   params,   lr = 0.001,   betas = c(0.9, 0.999),   eps = 1e-08,   weight_decay = 0,   amsgrad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/optim_adam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Implements Adam algorithm. — optim_adam","text":"params (iterable): iterable parameters optimize dicts defining parameter groups lr (float, optional): learning rate (default: 1e-3) betas (Tuple[float, float], optional): coefficients used computing running averages gradient square (default: (0.9, 0.999)) eps (float, optional): term added denominator improve numerical stability (default: 1e-8) weight_decay (float, optional): weight decay (L2 penalty) (default: 0) amsgrad (boolean, optional): whether use AMSGrad variant algorithm paper Convergence Adam Beyond (default: FALSE)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adam.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Implements Adam algorithm. — optim_adam","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Implements Adam algorithm. — optim_adam","text":"","code":"if (torch_is_installed()) { if (FALSE) { optimizer <- optim_adam(model$parameters(), lr = 0.1) optimizer$zero_grad() loss_fn(model(input), target)$backward() optimizer$step() }  }"},{"path":"https://torch.mlverse.org/docs/reference/optim_adamw.html","id":null,"dir":"Reference","previous_headings":"","what":"Implements AdamW algorithm — optim_adamw","title":"Implements AdamW algorithm — optim_adamw","text":"details regarding algorithm refer Decoupled Weight Decay Regularization","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_adamw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Implements AdamW algorithm — optim_adamw","text":"","code":"optim_adamw(   params,   lr = 0.001,   betas = c(0.9, 0.999),   eps = 1e-08,   weight_decay = 0.01,   amsgrad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/optim_adamw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Implements AdamW algorithm — optim_adamw","text":"params (iterable): iterable parameters optimize dicts defining parameter groups lr (float, optional): learning rate (default: 1e-3) betas (Tuple[float, float], optional): coefficients used computing running averages gradient square (default: (0.9, 0.999)) eps (float, optional): term added denominator improve numerical stability (default: 1e-8) weight_decay (float, optional): weight decay (L2 penalty) (default: 0) amsgrad (boolean, optional): whether use AMSGrad variant algorithm paper Convergence Adam Beyond (default: FALSE)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_asgd.html","id":null,"dir":"Reference","previous_headings":"","what":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","title":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","text":"Proposed Acceleration stochastic approximation averaging","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_asgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","text":"","code":"optim_asgd(   params,   lr = 0.01,   lambda = 1e-04,   alpha = 0.75,   t0 = 1e+06,   weight_decay = 0 )"},{"path":"https://torch.mlverse.org/docs/reference/optim_asgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","text":"params (iterable): iterable parameters optimize lists defining parameter groups lr (float): learning rate lambda (float, optional): decay term (default: 1e-4) alpha (float, optional): power eta update (default: 0.75) t0 (float, optional): point start averaging (default: 1e6) weight_decay (float, optional): weight decay (L2 penalty) (default: 0)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_asgd.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_asgd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Averaged Stochastic Gradient Descent optimizer — optim_asgd","text":"","code":"if (torch_is_installed()) { if (FALSE) { optimizer <- optim_asgd(model$parameters(), lr = 0.1) optimizer$zero_grad() loss_fn(model(input), target)$backward() optimizer$step() }  }"},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":null,"dir":"Reference","previous_headings":"","what":"LBFGS optimizer — optim_lbfgs","title":"LBFGS optimizer — optim_lbfgs","text":"Implements L-BFGS algorithm, heavily inspired minFunc","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LBFGS optimizer — optim_lbfgs","text":"","code":"optim_lbfgs(   params,   lr = 1,   max_iter = 20,   max_eval = NULL,   tolerance_grad = 1e-07,   tolerance_change = 1e-09,   history_size = 100,   line_search_fn = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LBFGS optimizer — optim_lbfgs","text":"params (iterable): iterable parameters optimize dicts defining parameter groups lr (float): learning rate (default: 1) max_iter (int): maximal number iterations per optimization step (default: 20) max_eval (int): maximal number function evaluations per optimization step (default: max_iter * 1.25). tolerance_grad (float): termination tolerance first order optimality (default: 1e-5). tolerance_change (float): termination tolerance function value/parameter changes (default: 1e-9). history_size (int): update history size (default: 100). line_search_fn (str): either 'strong_wolfe' None (default: None).","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"LBFGS optimizer — optim_lbfgs","text":"optimizer different others optimizer$step(), needs passed closure (1) calculates loss, (2) calls backward() , (3) returns . See example .","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"LBFGS optimizer — optim_lbfgs","text":"memory intensive optimizer (requires additional param_bytes * (history_size + 1) bytes). fit memory try reducing history size, use different algorithm.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"LBFGS optimizer — optim_lbfgs","text":"optimizer support per-parameter options parameter groups (can one). Right now parameters single device. improved future. need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_lbfgs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LBFGS optimizer — optim_lbfgs","text":"","code":"if (torch_is_installed()) { a <- 1 b <- 5 rosenbrock <- function(x) {   x1 <- x[1]   x2 <- x[2]   (a - x1)^2 + b * (x2 - x1^2)^2 }   x <- torch_tensor(c(-1, 1), requires_grad = TRUE)  optimizer <- optim_lbfgs(x) calc_loss <- function() {   optimizer$zero_grad()   value <- rosenbrock(x)   value$backward()   value }    num_iterations <- 2 for (i in 1:num_iterations) {   optimizer$step(calc_loss) }      rosenbrock(x)  } #> torch_tensor #> 1e-12 * #>  5.7554 #> [ CPUFloatType{1} ][ grad_fn = <AddBackward0> ]"},{"path":"https://torch.mlverse.org/docs/reference/optim_required.html","id":null,"dir":"Reference","previous_headings":"","what":"Dummy value indicating a required value. — optim_required","title":"Dummy value indicating a required value. — optim_required","text":"export","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_required.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dummy value indicating a required value. — optim_required","text":"","code":"optim_required()"},{"path":"https://torch.mlverse.org/docs/reference/optim_rmsprop.html","id":null,"dir":"Reference","previous_headings":"","what":"RMSprop optimizer — optim_rmsprop","title":"RMSprop optimizer — optim_rmsprop","text":"Proposed G. Hinton course.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rmsprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RMSprop optimizer — optim_rmsprop","text":"","code":"optim_rmsprop(   params,   lr = 0.01,   alpha = 0.99,   eps = 1e-08,   weight_decay = 0,   momentum = 0,   centered = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/optim_rmsprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RMSprop optimizer — optim_rmsprop","text":"params (iterable): iterable parameters optimize list defining parameter groups lr (float, optional): learning rate (default: 1e-2) alpha (float, optional): smoothing constant (default: 0.99) eps (float, optional): term added denominator improve numerical stability (default: 1e-8) weight_decay optional weight decay penalty. (default: 0) momentum (float, optional): momentum factor (default: 0) centered (bool, optional) : TRUE, compute centered RMSProp, gradient normalized estimation variance weight_decay (float, optional): weight decay (L2 penalty) (default: 0)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rmsprop.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"RMSprop optimizer — optim_rmsprop","text":"centered version first appears Generating Sequences Recurrent Neural Networks. implementation takes square root gradient average adding epsilon (note TensorFlow interchanges two operations). effective learning rate thus \\(\\alpha/(\\sqrt{v} + \\epsilon)\\) \\(\\alpha\\) scheduled learning rate \\(v\\) weighted moving average squared gradient. Update rule: $$ \\theta_{t+1} = \\theta_{t} - \\frac{\\eta }{\\sqrt{{E[g^2]}_{t} + \\epsilon}} * g_{t} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rmsprop.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"RMSprop optimizer — optim_rmsprop","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rprop.html","id":null,"dir":"Reference","previous_headings":"","what":"Implements the resilient backpropagation algorithm. — optim_rprop","title":"Implements the resilient backpropagation algorithm. — optim_rprop","text":"Proposed first RPROP - Fast Adaptive Learning Algorithm","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rprop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Implements the resilient backpropagation algorithm. — optim_rprop","text":"","code":"optim_rprop(params, lr = 0.01, etas = c(0.5, 1.2), step_sizes = c(1e-06, 50))"},{"path":"https://torch.mlverse.org/docs/reference/optim_rprop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Implements the resilient backpropagation algorithm. — optim_rprop","text":"params (iterable): iterable parameters optimize lists defining parameter groups lr (float, optional): learning rate (default: 1e-2) etas (Tuple(float, float), optional): pair (etaminus, etaplis), multiplicative increase decrease factors (default: (0.5, 1.2)) step_sizes (vector(float, float), optional): pair minimal maximal allowed step sizes (default: (1e-6, 50))","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rprop.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Implements the resilient backpropagation algorithm. — optim_rprop","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_rprop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Implements the resilient backpropagation algorithm. — optim_rprop","text":"","code":"if (torch_is_installed()) { if (FALSE) { optimizer <- optim_rprop(model$parameters(), lr = 0.1) optimizer$zero_grad() loss_fn(model(input), target)$backward() optimizer$step() } }"},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":null,"dir":"Reference","previous_headings":"","what":"SGD optimizer — optim_sgd","title":"SGD optimizer — optim_sgd","text":"Implements stochastic gradient descent (optionally momentum). Nesterov momentum based formula importance initialization momentum deep learning.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SGD optimizer — optim_sgd","text":"","code":"optim_sgd(   params,   lr = optim_required(),   momentum = 0,   dampening = 0,   weight_decay = 0,   nesterov = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SGD optimizer — optim_sgd","text":"params (iterable): iterable parameters optimize dicts defining parameter groups lr (float): learning rate momentum (float, optional): momentum factor (default: 0) dampening (float, optional): dampening momentum (default: 0) weight_decay (float, optional): weight decay (L2 penalty) (default: 0) nesterov (bool, optional): enables Nesterov momentum (default: FALSE)","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"SGD optimizer — optim_sgd","text":"implementation SGD Momentum-Nesterov subtly differs Sutskever et. al. implementations frameworks. Considering specific case Momentum, update can written $$   \\begin{array}{ll} v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\ p_{t+1} & = p_{t} - \\mbox{lr} * v_{t+1}, \\end{array} $$ \\(p\\), \\(g\\), \\(v\\) \\(\\mu\\) denote parameters, gradient, velocity, momentum respectively. contrast Sutskever et. al. frameworks employ update form $$   \\begin{array}{ll} v_{t+1} & = \\mu * v_{t} + \\mbox{lr} * g_{t+1}, \\\\ p_{t+1} & = p_{t} - v_{t+1}. \\end{array} $$ Nesterov version analogously modified.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"SGD optimizer — optim_sgd","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optim_sgd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SGD optimizer — optim_sgd","text":"","code":"if (torch_is_installed()) { if (FALSE) { optimizer <- optim_sgd(model$parameters(), lr = 0.1, momentum = 0.9) optimizer$zero_grad() loss_fn(model(input), target)$backward() optimizer$step() }  }"},{"path":"https://torch.mlverse.org/docs/reference/optimizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a custom optimizer — optimizer","title":"Creates a custom optimizer — optimizer","text":"implementing custom optimizers usually need implement initialize step methods. See example section full example.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optimizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a custom optimizer — optimizer","text":"","code":"optimizer(   name = NULL,   inherit = Optimizer,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/optimizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a custom optimizer — optimizer","text":"name (optional) name optimizer inherit (optional) can inherit optimizers re-use methods. ... Pass number fields methods. least define initialize step methods. See examples section. private (optional) list private methods optimizer. active (optional) list active methods optimizer. parent_env used capture right environment define class. default fine situations.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optimizer.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Creates a custom optimizer — optimizer","text":"need move model GPU via $cuda(), please constructing optimizers . Parameters model $cuda() different objects call. general, make sure objects pointed model parameters subject optimization remain whole lifecycle optimizer creation usage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/optimizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a custom optimizer — optimizer","text":"","code":"if (torch_is_installed()) {  # In this example we will create a custom optimizer # that's just a simplified version of the `optim_sgd` function.  optim_sgd2 <- optimizer(   initialize = function(params, learning_rate) {     defaults <- list(       learning_rate = learning_rate     )     super$initialize(params, defaults)   },   step = function() {     with_no_grad({       for (g in seq_along(self$param_groups)) {         group <- self$param_groups[[g]]         for (p in seq_along(group$params)) {           param <- group$params[[p]]            if (is.null(param$grad) || is_undefined_tensor(param$grad)) {             next           }            param$add_(param$grad, alpha = -group$learning_rate)         }       }     })   } )  x <- torch_randn(1, requires_grad = TRUE) opt <- optim_sgd2(x, learning_rate = 0.1) for (i in 1:100) {   opt$zero_grad()   y <- x^2   y$backward()   opt$step() } all.equal(x$item(), 0, tolerance = 1e-9) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://torch.mlverse.org/docs/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://torch.mlverse.org/docs/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Re-exporting the as_iterator function. — reexports","title":"Re-exporting the as_iterator function. — reexports","text":"objects imported packages. Follow links see documentation. coro as_iterator, loop, yield","code":""},{"path":"https://torch.mlverse.org/docs/reference/sampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a new Sampler — sampler","title":"Creates a new Sampler — sampler","text":"Samplers can used dataloader() creating batches torch dataset().","code":""},{"path":"https://torch.mlverse.org/docs/reference/sampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a new Sampler — sampler","text":"","code":"sampler(   name = NULL,   inherit = Sampler,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"https://torch.mlverse.org/docs/reference/sampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a new Sampler — sampler","text":"name (optional) name sampler inherit (optional) can inherit samplers re-use methods. ... Pass number fields methods. least define initialize step methods. See examples section. private (optional) list private methods sampler active (optional) list active methods sampler. parent_env used capture right environment define class. default fine situations.","code":""},{"path":"https://torch.mlverse.org/docs/reference/sampler.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a new Sampler — sampler","text":"sampler must implement .iter .length() methods. initialize takes data_source. general dataset(). .iter returns function returns dataset index everytime called. .length returns maximum number samples can retrieved sampler.","code":""},{"path":"https://torch.mlverse.org/docs/reference/slc.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a slice — slc","title":"Creates a slice — slc","text":"Creates slice object can used indexing torch tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/slc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a slice — slc","text":"","code":"slc(start, end, step = 1)"},{"path":"https://torch.mlverse.org/docs/reference/slc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a slice — slc","text":"start (integer) starting index. end (integer) last selected index. step (integer) step indexes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/slc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a slice — slc","text":"","code":"if (torch_is_installed()) { x <- torch_randn(10) x[slc(start = 1, end = 5, step = 2)]  } #> torch_tensor #> -1.1161 #>  0.1016 #> -1.2852 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/tensor_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset wrapping tensors. — tensor_dataset","title":"Dataset wrapping tensors. — tensor_dataset","text":"sample retrieved indexing tensors along first dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/tensor_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset wrapping tensors. — tensor_dataset","text":"","code":"tensor_dataset(...)"},{"path":"https://torch.mlverse.org/docs/reference/tensor_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dataset wrapping tensors. — tensor_dataset","text":"... tensors size first dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/threads.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of threads — threads","title":"Number of threads — threads","text":"Get set numbers used torch computations.","code":""},{"path":"https://torch.mlverse.org/docs/reference/threads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of threads — threads","text":"","code":"torch_set_num_threads(num_threads)  torch_set_num_interop_threads(num_threads)  torch_get_num_interop_threads()  torch_get_num_threads()"},{"path":"https://torch.mlverse.org/docs/reference/threads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of threads — threads","text":"num_threads number threads set.","code":""},{"path":"https://torch.mlverse.org/docs/reference/threads.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number of threads — threads","text":"details see CPU threading article PyTorch documentation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/threads.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Number of threads — threads","text":"torch_set_threads work macOS system must 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_abs.html","id":null,"dir":"Reference","previous_headings":"","what":"Abs — torch_abs","title":"Abs — torch_abs","text":"Abs","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_abs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Abs — torch_abs","text":"","code":"torch_abs(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_abs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Abs — torch_abs","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_abs.html","id":"abs-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"abs(input) -> Tensor","title":"Abs — torch_abs","text":"Computes element-wise absolute value given input tensor. $$     \\mbox{}_{} = |\\mbox{input}_{}| $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_abs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Abs — torch_abs","text":"","code":"if (torch_is_installed()) {  torch_abs(torch_tensor(c(-1, -2, 3))) } #> torch_tensor #>  1 #>  2 #>  3 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_absolute.html","id":null,"dir":"Reference","previous_headings":"","what":"Absolute — torch_absolute","title":"Absolute — torch_absolute","text":"Absolute","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_absolute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Absolute — torch_absolute","text":"","code":"torch_absolute(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_absolute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Absolute — torch_absolute","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_absolute.html","id":"absolute-input-out-none-gt-tensor","dir":"Reference","previous_headings":"","what":"absolute(input, *, out=None) -> Tensor","title":"Absolute — torch_absolute","text":"Alias torch_abs()","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acos.html","id":null,"dir":"Reference","previous_headings":"","what":"Acos — torch_acos","title":"Acos — torch_acos","text":"Acos","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acos — torch_acos","text":"","code":"torch_acos(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_acos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acos — torch_acos","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acos.html","id":"acos-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"acos(input) -> Tensor","title":"Acos — torch_acos","text":"Returns new tensor arccosine  elements input. $$     \\mbox{}_{} = \\cos^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acos — torch_acos","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_acos(a) } #> torch_tensor #>  1.9000 #>     nan #>  2.5559 #>     nan #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Acosh — torch_acosh","title":"Acosh — torch_acosh","text":"Acosh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acosh — torch_acosh","text":"","code":"torch_acosh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acosh — torch_acosh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Acosh — torch_acosh","text":"domain inverse hyperbolic cosine [1, inf) values outside range mapped NaN, except + INF output mapped + INF. $$     \\mbox{}_{} = \\cosh^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":"acosh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"acosh(input, *, out=None) -> Tensor","title":"Acosh — torch_acosh","text":"Returns new tensor inverse hyperbolic cosine elements input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_acosh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acosh — torch_acosh","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(4))$uniform_(1, 2) a torch_acosh(a) } #> torch_tensor #>  1.0694 #>  0.5761 #>  0.8503 #>  0.6869 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_adaptive_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptive_avg_pool1d — torch_adaptive_avg_pool1d","title":"Adaptive_avg_pool1d — torch_adaptive_avg_pool1d","text":"Adaptive_avg_pool1d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_adaptive_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptive_avg_pool1d — torch_adaptive_avg_pool1d","text":"","code":"torch_adaptive_avg_pool1d(self, output_size)"},{"path":"https://torch.mlverse.org/docs/reference/torch_adaptive_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adaptive_avg_pool1d — torch_adaptive_avg_pool1d","text":"self input tensor output_size target output size (single integer)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_adaptive_avg_pool1d.html","id":"adaptive-avg-pool-d-input-output-size-gt-tensor-","dir":"Reference","previous_headings":"","what":"adaptive_avg_pool1d(input, output_size) -> Tensor","title":"Adaptive_avg_pool1d — torch_adaptive_avg_pool1d","text":"Applies 1D adaptive average pooling input signal composed several input planes. See nn_adaptive_avg_pool1d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Add — torch_add","title":"Add — torch_add","text":"Add","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add — torch_add","text":"","code":"torch_add(self, other, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add — torch_add","text":"self (Tensor) input tensor. (Tensor/Number) second input tensor/number. alpha (Number) scalar multiplier ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":"add-input-other-out-null-","dir":"Reference","previous_headings":"","what":"add(input, other, out=NULL)","title":"Add — torch_add","text":"Adds scalar element input input returns new resulting tensor. $$     \\mbox{} = \\mbox{input} + \\mbox{} $$ input type FloatTensor DoubleTensor, must real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":"add-input-other-alpha-out-null-","dir":"Reference","previous_headings":"","what":"add(input, other, *, alpha=1, out=NULL)","title":"Add — torch_add","text":"element tensor multiplied scalar alpha added element tensor input. resulting tensor returned. shapes input must broadcastable . $$     \\mbox{} = \\mbox{input} + \\mbox{alpha} \\times \\mbox{} $$ type FloatTensor DoubleTensor, alpha must real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_add.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add — torch_add","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_add(a, 20)   a = torch_randn(c(4)) a b = torch_randn(c(4, 1)) b torch_add(a, b) } #> torch_tensor #> -1.9521 -1.7848 -1.0599 -1.0725 #>  0.3564  0.5238  1.2487  1.2360 #> -0.8335 -0.6662  0.0587  0.0461 #> -0.5819 -0.4146  0.3103  0.2977 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addbmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Addbmm — torch_addbmm","title":"Addbmm — torch_addbmm","text":"Addbmm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addbmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addbmm — torch_addbmm","text":"","code":"torch_addbmm(self, batch1, batch2, beta = 1L, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addbmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addbmm — torch_addbmm","text":"self (Tensor) matrix added batch1 (Tensor) first batch matrices multiplied batch2 (Tensor) second batch matrices multiplied beta (Number, optional) multiplier input (\\(\\beta\\)) alpha (Number, optional) multiplier batch1 @ batch2 (\\(\\alpha\\))","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addbmm.html","id":"addbmm-input-batch-batch-beta-alpha-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addbmm(input, batch1, batch2, *, beta=1, alpha=1, out=NULL) -> Tensor","title":"Addbmm — torch_addbmm","text":"Performs batch matrix-matrix product matrices stored batch1 batch2, reduced add step (matrix multiplications get accumulated along first dimension). input added final result. batch1 batch2 must 3-D tensors containing number matrices. batch1 \\((b \\times n \\times m)\\) tensor, batch2 \\((b \\times m \\times p)\\) tensor, input must broadcastable  \\((n \\times p)\\) tensor \\((n \\times p)\\) tensor. $$     = \\beta\\ \\mbox{input} + \\alpha\\ (\\sum_{=0}^{b-1} \\mbox{batch1}_i \\mathbin{@} \\mbox{batch2}_i) $$ inputs type FloatTensor DoubleTensor, arguments beta alpha must real numbers, otherwise integers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addbmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addbmm — torch_addbmm","text":"","code":"if (torch_is_installed()) {  M = torch_randn(c(3, 5)) batch1 = torch_randn(c(10, 3, 4)) batch2 = torch_randn(c(10, 4, 5)) torch_addbmm(M, batch1, batch2) } #> torch_tensor #> -7.4262 -4.7504 -1.8705  7.8178 -5.9200 #>  7.8648 -0.8338  1.4864 -9.0308 -8.3291 #>  0.4138 -3.4227  3.5947 -0.8622 -5.4645 #> [ CPUFloatType{3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":null,"dir":"Reference","previous_headings":"","what":"Addcdiv — torch_addcdiv","title":"Addcdiv — torch_addcdiv","text":"Addcdiv","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addcdiv — torch_addcdiv","text":"","code":"torch_addcdiv(self, tensor1, tensor2, value = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addcdiv — torch_addcdiv","text":"self (Tensor) tensor added tensor1 (Tensor) numerator tensor tensor2 (Tensor) denominator tensor value (Number, optional) multiplier \\(\\mbox{tensor1} / \\mbox{tensor2}\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":"addcdiv-input-tensor-tensor-value-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addcdiv(input, tensor1, tensor2, *, value=1, out=NULL) -> Tensor","title":"Addcdiv — torch_addcdiv","text":"Performs element-wise division tensor1 tensor2, multiply result scalar value add input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Addcdiv — torch_addcdiv","text":"Integer division addcdiv deprecated, future release addcdiv perform true division tensor1 tensor2. current addcdiv behavior can replicated using torch_floor_divide() integral inputs (input + value * tensor1 // tensor2) torch_div() float inputs (input + value * tensor1 / tensor2). new addcdiv behavior can implemented torch_true_divide() (input + value * torch.true_divide(tensor1, tensor2). $$     \\mbox{}_i = \\mbox{input}_i + \\mbox{value} \\times \\frac{\\mbox{tensor1}_i}{\\mbox{tensor2}_i} $$ shapes input, tensor1, tensor2 must broadcastable . inputs type FloatTensor DoubleTensor, value must real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcdiv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addcdiv — torch_addcdiv","text":"","code":"if (torch_is_installed()) {  t = torch_randn(c(1, 3)) t1 = torch_randn(c(3, 1)) t2 = torch_randn(c(1, 3)) torch_addcdiv(t, t1, t2, 0.1) } #> torch_tensor #>  0.4138 -3.3908 -0.0976 #>  0.1676 -0.6541 -0.6481 #>  0.3376 -2.5442 -0.2679 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addcmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Addcmul — torch_addcmul","title":"Addcmul — torch_addcmul","text":"Addcmul","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addcmul — torch_addcmul","text":"","code":"torch_addcmul(self, tensor1, tensor2, value = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addcmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addcmul — torch_addcmul","text":"self (Tensor) tensor added tensor1 (Tensor) tensor multiplied tensor2 (Tensor) tensor multiplied value (Number, optional) multiplier \\(tensor1 .* tensor2\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcmul.html","id":"addcmul-input-tensor-tensor-value-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addcmul(input, tensor1, tensor2, *, value=1, out=NULL) -> Tensor","title":"Addcmul — torch_addcmul","text":"Performs element-wise multiplication tensor1 tensor2, multiply result scalar value add input. $$     \\mbox{}_i = \\mbox{input}_i + \\mbox{value} \\times \\mbox{tensor1}_i \\times \\mbox{tensor2}_i $$ shapes tensor, tensor1, tensor2 must broadcastable . inputs type FloatTensor DoubleTensor, value must real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addcmul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addcmul — torch_addcmul","text":"","code":"if (torch_is_installed()) {  t = torch_randn(c(1, 3)) t1 = torch_randn(c(3, 1)) t2 = torch_randn(c(1, 3)) torch_addcmul(t, t1, t2, 0.1) } #> torch_tensor #> -1.0627  2.9080 -0.3882 #> -0.6749  2.6368 -0.3886 #> -0.7420  2.6837 -0.3886 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Addmm — torch_addmm","title":"Addmm — torch_addmm","text":"Addmm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addmm — torch_addmm","text":"","code":"torch_addmm(self, mat1, mat2, beta = 1L, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addmm — torch_addmm","text":"self (Tensor) matrix added mat1 (Tensor) first matrix multiplied mat2 (Tensor) second matrix multiplied beta (Number, optional) multiplier input (\\(\\beta\\)) alpha (Number, optional) multiplier \\(mat1 @ mat2\\) (\\(\\alpha\\))","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmm.html","id":"addmm-input-mat-mat-beta-alpha-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addmm(input, mat1, mat2, *, beta=1, alpha=1, out=NULL) -> Tensor","title":"Addmm — torch_addmm","text":"Performs matrix multiplication matrices mat1 mat2. matrix input added final result. mat1 \\((n \\times m)\\) tensor, mat2 \\((m \\times p)\\) tensor, input must broadcastable  \\((n \\times p)\\) tensor \\((n \\times p)\\) tensor. alpha beta scaling factors matrix-vector product mat1 mat2 added matrix input respectively. $$     \\mbox{} = \\beta\\ \\mbox{input} + \\alpha\\ (\\mbox{mat1}_i \\mathbin{@} \\mbox{mat2}_i) $$ inputs type FloatTensor DoubleTensor, arguments beta alpha must real numbers, otherwise integers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addmm — torch_addmm","text":"","code":"if (torch_is_installed()) {  M = torch_randn(c(2, 3)) mat1 = torch_randn(c(2, 3)) mat2 = torch_randn(c(3, 3)) torch_addmm(M, mat1, mat2) } #> torch_tensor #> -0.8938 -1.2562 -0.4730 #> -3.5750  0.6293  1.7723 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addmv.html","id":null,"dir":"Reference","previous_headings":"","what":"Addmv — torch_addmv","title":"Addmv — torch_addmv","text":"Addmv","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addmv — torch_addmv","text":"","code":"torch_addmv(self, mat, vec, beta = 1L, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addmv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addmv — torch_addmv","text":"self (Tensor) vector added mat (Tensor) matrix multiplied vec (Tensor) vector multiplied beta (Number, optional) multiplier input (\\(\\beta\\)) alpha (Number, optional) multiplier \\(mat @ vec\\) (\\(\\alpha\\))","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmv.html","id":"addmv-input-mat-vec-beta-alpha-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addmv(input, mat, vec, *, beta=1, alpha=1, out=NULL) -> Tensor","title":"Addmv — torch_addmv","text":"Performs matrix-vector product matrix mat vector vec. vector input added final result. mat \\((n \\times m)\\) tensor, vec 1-D tensor size m, input must broadcastable  1-D tensor size n 1-D tensor size n. alpha beta scaling factors matrix-vector product mat vec added tensor input respectively. $$     \\mbox{} = \\beta\\ \\mbox{input} + \\alpha\\ (\\mbox{mat} \\mathbin{@} \\mbox{vec}) $$ inputs type FloatTensor DoubleTensor, arguments beta alpha must real numbers, otherwise integers","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addmv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addmv — torch_addmv","text":"","code":"if (torch_is_installed()) {  M = torch_randn(c(2)) mat = torch_randn(c(2, 3)) vec = torch_randn(c(3)) torch_addmv(M, mat, vec) } #> torch_tensor #>  0.4158 #>  2.1916 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_addr.html","id":null,"dir":"Reference","previous_headings":"","what":"Addr — torch_addr","title":"Addr — torch_addr","text":"Addr","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Addr — torch_addr","text":"","code":"torch_addr(self, vec1, vec2, beta = 1L, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_addr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Addr — torch_addr","text":"self (Tensor) matrix added vec1 (Tensor) first vector outer product vec2 (Tensor) second vector outer product beta (Number, optional) multiplier input (\\(\\beta\\)) alpha (Number, optional) multiplier \\(\\mbox{vec1} \\otimes \\mbox{vec2}\\) (\\(\\alpha\\))","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addr.html","id":"addr-input-vec-vec-beta-alpha-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"addr(input, vec1, vec2, *, beta=1, alpha=1, out=NULL) -> Tensor","title":"Addr — torch_addr","text":"Performs outer-product vectors vec1 vec2 adds matrix input. Optional values beta alpha scaling factors outer product vec1 vec2 added matrix input respectively. $$     \\mbox{} = \\beta\\ \\mbox{input} + \\alpha\\ (\\mbox{vec1} \\otimes \\mbox{vec2}) $$ vec1 vector size n vec2 vector size m, input must broadcastable  matrix size \\((n \\times m)\\) matrix size \\((n \\times m)\\). inputs type FloatTensor DoubleTensor, arguments beta alpha must real numbers, otherwise integers","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_addr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Addr — torch_addr","text":"","code":"if (torch_is_installed()) {  vec1 = torch_arange(1, 3) vec2 = torch_arange(1, 2) M = torch_zeros(c(3, 2)) torch_addr(M, vec1, vec2) } #> torch_tensor #>  1  2 #>  2  4 #>  3  6 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_allclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Allclose — torch_allclose","title":"Allclose — torch_allclose","text":"Allclose","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_allclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allclose — torch_allclose","text":"","code":"torch_allclose(self, other, rtol = 1e-05, atol = 1e-08, equal_nan = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_allclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allclose — torch_allclose","text":"self (Tensor) first tensor compare (Tensor) second tensor compare rtol (float, optional) relative tolerance. Default: 1e-05 atol (float, optional) absolute tolerance. Default: 1e-08 equal_nan (bool, optional) TRUE, two NaN s compared equal. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_allclose.html","id":"allclose-input-other-rtol-e-atol-e-equal-nan-false-gt-bool-","dir":"Reference","previous_headings":"","what":"allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False) -> bool","title":"Allclose — torch_allclose","text":"function checks input satisfy condition: $$     \\vert \\mbox{input} - \\mbox{} \\vert \\leq \\mbox{atol} + \\mbox{rtol} \\times \\vert \\mbox{} \\vert $$ elementwise, elements input . behaviour function analogous numpy.allclose <https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html>_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_allclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allclose — torch_allclose","text":"","code":"if (torch_is_installed()) {  torch_allclose(torch_tensor(c(10000., 1e-07)), torch_tensor(c(10000.1, 1e-08))) torch_allclose(torch_tensor(c(10000., 1e-08)), torch_tensor(c(10000.1, 1e-09))) torch_allclose(torch_tensor(c(1.0, NaN)), torch_tensor(c(1.0, NaN))) torch_allclose(torch_tensor(c(1.0, NaN)), torch_tensor(c(1.0, NaN)), equal_nan=TRUE) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":null,"dir":"Reference","previous_headings":"","what":"Amax — torch_amax","title":"Amax — torch_amax","text":"Amax","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Amax — torch_amax","text":"","code":"torch_amax(self, dim = list(), keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Amax — torch_amax","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Amax — torch_amax","text":"difference max/min amax/amin : amax/amin supports reducing multiple dimensions, amax/amin return indices, amax/amin evenly distributes gradient equal values, max(dim)/min(dim) propagates gradient single index source tensor. keepdim TRUE, output tensors size inputexcept dimension(s)dimwhere size 1. Otherwise,dims squeezed (see [torch_squeeze()]), resulting output tensors fewer dimension input`.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":"amax-input-dim-keepdim-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"amax(input, dim, keepdim=FALSE, *, out=None) -> Tensor","title":"Amax — torch_amax","text":"Returns maximum value slice input tensor given dimension(s) dim.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Amax — torch_amax","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(4, 4)) a torch_amax(a, 1) } #> torch_tensor #>  0.7694 #>  1.3002 #>  0.8770 #> -0.3539 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":null,"dir":"Reference","previous_headings":"","what":"Amin — torch_amin","title":"Amin — torch_amin","text":"Amin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Amin — torch_amin","text":"","code":"torch_amin(self, dim = list(), keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Amin — torch_amin","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Amin — torch_amin","text":"difference max/min amax/amin : amax/amin supports reducing multiple dimensions, amax/amin return indices, amax/amin evenly distributes gradient equal values, max(dim)/min(dim) propagates gradient single index source tensor. keepdim TRUE, output tensors size input except dimension(s) dim size 1. Otherwise, dims squeezed (see torch_squeeze()), resulting output tensors fewer dimensions input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":"amin-input-dim-keepdim-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"amin(input, dim, keepdim=FALSE, *, out=None) -> Tensor","title":"Amin — torch_amin","text":"Returns minimum value slice input tensor given dimension(s) dim.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_amin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Amin — torch_amin","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(4, 4)) a torch_amin(a, 1) } #> torch_tensor #> -0.8406 #> -0.5179 #> -0.9084 #> -2.1076 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_angle.html","id":null,"dir":"Reference","previous_headings":"","what":"Angle — torch_angle","title":"Angle — torch_angle","text":"Angle","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_angle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Angle — torch_angle","text":"","code":"torch_angle(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_angle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Angle — torch_angle","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_angle.html","id":"angle-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"angle(input) -> Tensor","title":"Angle — torch_angle","text":"Computes element-wise angle (radians) given input tensor. $$     \\mbox{}_{} = angle(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_angle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Angle — torch_angle","text":"","code":"if (torch_is_installed()) { if (FALSE) { torch_angle(torch_tensor(c(-1 + 1i, -2 + 2i, 3 - 3i)))*180/3.14159 }  }"},{"path":"https://torch.mlverse.org/docs/reference/torch_arange.html","id":null,"dir":"Reference","previous_headings":"","what":"Arange — torch_arange","title":"Arange — torch_arange","text":"Arange","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arange — torch_arange","text":"","code":"torch_arange(   start,   end,   step = 1L,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_arange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arange — torch_arange","text":"start (Number) starting value set points. Default: 0. end (Number) ending value set points step (Number) gap pair adjacent points. Default: 1. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). dtype given, infer data type input        arguments. start, end, stop floating-point,        dtype inferred default dtype, see        ~torch.get_default_dtype. Otherwise, dtype inferred        torch.int64. layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arange.html","id":"arange-start-end-step-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"arange(start=0, end, step=1, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Arange — torch_arange","text":"Returns 1-D tensor size \\(\\left\\lceil \\frac{\\mbox{end} - \\mbox{start}}{\\mbox{step}} \\right\\rceil\\) values interval [start, end) taken common difference step beginning start. Note non-integer step subject floating point rounding errors comparing end; avoid inconsistency, advise adding small epsilon end cases. $$     \\mbox{}_{{+1}} = \\mbox{}_{} + \\mbox{step} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Arange — torch_arange","text":"","code":"if (torch_is_installed()) {  torch_arange(start = 0, end = 5) torch_arange(1, 4) torch_arange(1, 2.5, 0.5) } #> torch_tensor #>  1.0000 #>  1.5000 #>  2.0000 #>  2.5000 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_arccos.html","id":null,"dir":"Reference","previous_headings":"","what":"Arccos — torch_arccos","title":"Arccos — torch_arccos","text":"Arccos","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arccos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arccos — torch_arccos","text":"","code":"torch_arccos(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arccos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arccos — torch_arccos","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arccos.html","id":"arccos-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arccos(input, *, out=None) -> Tensor","title":"Arccos — torch_arccos","text":"Alias torch_acos().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arccosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Arccosh — torch_arccosh","title":"Arccosh — torch_arccosh","text":"Arccosh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arccosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arccosh — torch_arccosh","text":"","code":"torch_arccosh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arccosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arccosh — torch_arccosh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arccosh.html","id":"arccosh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arccosh(input, *, out=None) -> Tensor","title":"Arccosh — torch_arccosh","text":"Alias torch_acosh().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsin.html","id":null,"dir":"Reference","previous_headings":"","what":"Arcsin — torch_arcsin","title":"Arcsin — torch_arcsin","text":"Arcsin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arcsin — torch_arcsin","text":"","code":"torch_arcsin(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arcsin — torch_arcsin","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsin.html","id":"arcsin-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arcsin(input, *, out=None) -> Tensor","title":"Arcsin — torch_arcsin","text":"Alias torch_asin().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsinh.html","id":null,"dir":"Reference","previous_headings":"","what":"Arcsinh — torch_arcsinh","title":"Arcsinh — torch_arcsinh","text":"Arcsinh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsinh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arcsinh — torch_arcsinh","text":"","code":"torch_arcsinh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsinh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arcsinh — torch_arcsinh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arcsinh.html","id":"arcsinh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arcsinh(input, *, out=None) -> Tensor","title":"Arcsinh — torch_arcsinh","text":"Alias torch_asinh().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctan.html","id":null,"dir":"Reference","previous_headings":"","what":"Arctan — torch_arctan","title":"Arctan — torch_arctan","text":"Arctan","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arctan — torch_arctan","text":"","code":"torch_arctan(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arctan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arctan — torch_arctan","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctan.html","id":"arctan-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arctan(input, *, out=None) -> Tensor","title":"Arctan — torch_arctan","text":"Alias torch_atan().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Arctanh — torch_arctanh","title":"Arctanh — torch_arctanh","text":"Arctanh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Arctanh — torch_arctanh","text":"","code":"torch_arctanh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_arctanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arctanh — torch_arctanh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_arctanh.html","id":"arctanh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"arctanh(input, *, out=None) -> Tensor","title":"Arctanh — torch_arctanh","text":"Alias torch_atanh().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmax.html","id":null,"dir":"Reference","previous_headings":"","what":"Argmax — torch_argmax","title":"Argmax — torch_argmax","text":"Argmax","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Argmax — torch_argmax","text":"self (Tensor) input tensor. dim (int) dimension reduce. NULL, argmax flattened input returned. keepdim (bool) whether output tensor dim retained . Ignored dim=NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmax.html","id":"argmax-input-gt-longtensor-","dir":"Reference","previous_headings":"","what":"argmax(input) -> LongTensor","title":"Argmax — torch_argmax","text":"Returns indices maximum value elements input tensor. second value returned torch_max. See documentation exact semantics method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmax.html","id":"argmax-input-dim-keepdim-false-gt-longtensor-","dir":"Reference","previous_headings":"","what":"argmax(input, dim, keepdim=False) -> LongTensor","title":"Argmax — torch_argmax","text":"Returns indices maximum values tensor across dimension. second value returned torch_max. See documentation exact semantics method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Argmax — torch_argmax","text":"","code":"if (torch_is_installed()) {  if (FALSE) { a = torch_randn(c(4, 4)) a torch_argmax(a) }   a = torch_randn(c(4, 4)) a torch_argmax(a, dim=1) } #> torch_tensor #>  1 #>  3 #>  4 #>  1 #> [ CPULongType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_argmin.html","id":null,"dir":"Reference","previous_headings":"","what":"Argmin — torch_argmin","title":"Argmin — torch_argmin","text":"Argmin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Argmin — torch_argmin","text":"self (Tensor) input tensor. dim (int) dimension reduce. NULL, argmin flattened input returned. keepdim (bool) whether output tensor dim retained . Ignored dim=NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmin.html","id":"argmin-input-gt-longtensor-","dir":"Reference","previous_headings":"","what":"argmin(input) -> LongTensor","title":"Argmin — torch_argmin","text":"Returns indices minimum value elements input tensor. second value returned torch_min. See documentation exact semantics method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmin.html","id":"argmin-input-dim-keepdim-false-out-null-gt-longtensor-","dir":"Reference","previous_headings":"","what":"argmin(input, dim, keepdim=False, out=NULL) -> LongTensor","title":"Argmin — torch_argmin","text":"Returns indices minimum values tensor across dimension. second value returned torch_min. See documentation exact semantics method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argmin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Argmin — torch_argmin","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4, 4)) a torch_argmin(a)   a = torch_randn(c(4, 4)) a torch_argmin(a, dim=1) } #> torch_tensor #>  2 #>  2 #>  4 #>  4 #> [ CPULongType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_argsort.html","id":null,"dir":"Reference","previous_headings":"","what":"Argsort — torch_argsort","title":"Argsort — torch_argsort","text":"Argsort","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argsort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Argsort — torch_argsort","text":"","code":"torch_argsort(self, dim = -1L, descending = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_argsort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Argsort — torch_argsort","text":"self (Tensor) input tensor. dim (int, optional) dimension sort along descending (bool, optional) controls sorting order (ascending descending)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argsort.html","id":"argsort-input-dim-descending-false-gt-longtensor-","dir":"Reference","previous_headings":"","what":"argsort(input, dim=-1, descending=False) -> LongTensor","title":"Argsort — torch_argsort","text":"Returns indices sort tensor along given dimension ascending order value. second value returned torch_sort.  See documentation exact semantics method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_argsort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Argsort — torch_argsort","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4, 4)) a torch_argsort(a, dim=1) } #> torch_tensor #>  1  2  1  2 #>  2  4  2  1 #>  3  3  4  4 #>  4  1  3  3 #> [ CPULongType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":null,"dir":"Reference","previous_headings":"","what":"As_strided — torch_as_strided","title":"As_strided — torch_as_strided","text":"As_strided","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"As_strided — torch_as_strided","text":"","code":"torch_as_strided(self, size, stride, storage_offset = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"As_strided — torch_as_strided","text":"self (Tensor) input tensor. size (tuple ints) shape output tensor stride (tuple ints) stride output tensor storage_offset (int, optional) offset underlying storage output tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":"as-strided-input-size-stride-storage-offset-gt-tensor-","dir":"Reference","previous_headings":"","what":"as_strided(input, size, stride, storage_offset=0) -> Tensor","title":"As_strided — torch_as_strided","text":"Create view existing torch_Tensor input specified size, stride storage_offset.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"As_strided — torch_as_strided","text":"one element created tensor may refer single memory location. result, -place operations (especially ones vectorized) may result incorrect behavior. need write tensors, please clone first.","code":"Many PyTorch functions, which return a view of a tensor, are internally implemented with this function. Those functions, like `torch_Tensor.expand`, are easier to read and are therefore more advisable to use."},{"path":"https://torch.mlverse.org/docs/reference/torch_as_strided.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"As_strided — torch_as_strided","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(3, 3)) x t = torch_as_strided(x, list(2, 2), list(1, 2)) t t = torch_as_strided(x, list(2, 2), list(1, 2), 1) t } #> torch_tensor #> -1.0386  0.9525 #> -0.9742 -0.9887 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_asin.html","id":null,"dir":"Reference","previous_headings":"","what":"Asin — torch_asin","title":"Asin — torch_asin","text":"Asin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Asin — torch_asin","text":"","code":"torch_asin(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_asin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Asin — torch_asin","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asin.html","id":"asin-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"asin(input, out=NULL) -> Tensor","title":"Asin — torch_asin","text":"Returns new tensor arcsine  elements input. $$     \\mbox{}_{} = \\sin^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Asin — torch_asin","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_asin(a) } #> torch_tensor #>  0.9477 #> -0.2969 #>     nan #>  0.0865 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_asinh.html","id":null,"dir":"Reference","previous_headings":"","what":"Asinh — torch_asinh","title":"Asinh — torch_asinh","text":"Asinh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asinh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Asinh — torch_asinh","text":"","code":"torch_asinh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_asinh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Asinh — torch_asinh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asinh.html","id":"asinh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"asinh(input, *, out=None) -> Tensor","title":"Asinh — torch_asinh","text":"Returns new tensor inverse hyperbolic sine elements input. $$     \\mbox{}_{} = \\sinh^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_asinh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Asinh — torch_asinh","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(4)) a torch_asinh(a) } #> torch_tensor #> -0.6463 #> -1.0318 #>  1.3634 #> -0.6190 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_atan.html","id":null,"dir":"Reference","previous_headings":"","what":"Atan — torch_atan","title":"Atan — torch_atan","text":"Atan","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atan — torch_atan","text":"","code":"torch_atan(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atan — torch_atan","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan.html","id":"atan-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"atan(input, out=NULL) -> Tensor","title":"Atan — torch_atan","text":"Returns new tensor arctangent  elements input. $$     \\mbox{}_{} = \\tan^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Atan — torch_atan","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_atan(a) } #> torch_tensor #>  0.3500 #> -1.0859 #> -1.1293 #> -0.2667 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_atan2.html","id":null,"dir":"Reference","previous_headings":"","what":"Atan2 — torch_atan2","title":"Atan2 — torch_atan2","text":"Atan2","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atan2 — torch_atan2","text":"","code":"torch_atan2(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atan2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atan2 — torch_atan2","text":"self (Tensor) first input tensor (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan2.html","id":"atan-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"atan2(input, other, out=NULL) -> Tensor","title":"Atan2 — torch_atan2","text":"Element-wise arctangent \\(\\mbox{input}_{} / \\mbox{}_{}\\) consideration quadrant. Returns new tensor signed angles radians vector \\((\\mbox{}_{}, \\mbox{input}_{})\\) vector \\((1, 0)\\). (Note \\(\\mbox{}_{}\\), second parameter, x-coordinate, \\(\\mbox{input}_{}\\), first parameter, y-coordinate.) shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atan2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Atan2 — torch_atan2","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_atan2(a, torch_randn(c(4))) } #> torch_tensor #> -0.0465 #> -2.7011 #>  2.7868 #>  0.5454 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Atanh — torch_atanh","title":"Atanh — torch_atanh","text":"Atanh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atanh — torch_atanh","text":"","code":"torch_atanh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atanh — torch_atanh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Atanh — torch_atanh","text":"domain inverse hyperbolic tangent (-1, 1) values outside range mapped NaN, except values 1 -1 output mapped +/-INF respectively. $$     \\mbox{}_{} = \\tanh^{-1}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":"atanh-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"atanh(input, *, out=None) -> Tensor","title":"Atanh — torch_atanh","text":"Returns new tensor inverse hyperbolic tangent elements input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Atanh — torch_atanh","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4))$uniform_(-1, 1) a torch_atanh(a) } #> torch_tensor #> -0.0134 #> -0.1849 #> -0.0527 #>  0.9015 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Atleast_1d — torch_atleast_1d","title":"Atleast_1d — torch_atleast_1d","text":"Returns 1-dimensional view input tensor zero dimensions. Input tensors one dimensions returned -.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atleast_1d — torch_atleast_1d","text":"","code":"torch_atleast_1d(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atleast_1d — torch_atleast_1d","text":"self (Tensor list Tensors)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Atleast_1d — torch_atleast_1d","text":"","code":"if (torch_is_installed()) {  x <- torch_randn(c(2)) x torch_atleast_1d(x) x <- torch_tensor(1.) x torch_atleast_1d(x) x <- torch_tensor(0.5) y <- torch_tensor(1.) torch_atleast_1d(list(x,y)) } #> [[1]] #> torch_tensor #>  0.5000 #> [ CPUFloatType{1} ] #>  #> [[2]] #> torch_tensor #>  1 #> [ CPUFloatType{1} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Atleast_2d — torch_atleast_2d","title":"Atleast_2d — torch_atleast_2d","text":"Returns 2-dimensional view input tensor zero dimensions. Input tensors two dimensions returned -.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atleast_2d — torch_atleast_2d","text":"","code":"torch_atleast_2d(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atleast_2d — torch_atleast_2d","text":"self (Tensor list Tensors)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Atleast_2d — torch_atleast_2d","text":"","code":"if (torch_is_installed()) {  x <- torch_tensor(1.) x torch_atleast_2d(x) x <- torch_randn(c(2,2)) x torch_atleast_2d(x) x <- torch_tensor(0.5) y <- torch_tensor(1.) torch_atleast_2d(list(x,y)) } #> [[1]] #> torch_tensor #>  0.5000 #> [ CPUFloatType{1,1} ] #>  #> [[2]] #> torch_tensor #>  1 #> [ CPUFloatType{1,1} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Atleast_3d — torch_atleast_3d","title":"Atleast_3d — torch_atleast_3d","text":"Returns 3-dimensional view input tensor zero dimensions. Input tensors three dimensions returned -.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Atleast_3d — torch_atleast_3d","text":"","code":"torch_atleast_3d(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_atleast_3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Atleast_3d — torch_atleast_3d","text":"self (Tensor list Tensors)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_avg_pool1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Avg_pool1d — torch_avg_pool1d","title":"Avg_pool1d — torch_avg_pool1d","text":"Avg_pool1d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_avg_pool1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Avg_pool1d — torch_avg_pool1d","text":"","code":"torch_avg_pool1d(   self,   kernel_size,   stride = list(),   padding = 0L,   ceil_mode = FALSE,   count_include_pad = TRUE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_avg_pool1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Avg_pool1d — torch_avg_pool1d","text":"self input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , iW)\\) kernel_size size window. Can single number tuple (kW,) stride stride window. Can single number tuple (sW,). Default: kernel_size padding implicit zero paddings sides input. Can single number tuple (padW,). Default: 0 ceil_mode TRUE, use ceil instead floor compute output shape. Default: FALSE count_include_pad TRUE, include zero-padding averaging calculation. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_avg_pool1d.html","id":"avg-pool-d-input-kernel-size-stride-null-padding-ceil-mode-false-count-include-pad-true-gt-tensor-","dir":"Reference","previous_headings":"","what":"avg_pool1d(input, kernel_size, stride=NULL, padding=0, ceil_mode=FALSE, count_include_pad=TRUE) -> Tensor","title":"Avg_pool1d — torch_avg_pool1d","text":"Applies 1D average pooling input signal composed several input planes. See nn_avg_pool1d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_baddbmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Baddbmm — torch_baddbmm","title":"Baddbmm — torch_baddbmm","text":"Baddbmm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_baddbmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Baddbmm — torch_baddbmm","text":"","code":"torch_baddbmm(self, batch1, batch2, beta = 1L, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_baddbmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Baddbmm — torch_baddbmm","text":"self (Tensor) tensor added batch1 (Tensor) first batch matrices multiplied batch2 (Tensor) second batch matrices multiplied beta (Number, optional) multiplier input (\\(\\beta\\)) alpha (Number, optional) multiplier \\(\\mbox{batch1} \\mathbin{@} \\mbox{batch2}\\) (\\(\\alpha\\))","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_baddbmm.html","id":"baddbmm-input-batch-batch-beta-alpha-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"baddbmm(input, batch1, batch2, *, beta=1, alpha=1, out=NULL) -> Tensor","title":"Baddbmm — torch_baddbmm","text":"Performs batch matrix-matrix product matrices batch1 batch2. input added final result. batch1 batch2 must 3-D tensors containing number matrices. batch1 \\((b \\times n \\times m)\\) tensor, batch2 \\((b \\times m \\times p)\\) tensor, input must broadcastable  \\((b \\times n \\times p)\\) tensor \\((b \\times n \\times p)\\) tensor. alpha beta mean scaling factors used torch_addbmm. $$     \\mbox{}_i = \\beta\\ \\mbox{input}_i + \\alpha\\ (\\mbox{batch1}_i \\mathbin{@} \\mbox{batch2}_i) $$ inputs type FloatTensor DoubleTensor, arguments beta alpha must real numbers, otherwise integers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_baddbmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Baddbmm — torch_baddbmm","text":"","code":"if (torch_is_installed()) {  M = torch_randn(c(10, 3, 5)) batch1 = torch_randn(c(10, 3, 4)) batch2 = torch_randn(c(10, 4, 5)) torch_baddbmm(M, batch1, batch2) } #> torch_tensor #> (1,.,.) =  #>   0.5111 -3.1852  3.7126 -1.3524  3.9963 #>   4.7965 -0.0369 -0.3263 -1.2753  0.0556 #>   2.3793  0.1486  0.1915 -0.4350  1.2126 #>  #> (2,.,.) =  #>   1.5858 -1.5813 -0.6729 -1.2245 -1.2957 #>   2.2479  0.2300  0.6143  1.7530  0.5099 #>  -2.0699  2.4970  0.9025 -0.7765  1.3482 #>  #> (3,.,.) =  #>   1.8821  0.1650  2.2522 -0.3192 -0.3841 #>  -3.8732 -1.4290  0.6768 -1.7308  3.1746 #>   0.3767 -0.8012 -0.3291  0.9759 -1.7650 #>  #> (4,.,.) =  #>   0.0757  1.7507  2.5247 -2.5280  0.1248 #>   2.0840  1.4858  0.4577 -1.2264  1.5897 #>   2.7945  0.7971 -0.6055 -0.2607  0.7605 #>  #> (5,.,.) =  #>   0.7051  0.2898  1.5222 -0.2621 -2.5265 #>  -0.4269 -1.8950 -2.1202  1.3455  0.5589 #>   3.2963  5.4668  4.0805 -4.1564 -2.0503 #>  #> (6,.,.) =  #>   0.5190 -0.5352 -1.4169 -0.1021  2.8163 #>  -0.1018  0.0950  1.8032 -1.3999 -1.6487 #>  -0.2259  2.6865  4.0377  1.6081  1.1882 #>  #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{10,3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_bartlett_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Bartlett_window — torch_bartlett_window","title":"Bartlett_window — torch_bartlett_window","text":"Bartlett_window","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bartlett_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bartlett_window — torch_bartlett_window","text":"","code":"torch_bartlett_window(   window_length,   periodic = TRUE,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_bartlett_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bartlett_window — torch_bartlett_window","text":"window_length (int) size returned window periodic (bool, optional) TRUE, returns window used periodic        function. False, return symmetric window. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). floating point types supported. layout (torch.layout, optional) desired layout returned window tensor.          torch_strided (dense layout) supported. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bartlett_window.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Bartlett_window — torch_bartlett_window","text":"","code":"If `window_length` \\eqn{=1}, the returned window contains a single value 1."},{"path":"https://torch.mlverse.org/docs/reference/torch_bartlett_window.html","id":"bartlett-window-window-length-periodic-true-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"bartlett_window(window_length, periodic=TRUE, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Bartlett_window — torch_bartlett_window","text":"Bartlett window function. $$     w[n] = 1 - \\left| \\frac{2n}{N-1} - 1 \\right| = \\left\\{ \\begin{array}{ll}         \\frac{2n}{N - 1} & \\mbox{} 0 \\leq n \\leq \\frac{N - 1}{2} \\\\         2 - \\frac{2n}{N - 1} & \\mbox{} \\frac{N - 1}{2} < n < N \\\\     \\end{array}     \\right. , $$ \\(N\\) full window size. input window_length positive integer controlling returned window size. periodic flag determines whether returned window trims last duplicate value symmetric window ready used periodic window functions like torch_stft. Therefore, periodic true, \\(N\\) formula fact \\(\\mbox{window\\_length} + 1\\). Also, always torch_bartlett_window(L, periodic=TRUE) equal torch_bartlett_window(L + 1, periodic=False)[:-1]).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bernoulli.html","id":null,"dir":"Reference","previous_headings":"","what":"Bernoulli — torch_bernoulli","title":"Bernoulli — torch_bernoulli","text":"Bernoulli","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bernoulli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bernoulli — torch_bernoulli","text":"","code":"torch_bernoulli(self, p, generator = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bernoulli.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bernoulli — torch_bernoulli","text":"self (Tensor) input tensor probability values Bernoulli distribution p (Number) probability value. p passed used instead values self tensor. generator (torch.Generator, optional) pseudorandom number generator sampling","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bernoulli.html","id":"bernoulli-input-generator-null-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bernoulli(input, *, generator=NULL, out=NULL) -> Tensor","title":"Bernoulli — torch_bernoulli","text":"Draws binary random numbers (0 1) Bernoulli distribution. input tensor tensor containing probabilities used drawing binary random number. Hence, values input range: \\(0 \\leq \\mbox{input}_i \\leq 1\\). \\(\\mbox{}^{th}\\) element output tensor draw value \\(1\\) according \\(\\mbox{}^{th}\\) probability value given input. $$     \\mbox{}_{} \\sim \\mathrm{Bernoulli}(p = \\mbox{input}_{}) $$ returned tensor values 0 1 shape input. can integral dtype, input must floating point dtype.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bernoulli.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bernoulli — torch_bernoulli","text":"","code":"if (torch_is_installed()) {  a = torch_empty(c(3, 3))$uniform_(0, 1)  # generate a uniform random matrix with range c(0, 1) a torch_bernoulli(a) a = torch_ones(c(3, 3)) # probability of drawing \"1\" is 1 torch_bernoulli(a) a = torch_zeros(c(3, 3)) # probability of drawing \"1\" is 0 torch_bernoulli(a) } #> torch_tensor #>  0  0  0 #>  0  0  0 #>  0  0  0 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_bincount.html","id":null,"dir":"Reference","previous_headings":"","what":"Bincount — torch_bincount","title":"Bincount — torch_bincount","text":"Bincount","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bincount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bincount — torch_bincount","text":"self (Tensor) 1-d int tensor weights (Tensor) optional, weight value input tensor.        size input tensor. minlength (int) optional, minimum number bins. non-negative.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bincount.html","id":"bincount-input-weights-null-minlength-gt-tensor-","dir":"Reference","previous_headings":"","what":"bincount(input, weights=NULL, minlength=0) -> Tensor","title":"Bincount — torch_bincount","text":"Count frequency value array non-negative ints. number bins (size 1) one larger largest value input unless input empty, case result tensor size 0. minlength specified, number bins least minlength input empty, result tensor size minlength filled zeros. n value position , [n] += weights[] weights specified else [n] += 1. .. include:: cuda_deterministic.rst","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bincount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bincount — torch_bincount","text":"","code":"if (torch_is_installed()) {  input = torch_randint(1, 8, list(5), dtype=torch_int64()) weights = torch_linspace(0, 1, steps=5) input weights torch_bincount(input, weights) input$bincount(weights) } #> torch_tensor #>  0.0000 #>  0.5000 #>  0.0000 #>  0.0000 #>  1.0000 #>  1.0000 #> [ CPUFloatType{6} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_and.html","id":null,"dir":"Reference","previous_headings":"","what":"Bitwise_and — torch_bitwise_and","title":"Bitwise_and — torch_bitwise_and","text":"Bitwise_and","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_and.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bitwise_and — torch_bitwise_and","text":"","code":"torch_bitwise_and(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_and.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bitwise_and — torch_bitwise_and","text":"self NA first input tensor NA second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_and.html","id":"bitwise-and-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bitwise_and(input, other, out=NULL) -> Tensor","title":"Bitwise_and — torch_bitwise_and","text":"Computes bitwise input . input tensor must integral Boolean types. bool tensors, computes logical .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_not.html","id":null,"dir":"Reference","previous_headings":"","what":"Bitwise_not — torch_bitwise_not","title":"Bitwise_not — torch_bitwise_not","text":"Bitwise_not","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_not.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bitwise_not — torch_bitwise_not","text":"","code":"torch_bitwise_not(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_not.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bitwise_not — torch_bitwise_not","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_not.html","id":"bitwise-not-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bitwise_not(input, out=NULL) -> Tensor","title":"Bitwise_not — torch_bitwise_not","text":"Computes bitwise given input tensor. input tensor must integral Boolean types. bool tensors, computes logical .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_or.html","id":null,"dir":"Reference","previous_headings":"","what":"Bitwise_or — torch_bitwise_or","title":"Bitwise_or — torch_bitwise_or","text":"Bitwise_or","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_or.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bitwise_or — torch_bitwise_or","text":"","code":"torch_bitwise_or(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_or.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bitwise_or — torch_bitwise_or","text":"self NA first input tensor NA second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_or.html","id":"bitwise-or-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bitwise_or(input, other, out=NULL) -> Tensor","title":"Bitwise_or — torch_bitwise_or","text":"Computes bitwise input . input tensor must integral Boolean types. bool tensors, computes logical .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_xor.html","id":null,"dir":"Reference","previous_headings":"","what":"Bitwise_xor — torch_bitwise_xor","title":"Bitwise_xor — torch_bitwise_xor","text":"Bitwise_xor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_xor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bitwise_xor — torch_bitwise_xor","text":"","code":"torch_bitwise_xor(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_xor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bitwise_xor — torch_bitwise_xor","text":"self NA first input tensor NA second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bitwise_xor.html","id":"bitwise-xor-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bitwise_xor(input, other, out=NULL) -> Tensor","title":"Bitwise_xor — torch_bitwise_xor","text":"Computes bitwise XOR input . input tensor must integral Boolean types. bool tensors, computes logical XOR.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_blackman_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Blackman_window — torch_blackman_window","title":"Blackman_window — torch_blackman_window","text":"Blackman_window","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_blackman_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blackman_window — torch_blackman_window","text":"","code":"torch_blackman_window(   window_length,   periodic = TRUE,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_blackman_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Blackman_window — torch_blackman_window","text":"window_length (int) size returned window periodic (bool, optional) TRUE, returns window used periodic        function. False, return symmetric window. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). floating point types supported. layout (torch.layout, optional) desired layout returned window tensor.          torch_strided (dense layout) supported. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_blackman_window.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Blackman_window — torch_blackman_window","text":"","code":"If `window_length` \\eqn{=1}, the returned window contains a single value 1."},{"path":"https://torch.mlverse.org/docs/reference/torch_blackman_window.html","id":"blackman-window-window-length-periodic-true-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"blackman_window(window_length, periodic=TRUE, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Blackman_window — torch_blackman_window","text":"Blackman window function. $$     w[n] = 0.42 - 0.5 \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right) + 0.08 \\cos \\left( \\frac{4 \\pi n}{N - 1} \\right) $$ \\(N\\) full window size. input window_length positive integer controlling returned window size. periodic flag determines whether returned window trims last duplicate value symmetric window ready used periodic window functions like torch_stft. Therefore, periodic true, \\(N\\) formula fact \\(\\mbox{window\\_length} + 1\\). Also, always torch_blackman_window(L, periodic=TRUE) equal torch_blackman_window(L + 1, periodic=False)[:-1]).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_block_diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Block_diag — torch_block_diag","title":"Block_diag — torch_block_diag","text":"Create block diagonal matrix provided tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_block_diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block_diag — torch_block_diag","text":"","code":"torch_block_diag(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_block_diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block_diag — torch_block_diag","text":"tensors (list tensors) One tensors 0, 1, 2 dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_block_diag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block_diag — torch_block_diag","text":"","code":"if (torch_is_installed()) {  A <- torch_tensor(rbind(c(0, 1), c(1, 0))) B <- torch_tensor(rbind(c(3, 4, 5), c(6, 7, 8))) C <- torch_tensor(7) D <- torch_tensor(c(1, 2, 3)) E <- torch_tensor(rbind(4, 5, 6)) torch_block_diag(list(A, B, C, D, E)) } #> torch_tensor #>  0  1  0  0  0  0  0  0  0  0 #>  1  0  0  0  0  0  0  0  0  0 #>  0  0  3  4  5  0  0  0  0  0 #>  0  0  6  7  8  0  0  0  0  0 #>  0  0  0  0  0  7  0  0  0  0 #>  0  0  0  0  0  0  1  2  3  0 #>  0  0  0  0  0  0  0  0  0  4 #>  0  0  0  0  0  0  0  0  0  5 #>  0  0  0  0  0  0  0  0  0  6 #> [ CPUFloatType{9,10} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Bmm — torch_bmm","title":"Bmm — torch_bmm","text":"Bmm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bmm — torch_bmm","text":"","code":"torch_bmm(self, mat2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bmm — torch_bmm","text":"self (Tensor) first batch matrices multiplied mat2 (Tensor) second batch matrices multiplied","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Bmm — torch_bmm","text":"function broadcast . broadcasting matrix products, see torch_matmul.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":"bmm-input-mat-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"bmm(input, mat2, out=NULL) -> Tensor","title":"Bmm — torch_bmm","text":"Performs batch matrix-matrix product matrices stored input mat2. input mat2 must 3-D tensors containing number matrices. input \\((b \\times n \\times m)\\) tensor, mat2 \\((b \\times m \\times p)\\) tensor, \\((b \\times n \\times p)\\) tensor. $$     \\mbox{}_i = \\mbox{input}_i \\mathbin{@} \\mbox{mat2}_i $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bmm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bmm — torch_bmm","text":"","code":"if (torch_is_installed()) {  input = torch_randn(c(10, 3, 4)) mat2 = torch_randn(c(10, 4, 5)) res = torch_bmm(input, mat2) res } #> torch_tensor #> (1,.,.) =  #>  -1.7765 -0.1350  0.8466  0.8478 -0.7594 #>   1.6370 -0.2408  0.3351  2.2860 -0.6668 #>   1.9089  0.2050 -1.6219 -2.5549  1.7960 #>  #> (2,.,.) =  #>  -1.8824  2.0253 -2.1206 -1.3713  0.0871 #>   2.8014 -0.8317 -0.6866 -1.2809  2.3431 #>   0.1755 -3.8833  0.2988  7.5040 -3.6713 #>  #> (3,.,.) =  #>   0.8480 -0.0850  1.4366  2.9513 -0.3949 #>  -0.9064 -0.8385  1.3575 -7.3166 -7.2062 #>   0.5430 -0.3684  0.4283  0.9606  2.1168 #>  #> (4,.,.) =  #>  -2.3839  1.7347  1.1756 -1.6514  0.6408 #>   1.6447 -1.2290  1.8483  1.1605 -3.7812 #>   1.8861  0.1105  0.4390  1.3200 -0.8549 #>  #> (5,.,.) =  #>   0.4684  1.1384  1.3886  1.1070 -1.7678 #>   3.1111  0.6010  1.0678 -0.0603 -2.4754 #>   1.0265 -0.3575  0.2944 -1.0106 -2.2023 #>  #> (6,.,.) =  #>   0.3164 -1.3392  0.5580 -1.6123  5.0994 #>   1.6859 -1.7957 -0.2757  0.7590  0.4473 #>  -0.4207  0.6214  0.0980  0.1298 -0.7558 #>  #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{10,3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_broadcast_tensors.html","id":null,"dir":"Reference","previous_headings":"","what":"Broadcast_tensors — torch_broadcast_tensors","title":"Broadcast_tensors — torch_broadcast_tensors","text":"Broadcast_tensors","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_broadcast_tensors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Broadcast_tensors — torch_broadcast_tensors","text":"","code":"torch_broadcast_tensors(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_broadcast_tensors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Broadcast_tensors — torch_broadcast_tensors","text":"tensors list containing number tensors type","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_broadcast_tensors.html","id":"broadcast-tensors-tensors-gt-list-of-tensors-","dir":"Reference","previous_headings":"","what":"broadcast_tensors(tensors) -> List of Tensors","title":"Broadcast_tensors — torch_broadcast_tensors","text":"Broadcasts given tensors according broadcasting-semantics.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_broadcast_tensors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Broadcast_tensors — torch_broadcast_tensors","text":"","code":"if (torch_is_installed()) {  x = torch_arange(0, 3)$view(c(1, 4)) y = torch_arange(0, 2)$view(c(3, 1)) out = torch_broadcast_tensors(list(x, y)) out[[1]] } #> torch_tensor #>  0  1  2  3 #>  0  1  2  3 #>  0  1  2  3 #> [ CPUFloatType{3,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_bucketize.html","id":null,"dir":"Reference","previous_headings":"","what":"Bucketize — torch_bucketize","title":"Bucketize — torch_bucketize","text":"Bucketize","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bucketize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bucketize — torch_bucketize","text":"","code":"torch_bucketize(self, boundaries, out_int32 = FALSE, right = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_bucketize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bucketize — torch_bucketize","text":"self (Tensor Scalar) N-D tensor Scalar containing search value(s). boundaries (Tensor) 1-D tensor, must contain monotonically increasing sequence. out_int32 (bool, optional) – indicate output data type. torch_int32() True, torch_int64() otherwise. Default value FALSE, .e. default output data type torch_int64(). right (bool, optional) – False, return first suitable location found. True, return last index. suitable index found, return 0 non-numerical value (eg. nan, inf) size boundaries (one pass last index). words, False, gets lower bound index value input boundaries. True, gets upper bound index instead. Default value False.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bucketize.html","id":"bucketize-input-boundaries-out-int-false-right-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"bucketize(input, boundaries, *, out_int32=FALSE, right=FALSE, out=None) -> Tensor","title":"Bucketize — torch_bucketize","text":"Returns indices buckets value input belongs, boundaries buckets set boundaries. Return new tensor size input. right FALSE (default), left boundary closed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_bucketize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bucketize — torch_bucketize","text":"","code":"if (torch_is_installed()) {  boundaries <- torch_tensor(c(1, 3, 5, 7, 9)) boundaries v <- torch_tensor(rbind(c(3, 6, 9), c(3, 6, 9))) v torch_bucketize(v, boundaries) torch_bucketize(v, boundaries, right=TRUE) } #> torch_tensor #>  2  3  5 #>  2  3  5 #> [ CPULongType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_can_cast.html","id":null,"dir":"Reference","previous_headings":"","what":"Can_cast — torch_can_cast","title":"Can_cast — torch_can_cast","text":"Can_cast","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_can_cast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Can_cast — torch_can_cast","text":"","code":"torch_can_cast(from, to)"},{"path":"https://torch.mlverse.org/docs/reference/torch_can_cast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Can_cast — torch_can_cast","text":"(dtype) original torch_dtype. (dtype) target torch_dtype.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_can_cast.html","id":"can-cast-from-to-gt-bool-","dir":"Reference","previous_headings":"","what":"can_cast(from, to) -> bool","title":"Can_cast — torch_can_cast","text":"Determines type conversion allowed PyTorch casting rules described type promotion documentation .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_can_cast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Can_cast — torch_can_cast","text":"","code":"if (torch_is_installed()) {  torch_can_cast(torch_double(), torch_float()) torch_can_cast(torch_float(), torch_int()) } #> [1] FALSE"},{"path":"https://torch.mlverse.org/docs/reference/torch_cartesian_prod.html","id":null,"dir":"Reference","previous_headings":"","what":"Cartesian_prod — torch_cartesian_prod","title":"Cartesian_prod — torch_cartesian_prod","text":"cartesian product given sequence tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cartesian_prod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cartesian_prod — torch_cartesian_prod","text":"","code":"torch_cartesian_prod(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cartesian_prod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cartesian_prod — torch_cartesian_prod","text":"tensors list containing number 1 dimensional tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cartesian_prod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cartesian_prod — torch_cartesian_prod","text":"","code":"if (torch_is_installed()) {  a = c(1, 2, 3) b = c(4, 5) tensor_a = torch_tensor(a) tensor_b = torch_tensor(b) torch_cartesian_prod(list(tensor_a, tensor_b)) } #> torch_tensor #>  1  4 #>  1  5 #>  2  4 #>  2  5 #>  3  4 #>  3  5 #> [ CPUFloatType{6,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Cat — torch_cat","title":"Cat — torch_cat","text":"Cat","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cat — torch_cat","text":"","code":"torch_cat(tensors, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cat — torch_cat","text":"tensors (sequence Tensors) python sequence tensors type.        Non-empty tensors provided must shape, except        cat dimension. dim (int, optional) dimension tensors concatenated","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cat.html","id":"cat-tensors-dim-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cat(tensors, dim=0, out=NULL) -> Tensor","title":"Cat — torch_cat","text":"Concatenates given sequence seq tensors given dimension. tensors must either shape (except concatenating dimension) empty. torch_cat can seen inverse operation torch_split() torch_chunk. torch_cat can best understood via examples.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cat — torch_cat","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(2, 3)) x torch_cat(list(x, x, x), 1) torch_cat(list(x, x, x), 2) } #> torch_tensor #>  0.3147 -0.6072 -1.1446  0.3147 -0.6072 -1.1446  0.3147 -0.6072 -1.1446 #> -0.2502  0.6148  0.3265 -0.2502  0.6148  0.3265 -0.2502  0.6148  0.3265 #> [ CPUFloatType{2,9} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cdist.html","id":null,"dir":"Reference","previous_headings":"","what":"Cdist — torch_cdist","title":"Cdist — torch_cdist","text":"Cdist","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cdist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cdist — torch_cdist","text":"","code":"torch_cdist(x1, x2, p = 2L, compute_mode = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cdist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cdist — torch_cdist","text":"x1 (Tensor) input tensor shape \\(B \\times P \\times M\\). x2 (Tensor) input tensor shape \\(B \\times R \\times M\\). p NA p value p-norm distance calculate vector pair        \\(\\[0, \\infty]\\). compute_mode NA 'use_mm_for_euclid_dist_if_necessary' - use matrix multiplication approach calculate        euclidean distance (p = 2) P > 25 R > 25        'use_mm_for_euclid_dist' - always use matrix multiplication approach calculate        euclidean distance (p = 2)        'donot_use_mm_for_euclid_dist' - never use matrix multiplication approach calculate        euclidean distance (p = 2)        Default: use_mm_for_euclid_dist_if_necessary.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cdist.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Cdist — torch_cdist","text":"Computes batched p-norm distance pair two collections row vectors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ceil.html","id":null,"dir":"Reference","previous_headings":"","what":"Ceil — torch_ceil","title":"Ceil — torch_ceil","text":"Ceil","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ceil.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ceil — torch_ceil","text":"","code":"torch_ceil(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_ceil.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ceil — torch_ceil","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ceil.html","id":"ceil-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"ceil(input, out=NULL) -> Tensor","title":"Ceil — torch_ceil","text":"Returns new tensor ceil elements input, smallest integer greater equal element. $$     \\mbox{}_{} = \\left\\lceil \\mbox{input}_{} \\right\\rceil = \\left\\lfloor \\mbox{input}_{} \\right\\rfloor + 1 $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ceil.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ceil — torch_ceil","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_ceil(a) } #> torch_tensor #> -1 #>  1 #> -1 #>  1 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_celu.html","id":null,"dir":"Reference","previous_headings":"","what":"Celu — torch_celu","title":"Celu — torch_celu","text":"Celu","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_celu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Celu — torch_celu","text":"","code":"torch_celu(self, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_celu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Celu — torch_celu","text":"self input tensor alpha alpha value CELU formulation. Default: 1.0","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_celu.html","id":"celu-input-alpha-gt-tensor-","dir":"Reference","previous_headings":"","what":"celu(input, alpha=1.) -> Tensor","title":"Celu — torch_celu","text":"See nnf_celu() info.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_celu_.html","id":null,"dir":"Reference","previous_headings":"","what":"Celu_ — torch_celu_","title":"Celu_ — torch_celu_","text":"Celu_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_celu_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Celu_ — torch_celu_","text":"","code":"torch_celu_(self, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_celu_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Celu_ — torch_celu_","text":"self input tensor alpha alpha value CELU formulation. Default: 1.0","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_celu_.html","id":"celu-input-alpha-gt-tensor-","dir":"Reference","previous_headings":"","what":"celu_(input, alpha=1.) -> Tensor","title":"Celu_ — torch_celu_","text":"-place version torch_celu().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chain_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Chain_matmul — torch_chain_matmul","title":"Chain_matmul — torch_chain_matmul","text":"Chain_matmul","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chain_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chain_matmul — torch_chain_matmul","text":"","code":"torch_chain_matmul(matrices)"},{"path":"https://torch.mlverse.org/docs/reference/torch_chain_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chain_matmul — torch_chain_matmul","text":"matrices (Tensors...) sequence 2 2-D tensors whose product determined.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chain_matmul.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Chain_matmul — torch_chain_matmul","text":"Returns matrix product \\(N\\) 2-D tensors. product efficiently computed using matrix chain order algorithm selects order incurs lowest cost terms arithmetic operations ([CLRS]_). Note since function compute product, \\(N\\) needs greater equal 2; equal 2 trivial matrix-matrix product returned. \\(N\\) 1, -op - original matrix returned .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chain_matmul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chain_matmul — torch_chain_matmul","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 4)) b = torch_randn(c(4, 5)) c = torch_randn(c(5, 6)) d = torch_randn(c(6, 7)) torch_chain_matmul(list(a, b, c, d)) } #> torch_tensor #>  -4.9114  11.1095  -3.5044  14.9431  17.5463  -4.6954  -8.2067 #>  -4.2924   2.9680  -1.0878   3.3883   7.5599  -2.4557  -3.2995 #>   5.2357  -3.2431   5.0502  -2.0051  -8.0577  -1.0972   1.1601 #> [ CPUFloatType{3,7} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_channel_shuffle.html","id":null,"dir":"Reference","previous_headings":"","what":"Channel_shuffle — torch_channel_shuffle","title":"Channel_shuffle — torch_channel_shuffle","text":"Channel_shuffle","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_channel_shuffle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Channel_shuffle — torch_channel_shuffle","text":"","code":"torch_channel_shuffle(self, groups)"},{"path":"https://torch.mlverse.org/docs/reference/torch_channel_shuffle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Channel_shuffle — torch_channel_shuffle","text":"self (Tensor) input tensor groups (int) number groups divide channels rearrange.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_channel_shuffle.html","id":"divide-the-channels-in-a-tensor-of-shape-","dir":"Reference","previous_headings":"","what":"Divide the channels in a tensor of shape","title":"Channel_shuffle — torch_channel_shuffle","text":"math:(*, C , H, W) : Divide channels tensor shape \\((*, C , H, W)\\) g groups rearrange \\((*, C \\frac g, g, H, W)\\), keeping original tensor shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_channel_shuffle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Channel_shuffle — torch_channel_shuffle","text":"","code":"if (torch_is_installed()) {  input <- torch_randn(c(1, 4, 2, 2)) print(input) output <- torch_channel_shuffle(input, 2) print(output) } #> torch_tensor #> (1,1,.,.) =  #>  -1.7996 -0.4875 #>  -0.1402  0.6430 #>  #> (1,2,.,.) =  #>   1.6013 -2.8596 #>   0.6372  0.1704 #>  #> (1,3,.,.) =  #>  -0.8334  1.1602 #>   0.2836  0.8798 #>  #> (1,4,.,.) =  #>   0.5182 -1.2047 #>   0.9831  0.0413 #> [ CPUFloatType{1,4,2,2} ] #> torch_tensor #> (1,1,.,.) =  #>  -1.7996 -0.4875 #>  -0.1402  0.6430 #>  #> (1,2,.,.) =  #>  -0.8334  1.1602 #>   0.2836  0.8798 #>  #> (1,3,.,.) =  #>   1.6013 -2.8596 #>   0.6372  0.1704 #>  #> (1,4,.,.) =  #>   0.5182 -1.2047 #>   0.9831  0.0413 #> [ CPUFloatType{1,4,2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky.html","id":null,"dir":"Reference","previous_headings":"","what":"Cholesky — torch_cholesky","title":"Cholesky — torch_cholesky","text":"Cholesky","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cholesky — torch_cholesky","text":"","code":"torch_cholesky(self, upper = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cholesky — torch_cholesky","text":"self (Tensor) input tensor \\(\\) size \\((*, n, n)\\) * zero batch dimensions consisting symmetric positive-definite matrices. upper (bool, optional) flag indicates whether return upper lower triangular matrix. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky.html","id":"cholesky-input-upper-false-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cholesky(input, upper=False, out=NULL) -> Tensor","title":"Cholesky — torch_cholesky","text":"Computes Cholesky decomposition symmetric positive-definite matrix \\(\\) batches symmetric positive-definite matrices. upper TRUE, returned matrix U upper-triangular, decomposition form: $$   = U^TU $$ upper FALSE, returned matrix L lower-triangular, decomposition form: $$     = LL^T $$ upper TRUE, \\(\\) batch symmetric positive-definite matrices, returned tensor composed upper-triangular Cholesky factors individual matrices. Similarly, upper FALSE, returned tensor composed lower-triangular Cholesky factors individual matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cholesky — torch_cholesky","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) a = torch_mm(a, a$t()) # make symmetric positive-definite l = torch_cholesky(a) a l torch_mm(l, l$t()) a = torch_randn(c(3, 2, 2)) if (FALSE) { a = torch_matmul(a, a$transpose(-1, -2)) + 1e-03 # make symmetric positive-definite l = torch_cholesky(a) z = torch_matmul(l, l$transpose(-1, -2)) torch_max(torch_abs(z - a)) # Max non-zero } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_inverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Cholesky_inverse — torch_cholesky_inverse","title":"Cholesky_inverse — torch_cholesky_inverse","text":"Cholesky_inverse","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_inverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cholesky_inverse — torch_cholesky_inverse","text":"","code":"torch_cholesky_inverse(self, upper = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_inverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cholesky_inverse — torch_cholesky_inverse","text":"self (Tensor) input 2-D tensor \\(u\\), upper lower triangular           Cholesky factor upper (bool, optional) whether return lower (default) upper triangular matrix","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_inverse.html","id":"cholesky-inverse-input-upper-false-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cholesky_inverse(input, upper=False, out=NULL) -> Tensor","title":"Cholesky_inverse — torch_cholesky_inverse","text":"Computes inverse symmetric positive-definite matrix \\(\\) using Cholesky factor \\(u\\): returns matrix inv. inverse computed using LAPACK routines dpotri spotri (corresponding MAGMA routines). upper FALSE, \\(u\\) lower triangular returned tensor $$     inv = (uu^{{T}})^{{-1}} $$ upper TRUE provided, \\(u\\) upper triangular returned tensor $$     inv = (u^T u)^{{-1}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_inverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cholesky_inverse — torch_cholesky_inverse","text":"","code":"if (torch_is_installed()) {  if (FALSE) { a = torch_randn(c(3, 3)) a = torch_mm(a, a$t()) + 1e-05 * torch_eye(3) # make symmetric positive definite u = torch_cholesky(a) a torch_cholesky_inverse(u) a$inverse() } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Cholesky_solve — torch_cholesky_solve","title":"Cholesky_solve — torch_cholesky_solve","text":"Cholesky_solve","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cholesky_solve — torch_cholesky_solve","text":"","code":"torch_cholesky_solve(self, input2, upper = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cholesky_solve — torch_cholesky_solve","text":"self (Tensor) input matrix \\(b\\) size \\((*, m, k)\\),                \\(*\\) zero batch dimensions input2 (Tensor) input matrix \\(u\\) size \\((*, m, m)\\),                \\(*\\) zero batch dimensions composed                upper lower triangular Cholesky factor upper (bool, optional) whether consider Cholesky factor                            lower upper triangular matrix. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_solve.html","id":"cholesky-solve-input-input-upper-false-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cholesky_solve(input, input2, upper=False, out=NULL) -> Tensor","title":"Cholesky_solve — torch_cholesky_solve","text":"Solves linear system equations positive semidefinite matrix inverted given Cholesky factor matrix \\(u\\). upper FALSE, \\(u\\) lower triangular c returned : $$     c = (u u^T)^{{-1}} b $$ upper TRUE provided, \\(u\\) upper triangular c returned : $$     c = (u^T u)^{{-1}} b $$ torch_cholesky_solve(b, u) can take 2D inputs b, u inputs batches 2D matrices. inputs batches, returns batched outputs c","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cholesky_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cholesky_solve — torch_cholesky_solve","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) a = torch_mm(a, a$t()) # make symmetric positive definite u = torch_cholesky(a) a b = torch_randn(c(3, 2)) b torch_cholesky_solve(b, u) torch_mm(a$inverse(), b) } #> torch_tensor #>  5.7628  2.1661 #>  1.8217  0.5086 #> -6.3133 -1.1261 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Chunk — torch_chunk","title":"Chunk — torch_chunk","text":"Chunk","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chunk — torch_chunk","text":"","code":"torch_chunk(self, chunks, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chunk — torch_chunk","text":"self (Tensor) tensor split chunks (int) number chunks return dim (int) dimension along split tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_chunk.html","id":"chunk-input-chunks-dim-gt-list-of-tensors-","dir":"Reference","previous_headings":"","what":"chunk(input, chunks, dim=0) -> List of Tensors","title":"Chunk — torch_chunk","text":"Splits tensor specific number chunks. chunk view input tensor. Last chunk smaller tensor size along given dimension dim divisible chunks.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":null,"dir":"Reference","previous_headings":"","what":"Clamp — torch_clamp","title":"Clamp — torch_clamp","text":"Clamp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clamp — torch_clamp","text":"","code":"torch_clamp(self, min = NULL, max = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clamp — torch_clamp","text":"self (Tensor) input tensor. min (Number) lower-bound range clamped max (Number) upper-bound range clamped ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"clamp-input-min-max-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"clamp(input, min, max, out=NULL) -> Tensor","title":"Clamp — torch_clamp","text":"Clamp elements input range [ min, max ] return resulting tensor: $$     y_i = \\left\\{ \\begin{array}{ll}         \\mbox{min} & \\mbox{} x_i < \\mbox{min} \\\\         x_i & \\mbox{} \\mbox{min} \\leq x_i \\leq \\mbox{max} \\\\         \\mbox{max} & \\mbox{} x_i > \\mbox{max}     \\end{array}     \\right. $$ input type FloatTensor DoubleTensor, args min max must real numbers, otherwise integers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"clamp-input-min-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"clamp(input, *, min, out=NULL) -> Tensor","title":"Clamp — torch_clamp","text":"Clamps elements input larger equal min. input type FloatTensor DoubleTensor, value real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"clamp-input-max-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"clamp(input, *, max, out=NULL) -> Tensor","title":"Clamp — torch_clamp","text":"Clamps elements input smaller equal max. input type FloatTensor DoubleTensor, value real number, otherwise integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clamp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clamp — torch_clamp","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_clamp(a, min=-0.5, max=0.5)   a = torch_randn(c(4)) a torch_clamp(a, min=0.5)   a = torch_randn(c(4)) a torch_clamp(a, max=0.5) } #> torch_tensor #> -0.3931 #>  0.5000 #> -0.3415 #> -0.5366 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_clip.html","id":null,"dir":"Reference","previous_headings":"","what":"Clip — torch_clip","title":"Clip — torch_clip","text":"Clip","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clip — torch_clip","text":"","code":"torch_clip(self, min = NULL, max = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_clip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clip — torch_clip","text":"self (Tensor) input tensor. min (Number) lower-bound range clamped max (Number) upper-bound range clamped ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clip.html","id":"clip-input-min-max-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"clip(input, min, max, *, out=None) -> Tensor","title":"Clip — torch_clip","text":"Alias torch_clamp().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clone.html","id":null,"dir":"Reference","previous_headings":"","what":"Clone — torch_clone","title":"Clone — torch_clone","text":"Clone","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clone.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clone — torch_clone","text":"","code":"torch_clone(self, memory_format = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_clone.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clone — torch_clone","text":"self (Tensor) input tensor. memory_format torch memory format. see torch_preserve_format().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clone.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Clone — torch_clone","text":"function differentiable, gradients flow back result operation input. create tensor without autograd relationship input see Tensor$detach.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_clone.html","id":"clone-input-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"clone(input, *, memory_format=torch.preserve_format) -> Tensor","title":"Clone — torch_clone","text":"Returns copy input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_combinations.html","id":null,"dir":"Reference","previous_headings":"","what":"Combinations — torch_combinations","title":"Combinations — torch_combinations","text":"Combinations","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_combinations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combinations — torch_combinations","text":"","code":"torch_combinations(self, r = 2L, with_replacement = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_combinations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combinations — torch_combinations","text":"self (Tensor) 1D vector. r (int, optional) number elements combine with_replacement (boolean, optional) whether allow duplication combination","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_combinations.html","id":"combinations-input-r-with-replacement-false-gt-seq-","dir":"Reference","previous_headings":"","what":"combinations(input, r=2, with_replacement=False) -> seq","title":"Combinations — torch_combinations","text":"Compute combinations length \\(r\\) given tensor. behavior similar python's itertools.combinations with_replacement set False, itertools.combinations_with_replacement with_replacement set TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_combinations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combinations — torch_combinations","text":"","code":"if (torch_is_installed()) {  a = c(1, 2, 3) tensor_a = torch_tensor(a) torch_combinations(tensor_a) torch_combinations(tensor_a, r=3) torch_combinations(tensor_a, with_replacement=TRUE) } #> torch_tensor #>  1  1 #>  1  2 #>  1  3 #>  2  2 #>  2  3 #>  3  3 #> [ CPUFloatType{6,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_complex.html","id":null,"dir":"Reference","previous_headings":"","what":"Complex — torch_complex","title":"Complex — torch_complex","text":"Complex","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_complex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Complex — torch_complex","text":"","code":"torch_complex(real, imag)"},{"path":"https://torch.mlverse.org/docs/reference/torch_complex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Complex — torch_complex","text":"real (Tensor) real part complex tensor. Must float double. imag (Tensor) imaginary part complex tensor. Must dtype real.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_complex.html","id":"complex-real-imag-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"complex(real, imag, *, out=None) -> Tensor","title":"Complex — torch_complex","text":"Constructs complex tensor real part equal real imaginary part equal imag.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_complex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Complex — torch_complex","text":"","code":"if (torch_is_installed()) {  real <- torch_tensor(c(1, 2), dtype=torch_float32()) imag <- torch_tensor(c(3, 4), dtype=torch_float32()) z <- torch_complex(real, imag) z z$dtype } #> torch_ComplexFloat"},{"path":"https://torch.mlverse.org/docs/reference/torch_conj.html","id":null,"dir":"Reference","previous_headings":"","what":"Conj — torch_conj","title":"Conj — torch_conj","text":"Conj","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conj — torch_conj","text":"","code":"torch_conj(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_conj.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conj — torch_conj","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conj.html","id":"conj-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"conj(input) -> Tensor","title":"Conj — torch_conj","text":"Computes element-wise conjugate given input tensor. $$     \\mbox{}_{} = conj(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conj.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conj — torch_conj","text":"","code":"if (torch_is_installed()) { if (FALSE) { torch_conj(torch_tensor(c(-1 + 1i, -2 + 2i, 3 - 3i))) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv1d — torch_conv1d","title":"Conv1d — torch_conv1d","text":"Conv1d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv1d — torch_conv1d","text":"","code":"torch_conv1d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   dilation = 1L,   groups = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv1d — torch_conv1d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kW)\\) bias optional bias shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      one-element tuple (sW,). Default: 1 padding implicit paddings sides input. Can      single number one-element tuple (padW,). Default: 0 dilation spacing kernel elements. Can single number      one-element tuple (dW,). Default: 1 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv1d.html","id":"conv-d-input-weight-bias-null-stride-padding-dilation-groups-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv1d(input, weight, bias=NULL, stride=1, padding=0, dilation=1, groups=1) -> Tensor","title":"Conv1d — torch_conv1d","text":"Applies 1D convolution input signal composed several input planes. See nn_conv1d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv1d — torch_conv1d","text":"","code":"if (torch_is_installed()) {  filters = torch_randn(c(33, 16, 3)) inputs = torch_randn(c(20, 16, 50)) nnf_conv1d(inputs, filters) } #> torch_tensor #> (1,.,.) =  #>  Columns 1 to 6 -8.3169e+00 -2.1014e+00 -5.1744e+00  4.7219e+00 -7.2245e+00 -3.7793e+00 #>  -2.3550e+00  3.5967e-01 -5.9571e+00  1.9716e+00 -2.8001e+00  9.2921e+00 #>  -2.9458e+00  7.0693e+00 -2.3263e+00 -4.4576e+00 -3.0706e+00 -3.6137e+00 #>   7.6318e+00  7.6674e+00  6.7905e-01 -1.0191e+00  2.8939e+00  3.7213e+00 #>   3.5952e+00 -1.5817e+01  9.1722e+00  8.3184e-01  1.4853e+00 -1.3252e+00 #>   4.0351e+00  4.5588e-01  4.6643e+00 -5.1794e+00  2.4778e+00 -3.6634e+00 #>  -7.6635e+00  2.3136e+00  1.3166e+00  1.3124e+00 -3.7686e+00 -1.1524e+01 #>  -4.7977e+00  3.8666e+00  7.2739e+00 -1.3060e+01 -1.6958e+00  9.6115e+00 #>  -1.3698e+01 -6.0547e+00  1.0270e+01  1.7839e+01 -4.4191e+00 -5.6308e+00 #>   1.7233e+00 -2.1186e+00 -1.1272e+00 -4.6070e+00 -1.3363e+00  1.4993e+01 #>   4.1939e+00 -1.2392e+01  3.6945e+00  7.5041e+00  7.6516e+00 -7.6661e+00 #>   4.6416e+00 -8.4228e+00 -2.2767e+00  1.5158e+00  6.5058e+00 -7.3223e-01 #>   1.9778e+00 -2.0790e+00  1.6602e+00  9.3931e+00  2.3396e+00  1.5080e+01 #>   5.6369e+00 -4.9868e+00  8.2276e+00 -1.1036e+01  3.5321e+00  2.3121e+00 #>   1.8445e+00 -9.2048e-01 -4.2860e+00 -5.7858e+00 -2.1423e+00  1.3416e+01 #>  -8.5335e-01 -9.2716e+00 -4.5451e+00 -5.0947e+00  3.1179e-01  5.0687e-01 #>   2.1218e+00  3.3808e+00  6.7575e-02  1.9638e+00 -6.4383e-02  4.6061e+00 #>  -9.4345e+00 -1.2909e+01  4.5463e+00  5.7057e+00  7.9532e+00  1.0342e+00 #>   2.0564e+01  3.4541e+00  5.7038e-01 -1.0550e+01  6.2890e+00  2.9685e+00 #>   8.4836e+00  1.0381e+01 -4.9445e+00 -6.4267e-01 -8.5755e+00  3.4221e+00 #>   7.6088e-01  8.3236e+00 -9.5267e+00  4.5688e-01 -2.2607e+00  7.8716e+00 #>   7.3898e+00 -4.1470e+00  1.9449e+00 -1.8083e+00  1.9612e-01  1.6873e+00 #>  -4.0546e+00  3.4497e+00 -3.6739e+00  3.2975e+00 -4.9923e+00  6.4785e+00 #>   1.0131e+01  1.1753e+00 -9.1447e+00 -6.6979e+00  2.5119e+00  3.9920e+00 #>   2.9422e+00  1.0326e+01 -1.5198e+00 -1.6618e+00 -1.2997e+01 -1.6538e+01 #>  -4.5410e+00  1.7281e+00  2.8887e+00  7.1734e+00 -1.5699e-02  1.3118e+00 #>  -1.5259e+00 -5.7793e+00  1.5204e+00 -4.8937e-04 -1.0205e+00 -4.2960e+00 #>   2.3303e+00  6.4505e+00 -5.2870e+00  6.7430e-01 -1.5892e+00  1.6843e+01 #>   4.7452e+00 -3.9635e+00 -6.0927e+00  4.8368e+00 -1.0148e+00 -1.2588e+01 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{20,33,48} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv2d — torch_conv2d","title":"Conv2d — torch_conv2d","text":"Conv2d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv2d — torch_conv2d","text":"","code":"torch_conv2d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   dilation = 1L,   groups = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv2d — torch_conv2d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , iH , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kH , kW)\\) bias optional bias tensor shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      tuple (sH, sW). Default: 1 padding implicit paddings sides input. Can      single number tuple (padH, padW). Default: 0 dilation spacing kernel elements. Can single number      tuple (dH, dW). Default: 1 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv2d.html","id":"conv-d-input-weight-bias-null-stride-padding-dilation-groups-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv2d(input, weight, bias=NULL, stride=1, padding=0, dilation=1, groups=1) -> Tensor","title":"Conv2d — torch_conv2d","text":"Applies 2D convolution input image composed several input planes. See nn_conv2d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv2d — torch_conv2d","text":"","code":"if (torch_is_installed()) {  # With square kernels and equal stride filters = torch_randn(c(8,4,3,3)) inputs = torch_randn(c(1,4,5,5)) nnf_conv2d(inputs, filters, padding=1) } #> torch_tensor #> (1,1,.,.) =  #>  -6.2293  3.6368 -6.9950 -3.2092  4.0164 #>   4.4499  5.6002  5.9233  0.9858  4.2309 #>  -5.9799 -12.2515 -1.1408  5.2784  4.7481 #>   3.5944  0.3573  1.3755 -0.4545 -0.4302 #>   4.4743  3.5464  2.9807  3.5504  3.6378 #>  #> (1,2,.,.) =  #>  -14.1458  -2.4284  -1.6412  -4.7466  -0.5833 #>   -2.7556  -2.9063 -13.3437  -1.0216   0.0556 #>    8.1979  -9.5774  -2.3079  -9.8105  -6.1516 #>   -3.3297   1.0058   3.2910  -4.9661 -10.2056 #>   -2.9389   7.1504  -4.6618   3.7112   0.9689 #>  #> (1,3,.,.) =  #>   2.0213  4.8348 -0.0753 -5.5559  2.1641 #>   7.3397  5.3186 -0.5203 -10.4046 -2.4127 #>  -2.8926 -5.7183  7.3088  1.4437 -0.2859 #>  -0.1150  1.8809 -4.1334  4.5544  1.0229 #>  -4.4993  0.7790 -2.1356  1.6472 -3.0782 #>  #> (1,4,.,.) =  #>   -8.0488   0.3474   9.3235  -1.6900  -3.2958 #>   -8.0323  -9.7287  -6.8925   4.5854  10.4326 #>   10.2315 -12.7851  -6.9631 -11.5428  -1.7736 #>    1.9657   0.0843  -5.3749  -8.2050  -2.8523 #>   -1.6009   3.4971   2.5930   0.7100   5.0198 #>  #> (1,5,.,.) =  #>   -3.1366   2.1507  -1.2642   1.5051  -3.3853 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{1,8,5,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv3d — torch_conv3d","title":"Conv3d — torch_conv3d","text":"Conv3d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv3d — torch_conv3d","text":"","code":"torch_conv3d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   dilation = 1L,   groups = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv3d — torch_conv3d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , , iH , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kT , kH , kW)\\) bias optional bias tensor shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      tuple (sT, sH, sW). Default: 1 padding implicit paddings sides input. Can      single number tuple (padT, padH, padW). Default: 0 dilation spacing kernel elements. Can single number      tuple (dT, dH, dW). Default: 1 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv3d.html","id":"conv-d-input-weight-bias-null-stride-padding-dilation-groups-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv3d(input, weight, bias=NULL, stride=1, padding=0, dilation=1, groups=1) -> Tensor","title":"Conv3d — torch_conv3d","text":"Applies 3D convolution input image composed several input planes. See nn_conv3d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv3d — torch_conv3d","text":"","code":"if (torch_is_installed()) {  # filters = torch_randn(c(33, 16, 3, 3, 3)) # inputs = torch_randn(c(20, 16, 50, 10, 20)) # nnf_conv3d(inputs, filters) } #> NULL"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_tbc.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_tbc — torch_conv_tbc","title":"Conv_tbc — torch_conv_tbc","text":"Conv_tbc","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_tbc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_tbc — torch_conv_tbc","text":"","code":"torch_conv_tbc(self, weight, bias, pad = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_tbc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_tbc — torch_conv_tbc","text":"self NA input tensor shape \\((\\mbox{sequence length} \\times batch \\times \\mbox{\\_channels})\\) weight NA filter shape (\\(\\mbox{kernel width} \\times \\mbox{\\_channels} \\times \\mbox{\\_channels}\\)) bias NA bias shape (\\(\\mbox{\\_channels}\\)) pad NA number timesteps pad. Default: 0","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_tbc.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Conv_tbc — torch_conv_tbc","text":"Applies 1-dimensional sequence convolution input sequence. Input output dimensions (Time, Batch, Channels) - hence TBC.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose1d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose1d — torch_conv_transpose1d","title":"Conv_transpose1d — torch_conv_transpose1d","text":"Conv_transpose1d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose1d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose1d — torch_conv_transpose1d","text":"","code":"torch_conv_transpose1d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   output_padding = 0L,   groups = 1L,   dilation = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose1d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose1d — torch_conv_transpose1d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kW)\\) bias optional bias shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      tuple (sW,). Default: 1 padding dilation * (kernel_size - 1) - padding zero-padding added      sides dimension input. Can single number tuple      (padW,). Default: 0 output_padding additional size added one side dimension      output shape. Can single number tuple (out_padW). Default: 0 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1 dilation spacing kernel elements. Can single number      tuple (dW,). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose1d.html","id":"conv-transpose-d-input-weight-bias-null-stride-padding-output-padding-groups-dilation-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv_transpose1d(input, weight, bias=NULL, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor","title":"Conv_transpose1d — torch_conv_transpose1d","text":"Applies 1D transposed convolution operator input signal composed several input planes, sometimes also called \"deconvolution\". See nn_conv_transpose1d()  details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose1d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv_transpose1d — torch_conv_transpose1d","text":"","code":"if (torch_is_installed()) {  inputs = torch_randn(c(20, 16, 50)) weights = torch_randn(c(16, 33, 5)) nnf_conv_transpose1d(inputs, weights) } #> torch_tensor #> (1,.,.) =  #>  Columns 1 to 8  -4.1502   5.2662   1.2746  -3.9347   2.2134   7.8490  -1.4314   5.7363 #>   -5.8787  -3.6590  -5.1717  -6.2001  12.6397  13.7569   6.9527   0.8596 #>   -1.2104   0.7274   0.4443  -5.9108   7.5095  -6.3658  -6.4068  13.9326 #>   -5.9152  -6.9704   7.5327   3.7642  -1.7677  -5.2399  15.3008  -8.7244 #>    0.4521  -6.3098  -9.1746   6.6661  14.1740  15.3086  -8.1402   0.9600 #>    2.2716   0.8837  -0.1830  -4.7564  14.5371  14.8455  -4.3501  -9.0601 #>   -1.5410  11.1980   9.0446  -3.0310  -1.8131  15.7361 -12.3093  16.3265 #>   -3.2634   8.4169 -10.9854  -3.6416   5.5400   3.7850   5.8189  -1.2514 #>    1.1178  11.4405  -1.1431  -8.9672  -6.1387  14.0108  -1.0153   5.5063 #>    2.8625   4.9656   6.2678  -7.2279  -0.8833   5.9117   9.8635   0.9836 #>    2.9008   9.2096  -5.7410   4.0162   1.7477   0.0787  -0.9875  14.4767 #>    7.4777  -2.6968   7.8789  10.3786  -0.9959  15.2169  12.7871   1.1561 #>   -6.8383   8.0303   3.1514  11.9488  -1.3620  -9.9862   0.0746  -4.0376 #>   -2.2166   1.9659  -5.3781 -14.7103  -3.3162   4.7723   2.4020  -8.3331 #>    7.2071   7.2636  12.6062  -0.7760   9.4554  -7.9184 -11.9570   5.5830 #>    2.1695   6.4469   7.0870  -0.3204   2.3094  -6.7242  -1.6000   3.1596 #>    3.3520   4.1517  -2.1789   4.5343   2.5825   2.1492   1.1830  -4.4321 #>    0.0922  -1.3383  -4.0789   7.5349   0.3219   5.2433  -2.6360   3.7869 #>    4.7933   3.3512  -4.5051  -2.1901  22.3008  18.8490   7.5580  -5.6750 #>    7.3938 -11.1678  -2.0972  -5.7141 -11.4733  -7.5001   3.0933  -9.5548 #>   -9.2641 -12.2349   1.5176  -5.4936   4.9133  -1.5024 -10.7774 -11.2684 #>    3.2107   1.9521  11.6881  10.0457  12.0771   5.5904   2.8542 -15.3766 #>    3.3805  -0.6111  -3.0381   4.6090  -6.2199   7.1722  -3.4843  -3.2336 #>   -3.0108   6.0233   4.3482 -10.2952  -0.5250   1.0059   6.7320  12.2936 #>    6.2232   0.8173   2.2507   4.4085   6.0984 -12.9619  -7.8572   1.1984 #>    6.3426 -11.2770   4.4595  -5.8399  -1.1147  -5.2786 -11.4394  -7.1858 #>    4.6621  -2.3163   4.1256  -9.2621   0.6303   0.6374  11.0537   8.0226 #>   -4.4188   2.5024   7.9690 -10.1976  -2.7284  -1.7297 -14.5485  -1.5143 #>   -3.2679  -4.1840   6.4311   6.7153  11.8356   8.8752   0.9989   1.3909 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{20,33,54} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose2d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose2d — torch_conv_transpose2d","title":"Conv_transpose2d — torch_conv_transpose2d","text":"Conv_transpose2d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose2d — torch_conv_transpose2d","text":"","code":"torch_conv_transpose2d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   output_padding = 0L,   groups = 1L,   dilation = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose2d — torch_conv_transpose2d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , iH , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kH , kW)\\) bias optional bias shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      tuple (sH, sW). Default: 1 padding dilation * (kernel_size - 1) - padding zero-padding added      sides dimension input. Can single number tuple      (padH, padW). Default: 0 output_padding additional size added one side dimension      output shape. Can single number tuple (out_padH, out_padW).      Default: 0 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1 dilation spacing kernel elements. Can single number      tuple (dH, dW). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose2d.html","id":"conv-transpose-d-input-weight-bias-null-stride-padding-output-padding-groups-dilation-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv_transpose2d(input, weight, bias=NULL, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor","title":"Conv_transpose2d — torch_conv_transpose2d","text":"Applies 2D transposed convolution operator input image composed several input planes, sometimes also called \"deconvolution\". See nn_conv_transpose2d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv_transpose2d — torch_conv_transpose2d","text":"","code":"if (torch_is_installed()) {  # With square kernels and equal stride inputs = torch_randn(c(1, 4, 5, 5)) weights = torch_randn(c(4, 8, 3, 3)) nnf_conv_transpose2d(inputs, weights, padding=1) } #> torch_tensor #> (1,1,.,.) =  #>  -0.9863 -2.1015 -0.7686  4.6569  4.3497 #>  -4.9922  3.4184  0.0460 -0.6890  7.4952 #>   5.5314 -1.1805 -0.0253  5.8615 -2.7114 #>   2.1113  3.0726  7.1237 -2.0755 -3.5216 #>   4.6665 -5.3079 -2.6928 -0.7921  1.6514 #>  #> (1,2,.,.) =  #>  -5.4506 -14.0902  0.0557  9.6182  1.5526 #>   0.7919  0.8676  4.5834  4.1394 -0.5979 #>  -2.8559  2.2970  4.3644 -14.7250 -1.2473 #>  -5.2405 -2.2707 -2.3420  0.0843  3.2389 #>   1.5088 -0.2471  2.9301  6.5253  4.5815 #>  #> (1,3,.,.) =  #>   -8.1272  -3.7910   1.7024  10.5755   1.1526 #>    5.3352   0.1813   7.7843   1.7031   2.8132 #>    5.1791  -4.5619   4.4660  -2.8693   7.4604 #>    2.2076   1.4190  -2.2263  -2.5487  -3.6389 #>    2.8728  -2.9609   4.4764  -3.8207   4.7798 #>  #> (1,4,.,.) =  #>    7.5384   5.1471   3.5030  -6.6308   2.5658 #>   -3.0810  -7.5815  -5.2492   8.1604  -2.4829 #>    4.6761  -3.1848   3.4074   0.4728  -0.2657 #>   -5.8688  13.5493   3.0594 -13.3597   0.1405 #>   -2.6346  -4.1050   1.9900   6.8615   1.5911 #>  #> (1,5,.,.) =  #>  -1.4595 -6.9167 -9.4588  4.4856  3.8772 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{1,8,5,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose3d.html","id":null,"dir":"Reference","previous_headings":"","what":"Conv_transpose3d — torch_conv_transpose3d","title":"Conv_transpose3d — torch_conv_transpose3d","text":"Conv_transpose3d","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose3d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conv_transpose3d — torch_conv_transpose3d","text":"","code":"torch_conv_transpose3d(   input,   weight,   bias = list(),   stride = 1L,   padding = 0L,   output_padding = 0L,   groups = 1L,   dilation = 1L )"},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose3d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conv_transpose3d — torch_conv_transpose3d","text":"input input tensor shape \\((\\mbox{minibatch} , \\mbox{\\_channels} , , iH , iW)\\) weight filters shape \\((\\mbox{\\_channels} , \\frac{\\mbox{\\_channels}}{\\mbox{groups}} , kT , kH , kW)\\) bias optional bias shape \\((\\mbox{\\_channels})\\). Default: NULL stride stride convolving kernel. Can single number      tuple (sT, sH, sW). Default: 1 padding dilation * (kernel_size - 1) - padding zero-padding added      sides dimension input. Can single number tuple      (padT, padH, padW). Default: 0 output_padding additional size added one side dimension      output shape. Can single number tuple      (out_padT, out_padH, out_padW). Default: 0 groups split input groups, \\(\\mbox{\\_channels}\\) divisible      number groups. Default: 1 dilation spacing kernel elements. Can single number      tuple (dT, dH, dW). Default: 1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose3d.html","id":"conv-transpose-d-input-weight-bias-null-stride-padding-output-padding-groups-dilation-gt-tensor-","dir":"Reference","previous_headings":"","what":"conv_transpose3d(input, weight, bias=NULL, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor","title":"Conv_transpose3d — torch_conv_transpose3d","text":"Applies 3D transposed convolution operator input image composed several input planes, sometimes also called \"deconvolution\" See nn_conv_transpose3d() details output shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_conv_transpose3d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conv_transpose3d — torch_conv_transpose3d","text":"","code":"if (torch_is_installed()) { if (FALSE) { inputs = torch_randn(c(20, 16, 50, 10, 20)) weights = torch_randn(c(16, 33, 3, 3, 3)) nnf_conv_transpose3d(inputs, weights) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_cos.html","id":null,"dir":"Reference","previous_headings":"","what":"Cos — torch_cos","title":"Cos — torch_cos","text":"Cos","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cos — torch_cos","text":"","code":"torch_cos(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cos — torch_cos","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cos.html","id":"cos-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cos(input, out=NULL) -> Tensor","title":"Cos — torch_cos","text":"Returns new tensor cosine  elements input. $$     \\mbox{}_{} = \\cos(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cos.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cos — torch_cos","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_cos(a) } #> torch_tensor #>  0.8458 #>  0.5691 #>  0.9922 #>  0.6951 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cosh.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosh — torch_cosh","title":"Cosh — torch_cosh","text":"Cosh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosh — torch_cosh","text":"","code":"torch_cosh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cosh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosh — torch_cosh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosh.html","id":"cosh-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cosh(input, out=NULL) -> Tensor","title":"Cosh — torch_cosh","text":"Returns new tensor hyperbolic cosine  elements input. $$     \\mbox{}_{} = \\cosh(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cosh — torch_cosh","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_cosh(a) } #> torch_tensor #>  1.1358 #>  2.7650 #>  1.0465 #>  2.4691 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cosine_similarity.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine_similarity — torch_cosine_similarity","title":"Cosine_similarity — torch_cosine_similarity","text":"Cosine_similarity","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosine_similarity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine_similarity — torch_cosine_similarity","text":"","code":"torch_cosine_similarity(x1, x2, dim = 2L, eps = 1e-08)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cosine_similarity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine_similarity — torch_cosine_similarity","text":"x1 (Tensor) First input. x2 (Tensor) Second input (size matching x1). dim (int, optional) Dimension vectors. Default: 1 eps (float, optional) Small value avoid division zero.        Default: 1e-8","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosine_similarity.html","id":"cosine-similarity-x-x-dim-eps-e-gt-tensor-","dir":"Reference","previous_headings":"","what":"cosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor","title":"Cosine_similarity — torch_cosine_similarity","text":"Returns cosine similarity x1 x2, computed along dim. $$     \\mbox{similarity} = \\frac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cosine_similarity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cosine_similarity — torch_cosine_similarity","text":"","code":"if (torch_is_installed()) {  input1 = torch_randn(c(100, 128)) input2 = torch_randn(c(100, 128)) output = torch_cosine_similarity(input1, input2) output } #> torch_tensor #>  0.0305 #> -0.0182 #>  0.0420 #>  0.1624 #> -0.0298 #>  0.1531 #> -0.0605 #>  0.0000 #> -0.0160 #> -0.0241 #>  0.0530 #> -0.0665 #> -0.0217 #> -0.0156 #> -0.1495 #> -0.0518 #>  0.0479 #> -0.0701 #>  0.0126 #> -0.0778 #> -0.0188 #>  0.0288 #> -0.0369 #> -0.0133 #> -0.0499 #> -0.0711 #>  0.0695 #>  0.0328 #> -0.1419 #>  0.0098 #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{100} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_count_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"Count_nonzero — torch_count_nonzero","title":"Count_nonzero — torch_count_nonzero","text":"Count_nonzero","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_count_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count_nonzero — torch_count_nonzero","text":"","code":"torch_count_nonzero(self, dim = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_count_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count_nonzero — torch_count_nonzero","text":"self (Tensor) input tensor. dim (int tuple ints, optional) Dim tuple dims along count non-zeros.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_count_nonzero.html","id":"count-nonzero-input-dim-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"count_nonzero(input, dim=None) -> Tensor","title":"Count_nonzero — torch_count_nonzero","text":"Counts number non-zero values tensor input along given dim. dim specified non-zeros tensor counted.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_count_nonzero.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count_nonzero — torch_count_nonzero","text":"","code":"if (torch_is_installed()) {  x <- torch_zeros(3,3) x[torch_randn(3,3) > 0.5] = 1 x torch_count_nonzero(x) torch_count_nonzero(x, dim=1) } #> torch_tensor #>  2 #>  1 #>  1 #> [ CPULongType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross — torch_cross","title":"Cross — torch_cross","text":"Cross","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross — torch_cross","text":"","code":"torch_cross(self, other, dim = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cross.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross — torch_cross","text":"self (Tensor) input tensor. (Tensor) second input tensor dim (int, optional) dimension take cross-product .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cross.html","id":"cross-input-other-dim-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cross(input, other, dim=-1, out=NULL) -> Tensor","title":"Cross — torch_cross","text":"Returns cross product vectors dimension dim input . input must size, size dim dimension 3. dim given, defaults first dimension found size 3.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cross.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross — torch_cross","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4, 3)) a b = torch_randn(c(4, 3)) b torch_cross(a, b, dim=2) torch_cross(a, b) } #> torch_tensor #> -0.0327  0.1124 -0.1158 #> -0.0779  0.3301 -0.3027 #> -1.3833 -0.0304 -0.8002 #> -0.6250  0.9997  0.1767 #> [ CPUFloatType{4,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cummax.html","id":null,"dir":"Reference","previous_headings":"","what":"Cummax — torch_cummax","title":"Cummax — torch_cummax","text":"Cummax","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cummax — torch_cummax","text":"","code":"torch_cummax(self, dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cummax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cummax — torch_cummax","text":"self (Tensor) input tensor. dim (int) dimension operation ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummax.html","id":"cummax-input-dim-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"cummax(input, dim) -> (Tensor, LongTensor)","title":"Cummax — torch_cummax","text":"Returns namedtuple (values, indices) values cumulative maximum elements input dimension dim. indices index location maximum value found dimension dim. $$     y_i = max(x_1, x_2, x_3, \\dots, x_i) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cummax — torch_cummax","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(10)) a torch_cummax(a, dim=1) } #> [[1]] #> torch_tensor #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #>  1.2996 #> [ CPUFloatType{10} ] #>  #> [[2]] #> torch_tensor #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #> [ CPULongType{10} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_cummin.html","id":null,"dir":"Reference","previous_headings":"","what":"Cummin — torch_cummin","title":"Cummin — torch_cummin","text":"Cummin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cummin — torch_cummin","text":"","code":"torch_cummin(self, dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cummin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cummin — torch_cummin","text":"self (Tensor) input tensor. dim (int) dimension operation ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummin.html","id":"cummin-input-dim-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"cummin(input, dim) -> (Tensor, LongTensor)","title":"Cummin — torch_cummin","text":"Returns namedtuple (values, indices) values cumulative minimum elements input dimension dim. indices index location maximum value found dimension dim. $$     y_i = min(x_1, x_2, x_3, \\dots, x_i) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cummin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cummin — torch_cummin","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(10)) a torch_cummin(a, dim=1) } #> [[1]] #> torch_tensor #> 0.01 * #>  5.5115 #>  5.5115 #>  5.5115 #>  5.5115 #>  5.5115 #>  5.5115 #> -120.6017 #> -120.6017 #> -120.6017 #> -120.6017 #> [ CPUFloatType{10} ] #>  #> [[2]] #> torch_tensor #>  0 #>  0 #>  0 #>  0 #>  0 #>  0 #>  6 #>  6 #>  6 #>  6 #> [ CPULongType{10} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_cumprod.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumprod — torch_cumprod","title":"Cumprod — torch_cumprod","text":"Cumprod","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumprod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumprod — torch_cumprod","text":"","code":"torch_cumprod(self, dim, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cumprod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumprod — torch_cumprod","text":"self (Tensor) input tensor. dim (int) dimension operation dtype (torch.dtype, optional) desired data type returned tensor.        specified, input tensor casted dtype operation        performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumprod.html","id":"cumprod-input-dim-out-null-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cumprod(input, dim, out=NULL, dtype=NULL) -> Tensor","title":"Cumprod — torch_cumprod","text":"Returns cumulative product elements input dimension dim. example, input vector size N, result also vector size N, elements. $$     y_i = x_1 \\times x_2\\times x_3\\times \\dots \\times x_i $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumprod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumprod — torch_cumprod","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(10)) a torch_cumprod(a, dim=1) } #> torch_tensor #> -0.7135 #> -0.2467 #> -0.4431 #>  0.2452 #>  0.2581 #> -0.3817 #>  0.2863 #> -0.4371 #>  0.5322 #> -0.1767 #> [ CPUFloatType{10} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_cumsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumsum — torch_cumsum","title":"Cumsum — torch_cumsum","text":"Cumsum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumsum — torch_cumsum","text":"","code":"torch_cumsum(self, dim, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_cumsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumsum — torch_cumsum","text":"self (Tensor) input tensor. dim (int) dimension operation dtype (torch.dtype, optional) desired data type returned tensor.        specified, input tensor casted dtype operation        performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumsum.html","id":"cumsum-input-dim-out-null-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"cumsum(input, dim, out=NULL, dtype=NULL) -> Tensor","title":"Cumsum — torch_cumsum","text":"Returns cumulative sum elements input dimension dim. example, input vector size N, result also vector size N, elements. $$     y_i = x_1 + x_2 + x_3 + \\dots + x_i $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_cumsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumsum — torch_cumsum","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(10)) a torch_cumsum(a, dim=1) } #> torch_tensor #>  0.7570 #>  0.2946 #> -0.2459 #> -0.1427 #> -0.1599 #>  0.7696 #>  1.3670 #>  1.9541 #>  2.5709 #>  2.4159 #> [ CPUFloatType{10} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_deg2rad.html","id":null,"dir":"Reference","previous_headings":"","what":"Deg2rad — torch_deg2rad","title":"Deg2rad — torch_deg2rad","text":"Deg2rad","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_deg2rad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deg2rad — torch_deg2rad","text":"","code":"torch_deg2rad(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_deg2rad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Deg2rad — torch_deg2rad","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_deg2rad.html","id":"deg-rad-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"deg2rad(input, *, out=None) -> Tensor","title":"Deg2rad — torch_deg2rad","text":"Returns new tensor elements input converted angles degrees radians.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_deg2rad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Deg2rad — torch_deg2rad","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(rbind(c(180.0, -180.0), c(360.0, -360.0), c(90.0, -90.0))) torch_deg2rad(a) } #> torch_tensor #>  3.1416 -3.1416 #>  6.2832 -6.2832 #>  1.5708 -1.5708 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_dequantize.html","id":null,"dir":"Reference","previous_headings":"","what":"Dequantize — torch_dequantize","title":"Dequantize — torch_dequantize","text":"Dequantize","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dequantize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dequantize — torch_dequantize","text":"","code":"torch_dequantize(tensor)"},{"path":"https://torch.mlverse.org/docs/reference/torch_dequantize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dequantize — torch_dequantize","text":"tensor (Tensor) quantized Tensor list oof quantized tensors","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dequantize.html","id":"dequantize-tensor-gt-tensor-","dir":"Reference","previous_headings":"","what":"dequantize(tensor) -> Tensor","title":"Dequantize — torch_dequantize","text":"Returns fp32 Tensor dequantizing quantized Tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dequantize.html","id":"dequantize-tensors-gt-sequence-of-tensors-","dir":"Reference","previous_headings":"","what":"dequantize(tensors) -> sequence of Tensors","title":"Dequantize — torch_dequantize","text":"Given list quantized Tensors, dequantize return list fp32 Tensors","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":null,"dir":"Reference","previous_headings":"","what":"Det — torch_det","title":"Det — torch_det","text":"Det","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Det — torch_det","text":"","code":"torch_det(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Det — torch_det","text":"self (Tensor) input tensor size (*, n, n) * zero                batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Det — torch_det","text":"","code":"Backward through `det` internally uses SVD results when `input` is not invertible. In this case, double backward through `det` will be unstable in when `input` doesn't have distinct singular values. See `~torch.svd` for details."},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":"det-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"det(input) -> Tensor","title":"Det — torch_det","text":"Calculates determinant square matrix batches square matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_det.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Det — torch_det","text":"","code":"if (torch_is_installed()) {  A = torch_randn(c(3, 3)) torch_det(A) A = torch_randn(c(3, 2, 2)) A A$det() } #> torch_tensor #> -1.5133 #>  3.3801 #>  1.1298 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_device.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Device object — torch_device","title":"Create a Device object — torch_device","text":"torch_device  object representing device torch_tensor allocated.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_device.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Device object — torch_device","text":"","code":"torch_device(type, index = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_device.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Device object — torch_device","text":"type (character) device type \"cuda\" \"cpu\" index (integer) optional device ordinal device type.  device ordinal present, object always represent current device device type, even torch_cuda_set_device() called; e.g., torch_tensor constructed device 'cuda' equivalent 'cuda:X' X result torch_cuda_current_device(). torch_device can constructed via string via string device ordinal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_device.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Device object — torch_device","text":"","code":"if (torch_is_installed()) {  # Via string torch_device(\"cuda:1\") torch_device(\"cpu\") torch_device(\"cuda\") # current cuda device  # Via string and device ordinal torch_device(\"cuda\", 0) torch_device(\"cpu\", 0) } #> torch_device(type='cpu', index=0)"},{"path":"https://torch.mlverse.org/docs/reference/torch_diag.html","id":null,"dir":"Reference","previous_headings":"","what":"Diag — torch_diag","title":"Diag — torch_diag","text":"Diag","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diag — torch_diag","text":"","code":"torch_diag(self, diagonal = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_diag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diag — torch_diag","text":"self (Tensor) input tensor. diagonal (int, optional) diagonal consider","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag.html","id":"diag-input-diagonal-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"diag(input, diagonal=0, out=NULL) -> Tensor","title":"Diag — torch_diag","text":"input vector (1-D tensor), returns 2-D square tensor elements input diagonal. input matrix (2-D tensor), returns 1-D tensor diagonal elements input. argument diagonal controls diagonal consider: diagonal = 0, main diagonal. diagonal > 0, main diagonal. diagonal < 0, main diagonal.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag_embed.html","id":null,"dir":"Reference","previous_headings":"","what":"Diag_embed — torch_diag_embed","title":"Diag_embed — torch_diag_embed","text":"Diag_embed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag_embed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diag_embed — torch_diag_embed","text":"","code":"torch_diag_embed(self, offset = 0L, dim1 = -2L, dim2 = -1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_diag_embed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diag_embed — torch_diag_embed","text":"self (Tensor) input tensor. Must least 1-dimensional. offset (int, optional) diagonal consider. Default: 0        (main diagonal). dim1 (int, optional) first dimension respect        take diagonal. Default: -2. dim2 (int, optional) second dimension respect        take diagonal. Default: -1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag_embed.html","id":"diag-embed-input-offset-dim-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"diag_embed(input, offset=0, dim1=-2, dim2=-1) -> Tensor","title":"Diag_embed — torch_diag_embed","text":"Creates tensor whose diagonals certain 2D planes (specified dim1 dim2) filled input. facilitate creating batched diagonal matrices, 2D planes formed last two dimensions returned tensor chosen default. argument offset controls diagonal consider: offset = 0, main diagonal. offset > 0, main diagonal. offset < 0, main diagonal. size new matrix calculated make specified diagonal size last input dimension. Note offset \\(0\\), order dim1 dim2 matters. Exchanging equivalent changing sign offset. Applying torch_diagonal output function arguments yields matrix identical input. However, torch_diagonal different default dimensions, need explicitly specified.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diag_embed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diag_embed — torch_diag_embed","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(2, 3)) torch_diag_embed(a) torch_diag_embed(a, offset=1, dim1=1, dim2=3) } #> torch_tensor #> (1,.,.) =  #>   0.0000  1.4648  0.0000  0.0000 #>   0.0000 -0.1176  0.0000  0.0000 #>  #> (2,.,.) =  #>   0.0000  0.0000 -0.0131  0.0000 #>   0.0000  0.0000 -0.6292  0.0000 #>  #> (3,.,.) =  #>   0.0000  0.0000  0.0000  0.2110 #>   0.0000  0.0000  0.0000 -0.2680 #>  #> (4,.,.) =  #>   0  0  0  0 #>   0  0  0  0 #> [ CPUFloatType{4,2,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_diagflat.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagflat — torch_diagflat","title":"Diagflat — torch_diagflat","text":"Diagflat","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagflat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagflat — torch_diagflat","text":"","code":"torch_diagflat(self, offset = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_diagflat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagflat — torch_diagflat","text":"self (Tensor) input tensor. offset (int, optional) diagonal consider. Default: 0 (main        diagonal).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagflat.html","id":"diagflat-input-offset-gt-tensor-","dir":"Reference","previous_headings":"","what":"diagflat(input, offset=0) -> Tensor","title":"Diagflat — torch_diagflat","text":"input vector (1-D tensor), returns 2-D square tensor elements input diagonal. input tensor one dimension, returns 2-D tensor diagonal elements equal flattened input. argument offset controls diagonal consider: offset = 0, main diagonal. offset > 0, main diagonal. offset < 0, main diagonal.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagflat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diagflat — torch_diagflat","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3)) a torch_diagflat(a) torch_diagflat(a, 1) a = torch_randn(c(2, 2)) a torch_diagflat(a) } #> torch_tensor #>  0.1981  0.0000  0.0000  0.0000 #>  0.0000  0.3182  0.0000  0.0000 #>  0.0000  0.0000  0.0107  0.0000 #>  0.0000  0.0000  0.0000 -0.2125 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_diagonal.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagonal — torch_diagonal","title":"Diagonal — torch_diagonal","text":"Diagonal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagonal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagonal — torch_diagonal","text":"","code":"torch_diagonal(self, outdim, dim1 = 1L, dim2 = 2L, offset = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_diagonal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagonal — torch_diagonal","text":"self (Tensor) input tensor. Must least 2-dimensional. outdim dimension name self named tensor. dim1 (int, optional) first dimension respect        take diagonal. Default: 0. dim2 (int, optional) second dimension respect        take diagonal. Default: 1. offset (int, optional) diagonal consider. Default: 0        (main diagonal).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagonal.html","id":"diagonal-input-offset-dim-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"diagonal(input, offset=0, dim1=0, dim2=1) -> Tensor","title":"Diagonal — torch_diagonal","text":"Returns partial view input diagonal elements respect dim1 dim2 appended dimension end shape. argument offset controls diagonal consider: offset = 0, main diagonal. offset > 0, main diagonal. offset < 0, main diagonal. Applying torch_diag_embed output function arguments yields diagonal matrix diagonal entries input. However, torch_diag_embed different default dimensions, need explicitly specified.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diagonal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Diagonal — torch_diagonal","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) a torch_diagonal(a, offset = 0) torch_diagonal(a, offset = 1) x = torch_randn(c(2, 5, 4, 2)) torch_diagonal(x, offset=-1, dim1=1, dim2=2) } #> torch_tensor #> (1,.,.) =  #>   0.4361 #>  -0.5322 #>  #> (2,.,.) =  #>  -1.4098 #>   1.1068 #>  #> (3,.,.) =  #>  -1.1374 #>  -0.0536 #>  #> (4,.,.) =  #>   0.3274 #>   0.4074 #> [ CPUFloatType{4,2,1} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes the n-th forward difference along the given dimension. — torch_diff","title":"Computes the n-th forward difference along the given dimension. — torch_diff","text":"first-order differences given [] = input[+ 1] - input[]. Higher-order differences calculated using torch_diff() recursively.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes the n-th forward difference along the given dimension. — torch_diff","text":"","code":"torch_diff(self, n = 1L, dim = -1L, prepend = list(), append = list())"},{"path":"https://torch.mlverse.org/docs/reference/torch_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes the n-th forward difference along the given dimension. — torch_diff","text":"self tensor compute differences n number times recursively compute difference dim dimension compute difference along. Default last dimension. prepend values prepend input along dim computing difference. dimensions must equivalent input, shapes must match input’s shape except dim. append values append input along dim computing difference. dimensions must equivalent input, shapes must match input’s shape except dim.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diff.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Computes the n-th forward difference along the given dimension. — torch_diff","text":"n = 1 currently supported","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_diff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes the n-th forward difference along the given dimension. — torch_diff","text":"","code":"if (torch_is_installed()) { a <- torch_tensor(c(1,2,3)) torch_diff(a)  b <- torch_tensor(c(4, 5)) torch_diff(a, append = b)  c <- torch_tensor(rbind(c(1,2,3), c(3,4,5))) torch_diff(c, dim = 1) torch_diff(c, dim = 2)   } #> torch_tensor #>  1  1 #>  1  1 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_digamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Digamma — torch_digamma","title":"Digamma — torch_digamma","text":"Digamma","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_digamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Digamma — torch_digamma","text":"","code":"torch_digamma(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_digamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Digamma — torch_digamma","text":"self (Tensor) tensor compute digamma function ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_digamma.html","id":"digamma-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"digamma(input, out=NULL) -> Tensor","title":"Digamma — torch_digamma","text":"Computes logarithmic derivative gamma function input. $$     \\psi(x) = \\frac{d}{dx} \\ln\\left(\\Gamma\\left(x\\right)\\right) = \\frac{\\Gamma'(x)}{\\Gamma(x)} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_digamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Digamma — torch_digamma","text":"","code":"if (torch_is_installed()) {  a = torch_tensor(c(1, 0.5)) torch_digamma(a) } #> torch_tensor #> -0.5772 #> -1.9635 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_dist.html","id":null,"dir":"Reference","previous_headings":"","what":"Dist — torch_dist","title":"Dist — torch_dist","text":"Dist","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dist — torch_dist","text":"","code":"torch_dist(self, other, p = 2L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_dist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dist — torch_dist","text":"self (Tensor) input tensor. (Tensor) Right-hand-side input tensor p (float, optional) norm computed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dist.html","id":"dist-input-other-p-gt-tensor-","dir":"Reference","previous_headings":"","what":"dist(input, other, p=2) -> Tensor","title":"Dist — torch_dist","text":"Returns p-norm (input - ) shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dist — torch_dist","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(4)) x y = torch_randn(c(4)) y torch_dist(x, y, 3.5) torch_dist(x, y, 3) torch_dist(x, y, 0) torch_dist(x, y, 1) } #> torch_tensor #> 3.93348 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":null,"dir":"Reference","previous_headings":"","what":"Div — torch_div","title":"Div — torch_div","text":"Div","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Div — torch_div","text":"","code":"torch_div(self, other, rounding_mode)"},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Div — torch_div","text":"self (Tensor) input tensor. (Number) number divided element input rounding_mode (str, optional) – Type rounding applied result: NULL - default behavior. Performs rounding , input integer types, promotes inputs default scalar type. Equivalent true division Python (/ operator) NumPy’s np.true_divide. \"trunc\" - rounds results division towards zero. Equivalent C-style integer division. \"floor\" - rounds results division . Equivalent floor division Python (// operator) NumPy’s np.floor_divide.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":"div-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"div(input, other, out=NULL) -> Tensor","title":"Div — torch_div","text":"Divides element input input scalar returns new resulting tensor. element tensor input divided element tensor . resulting tensor returned. $$     \\mbox{}_i = \\frac{\\mbox{input}_i}{\\mbox{}_i} $$ shapes input must broadcastable . torch_dtype input differ, torch_dtype result tensor determined following rules described type promotion documentation . specified, result must castable  torch_dtype specified output tensor. Integral division zero leads undefined behavior.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Div — torch_div","text":"Integer division using div deprecated, future release div perform true division like torch_true_divide(). Use torch_floor_divide() perform integer division, instead. $$     \\mbox{}_i = \\frac{\\mbox{input}_i}{\\mbox{}} $$ torch_dtype input differ, torch_dtype result tensor determined following rules described type promotion documentation . specified, result must castable torch_dtype specified output tensor. Integral division zero leads undefined behavior.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_div.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Div — torch_div","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(5)) a torch_div(a, 0.5)   a = torch_randn(c(4, 4)) a b = torch_randn(c(4)) b torch_div(a, b) } #> torch_tensor #>  2.1205  0.0517  0.4914 -1.1369 #>  0.4111  0.4443  0.3243 -3.1527 #>  2.1085 -1.0652  1.2698 -0.9235 #> -2.1766 -0.8320  0.8040 -4.1717 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_divide.html","id":null,"dir":"Reference","previous_headings":"","what":"Divide — torch_divide","title":"Divide — torch_divide","text":"Divide","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_divide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Divide — torch_divide","text":"","code":"torch_divide(self, other, rounding_mode)"},{"path":"https://torch.mlverse.org/docs/reference/torch_divide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Divide — torch_divide","text":"self (Tensor) input tensor. (Number) number divided element input rounding_mode (str, optional) – Type rounding applied result: NULL - default behavior. Performs rounding , input integer types, promotes inputs default scalar type. Equivalent true division Python (/ operator) NumPy’s np.true_divide. \"trunc\" - rounds results division towards zero. Equivalent C-style integer division. \"floor\" - rounds results division . Equivalent floor division Python (// operator) NumPy’s np.floor_divide.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_divide.html","id":"divide-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"divide(input, other, *, out=None) -> Tensor","title":"Divide — torch_divide","text":"Alias torch_div().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":null,"dir":"Reference","previous_headings":"","what":"Dot — torch_dot","title":"Dot — torch_dot","text":"Dot","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dot — torch_dot","text":"","code":"torch_dot(self, tensor)"},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dot — torch_dot","text":"self input tensor tensor input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Dot — torch_dot","text":"function broadcast .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":"dot-input-tensor-gt-tensor-","dir":"Reference","previous_headings":"","what":"dot(input, tensor) -> Tensor","title":"Dot — torch_dot","text":"Computes dot product (inner product) two tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dot — torch_dot","text":"","code":"if (torch_is_installed()) {  torch_dot(torch_tensor(c(2, 3)), torch_tensor(c(2, 1))) } #> torch_tensor #> 7 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_dstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Dstack — torch_dstack","title":"Dstack — torch_dstack","text":"Dstack","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dstack — torch_dstack","text":"","code":"torch_dstack(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_dstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Dstack — torch_dstack","text":"tensors (sequence Tensors) sequence tensors concatenate","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dstack.html","id":"dstack-tensors-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"dstack(tensors, *, out=None) -> Tensor","title":"Dstack — torch_dstack","text":"Stack tensors sequence depthwise (along third axis). equivalent concatenation along third axis 1-D 2-D tensors reshaped torch_atleast_3d().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dstack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Dstack — torch_dstack","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2, 3)) b <- torch_tensor(c(4, 5, 6)) torch_dstack(list(a,b)) a <- torch_tensor(rbind(1,2,3)) b <- torch_tensor(rbind(4,5,6)) torch_dstack(list(a,b)) } #> torch_tensor #> (1,.,.) =  #>   1  4 #>  #> (2,.,.) =  #>   2  5 #>  #> (3,.,.) =  #>   3  6 #> [ CPUFloatType{3,1,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_dtype.html","id":null,"dir":"Reference","previous_headings":"","what":"Torch data types — torch_dtype","title":"Torch data types — torch_dtype","text":"Returns correspondent data type.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_dtype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Torch data types — torch_dtype","text":"","code":"torch_float32()  torch_float()  torch_float64()  torch_double()  torch_cfloat32()  torch_chalf()  torch_cfloat()  torch_cfloat64()  torch_cdouble()  torch_cfloat128()  torch_float16()  torch_half()  torch_uint8()  torch_int8()  torch_int16()  torch_short()  torch_int32()  torch_int()  torch_int64()  torch_long()  torch_bool()  torch_quint8()  torch_qint8()  torch_qint32()"},{"path":"https://torch.mlverse.org/docs/reference/torch_eig.html","id":null,"dir":"Reference","previous_headings":"","what":"Eig — torch_eig","title":"Eig — torch_eig","text":"Eig","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eig — torch_eig","text":"self (Tensor) square matrix shape \\((n \\times n)\\) eigenvalues eigenvectors        computed eigenvectors (bool) TRUE compute eigenvalues eigenvectors;        otherwise, eigenvalues computed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eig.html","id":"eig-input-eigenvectors-false-out-null-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"eig(input, eigenvectors=False, out=NULL) -> (Tensor, Tensor)","title":"Eig — torch_eig","text":"Computes eigenvalues eigenvectors real square matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_einsum.html","id":null,"dir":"Reference","previous_headings":"","what":"Einsum — torch_einsum","title":"Einsum — torch_einsum","text":"Einsum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_einsum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Einsum — torch_einsum","text":"","code":"torch_einsum(equation, tensors, path = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_einsum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Einsum — torch_einsum","text":"equation (string) equation given terms lower case letters (indices) associated           dimension operands result. left hand side lists operands           dimensions, separated commas. one index letter per tensor dimension.           right hand side follows -> gives indices output.           -> right hand side omitted, implicitly defined alphabetically           sorted list indices appearing exactly left hand side.           indices apprearing output summed multiplying operands           entries.           index appears several times operand, diagonal taken.           Ellipses ... represent fixed number dimensions. right hand side inferred,           ellipsis dimensions beginning output. tensors (Tensor) operands compute Einstein sum . path (int) function uses opt_einsum speed computation consume less memory optimizing contraction order. optimization occurs least three inputs, since order matter otherwise. Note finding optimal path NP-hard problem, thus, opt_einsum relies different heuristics achieve near-optimal results. opt_einsum available, default order contract left right. path argument used changed default, set advanced users.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_einsum.html","id":"einsum-equation-operands-gt-tensor-","dir":"Reference","previous_headings":"","what":"einsum(equation, *operands) -> Tensor","title":"Einsum — torch_einsum","text":"function provides way computing multilinear expressions (.e. sums products) using Einstein summation convention.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_einsum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Einsum — torch_einsum","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(5)) y = torch_randn(c(4)) torch_einsum('i,j->ij', list(x, y))  # outer product A = torch_randn(c(3,5,4)) l = torch_randn(c(2,5)) r = torch_randn(c(2,4)) torch_einsum('bn,anm,bm->ba', list(l, A, r)) # compare torch_nn$functional$bilinear As = torch_randn(c(3,2,5)) Bs = torch_randn(c(3,5,4)) torch_einsum('bij,bjk->bik', list(As, Bs)) # batch matrix multiplication A = torch_randn(c(3, 3)) torch_einsum('ii->i', list(A)) # diagonal A = torch_randn(c(4, 3, 3)) torch_einsum('...ii->...i', list(A)) # batch diagonal A = torch_randn(c(2, 3, 4, 5)) torch_einsum('...ij->...ji', list(A))$shape # batch permute  } #> [1] 2 3 5 4"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty — torch_empty","title":"Empty — torch_empty","text":"Empty","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty — torch_empty","text":"","code":"torch_empty(   ...,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empty — torch_empty","text":"... sequence integers defining shape output tensor. names optional character vector naming dimension. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty.html","id":"empty-size-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-pin-memory-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"empty(*size, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False, pin_memory=False) -> Tensor","title":"Empty — torch_empty","text":"Returns tensor filled uninitialized data. shape tensor defined variable argument size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empty — torch_empty","text":"","code":"if (torch_is_installed()) {  torch_empty(c(2, 3)) } #> torch_tensor #>  0  0  0 #>  0  0  0 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty_like — torch_empty_like","title":"Empty_like — torch_empty_like","text":"Empty_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty_like — torch_empty_like","text":"","code":"torch_empty_like(   input,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empty_like — torch_empty_like","text":"input (Tensor) size input determine size output tensor. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_like.html","id":"empty-like-input-dtype-null-layout-null-device-null-requires-grad-false-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"empty_like(input, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, memory_format=torch.preserve_format) -> Tensor","title":"Empty_like — torch_empty_like","text":"Returns uninitialized tensor size input. torch_empty_like(input) equivalent torch_empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empty_like — torch_empty_like","text":"","code":"if (torch_is_installed()) {  torch_empty(list(2,3), dtype = torch_int64()) } #> torch_tensor #>  0  0  0 #>  0  0  0 #> [ CPULongType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty_strided — torch_empty_strided","title":"Empty_strided — torch_empty_strided","text":"Empty_strided","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty_strided — torch_empty_strided","text":"","code":"torch_empty_strided(   size,   stride,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   pin_memory = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empty_strided — torch_empty_strided","text":"size (tuple ints) shape output tensor stride (tuple ints) strides output tensor dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. pin_memory (bool, optional) set, returned tensor allocated        pinned memory. Works CPU tensors. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":"empty-strided-size-stride-dtype-null-layout-null-device-null-requires-grad-false-pin-memory-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"empty_strided(size, stride, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, pin_memory=False) -> Tensor","title":"Empty_strided — torch_empty_strided","text":"Returns tensor filled uninitialized data. shape strides tensor defined variable argument size stride respectively. torch_empty_strided(size, stride) equivalent torch_empty(size).as_strided(size, stride).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Empty_strided — torch_empty_strided","text":"one element created tensor may refer single memory location. result, -place operations (especially ones vectorized) may result incorrect behavior. need write tensors, please clone first.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_empty_strided.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Empty_strided — torch_empty_strided","text":"","code":"if (torch_is_installed()) {  a = torch_empty_strided(list(2, 3), list(1, 2)) a a$stride(1) a$size(1) } #> [1] 2"},{"path":"https://torch.mlverse.org/docs/reference/torch_eq.html","id":null,"dir":"Reference","previous_headings":"","what":"Eq — torch_eq","title":"Eq — torch_eq","text":"Eq","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eq — torch_eq","text":"","code":"torch_eq(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_eq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eq — torch_eq","text":"self (Tensor) tensor compare (Tensor float) tensor value compare Must ByteTensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eq.html","id":"eq-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"eq(input, other, out=NULL) -> Tensor","title":"Eq — torch_eq","text":"Computes element-wise equality second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eq — torch_eq","text":"","code":"if (torch_is_installed()) {  torch_eq(torch_tensor(c(1,2,3,4)), torch_tensor(c(1, 3, 2, 4))) } #> torch_tensor #>  1 #>  0 #>  0 #>  1 #> [ CPUBoolType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Equal — torch_equal","title":"Equal — torch_equal","text":"Equal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Equal — torch_equal","text":"","code":"torch_equal(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Equal — torch_equal","text":"self input tensor input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_equal.html","id":"equal-input-other-gt-bool-","dir":"Reference","previous_headings":"","what":"equal(input, other) -> bool","title":"Equal — torch_equal","text":"TRUE two tensors size elements, FALSE otherwise.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_equal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Equal — torch_equal","text":"","code":"if (torch_is_installed()) {  torch_equal(torch_tensor(c(1, 2)), torch_tensor(c(1, 2))) } #> [1] TRUE"},{"path":"https://torch.mlverse.org/docs/reference/torch_erf.html","id":null,"dir":"Reference","previous_headings":"","what":"Erf — torch_erf","title":"Erf — torch_erf","text":"Erf","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Erf — torch_erf","text":"","code":"torch_erf(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_erf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Erf — torch_erf","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erf.html","id":"erf-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"erf(input, out=NULL) -> Tensor","title":"Erf — torch_erf","text":"Computes error function element. error function defined follows: $$     \\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Erf — torch_erf","text":"","code":"if (torch_is_installed()) {  torch_erf(torch_tensor(c(0, -1., 10.))) } #> torch_tensor #>  0.0000 #> -0.8427 #>  1.0000 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_erfc.html","id":null,"dir":"Reference","previous_headings":"","what":"Erfc — torch_erfc","title":"Erfc — torch_erfc","text":"Erfc","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Erfc — torch_erfc","text":"","code":"torch_erfc(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_erfc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Erfc — torch_erfc","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfc.html","id":"erfc-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"erfc(input, out=NULL) -> Tensor","title":"Erfc — torch_erfc","text":"Computes complementary error function element input. complementary error function defined follows: $$     \\mathrm{erfc}(x) = 1 - \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Erfc — torch_erfc","text":"","code":"if (torch_is_installed()) {  torch_erfc(torch_tensor(c(0, -1., 10.))) } #> torch_tensor #>  1.0000e+00 #>  1.8427e+00 #>  2.8026e-45 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_erfinv.html","id":null,"dir":"Reference","previous_headings":"","what":"Erfinv — torch_erfinv","title":"Erfinv — torch_erfinv","text":"Erfinv","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfinv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Erfinv — torch_erfinv","text":"","code":"torch_erfinv(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_erfinv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Erfinv — torch_erfinv","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfinv.html","id":"erfinv-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"erfinv(input, out=NULL) -> Tensor","title":"Erfinv — torch_erfinv","text":"Computes inverse error function element input. inverse error function defined range \\((-1, 1)\\) : $$     \\mathrm{erfinv}(\\mathrm{erf}(x)) = x $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_erfinv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Erfinv — torch_erfinv","text":"","code":"if (torch_is_installed()) {  torch_erfinv(torch_tensor(c(0, 0.5, -1.))) } #> torch_tensor #>  0.0000 #>  0.4769 #>    -inf #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Exp — torch_exp","title":"Exp — torch_exp","text":"Exp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exp — torch_exp","text":"","code":"torch_exp(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exp — torch_exp","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp.html","id":"exp-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"exp(input, out=NULL) -> Tensor","title":"Exp — torch_exp","text":"Returns new tensor exponential elements input tensor input. $$     y_{} = e^{x_{}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exp — torch_exp","text":"","code":"if (torch_is_installed()) {  torch_exp(torch_tensor(c(0, log(2)))) } #> torch_tensor #>  1 #>  2 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_exp2.html","id":null,"dir":"Reference","previous_headings":"","what":"Exp2 — torch_exp2","title":"Exp2 — torch_exp2","text":"Exp2","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exp2 — torch_exp2","text":"","code":"torch_exp2(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_exp2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exp2 — torch_exp2","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp2.html","id":"exp-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"exp2(input, *, out=None) -> Tensor","title":"Exp2 — torch_exp2","text":"Computes base two exponential function input. $$     y_{} = 2^{x_{}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_exp2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exp2 — torch_exp2","text":"","code":"if (torch_is_installed()) {  torch_exp2(torch_tensor(c(0, log2(2.), 3, 4))) } #> torch_tensor #>   1 #>   2 #>   8 #>  16 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_expm1.html","id":null,"dir":"Reference","previous_headings":"","what":"Expm1 — torch_expm1","title":"Expm1 — torch_expm1","text":"Expm1","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_expm1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expm1 — torch_expm1","text":"","code":"torch_expm1(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_expm1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expm1 — torch_expm1","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_expm1.html","id":"expm-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"expm1(input, out=NULL) -> Tensor","title":"Expm1 — torch_expm1","text":"Returns new tensor exponential elements minus 1 input. $$     y_{} = e^{x_{}} - 1 $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_expm1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expm1 — torch_expm1","text":"","code":"if (torch_is_installed()) {  torch_expm1(torch_tensor(c(0, log(2)))) } #> torch_tensor #>  0 #>  1 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_eye.html","id":null,"dir":"Reference","previous_headings":"","what":"Eye — torch_eye","title":"Eye — torch_eye","text":"Eye","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eye.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Eye — torch_eye","text":"","code":"torch_eye(   n,   m = n,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_eye.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Eye — torch_eye","text":"n (int) number rows m (int, optional) number columns default n dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eye.html","id":"eye-n-m-null-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"eye(n, m=NULL, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Eye — torch_eye","text":"Returns 2-D tensor ones diagonal zeros elsewhere.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_eye.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Eye — torch_eye","text":"","code":"if (torch_is_installed()) {  torch_eye(3) } #> torch_tensor #>  1  0  0 #>  0  1  0 #>  0  0  1 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fft.html","id":null,"dir":"Reference","previous_headings":"","what":"Fft — torch_fft_fft","title":"Fft — torch_fft_fft","text":"Computes one dimensional discrete Fourier transform input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fft — torch_fft_fft","text":"","code":"torch_fft_fft(self, n = NULL, dim = -1L, norm = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fft — torch_fft_fft","text":"self (Tensor) input tensor n (int) Signal length. given, input either zero-padded trimmed length computing FFT. dim (int, optional) dimension along take one dimensional FFT. norm (str, optional) Normalization mode. forward transform, correspond : \"forward\" - normalize 1/n \"backward\" - normalization \"ortho\" - normalize 1/sqrt(n) (making FFT orthonormal) Calling backward transform (ifft()) normalization mode apply overall normalization 1/n two transforms. required make IFFT exact inverse. Default \"backward\" (normalization).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fft.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fft — torch_fft_fft","text":"Fourier domain representation real signal satisfies Hermitian property: X[] = conj(X[-]). function always returns positive negative frequency terms even though, real inputs, negative frequencies redundant. rfft() returns compact one-sided representation positive frequencies returned.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fft — torch_fft_fft","text":"","code":"if (torch_is_installed()) { t <- torch_arange(start = 0, end = 3) t torch_fft_fft(t, norm = \"backward\")  } #> torch_tensor #> ℹ Use `$real` or `$imag` to print the contents of this tensor. #> [ CPUComplexFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fftfreq.html","id":null,"dir":"Reference","previous_headings":"","what":"fftfreq — torch_fft_fftfreq","title":"fftfreq — torch_fft_fftfreq","text":"Computes discrete Fourier Transform sample frequencies signal size n.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fftfreq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fftfreq — torch_fft_fftfreq","text":"","code":"torch_fft_fftfreq(   n,   d = 1,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fftfreq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fftfreq — torch_fft_fftfreq","text":"n (integer) – FFT length d (float, optional) – sampling length scale. spacing individual samples FFT input. default assumes unit spacing, dividing result actual spacing gives result physical frequency units. dtype (default: torch_get_default_dtype()) desired data type returned tensor. layout (default: torch_strided()) desired layout returned tensor. device (default: NULL) desired device returned tensor.  Default: NULL, uses current device default tensor type. requires_grad (default: FALSE)  autograd record operations returned tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fftfreq.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"fftfreq — torch_fft_fftfreq","text":"convention, torch_fft_fft() returns positive frequency terms first, followed negative frequencies reverse order, f[-] 0 < <= n/2 gives negative frequency terms. FFT length n inputs spaced length unit d, frequencies : f = [0, 1, ..., (n - 1) // 2, -(n // 2), ..., -1] / (d * n) even lengths, Nyquist frequency f[n/2] can thought either negative positive. fftfreq() follows NumPy’s convention taking negative.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_fftfreq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"fftfreq — torch_fft_fftfreq","text":"","code":"if (torch_is_installed()) { torch_fft_fftfreq(5) # Nyquist frequency at f[3] is positive torch_fft_fftfreq(4) # Nyquist frequency at f[3] is given as negative  } #> torch_tensor #>  0.0000 #>  0.2500 #> -0.5000 #> -0.2500 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_ifft.html","id":null,"dir":"Reference","previous_headings":"","what":"Ifft — torch_fft_ifft","title":"Ifft — torch_fft_ifft","text":"Computes one dimensional inverse discrete Fourier transform input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_ifft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ifft — torch_fft_ifft","text":"","code":"torch_fft_ifft(self, n = NULL, dim = -1L, norm = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_ifft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ifft — torch_fft_ifft","text":"self (Tensor) input tensor n (int, optional) – Signal length. given, input either zero-padded trimmed length computing IFFT. dim (int, optional) – dimension along take one dimensional IFFT. norm (str, optional) – Normalization mode. backward transform, correspond : \"forward\" - normalization \"backward\" - normalize 1/n \"ortho\" - normalize 1/sqrt(n) (making IFFT orthonormal) Calling forward transform normalization mode apply overall normalization 1/n two transforms. required make ifft() exact inverse. Default \"backward\" (normalize 1/n).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_ifft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ifft — torch_fft_ifft","text":"","code":"if (torch_is_installed()) { t <- torch_arange(start = 0, end = 3) t x <- torch_fft_fft(t, norm = \"backward\") torch_fft_ifft(x)   } #> torch_tensor #> ℹ Use `$real` or `$imag` to print the contents of this tensor. #> [ CPUComplexFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_irfft.html","id":null,"dir":"Reference","previous_headings":"","what":"Irfft — torch_fft_irfft","title":"Irfft — torch_fft_irfft","text":"Computes inverse torch_fft_rfft(). Input interpreted one-sided Hermitian signal Fourier domain, produced torch_fft_rfft(). Hermitian property, output real-valued.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_irfft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Irfft — torch_fft_irfft","text":"","code":"torch_fft_irfft(self, n = NULL, dim = -1L, norm = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_irfft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Irfft — torch_fft_irfft","text":"self (Tensor) input tensor representing half-Hermitian signal n (int) Output signal length. determines length output signal. given, input either zero-padded trimmed length computing real IFFT. Defaults even output: n=2*(input.size(dim) - 1). dim (int, optional) – dimension along take one dimensional real IFFT. norm (str, optional) – Normalization mode. backward transform, correspond : \"forward\" - normalization \"backward\" - normalize 1/n \"ortho\" - normalize 1/sqrt(n) (making real IFFT orthonormal) Calling forward transform (torch_fft_rfft()) normalization mode apply overall normalization 1/n two transforms. required make irfft() exact inverse. Default \"backward\" (normalize 1/n).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_irfft.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Irfft — torch_fft_irfft","text":"input frequencies must real-valued satisfy Hermitian property. cases imaginary component ignored. example, imaginary component zero-frequency term represented real output always ignored. correct interpretation Hermitian input depends length original data, given n. input shape correspond either odd even length signal. default, signal assumed even length odd signals round-trip properly. , recommended always pass signal length n.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_irfft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Irfft — torch_fft_irfft","text":"","code":"if (torch_is_installed()) { t <- torch_arange(start = 0, end = 4) x <- torch_fft_rfft(t) torch_fft_irfft(x) torch_fft_irfft(x, n = t$numel())  } #> torch_tensor #>  0.0000 #>  1.0000 #>  2.0000 #>  3.0000 #>  4.0000 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_rfft.html","id":null,"dir":"Reference","previous_headings":"","what":"Rfft — torch_fft_rfft","title":"Rfft — torch_fft_rfft","text":"Computes one dimensional Fourier transform real-valued input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_rfft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rfft — torch_fft_rfft","text":"","code":"torch_fft_rfft(self, n = NULL, dim = -1L, norm = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_rfft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rfft — torch_fft_rfft","text":"self (Tensor)  real input tensor n (int) Signal length. given, input either zero-padded trimmed length computing real FFT. dim (int, optional) – dimension along take one dimensional real FFT. norm norm (str, optional) – Normalization mode. forward transform, correspond : \"forward\" - normalize 1/n \"backward\" - normalization \"ortho\" - normalize 1/sqrt(n) (making FFT orthonormal) Calling backward transform (torch_fft_irfft()) normalization mode apply overall normalization 1/n two transforms. required make irfft() exact inverse. Default \"backward\" (normalization).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_rfft.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rfft — torch_fft_rfft","text":"FFT real signal Hermitian-symmetric, X[] = conj(X[-]) output contains positive frequencies Nyquist frequency. compute full output, use torch_fft_fft().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fft_rfft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rfft — torch_fft_rfft","text":"","code":"if (torch_is_installed()) { t <- torch_arange(start = 0, end = 3) torch_fft_rfft(t)  } #> torch_tensor #> ℹ Use `$real` or `$imag` to print the contents of this tensor. #> [ CPUComplexFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_finfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Floating point type info — torch_finfo","title":"Floating point type info — torch_finfo","text":"list represents numerical properties floating point torch.dtype","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_finfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Floating point type info — torch_finfo","text":"","code":"torch_finfo(dtype)"},{"path":"https://torch.mlverse.org/docs/reference/torch_finfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Floating point type info — torch_finfo","text":"dtype dtype check information","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fix.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix — torch_fix","title":"Fix — torch_fix","text":"Fix","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix — torch_fix","text":"","code":"torch_fix(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix — torch_fix","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fix.html","id":"fix-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"fix(input, *, out=None) -> Tensor","title":"Fix — torch_fix","text":"Alias torch_trunc()","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flatten.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten — torch_flatten","title":"Flatten — torch_flatten","text":"Flatten","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flatten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten — torch_flatten","text":"","code":"torch_flatten(self, dims, start_dim = 1L, end_dim = -1L, out_dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_flatten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten — torch_flatten","text":"self (Tensor) input tensor. dims tensor named can pass name dimensions flatten start_dim (int) first dim flatten end_dim (int) last dim flatten out_dim name resulting dimension named tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flatten.html","id":"flatten-input-start-dim-end-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"flatten(input, start_dim=0, end_dim=-1) -> Tensor","title":"Flatten — torch_flatten","text":"Flattens contiguous range dims tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flatten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flatten — torch_flatten","text":"","code":"if (torch_is_installed()) {  t = torch_tensor(matrix(c(1, 2), ncol = 2)) torch_flatten(t) torch_flatten(t, start_dim=2) } #> torch_tensor #>  1  2 #> [ CPUFloatType{1,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_flip.html","id":null,"dir":"Reference","previous_headings":"","what":"Flip — torch_flip","title":"Flip — torch_flip","text":"Flip","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flip — torch_flip","text":"","code":"torch_flip(self, dims)"},{"path":"https://torch.mlverse.org/docs/reference/torch_flip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flip — torch_flip","text":"self (Tensor) input tensor. dims (list tuple) axis flip ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flip.html","id":"flip-input-dims-gt-tensor-","dir":"Reference","previous_headings":"","what":"flip(input, dims) -> Tensor","title":"Flip — torch_flip","text":"Reverse order n-D tensor along given axis dims.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flip — torch_flip","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(1, 8)$view(c(2, 2, 2)) x torch_flip(x, c(1, 2)) } #> torch_tensor #> (1,.,.) =  #>   7  8 #>   5  6 #>  #> (2,.,.) =  #>   3  4 #>   1  2 #> [ CPUFloatType{2,2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":null,"dir":"Reference","previous_headings":"","what":"Fliplr — torch_fliplr","title":"Fliplr — torch_fliplr","text":"Fliplr","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fliplr — torch_fliplr","text":"","code":"torch_fliplr(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fliplr — torch_fliplr","text":"self (Tensor) Must least 2-dimensional.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Fliplr — torch_fliplr","text":"Equivalent input[,-1]. Requires array least 2-D.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":"fliplr-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"fliplr(input) -> Tensor","title":"Fliplr — torch_fliplr","text":"Flip array left/right direction, returning new tensor. Flip entries row left/right direction. Columns preserved, appear different order .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fliplr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fliplr — torch_fliplr","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(start = 1, end = 4)$view(c(2, 2)) x torch_fliplr(x) } #> torch_tensor #>  2  1 #>  4  3 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":null,"dir":"Reference","previous_headings":"","what":"Flipud — torch_flipud","title":"Flipud — torch_flipud","text":"Flipud","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flipud — torch_flipud","text":"","code":"torch_flipud(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flipud — torch_flipud","text":"self (Tensor) Must least 1-dimensional.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Flipud — torch_flipud","text":"Equivalent input[-1,]. Requires array least 1-D.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":"flipud-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"flipud(input) -> Tensor","title":"Flipud — torch_flipud","text":"Flip array /direction, returning new tensor. Flip entries column /direction. Rows preserved, appear different order .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_flipud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Flipud — torch_flipud","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(start = 1, end = 4)$view(c(2, 2)) x torch_flipud(x) } #> torch_tensor #>  3  4 #>  1  2 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_floor.html","id":null,"dir":"Reference","previous_headings":"","what":"Floor — torch_floor","title":"Floor — torch_floor","text":"Floor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Floor — torch_floor","text":"","code":"torch_floor(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_floor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Floor — torch_floor","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor.html","id":"floor-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"floor(input, out=NULL) -> Tensor","title":"Floor — torch_floor","text":"Returns new tensor floor elements input, largest integer less equal element. $$     \\mbox{}_{} = \\left\\lfloor \\mbox{input}_{} \\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Floor — torch_floor","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_floor(a) } #> torch_tensor #>  0 #> -1 #>  0 #>  0 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_floor_divide.html","id":null,"dir":"Reference","previous_headings":"","what":"Floor_divide — torch_floor_divide","title":"Floor_divide — torch_floor_divide","text":"Floor_divide","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor_divide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Floor_divide — torch_floor_divide","text":"","code":"torch_floor_divide(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_floor_divide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Floor_divide — torch_floor_divide","text":"self (Tensor) numerator tensor (Tensor Scalar) denominator","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor_divide.html","id":"floor-divide-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"floor_divide(input, other, out=NULL) -> Tensor","title":"Floor_divide — torch_floor_divide","text":"Return division inputs rounded nearest integer. See torch_div type promotion broadcasting rules. $$     \\mbox{{}}_i = \\left\\lfloor \\frac{{\\mbox{{input}}_i}}{{\\mbox{{}}_i}} \\right\\rfloor $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_floor_divide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Floor_divide — torch_floor_divide","text":"","code":"if (torch_is_installed()) {  a = torch_tensor(c(4.0, 3.0)) b = torch_tensor(c(2.0, 2.0)) torch_floor_divide(a, b) torch_floor_divide(a, 1.4) } #> torch_tensor #>  2 #>  2 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_fmod.html","id":null,"dir":"Reference","previous_headings":"","what":"Fmod — torch_fmod","title":"Fmod — torch_fmod","text":"Fmod","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fmod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fmod — torch_fmod","text":"","code":"torch_fmod(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_fmod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fmod — torch_fmod","text":"self (Tensor) dividend (Tensor float) divisor, may either number tensor shape dividend","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fmod.html","id":"fmod-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"fmod(input, other, out=NULL) -> Tensor","title":"Fmod — torch_fmod","text":"Computes element-wise remainder division. dividend divisor may contain integer floating point numbers. remainder sign dividend input. tensor, shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_fmod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fmod — torch_fmod","text":"","code":"if (torch_is_installed()) {  torch_fmod(torch_tensor(c(-3., -2, -1, 1, 2, 3)), 2) torch_fmod(torch_tensor(c(1., 2, 3, 4, 5)), 1.5) } #> torch_tensor #>  1.0000 #>  0.5000 #>  0.0000 #>  1.0000 #>  0.5000 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_frac.html","id":null,"dir":"Reference","previous_headings":"","what":"Frac — torch_frac","title":"Frac — torch_frac","text":"Frac","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_frac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frac — torch_frac","text":"","code":"torch_frac(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_frac.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frac — torch_frac","text":"self input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_frac.html","id":"frac-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"frac(input, out=NULL) -> Tensor","title":"Frac — torch_frac","text":"Computes fractional portion element input. $$     \\mbox{}_{} = \\mbox{input}_{} - \\left\\lfloor |\\mbox{input}_{}| \\right\\rfloor * \\mbox{sgn}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_frac.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frac — torch_frac","text":"","code":"if (torch_is_installed()) {  torch_frac(torch_tensor(c(1, 2.5, -3.2))) } #> torch_tensor #>  0.0000 #>  0.5000 #> -0.2000 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Full — torch_full","title":"Full — torch_full","text":"Full","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full — torch_full","text":"","code":"torch_full(   size,   fill_value,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full — torch_full","text":"size (int...) list, tuple, torch_Size integers defining        shape output tensor. fill_value NA number fill output tensor . names optional names dimensions dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":"full-size-fill-value-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"full(size, fill_value, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Full — torch_full","text":"Returns tensor size size filled fill_value.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Full — torch_full","text":"PyTorch 1.5 bool integral fill_value produce warning dtype set. future PyTorch release, dtype set bool fill_value return tensor torch.bool dtype, integral fill_value return tensor torch.long dtype.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full — torch_full","text":"","code":"if (torch_is_installed()) {  torch_full(list(2, 3), 3.141592) } #> torch_tensor #>  3.1416  3.1416  3.1416 #>  3.1416  3.1416  3.1416 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_full_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Full_like — torch_full_like","title":"Full_like — torch_full_like","text":"Full_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full_like — torch_full_like","text":"","code":"torch_full_like(   input,   fill_value,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_full_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full_like — torch_full_like","text":"input (Tensor) size input determine size output tensor. fill_value number fill output tensor . dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_full_like.html","id":"full-like-input-fill-value-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-","dir":"Reference","previous_headings":"","what":"full_like(input, fill_value, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False,","title":"Full_like — torch_full_like","text":"memory_format=torch.preserve_format) -> Tensor Returns tensor size input filled fill_value. torch_full_like(input, fill_value) equivalent torch_full(input.size(), fill_value, dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gather.html","id":null,"dir":"Reference","previous_headings":"","what":"Gather — torch_gather","title":"Gather — torch_gather","text":"Gather","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gather.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gather — torch_gather","text":"","code":"torch_gather(self, dim, index, sparse_grad = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_gather.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gather — torch_gather","text":"self (Tensor) source tensor dim (int) axis along index index (LongTensor) indices elements gather sparse_grad (bool,optional) TRUE, gradient w.r.t. input sparse tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gather.html","id":"gather-input-dim-index-sparse-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"gather(input, dim, index, sparse_grad=FALSE) -> Tensor","title":"Gather — torch_gather","text":"Gathers values along axis specified dim. 3-D tensor output specified ::   input n-dimensional tensor size \\((x_0, x_1..., x_{-1}, x_i, x_{+1}, ..., x_{n-1})\\) dim = , index must \\(n\\)-dimensional tensor size \\((x_0, x_1, ..., x_{-1}, y, x_{+1}, ..., x_{n-1})\\) \\(y \\geq 1\\) size index.","code":"out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0 out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1 out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2"},{"path":"https://torch.mlverse.org/docs/reference/torch_gather.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gather — torch_gather","text":"","code":"if (torch_is_installed()) {  t = torch_tensor(matrix(c(1,2,3,4), ncol = 2, byrow = TRUE)) torch_gather(t, 2, torch_tensor(matrix(c(1,1,2,1), ncol = 2, byrow=TRUE), dtype = torch_int64())) } #> torch_tensor #>  1  1 #>  4  3 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":null,"dir":"Reference","previous_headings":"","what":"Gcd — torch_gcd","title":"Gcd — torch_gcd","text":"Gcd","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gcd — torch_gcd","text":"","code":"torch_gcd(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gcd — torch_gcd","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Gcd — torch_gcd","text":"defines \\(gcd(0, 0) = 0\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":"gcd-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"gcd(input, other, *, out=None) -> Tensor","title":"Gcd — torch_gcd","text":"Computes element-wise greatest common divisor (GCD) input . input must integer types.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gcd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gcd — torch_gcd","text":"","code":"if (torch_is_installed()) {  if (torch::cuda_is_available()) { a <- torch_tensor(c(5, 10, 15), dtype = torch_long(), device = \"cuda\") b <- torch_tensor(c(3, 4, 5), dtype = torch_long(), device = \"cuda\") torch_gcd(a, b) c <- torch_tensor(c(3L), device = \"cuda\") torch_gcd(a, c) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_ge.html","id":null,"dir":"Reference","previous_headings":"","what":"Ge — torch_ge","title":"Ge — torch_ge","text":"Ge","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ge — torch_ge","text":"","code":"torch_ge(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_ge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ge — torch_ge","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ge.html","id":"ge-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"ge(input, other, out=NULL) -> Tensor","title":"Ge — torch_ge","text":"Computes \\(\\mbox{input} \\geq \\mbox{}\\) element-wise. second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ge — torch_ge","text":"","code":"if (torch_is_installed()) {  torch_ge(torch_tensor(matrix(1:4, ncol = 2, byrow=TRUE)),           torch_tensor(matrix(c(1,1,4,4), ncol = 2, byrow=TRUE))) } #> torch_tensor #>  1  1 #>  0  1 #> [ CPUBoolType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Generator object — torch_generator","title":"Create a Generator object — torch_generator","text":"torch_generator  object manages state algorithm produces pseudo random numbers. Used keyword argument many -place random sampling functions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Generator object — torch_generator","text":"","code":"torch_generator()"},{"path":"https://torch.mlverse.org/docs/reference/torch_generator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Generator object — torch_generator","text":"","code":"if (torch_is_installed()) {  # Via string generator <- torch_generator() generator$current_seed() generator$set_current_seed(1234567L) generator$current_seed()  } #> integer64 #> [1] 1234567"},{"path":"https://torch.mlverse.org/docs/reference/torch_geqrf.html","id":null,"dir":"Reference","previous_headings":"","what":"Geqrf — torch_geqrf","title":"Geqrf — torch_geqrf","text":"Geqrf","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_geqrf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Geqrf — torch_geqrf","text":"","code":"torch_geqrf(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_geqrf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Geqrf — torch_geqrf","text":"self (Tensor) input matrix","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_geqrf.html","id":"geqrf-input-out-null-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"geqrf(input, out=NULL) -> (Tensor, Tensor)","title":"Geqrf — torch_geqrf","text":"low-level function calling LAPACK directly. function returns namedtuple (, tau) defined LAPACK documentation geqrf_ . generally want use torch_qr instead. Computes QR decomposition input, without constructing \\(Q\\) \\(R\\) explicit separate matrices. Rather, directly calls underlying LAPACK function ?geqrf produces sequence 'elementary reflectors'. See LAPACK documentation geqrf_ details.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":null,"dir":"Reference","previous_headings":"","what":"Ger — torch_ger","title":"Ger — torch_ger","text":"Ger","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ger — torch_ger","text":"","code":"torch_ger(self, vec2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ger — torch_ger","text":"self (Tensor) 1-D input vector vec2 (Tensor) 1-D input vector","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Ger — torch_ger","text":"function broadcast .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":"ger-input-vec-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"ger(input, vec2, out=NULL) -> Tensor","title":"Ger — torch_ger","text":"Outer product input vec2. input vector size \\(n\\) vec2 vector size \\(m\\), must matrix size \\((n \\times m)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ger.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ger — torch_ger","text":"","code":"if (torch_is_installed()) {  v1 = torch_arange(1., 5.) v2 = torch_arange(1., 4.) torch_ger(v1, v2) } #> torch_tensor #>   1   2   3   4 #>   2   4   6   8 #>   3   6   9  12 #>   4   8  12  16 #>   5  10  15  20 #> [ CPUFloatType{5,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_get_rng_state.html","id":null,"dir":"Reference","previous_headings":"","what":"RNG state management — torch_get_rng_state","title":"RNG state management — torch_get_rng_state","text":"Low level functionality set change RNG state. recommended use torch_manual_seed() cases.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_get_rng_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RNG state management — torch_get_rng_state","text":"","code":"torch_get_rng_state()  torch_set_rng_state(state)  cuda_get_rng_state(device = NULL)  cuda_set_rng_state(state, device = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_get_rng_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RNG state management — torch_get_rng_state","text":"state tensor current state list containing state device - (CUDA). device cuda device index get set state. NULL gets state available devices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_get_rng_state.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"RNG state management — torch_get_rng_state","text":"torch_set_rng_state(): Sets RNG state CPU cuda_get_rng_state(): Gets RNG state CUDA. cuda_set_rng_state(): Sets RNG state CUDA.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater.html","id":null,"dir":"Reference","previous_headings":"","what":"Greater — torch_greater","title":"Greater — torch_greater","text":"Greater","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greater — torch_greater","text":"","code":"torch_greater(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_greater.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Greater — torch_greater","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater.html","id":"greater-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"greater(input, other, *, out=None) -> Tensor","title":"Greater — torch_greater","text":"Alias torch_gt().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Greater_equal — torch_greater_equal","title":"Greater_equal — torch_greater_equal","text":"Greater_equal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Greater_equal — torch_greater_equal","text":"","code":"torch_greater_equal(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_greater_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Greater_equal — torch_greater_equal","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_greater_equal.html","id":"greater-equal-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"greater_equal(input, other, *, out=None) -> Tensor","title":"Greater_equal — torch_greater_equal","text":"Alias torch_ge().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gt.html","id":null,"dir":"Reference","previous_headings":"","what":"Gt — torch_gt","title":"Gt — torch_gt","text":"Gt","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gt — torch_gt","text":"","code":"torch_gt(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_gt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gt — torch_gt","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gt.html","id":"gt-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"gt(input, other, out=NULL) -> Tensor","title":"Gt — torch_gt","text":"Computes \\(\\mbox{input} > \\mbox{}\\) element-wise. second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_gt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gt — torch_gt","text":"","code":"if (torch_is_installed()) {  torch_gt(torch_tensor(matrix(1:4, ncol = 2, byrow=TRUE)),           torch_tensor(matrix(c(1,1,4,4), ncol = 2, byrow=TRUE))) } #> torch_tensor #>  0  1 #>  0  0 #> [ CPUBoolType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_hamming_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Hamming_window — torch_hamming_window","title":"Hamming_window — torch_hamming_window","text":"Hamming_window","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hamming_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hamming_window — torch_hamming_window","text":"","code":"torch_hamming_window(   window_length,   periodic = TRUE,   alpha = 0.54,   beta = 0.46,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_hamming_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hamming_window — torch_hamming_window","text":"window_length (int) size returned window periodic (bool, optional) TRUE, returns window used periodic        function. False, return symmetric window. alpha (float, optional) coefficient \\(\\alpha\\) equation beta (float, optional) coefficient \\(\\beta\\) equation dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). floating point types supported. layout (torch.layout, optional) desired layout returned window tensor.          torch_strided (dense layout) supported. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hamming_window.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hamming_window — torch_hamming_window","text":"","code":"If `window_length` \\eqn{=1}, the returned window contains a single value 1. This is a generalized version of `torch_hann_window`."},{"path":"https://torch.mlverse.org/docs/reference/torch_hamming_window.html","id":"hamming-window-window-length-periodic-true-alpha-beta-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"hamming_window(window_length, periodic=TRUE, alpha=0.54, beta=0.46, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Hamming_window — torch_hamming_window","text":"Hamming window function. $$     w[n] = \\alpha - \\beta\\ \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right), $$ \\(N\\) full window size. input window_length positive integer controlling returned window size. periodic flag determines whether returned window trims last duplicate value symmetric window ready used periodic window functions like torch_stft. Therefore, periodic true, \\(N\\) formula fact \\(\\mbox{window\\_length} + 1\\). Also, always torch_hamming_window(L, periodic=TRUE) equal torch_hamming_window(L + 1, periodic=False)[:-1]).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hann_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Hann_window — torch_hann_window","title":"Hann_window — torch_hann_window","text":"Hann_window","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hann_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hann_window — torch_hann_window","text":"","code":"torch_hann_window(   window_length,   periodic = TRUE,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_hann_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hann_window — torch_hann_window","text":"window_length (int) size returned window periodic (bool, optional) TRUE, returns window used periodic        function. False, return symmetric window. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). floating point types supported. layout (torch.layout, optional) desired layout returned window tensor.          torch_strided (dense layout) supported. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hann_window.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Hann_window — torch_hann_window","text":"","code":"If `window_length` \\eqn{=1}, the returned window contains a single value 1."},{"path":"https://torch.mlverse.org/docs/reference/torch_hann_window.html","id":"hann-window-window-length-periodic-true-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"hann_window(window_length, periodic=TRUE, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Hann_window — torch_hann_window","text":"Hann window function. $$     w[n] = \\frac{1}{2}\\ \\left[1 - \\cos \\left( \\frac{2 \\pi n}{N - 1} \\right)\\right] =             \\sin^2 \\left( \\frac{\\pi n}{N - 1} \\right), $$ \\(N\\) full window size. input window_length positive integer controlling returned window size. periodic flag determines whether returned window trims last duplicate value symmetric window ready used periodic window functions like torch_stft. Therefore, periodic true, \\(N\\) formula fact \\(\\mbox{window\\_length} + 1\\). Also, always torch_hann_window(L, periodic=TRUE) equal torch_hann_window(L + 1, periodic=False)[:-1]).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_heaviside.html","id":null,"dir":"Reference","previous_headings":"","what":"Heaviside — torch_heaviside","title":"Heaviside — torch_heaviside","text":"Heaviside","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_heaviside.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Heaviside — torch_heaviside","text":"","code":"torch_heaviside(self, values)"},{"path":"https://torch.mlverse.org/docs/reference/torch_heaviside.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Heaviside — torch_heaviside","text":"self (Tensor) input tensor. values (Tensor) values use input zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_heaviside.html","id":"heaviside-input-values-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"heaviside(input, values, *, out=None) -> Tensor","title":"Heaviside — torch_heaviside","text":"Computes Heaviside step function element input. Heaviside step function defined : $$ \\mbox{{heaviside}}(input, values) = \\begin{array}{ll}  0, & \\mbox{input < 0}\\\\  values, & \\mbox{input == 0}\\\\  1, & \\mbox{input > 0}  \\end{array} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_heaviside.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Heaviside — torch_heaviside","text":"","code":"if (torch_is_installed()) {  input <- torch_tensor(c(-1.5, 0, 2.0)) values <- torch_tensor(c(0.5)) torch_heaviside(input, values) values <- torch_tensor(c(1.2, -2.0, 3.5)) torch_heaviside(input, values) } #> torch_tensor #>  0 #> -2 #>  1 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_histc.html","id":null,"dir":"Reference","previous_headings":"","what":"Histc — torch_histc","title":"Histc — torch_histc","text":"Histc","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_histc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histc — torch_histc","text":"","code":"torch_histc(self, bins = 100L, min = 0L, max = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_histc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histc — torch_histc","text":"self (Tensor) input tensor. bins (int) number histogram bins min (int) lower end range (inclusive) max (int) upper end range (inclusive)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_histc.html","id":"histc-input-bins-min-max-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"histc(input, bins=100, min=0, max=0, out=NULL) -> Tensor","title":"Histc — torch_histc","text":"Computes histogram tensor. elements sorted equal width bins min max. min max zero, minimum maximum values data used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_histc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Histc — torch_histc","text":"","code":"if (torch_is_installed()) {  torch_histc(torch_tensor(c(1., 2, 1)), bins=4, min=0, max=3) } #> torch_tensor #>  0 #>  2 #>  1 #>  0 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_hstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Hstack — torch_hstack","title":"Hstack — torch_hstack","text":"Hstack","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hstack — torch_hstack","text":"","code":"torch_hstack(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_hstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hstack — torch_hstack","text":"tensors (sequence Tensors) sequence tensors concatenate","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hstack.html","id":"hstack-tensors-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"hstack(tensors, *, out=None) -> Tensor","title":"Hstack — torch_hstack","text":"Stack tensors sequence horizontally (column wise). equivalent concatenation along first axis 1-D tensors, along second axis tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hstack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hstack — torch_hstack","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2, 3)) b <- torch_tensor(c(4, 5, 6)) torch_hstack(list(a,b)) a <- torch_tensor(rbind(1,2,3)) b <- torch_tensor(rbind(4,5,6)) torch_hstack(list(a,b)) } #> torch_tensor #>  1  4 #>  2  5 #>  3  6 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_hypot.html","id":null,"dir":"Reference","previous_headings":"","what":"Hypot — torch_hypot","title":"Hypot — torch_hypot","text":"Hypot","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hypot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hypot — torch_hypot","text":"","code":"torch_hypot(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_hypot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hypot — torch_hypot","text":"self (Tensor) first input tensor (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hypot.html","id":"hypot-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"hypot(input, other, *, out=None) -> Tensor","title":"Hypot — torch_hypot","text":"Given legs right triangle, return hypotenuse. $$ \\mbox{}_{} = \\sqrt{\\mbox{input}_{}^{2} + \\mbox{}_{}^{2}} $$ shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_hypot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hypot — torch_hypot","text":"","code":"if (torch_is_installed()) {  torch_hypot(torch_tensor(c(4.0)), torch_tensor(c(3.0, 4.0, 5.0))) } #> torch_tensor #>  5.0000 #>  5.6569 #>  6.4031 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_i0.html","id":null,"dir":"Reference","previous_headings":"","what":"I0 — torch_i0","title":"I0 — torch_i0","text":"I0","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_i0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"I0 — torch_i0","text":"","code":"torch_i0(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_i0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"I0 — torch_i0","text":"self (Tensor) input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_i0.html","id":"i-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"i0(input, *, out=None) -> Tensor","title":"I0 — torch_i0","text":"Computes zeroth order modified Bessel function first kind element input. $$ \\mbox{}_{} = I_0(\\mbox{input}_{}) = \\sum_{k=0}^{\\infty} \\frac{(\\mbox{input}_{}^2/4)^k}{(k!)^2} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_i0.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"I0 — torch_i0","text":"","code":"if (torch_is_installed()) {  torch_i0(torch_arange(start = 0, end = 5, dtype=torch_float32())) } #> torch_tensor #>   1.0000 #>   1.2661 #>   2.2796 #>   4.8808 #>  11.3019 #>  27.2399 #> [ CPUFloatType{6} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_iinfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Integer type info — torch_iinfo","title":"Integer type info — torch_iinfo","text":"list represents numerical properties integer type.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_iinfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integer type info — torch_iinfo","text":"","code":"torch_iinfo(dtype)"},{"path":"https://torch.mlverse.org/docs/reference/torch_iinfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integer type info — torch_iinfo","text":"dtype dtype get information .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":null,"dir":"Reference","previous_headings":"","what":"Imag — torch_imag","title":"Imag — torch_imag","text":"Imag","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Imag — torch_imag","text":"","code":"torch_imag(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Imag — torch_imag","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":"imag-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"imag(input) -> Tensor","title":"Imag — torch_imag","text":"Returns imaginary part input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Imag — torch_imag","text":"yet implemented. $$     \\mbox{}_{} = imag(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_imag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Imag — torch_imag","text":"","code":"if (torch_is_installed()) { if (FALSE) { torch_imag(torch_tensor(c(-1 + 1i, -2 + 2i, 3 - 3i))) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Index torch tensors — torch_index","title":"Index torch tensors — torch_index","text":"Helper functions index tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index torch tensors — torch_index","text":"","code":"torch_index(self, indices)"},{"path":"https://torch.mlverse.org/docs/reference/torch_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index torch tensors — torch_index","text":"self (Tensor) Tensor indexed. indices (List[Tensor]) List indices. Indices torch tensors torch_long() dtype.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify values selected by indices. — torch_index_put","title":"Modify values selected by indices. — torch_index_put","text":"Modify values selected indices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify values selected by indices. — torch_index_put","text":"","code":"torch_index_put(self, indices, values, accumulate = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify values selected by indices. — torch_index_put","text":"self (Tensor) Tensor indexed. indices (List[Tensor]) List indices. Indices torch tensors torch_long() dtype. values (Tensor) values replaced indexed location. Used torch_index_put torch_index_put_. accumulate (bool) Wether instead replacing current values values, want add .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put_.html","id":null,"dir":"Reference","previous_headings":"","what":"In-place version of torch_index_put. — torch_index_put_","title":"In-place version of torch_index_put. — torch_index_put_","text":"-place version torch_index_put.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"In-place version of torch_index_put. — torch_index_put_","text":"","code":"torch_index_put_(self, indices, values, accumulate = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_index_put_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"In-place version of torch_index_put. — torch_index_put_","text":"self (Tensor) Tensor indexed. indices (List[Tensor]) List indices. Indices torch tensors torch_long() dtype. values (Tensor) values replaced indexed location. Used torch_index_put torch_index_put_. accumulate (bool) Wether instead replacing current values values, want add .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":null,"dir":"Reference","previous_headings":"","what":"Index_select — torch_index_select","title":"Index_select — torch_index_select","text":"Index_select","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index_select — torch_index_select","text":"","code":"torch_index_select(self, dim, index)"},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index_select — torch_index_select","text":"self (Tensor) input tensor. dim (int) dimension index index (LongTensor) 1-D tensor containing indices index","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Index_select — torch_index_select","text":"returned tensor use storage original tensor.  different shape expected, silently change correct shape, reallocating underlying storage necessary.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":"index-select-input-dim-index-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"index_select(input, dim, index, out=NULL) -> Tensor","title":"Index_select — torch_index_select","text":"Returns new tensor indexes input tensor along dimension dim using entries index LongTensor. returned tensor number dimensions original tensor (input).  dim\\ th dimension size length index; dimensions size original tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_index_select.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Index_select — torch_index_select","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(3, 4)) x indices = torch_tensor(c(1, 3), dtype = torch_int64()) torch_index_select(x, 1, indices) torch_index_select(x, 2, indices) } #> torch_tensor #>  0.2459  2.5702 #> -1.0427  0.2300 #>  0.0728  0.7199 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_install_path.html","id":null,"dir":"Reference","previous_headings":"","what":"A simple exported version of install_path Returns the torch installation path. — torch_install_path","title":"A simple exported version of install_path Returns the torch installation path. — torch_install_path","text":"simple exported version install_path Returns torch installation path.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_install_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A simple exported version of install_path Returns the torch installation path. — torch_install_path","text":"","code":"torch_install_path()"},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse — torch_inverse","title":"Inverse — torch_inverse","text":"Inverse","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse — torch_inverse","text":"","code":"torch_inverse(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse — torch_inverse","text":"self (Tensor) input tensor size \\((*, n, n)\\) * zero                    batch dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Inverse — torch_inverse","text":"","code":"Irrespective of the original strides, the returned tensors will be transposed, i.e. with strides like `input.contiguous().transpose(-2, -1).stride()`"},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":"inverse-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"inverse(input, out=NULL) -> Tensor","title":"Inverse — torch_inverse","text":"Takes inverse square matrix input. input can batches 2D square tensors, case function return tensor composed individual inverses.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_inverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse — torch_inverse","text":"","code":"if (torch_is_installed()) { if (FALSE) { x = torch_rand(c(4, 4)) y = torch_inverse(x) z = torch_mm(x, y) z torch_max(torch_abs(z - torch_eye(4))) # Max non-zero # Batched inverse example x = torch_randn(c(2, 3, 4, 4)) y = torch_inverse(x) z = torch_matmul(x, y) torch_max(torch_abs(z - torch_eye(4)$expand_as(x))) # Max non-zero } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_is_complex.html","id":null,"dir":"Reference","previous_headings":"","what":"Is_complex — torch_is_complex","title":"Is_complex — torch_is_complex","text":"Is_complex","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_complex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is_complex — torch_is_complex","text":"","code":"torch_is_complex(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_is_complex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is_complex — torch_is_complex","text":"self (Tensor) PyTorch tensor test","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_complex.html","id":"is-complex-input-gt-bool-","dir":"Reference","previous_headings":"","what":"is_complex(input) -> (bool)","title":"Is_complex — torch_is_complex","text":"Returns TRUE data type input complex data type .e., one torch_complex64, torch.complex128.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_floating_point.html","id":null,"dir":"Reference","previous_headings":"","what":"Is_floating_point — torch_is_floating_point","title":"Is_floating_point — torch_is_floating_point","text":"Is_floating_point","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_floating_point.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is_floating_point — torch_is_floating_point","text":"","code":"torch_is_floating_point(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_is_floating_point.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is_floating_point — torch_is_floating_point","text":"self (Tensor) PyTorch tensor test","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_floating_point.html","id":"is-floating-point-input-gt-bool-","dir":"Reference","previous_headings":"","what":"is_floating_point(input) -> (bool)","title":"Is_floating_point — torch_is_floating_point","text":"Returns TRUE data type input floating point data type .e., one torch_float64, torch.float32 torch.float16.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_installed.html","id":null,"dir":"Reference","previous_headings":"","what":"Verifies if torch is installed — torch_is_installed","title":"Verifies if torch is installed — torch_is_installed","text":"Verifies torch installed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_installed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Verifies if torch is installed — torch_is_installed","text":"","code":"torch_is_installed()"},{"path":"https://torch.mlverse.org/docs/reference/torch_is_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"Is_nonzero — torch_is_nonzero","title":"Is_nonzero — torch_is_nonzero","text":"Is_nonzero","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Is_nonzero — torch_is_nonzero","text":"","code":"torch_is_nonzero(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_is_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Is_nonzero — torch_is_nonzero","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_nonzero.html","id":"is-nonzero-input-gt-bool-","dir":"Reference","previous_headings":"","what":"is_nonzero(input) -> (bool)","title":"Is_nonzero — torch_is_nonzero","text":"Returns TRUE input single element tensor equal zero type conversions. .e. equal torch_tensor(c(0)) torch_tensor(c(0)) torch_tensor(c(FALSE)). Throws RuntimeError torch_numel() != 1 (even case sparse tensors).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_is_nonzero.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Is_nonzero — torch_is_nonzero","text":"","code":"if (torch_is_installed()) {  torch_is_nonzero(torch_tensor(c(0.))) torch_is_nonzero(torch_tensor(c(1.5))) torch_is_nonzero(torch_tensor(c(FALSE))) torch_is_nonzero(torch_tensor(c(3))) if (FALSE) { torch_is_nonzero(torch_tensor(c(1, 3, 5))) torch_is_nonzero(torch_tensor(c())) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_isclose.html","id":null,"dir":"Reference","previous_headings":"","what":"Isclose — torch_isclose","title":"Isclose — torch_isclose","text":"Isclose","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isclose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isclose — torch_isclose","text":"","code":"torch_isclose(self, other, rtol = 1e-05, atol = 1e-08, equal_nan = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isclose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isclose — torch_isclose","text":"self (Tensor) first tensor compare (Tensor) second tensor compare rtol (float, optional) relative tolerance. Default: 1e-05 atol (float, optional) absolute tolerance. Default: 1e-08 equal_nan (bool, optional) TRUE, two NaN s considered equal. Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isclose.html","id":"isclose-input-other-rtol-e-atol-e-equal-nan-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"isclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=FALSE) -> Tensor","title":"Isclose — torch_isclose","text":"Returns new tensor boolean elements representing element input \"close\" corresponding element . Closeness defined : $$     \\vert \\mbox{input} - \\mbox{} \\vert \\leq \\mbox{atol} + \\mbox{rtol} \\times \\vert \\mbox{} \\vert $$ input finite. input /nonfinite close equal, NaNs considered equal equal_nan TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isclose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isclose — torch_isclose","text":"","code":"if (torch_is_installed()) {  torch_isclose(torch_tensor(c(1., 2, 3)), torch_tensor(c(1 + 1e-10, 3, 4))) torch_isclose(torch_tensor(c(Inf, 4)), torch_tensor(c(Inf, 6)), rtol=.5) } #> torch_tensor #>  1 #>  1 #> [ CPUBoolType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isfinite.html","id":null,"dir":"Reference","previous_headings":"","what":"Isfinite — torch_isfinite","title":"Isfinite — torch_isfinite","text":"Isfinite","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isfinite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isfinite — torch_isfinite","text":"","code":"torch_isfinite(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isfinite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isfinite — torch_isfinite","text":"self (Tensor) tensor check","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isfinite.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Isfinite — torch_isfinite","text":"Returns new tensor boolean elements representing element Finite .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isfinite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isfinite — torch_isfinite","text":"","code":"if (torch_is_installed()) {  torch_isfinite(torch_tensor(c(1, Inf, 2, -Inf, NaN))) } #> torch_tensor #>  1 #>  0 #>  1 #>  0 #>  0 #> [ CPUBoolType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isinf.html","id":null,"dir":"Reference","previous_headings":"","what":"Isinf — torch_isinf","title":"Isinf — torch_isinf","text":"Isinf","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isinf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isinf — torch_isinf","text":"","code":"torch_isinf(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isinf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isinf — torch_isinf","text":"self (Tensor) tensor check","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isinf.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Isinf — torch_isinf","text":"Returns new tensor boolean elements representing element +/-INF .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isinf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isinf — torch_isinf","text":"","code":"if (torch_is_installed()) {  torch_isinf(torch_tensor(c(1, Inf, 2, -Inf, NaN))) } #> torch_tensor #>  0 #>  1 #>  0 #>  1 #>  0 #> [ CPUBoolType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isnan.html","id":null,"dir":"Reference","previous_headings":"","what":"Isnan — torch_isnan","title":"Isnan — torch_isnan","text":"Isnan","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isnan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isnan — torch_isnan","text":"","code":"torch_isnan(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isnan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isnan — torch_isnan","text":"self (Tensor) tensor check","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isnan.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Isnan — torch_isnan","text":"Returns new tensor boolean elements representing element NaN .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isnan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isnan — torch_isnan","text":"","code":"if (torch_is_installed()) {  torch_isnan(torch_tensor(c(1, NaN, 2))) } #> torch_tensor #>  0 #>  1 #>  0 #> [ CPUBoolType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isneginf.html","id":null,"dir":"Reference","previous_headings":"","what":"Isneginf — torch_isneginf","title":"Isneginf — torch_isneginf","text":"Isneginf","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isneginf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isneginf — torch_isneginf","text":"","code":"torch_isneginf(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isneginf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isneginf — torch_isneginf","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isneginf.html","id":"isneginf-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"isneginf(input, *, out=None) -> Tensor","title":"Isneginf — torch_isneginf","text":"Tests element input negative infinity .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isneginf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isneginf — torch_isneginf","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(-Inf, Inf, 1.2)) torch_isneginf(a) } #> torch_tensor #>  1 #>  0 #>  0 #> [ CPUBoolType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isposinf.html","id":null,"dir":"Reference","previous_headings":"","what":"Isposinf — torch_isposinf","title":"Isposinf — torch_isposinf","text":"Isposinf","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isposinf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isposinf — torch_isposinf","text":"","code":"torch_isposinf(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isposinf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isposinf — torch_isposinf","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isposinf.html","id":"isposinf-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"isposinf(input, *, out=None) -> Tensor","title":"Isposinf — torch_isposinf","text":"Tests element input positive infinity .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isposinf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isposinf — torch_isposinf","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(-Inf, Inf, 1.2)) torch_isposinf(a) } #> torch_tensor #>  0 #>  1 #>  0 #> [ CPUBoolType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_isreal.html","id":null,"dir":"Reference","previous_headings":"","what":"Isreal — torch_isreal","title":"Isreal — torch_isreal","text":"Isreal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isreal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Isreal — torch_isreal","text":"","code":"torch_isreal(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_isreal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Isreal — torch_isreal","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isreal.html","id":"isreal-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"isreal(input) -> Tensor","title":"Isreal — torch_isreal","text":"Returns new tensor boolean elements representing element input real-valued . real-valued types considered real. Complex values considered real imaginary part 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_isreal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Isreal — torch_isreal","text":"","code":"if (torch_is_installed()) { if (FALSE) { torch_isreal(torch_tensor(c(1, 1+1i, 2+0i))) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_istft.html","id":null,"dir":"Reference","previous_headings":"","what":"Istft — torch_istft","title":"Istft — torch_istft","text":"Inverse short time Fourier Transform. expected inverse torch_stft().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_istft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Istft — torch_istft","text":"","code":"torch_istft(   self,   n_fft,   hop_length = NULL,   win_length = NULL,   window = list(),   center = TRUE,   normalized = FALSE,   onesided = NULL,   length = NULL,   return_complex = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_istft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Istft — torch_istft","text":"self (Tensor) input tensor. Expected output torch_stft(), can either complex (channel, fft_size, n_frame), real (channel, fft_size, n_frame, 2) channel dimension optional. n_fft (int) Size Fourier transform hop_length (Optional[int]) distance neighboring sliding window frames. (Default: n_fft %% 4) win_length (Optional[int]) size window frame STFT filter. (Default: n_fft) window (Optional(torch.Tensor)) optional window function. (Default: torch_ones(win_length)) center (bool) Whether input padded sides \\(t\\)-th frame centered time \\(t \\times \\mbox{hop\\_length}\\). (Default: TRUE) normalized (bool) Whether STFT normalized. (Default: FALSE) onesided (Optional(bool)) Whether STFT onesided. (Default: TRUE n_fft != fft_size input size) length (Optional(int)]) amount trim signal (.e. original signal length). (Default: whole signal) return_complex (Optional(bool)) Whether output complex, input assumed derive real signal window. Note incompatible onesided=TRUE. (Default: FALSE)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_istft.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Istft — torch_istft","text":"parameters (+ additional optional parameter length) return least squares estimation original signal. algorithm check using NOLA condition (nonzero overlap). Important consideration parameters window center envelop created summation windows never zero certain point time. Specifically, \\(\\sum_{t=-\\infty}^{\\infty} |w|^2(n-t\\times hop_length) \\neq 0\\). Since torch_stft() discards elements end signal fit frame, istft may return shorter signal original signal (can occur center FALSE since signal padded). center TRUE, padding e.g. 'constant', 'reflect', etc. Left padding can trimmed exactly can calculated right padding calculated without additional information. Example: Suppose last window : [c(17, 18, 0, 0, 0) vs c(18, 0, 0, 0, 0) n_fft, hop_length, win_length prevents calculation right padding. additional values zeros reflection signal providing length useful. length None padding aggressively removed (loss signal). D. W. Griffin J. S. Lim, \"Signal estimation modified short-time Fourier transform,\" IEEE Trans. ASSP, vol.32, .2, pp.236-243, Apr. 1984.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kaiser_window.html","id":null,"dir":"Reference","previous_headings":"","what":"Kaiser_window — torch_kaiser_window","title":"Kaiser_window — torch_kaiser_window","text":"Kaiser_window","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kaiser_window.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kaiser_window — torch_kaiser_window","text":"","code":"torch_kaiser_window(   window_length,   periodic,   beta,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_kaiser_window.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kaiser_window — torch_kaiser_window","text":"window_length (int) length window. periodic (bool, optional) TRUE, returns periodic window suitable use spectral analysis.        FALSE, returns symmetric window suitable use filter design. beta (float, optional) shape parameter window. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). dtype given, infer data type input        arguments. start, end, stop floating-point,        dtype inferred default dtype, see        ~torch.get_default_dtype. Otherwise, dtype inferred        torch.int64. layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kaiser_window.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Kaiser_window — torch_kaiser_window","text":"window_length one, returned window single element tensor containing one.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kaiser_window.html","id":"kaiser-window-window-length-periodic-true-beta-dtype-none-layout-torch-strided-device-none-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"kaiser_window(window_length, periodic=TRUE, beta=12.0, *, dtype=None, layout=torch.strided, device=None, requires_grad=FALSE) -> Tensor","title":"Kaiser_window — torch_kaiser_window","text":"Computes Kaiser window window length window_length shape parameter beta. Let I_0 zeroth order modified Bessel function first kind (see torch_i0()) N = L - 1 periodic FALSE L periodic TRUE, L window_length. function computes: $$     out_i = I_0 \\left( \\beta \\sqrt{1 - \\left( {\\frac{- N/2}{N/2}} \\right) ^2 } \\right) / I_0( \\beta ) $$ Calling torch_kaiser_window(L, B, periodic=TRUE) equivalent calling torch_kaiser_window(L + 1, B, periodic=FALSE)[:-1]). periodic argument intended helpful shorthand produce periodic window input functions like torch_stft().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kron.html","id":null,"dir":"Reference","previous_headings":"","what":"Kronecker product — torch_kron","title":"Kronecker product — torch_kron","text":"Computes Kronecker product self .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kron.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kronecker product — torch_kron","text":"","code":"torch_kron(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_kron.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kronecker product — torch_kron","text":"self (Tensor) input Tensor (Tensor) tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kthvalue.html","id":null,"dir":"Reference","previous_headings":"","what":"Kthvalue — torch_kthvalue","title":"Kthvalue — torch_kthvalue","text":"Kthvalue","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kthvalue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kthvalue — torch_kthvalue","text":"","code":"torch_kthvalue(self, k, dim = -1L, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_kthvalue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kthvalue — torch_kthvalue","text":"self (Tensor) input tensor. k (int) k k-th smallest element dim (int, optional) dimension find kth value along keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kthvalue.html","id":"kthvalue-input-k-dim-null-keepdim-false-out-null-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"kthvalue(input, k, dim=NULL, keepdim=False, out=NULL) -> (Tensor, LongTensor)","title":"Kthvalue — torch_kthvalue","text":"Returns namedtuple (values, indices) values k th smallest element row input tensor given dimension dim. indices index location element found. dim given, last dimension input chosen. keepdim TRUE, values indices tensors size input, except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting values indices tensors 1 fewer dimension input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_kthvalue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kthvalue — torch_kthvalue","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(1, 6) x torch_kthvalue(x, 4) x <- torch_arange(1,6)$resize_(c(2,3)) x torch_kthvalue(x, 2, 1, TRUE) } #> [[1]] #> torch_tensor #>  4  5  6 #> [ CPUFloatType{1,3} ] #>  #> [[2]] #> torch_tensor #>  1  1  1 #> [ CPULongType{1,3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_layout.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates the corresponding layout — torch_layout","title":"Creates the corresponding layout — torch_layout","text":"Creates corresponding layout","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_layout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates the corresponding layout — torch_layout","text":"","code":"torch_strided()  torch_sparse_coo()"},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":null,"dir":"Reference","previous_headings":"","what":"Lcm — torch_lcm","title":"Lcm — torch_lcm","text":"Lcm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lcm — torch_lcm","text":"","code":"torch_lcm(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lcm — torch_lcm","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Lcm — torch_lcm","text":"defines \\(lcm(0, 0) = 0\\) \\(lcm(0, ) = 0\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":"lcm-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"lcm(input, other, *, out=None) -> Tensor","title":"Lcm — torch_lcm","text":"Computes element-wise least common multiple (LCM) input . input must integer types.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lcm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lcm — torch_lcm","text":"","code":"if (torch_is_installed()) {  if (torch::cuda_is_available()) { a <- torch_tensor(c(5, 10, 15), dtype = torch_long(), device = \"cuda\") b <- torch_tensor(c(3, 4, 5), dtype = torch_long(), device = \"cuda\") torch_lcm(a, b) c <- torch_tensor(c(3L), device = \"cuda\") torch_lcm(a, c) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_le.html","id":null,"dir":"Reference","previous_headings":"","what":"Le — torch_le","title":"Le — torch_le","text":"Le","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_le.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Le — torch_le","text":"","code":"torch_le(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_le.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Le — torch_le","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_le.html","id":"le-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"le(input, other, out=NULL) -> Tensor","title":"Le — torch_le","text":"Computes \\(\\mbox{input} \\leq \\mbox{}\\) element-wise. second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_le.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Le — torch_le","text":"","code":"if (torch_is_installed()) {  torch_le(torch_tensor(matrix(1:4, ncol = 2, byrow=TRUE)),           torch_tensor(matrix(c(1,1,4,4), ncol = 2, byrow=TRUE))) } #> torch_tensor #>  1  0 #>  1  1 #> [ CPUBoolType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_lerp.html","id":null,"dir":"Reference","previous_headings":"","what":"Lerp — torch_lerp","title":"Lerp — torch_lerp","text":"Lerp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lerp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lerp — torch_lerp","text":"","code":"torch_lerp(self, end, weight)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lerp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lerp — torch_lerp","text":"self (Tensor) tensor starting points end (Tensor) tensor ending points weight (float tensor) weight interpolation formula","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lerp.html","id":"lerp-input-end-weight-out-null-","dir":"Reference","previous_headings":"","what":"lerp(input, end, weight, out=NULL)","title":"Lerp — torch_lerp","text":"linear interpolation two tensors start (given input) end based scalar tensor weight returns resulting tensor. $$     \\mbox{}_i = \\mbox{start}_i + \\mbox{weight}_i \\times (\\mbox{end}_i - \\mbox{start}_i) $$ shapes start end must broadcastable . weight tensor, shapes weight, start, end must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lerp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lerp — torch_lerp","text":"","code":"if (torch_is_installed()) {  start = torch_arange(1, 4) end = torch_empty(4)$fill_(10) start end torch_lerp(start, end, 0.5) torch_lerp(start, end, torch_full_like(start, 0.5)) } #> torch_tensor #>  5.5000 #>  6.0000 #>  6.5000 #>  7.0000 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_less.html","id":null,"dir":"Reference","previous_headings":"","what":"Less — torch_less","title":"Less — torch_less","text":"Less","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_less.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Less — torch_less","text":"","code":"torch_less(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_less.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Less — torch_less","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_less.html","id":"less-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"less(input, other, *, out=None) -> Tensor","title":"Less — torch_less","text":"Alias torch_lt().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_less_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Less_equal — torch_less_equal","title":"Less_equal — torch_less_equal","text":"Less_equal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_less_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Less_equal — torch_less_equal","text":"","code":"torch_less_equal(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_less_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Less_equal — torch_less_equal","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_less_equal.html","id":"less-equal-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"less_equal(input, other, *, out=None) -> Tensor","title":"Less_equal — torch_less_equal","text":"Alias torch_le().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Lgamma — torch_lgamma","title":"Lgamma — torch_lgamma","text":"Lgamma","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lgamma — torch_lgamma","text":"","code":"torch_lgamma(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lgamma — torch_lgamma","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lgamma.html","id":"lgamma-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"lgamma(input, out=NULL) -> Tensor","title":"Lgamma — torch_lgamma","text":"Computes logarithm gamma function input. $$     \\mbox{}_{} = \\log \\Gamma(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lgamma — torch_lgamma","text":"","code":"if (torch_is_installed()) {  a = torch_arange(0.5, 2, 0.5) torch_lgamma(a) } #> torch_tensor #>  0.5724 #>  0.0000 #> -0.1208 #>  0.0000 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_linspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Linspace — torch_linspace","title":"Linspace — torch_linspace","text":"Linspace","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_linspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linspace — torch_linspace","text":"","code":"torch_linspace(   start,   end,   steps = 100,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_linspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linspace — torch_linspace","text":"start (float) starting value set points end (float) ending value set points steps (int) number points sample start        end. Default: 100. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_linspace.html","id":"linspace-start-end-steps-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"linspace(start, end, steps=100, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Linspace — torch_linspace","text":"Returns one-dimensional tensor steps equally spaced points start end. output tensor 1-D size steps.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_linspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linspace — torch_linspace","text":"","code":"if (torch_is_installed()) {  torch_linspace(3, 10, steps=5) torch_linspace(-10, 10, steps=5) torch_linspace(start=-10, end=10, steps=5) torch_linspace(start=-10, end=10, steps=1) } #> torch_tensor #> -10 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads a saved object — torch_load","title":"Loads a saved object — torch_load","text":"Loads saved object","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads a saved object — torch_load","text":"","code":"torch_load(path, device = \"cpu\")"},{"path":"https://torch.mlverse.org/docs/reference/torch_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Loads a saved object — torch_load","text":"path path saved object device device load tensors . default load cpu can also load cuda device. NULL device tensor saved reused.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/torch_log.html","id":null,"dir":"Reference","previous_headings":"","what":"Log — torch_log","title":"Log — torch_log","text":"Log","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log — torch_log","text":"","code":"torch_log(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_log.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log — torch_log","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log.html","id":"log-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"log(input, out=NULL) -> Tensor","title":"Log — torch_log","text":"Returns new tensor natural logarithm elements input. $$     y_{} = \\log_{e} (x_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log — torch_log","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(5)) a torch_log(a) } #> torch_tensor #>     nan #>     nan #>     nan #>     nan #> -1.1847 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_log10.html","id":null,"dir":"Reference","previous_headings":"","what":"Log10 — torch_log10","title":"Log10 — torch_log10","text":"Log10","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log10 — torch_log10","text":"","code":"torch_log10(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_log10.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log10 — torch_log10","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log10.html","id":"log-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"log10(input, out=NULL) -> Tensor","title":"Log10 — torch_log10","text":"Returns new tensor logarithm base 10 elements input. $$     y_{} = \\log_{10} (x_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log10.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log10 — torch_log10","text":"","code":"if (torch_is_installed()) {  a = torch_rand(5) a torch_log10(a) } #> torch_tensor #> 0.01 * #> -8.2896 #> -100.2900 #> -3.4480 #> -46.5474 #> -13.5409 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":null,"dir":"Reference","previous_headings":"","what":"Log1p — torch_log1p","title":"Log1p — torch_log1p","text":"Log1p","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log1p — torch_log1p","text":"","code":"torch_log1p(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log1p — torch_log1p","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Log1p — torch_log1p","text":"function accurate torch_log small values input","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":"log-p-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"log1p(input, out=NULL) -> Tensor","title":"Log1p — torch_log1p","text":"Returns new tensor natural logarithm (1 + input). $$     y_i = \\log_{e} (x_i + 1) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log1p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log1p — torch_log1p","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(5)) a torch_log1p(a) } #> torch_tensor #> -0.4804 #>  0.2434 #>  0.0869 #>  0.7760 #> -1.0442 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_log2.html","id":null,"dir":"Reference","previous_headings":"","what":"Log2 — torch_log2","title":"Log2 — torch_log2","text":"Log2","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log2 — torch_log2","text":"","code":"torch_log2(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_log2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log2 — torch_log2","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log2.html","id":"log-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"log2(input, out=NULL) -> Tensor","title":"Log2 — torch_log2","text":"Returns new tensor logarithm base 2 elements input. $$     y_{} = \\log_{2} (x_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_log2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log2 — torch_log2","text":"","code":"if (torch_is_installed()) {  a = torch_rand(5) a torch_log2(a) } #> torch_tensor #> -1.7491 #> -3.9394 #> -1.5573 #> -0.6504 #> -0.4162 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Logaddexp — torch_logaddexp","title":"Logaddexp — torch_logaddexp","text":"Logaddexp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logaddexp — torch_logaddexp","text":"","code":"torch_logaddexp(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logaddexp — torch_logaddexp","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp.html","id":"logaddexp-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"logaddexp(input, other, *, out=None) -> Tensor","title":"Logaddexp — torch_logaddexp","text":"Logarithm sum exponentiations inputs. Calculates pointwise \\(\\log\\left(e^x + e^y\\right)\\). function useful statistics calculated probabilities events may small exceed range normal floating point numbers. cases logarithm calculated probability stored. function allows adding probabilities stored fashion. op disambiguated torch_logsumexp() performs reduction single tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logaddexp — torch_logaddexp","text":"","code":"if (torch_is_installed()) {  torch_logaddexp(torch_tensor(c(-1.0)), torch_tensor(c(-1.0, -2, -3))) torch_logaddexp(torch_tensor(c(-100.0, -200, -300)), torch_tensor(c(-1.0, -2, -3))) torch_logaddexp(torch_tensor(c(1.0, 2000, 30000)), torch_tensor(c(-1.0, -2, -3))) } #> torch_tensor #>      1.1269 #>   2000.0000 #>  30000.0000 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp2.html","id":null,"dir":"Reference","previous_headings":"","what":"Logaddexp2 — torch_logaddexp2","title":"Logaddexp2 — torch_logaddexp2","text":"Logaddexp2","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logaddexp2 — torch_logaddexp2","text":"","code":"torch_logaddexp2(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logaddexp2 — torch_logaddexp2","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logaddexp2.html","id":"logaddexp-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"logaddexp2(input, other, *, out=None) -> Tensor","title":"Logaddexp2 — torch_logaddexp2","text":"Logarithm sum exponentiations inputs base-2. Calculates pointwise \\(\\log_2\\left(2^x + 2^y\\right)\\). See torch_logaddexp() details.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logcumsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Logcumsumexp — torch_logcumsumexp","title":"Logcumsumexp — torch_logcumsumexp","text":"Logcumsumexp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logcumsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logcumsumexp — torch_logcumsumexp","text":"","code":"torch_logcumsumexp(self, dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logcumsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logcumsumexp — torch_logcumsumexp","text":"self (Tensor) input tensor. dim (int) dimension operation ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logcumsumexp.html","id":"logcumsumexp-input-dim-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"logcumsumexp(input, dim, *, out=None) -> Tensor","title":"Logcumsumexp — torch_logcumsumexp","text":"Returns logarithm cumulative summation exponentiation elements input dimension dim. summation index \\(j\\) given dim indices \\(\\), result $$         \\mbox{logcumsumexp}(x)_{ij} = \\log \\sum\\limits_{j=0}^{} \\exp(x_{ij}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logcumsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logcumsumexp — torch_logcumsumexp","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(10)) torch_logcumsumexp(a, dim=1) } #> torch_tensor #> -1.8849 #> -0.8080 #>  0.6037 #>  1.6575 #>  2.0437 #>  2.1585 #>  2.2251 #>  2.3805 #>  2.5151 #>  2.5274 #> [ CPUFloatType{10} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":null,"dir":"Reference","previous_headings":"","what":"Logdet — torch_logdet","title":"Logdet — torch_logdet","text":"Logdet","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logdet — torch_logdet","text":"","code":"torch_logdet(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logdet — torch_logdet","text":"self (Tensor) input tensor size (*, n, n) * zero                batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Logdet — torch_logdet","text":"","code":"Result is `-inf` if `input` has zero log determinant, and is `NaN` if `input` has negative determinant. Backward through `logdet` internally uses SVD results when `input` is not invertible. In this case, double backward through `logdet` will be unstable in when `input` doesn't have distinct singular values. See `~torch.svd` for details."},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":"logdet-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"logdet(input) -> Tensor","title":"Logdet — torch_logdet","text":"Calculates log determinant square matrix batches square matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logdet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logdet — torch_logdet","text":"","code":"if (torch_is_installed()) {  A = torch_randn(c(3, 3)) torch_det(A) torch_logdet(A) A A$det() A$det()$log() } #> torch_tensor #> nan #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_and.html","id":null,"dir":"Reference","previous_headings":"","what":"Logical_and — torch_logical_and","title":"Logical_and — torch_logical_and","text":"Logical_and","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_and.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logical_and — torch_logical_and","text":"","code":"torch_logical_and(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_and.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logical_and — torch_logical_and","text":"self (Tensor) input tensor. (Tensor) tensor compute ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_and.html","id":"logical-and-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"logical_and(input, other, out=NULL) -> Tensor","title":"Logical_and — torch_logical_and","text":"Computes element-wise logical given input tensors. Zeros treated FALSE nonzeros treated TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_and.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logical_and — torch_logical_and","text":"","code":"if (torch_is_installed()) {  torch_logical_and(torch_tensor(c(TRUE, FALSE, TRUE)), torch_tensor(c(TRUE, FALSE, FALSE))) a = torch_tensor(c(0, 1, 10, 0), dtype=torch_int8()) b = torch_tensor(c(4, 0, 1, 0), dtype=torch_int8()) torch_logical_and(a, b) if (FALSE) { torch_logical_and(a, b, out=torch_empty(4, dtype=torch_bool())) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_not.html","id":null,"dir":"Reference","previous_headings":"","what":"Logical_not — torch_logical_not","title":"Logical_not — torch_logical_not","text":"Logical_not","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_not.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logical_not — torch_logical_not","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_not.html","id":"logical-not-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"logical_not(input, out=NULL) -> Tensor","title":"Logical_not — torch_logical_not","text":"Computes element-wise logical given input tensor. specified, output tensor bool dtype. input tensor bool tensor, zeros treated FALSE non-zeros treated TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_not.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logical_not — torch_logical_not","text":"","code":"if (torch_is_installed()) {  torch_logical_not(torch_tensor(c(TRUE, FALSE))) torch_logical_not(torch_tensor(c(0, 1, -10), dtype=torch_int8())) torch_logical_not(torch_tensor(c(0., 1.5, -10.), dtype=torch_double())) } #> torch_tensor #>  1 #>  0 #>  0 #> [ CPUBoolType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_or.html","id":null,"dir":"Reference","previous_headings":"","what":"Logical_or — torch_logical_or","title":"Logical_or — torch_logical_or","text":"Logical_or","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_or.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logical_or — torch_logical_or","text":"","code":"torch_logical_or(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_or.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logical_or — torch_logical_or","text":"self (Tensor) input tensor. (Tensor) tensor compute ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_or.html","id":"logical-or-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"logical_or(input, other, out=NULL) -> Tensor","title":"Logical_or — torch_logical_or","text":"Computes element-wise logical given input tensors. Zeros treated FALSE nonzeros treated TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_or.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logical_or — torch_logical_or","text":"","code":"if (torch_is_installed()) {  torch_logical_or(torch_tensor(c(TRUE, FALSE, TRUE)), torch_tensor(c(TRUE, FALSE, FALSE))) a = torch_tensor(c(0, 1, 10, 0), dtype=torch_int8()) b = torch_tensor(c(4, 0, 1, 0), dtype=torch_int8()) torch_logical_or(a, b) if (FALSE) { torch_logical_or(a$double(), b$double()) torch_logical_or(a$double(), b) torch_logical_or(a, b, out=torch_empty(4, dtype=torch_bool())) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_xor.html","id":null,"dir":"Reference","previous_headings":"","what":"Logical_xor — torch_logical_xor","title":"Logical_xor — torch_logical_xor","text":"Logical_xor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_xor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logical_xor — torch_logical_xor","text":"","code":"torch_logical_xor(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_xor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logical_xor — torch_logical_xor","text":"self (Tensor) input tensor. (Tensor) tensor compute XOR ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_xor.html","id":"logical-xor-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"logical_xor(input, other, out=NULL) -> Tensor","title":"Logical_xor — torch_logical_xor","text":"Computes element-wise logical XOR given input tensors. Zeros treated FALSE nonzeros treated TRUE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logical_xor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logical_xor — torch_logical_xor","text":"","code":"if (torch_is_installed()) {  torch_logical_xor(torch_tensor(c(TRUE, FALSE, TRUE)), torch_tensor(c(TRUE, FALSE, FALSE))) a = torch_tensor(c(0, 1, 10, 0), dtype=torch_int8()) b = torch_tensor(c(4, 0, 1, 0), dtype=torch_int8()) torch_logical_xor(a, b) torch_logical_xor(a$to(dtype=torch_double()), b$to(dtype=torch_double())) torch_logical_xor(a$to(dtype=torch_double()), b) } #> torch_tensor #>  1 #>  1 #>  0 #>  0 #> [ CPUBoolType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logit.html","id":null,"dir":"Reference","previous_headings":"","what":"Logit — torch_logit","title":"Logit — torch_logit","text":"Logit","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logit — torch_logit","text":"","code":"torch_logit(self, eps = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logit — torch_logit","text":"self (Tensor) input tensor. eps (float, optional) epsilon input clamp bound. Default: None","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logit.html","id":"logit-input-eps-none-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"logit(input, eps=None, *, out=None) -> Tensor","title":"Logit — torch_logit","text":"Returns new tensor logit elements input. input clamped [eps, 1 - eps] eps None. eps None input < 0 input > 1, function yields NaN. $$     y_{} = \\ln(\\frac{z_{}}{1 - z_{}}) \\\\     z_{} = \\begin{array}{ll}         x_{} & \\mbox{eps None} \\\\         \\mbox{eps} & \\mbox{} x_{} < \\mbox{eps} \\\\         x_{} & \\mbox{} \\mbox{eps} \\leq x_{} \\leq 1 - \\mbox{eps} \\\\         1 - \\mbox{eps} & \\mbox{} x_{} > 1 - \\mbox{eps}     \\end{array} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logit — torch_logit","text":"","code":"if (torch_is_installed()) {  a <- torch_rand(5) a torch_logit(a, eps=1e-6) } #> torch_tensor #>  0.9320 #>  0.3958 #>  3.1804 #> -0.0449 #>  0.4256 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logspace.html","id":null,"dir":"Reference","previous_headings":"","what":"Logspace — torch_logspace","title":"Logspace — torch_logspace","text":"Logspace","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logspace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logspace — torch_logspace","text":"","code":"torch_logspace(   start,   end,   steps = 100,   base = 10,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_logspace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logspace — torch_logspace","text":"start (float) starting value set points end (float) ending value set points steps (int) number points sample start        end. Default: 100. base (float) base logarithm function. Default: 10.0. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logspace.html","id":"logspace-start-end-steps-base-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"logspace(start, end, steps=100, base=10.0, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Logspace — torch_logspace","text":"Returns one-dimensional tensor steps points logarithmically spaced base base \\({\\mbox{base}}^{\\mbox{start}}\\) \\({\\mbox{base}}^{\\mbox{end}}\\). output tensor 1-D size steps.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logspace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logspace — torch_logspace","text":"","code":"if (torch_is_installed()) {  torch_logspace(start=-10, end=10, steps=5) torch_logspace(start=0.1, end=1.0, steps=5) torch_logspace(start=0.1, end=1.0, steps=1) torch_logspace(start=2, end=2, steps=1, base=2) } #> torch_tensor #>  4 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_logsumexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Logsumexp — torch_logsumexp","title":"Logsumexp — torch_logsumexp","text":"Logsumexp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logsumexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logsumexp — torch_logsumexp","text":"","code":"torch_logsumexp(self, dim, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_logsumexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logsumexp — torch_logsumexp","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logsumexp.html","id":"logsumexp-input-dim-keepdim-false-out-null-","dir":"Reference","previous_headings":"","what":"logsumexp(input, dim, keepdim=False, out=NULL)","title":"Logsumexp — torch_logsumexp","text":"Returns log summed exponentials row input tensor given dimension dim. computation numerically stabilized. summation index \\(j\\) given dim indices \\(\\), result $$         \\mbox{logsumexp}(x)_{} = \\log \\sum_j \\exp(x_{ij}) $$ keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_logsumexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logsumexp — torch_logsumexp","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) torch_logsumexp(a, 1) } #> torch_tensor #>  1.8542 #>  1.3111 #>  2.1658 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_lstsq.html","id":null,"dir":"Reference","previous_headings":"","what":"Lstsq — torch_lstsq","title":"Lstsq — torch_lstsq","text":"Lstsq","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lstsq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lstsq — torch_lstsq","text":"self (Tensor) matrix \\(B\\) (Tensor) \\(m\\) \\(n\\) matrix \\(\\)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lstsq.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Lstsq — torch_lstsq","text":"","code":"The case when \\eqn{m < n} is not supported on the GPU."},{"path":"https://torch.mlverse.org/docs/reference/torch_lstsq.html","id":"lstsq-input-a-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"lstsq(input, A, out=NULL) -> Tensor","title":"Lstsq — torch_lstsq","text":"Computes solution least squares least norm problems full rank matrix \\(\\) size \\((m \\times n)\\) matrix \\(B\\) size \\((m \\times k)\\). \\(m \\geq n\\), torch_lstsq() solves least-squares problem: $$    \\begin{array}{ll}    \\min_X & \\|AX-B\\|_2.    \\end{array} $$ \\(m < n\\), torch_lstsq() solves least-norm problem: $$    \\begin{array}{llll}    \\min_X & \\|X\\|_2 & \\mbox{subject } & AX = B.    \\end{array} $$ Returned tensor \\(X\\) shape \\((\\mbox{max}(m, n) \\times k)\\). first \\(n\\) rows \\(X\\) contains solution. \\(m \\geq n\\), residual sum squares solution column given sum squares elements remaining \\(m - n\\) rows column.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lt.html","id":null,"dir":"Reference","previous_headings":"","what":"Lt — torch_lt","title":"Lt — torch_lt","text":"Lt","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lt — torch_lt","text":"","code":"torch_lt(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lt — torch_lt","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lt.html","id":"lt-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"lt(input, other, out=NULL) -> Tensor","title":"Lt — torch_lt","text":"Computes \\(\\mbox{input} < \\mbox{}\\) element-wise. second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lt — torch_lt","text":"","code":"if (torch_is_installed()) {  torch_lt(torch_tensor(matrix(1:4, ncol = 2, byrow=TRUE)),           torch_tensor(matrix(c(1,1,4,4), ncol = 2, byrow=TRUE))) } #> torch_tensor #>  0  0 #>  1  0 #> [ CPUBoolType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu.html","id":null,"dir":"Reference","previous_headings":"","what":"LU — torch_lu","title":"LU — torch_lu","text":"Computes LU factorization matrix batches matrices . Returns tuple containing LU factorization pivots . Pivoting done pivot set True.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LU — torch_lu","text":"","code":"torch_lu(A, pivot = TRUE, get_infos = FALSE, out = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LU — torch_lu","text":"(Tensor) tensor factor size (, m, n)(,m,n) pivot (bool, optional) – controls whether pivoting done. Default: TRUE get_infos (bool, optional) – set True, returns info IntTensor. Default: FALSE (tuple, optional) – optional output tuple. get_infos True, elements tuple Tensor, IntTensor, IntTensor. get_infos False, elements tuple Tensor, IntTensor. Default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"LU — torch_lu","text":"","code":"if (torch_is_installed()) {  A <- torch_randn(c(2, 3, 3)) torch_lu(A) } #> [[1]] #> torch_tensor #> (1,.,.) =  #>   0.3834  0.6801 -1.2962 #>   0.1962 -0.7595  1.2475 #>  -0.8721 -0.6387  0.5538 #>  #> (2,.,.) =  #>  -2.8596 -0.3844  1.0102 #>   0.7906 -0.3574 -1.2487 #>  -0.4587  0.5223  1.4304 #> [ CPUFloatType{2,3,3} ] #>  #> [[2]] #> torch_tensor #>  2  3  3 #>  2  3  3 #> [ CPUIntType{2,3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Lu_solve — torch_lu_solve","title":"Lu_solve — torch_lu_solve","text":"Lu_solve","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lu_solve — torch_lu_solve","text":"","code":"torch_lu_solve(self, LU_data, LU_pivots)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lu_solve — torch_lu_solve","text":"self (Tensor) RHS tensor size \\((*, m, k)\\), \\(*\\)                zero batch dimensions. LU_data (Tensor) pivoted LU factorization torch_lu size \\((*, m, m)\\),                       \\(*\\) zero batch dimensions. LU_pivots (IntTensor) pivots LU factorization torch_lu size \\((*, m)\\),                           \\(*\\) zero batch dimensions.                           batch dimensions LU_pivots must equal batch dimensions                           LU_data.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_solve.html","id":"lu-solve-input-lu-data-lu-pivots-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"lu_solve(input, LU_data, LU_pivots, out=NULL) -> Tensor","title":"Lu_solve — torch_lu_solve","text":"Returns LU solve linear system \\(Ax = b\\) using partially pivoted LU factorization torch_lu.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lu_solve — torch_lu_solve","text":"","code":"if (torch_is_installed()) { A = torch_randn(c(2, 3, 3)) b = torch_randn(c(2, 3, 1)) out = torch_lu(A) x = torch_lu_solve(b, out[[1]], out[[2]]) torch_norm(torch_bmm(A, x) - b) } #> torch_tensor #> 2.14908e-07 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_unpack.html","id":null,"dir":"Reference","previous_headings":"","what":"Lu_unpack — torch_lu_unpack","title":"Lu_unpack — torch_lu_unpack","text":"Lu_unpack","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_unpack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lu_unpack — torch_lu_unpack","text":"","code":"torch_lu_unpack(LU_data, LU_pivots, unpack_data = TRUE, unpack_pivots = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_unpack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lu_unpack — torch_lu_unpack","text":"LU_data (Tensor) – packed LU factorization data LU_pivots (Tensor) – packed LU factorization pivots unpack_data (logical) – flag indicating data unpacked. FALSE, returned L U NULL Default: TRUE unpack_pivots (logical) – flag indicating pivots unpacked permutation matrix P. FALSE, returned P None. Default: TRUE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_lu_unpack.html","id":"lu-unpack-lu-data-lu-pivots-unpack-data-true-unpack-pivots-true-gt-tensor-","dir":"Reference","previous_headings":"","what":"lu_unpack(LU_data, LU_pivots, unpack_data = TRUE, unpack_pivots=TRUE) -> Tensor","title":"Lu_unpack — torch_lu_unpack","text":"Unpacks data pivots LU factorization tensor tensors L U permutation tensor P LU_data_and_pivots <- torch_lu(P$matmul(L)$matmul(U)). Returns list tensors list(P tensor (permutation matrix), L tensor, U tensor)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_manual_seed.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets the seed for generating random numbers. — torch_manual_seed","title":"Sets the seed for generating random numbers. — torch_manual_seed","text":"Sets seed generating random numbers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_manual_seed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets the seed for generating random numbers. — torch_manual_seed","text":"","code":"torch_manual_seed(seed)  local_torch_manual_seed(seed, .env = parent.frame())  with_torch_manual_seed(code, ..., seed)"},{"path":"https://torch.mlverse.org/docs/reference/torch_manual_seed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets the seed for generating random numbers. — torch_manual_seed","text":"seed integer seed. .env environment take modifications manual_seed. code expression run context seed ... unused currently.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_manual_seed.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Sets the seed for generating random numbers. — torch_manual_seed","text":"local_torch_manual_seed(): Modifies torch seed environment scope. with_torch_manual_seed(): context change seed function execution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_manual_seed.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sets the seed for generating random numbers. — torch_manual_seed","text":"Currently local_torch_manual_seed with_torch_manual_seed work Tensors MPS device. can sample tensors CPU move MPS reproducibility required.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":null,"dir":"Reference","previous_headings":"","what":"Masked_select — torch_masked_select","title":"Masked_select — torch_masked_select","text":"Masked_select","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Masked_select — torch_masked_select","text":"","code":"torch_masked_select(self, mask)"},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Masked_select — torch_masked_select","text":"self (Tensor) input tensor. mask (BoolTensor) tensor containing binary mask index ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Masked_select — torch_masked_select","text":"returned tensor use storage original tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":"masked-select-input-mask-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"masked_select(input, mask, out=NULL) -> Tensor","title":"Masked_select — torch_masked_select","text":"Returns new 1-D tensor indexes input tensor according boolean mask mask BoolTensor. shapes mask tensor input tensor need match, must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_masked_select.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Masked_select — torch_masked_select","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(3, 4)) x mask = x$ge(0.5) mask torch_masked_select(x, mask) } #> torch_tensor #>  1.6461 #>  1.4241 #>  1.1868 #>  0.5365 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":null,"dir":"Reference","previous_headings":"","what":"Matmul — torch_matmul","title":"Matmul — torch_matmul","text":"Matmul","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matmul — torch_matmul","text":"","code":"torch_matmul(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matmul — torch_matmul","text":"self (Tensor) first tensor multiplied (Tensor) second tensor multiplied","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Matmul — torch_matmul","text":"","code":"The 1-dimensional dot product version of this function does not support an `out` parameter."},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":"matmul-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"matmul(input, other, out=NULL) -> Tensor","title":"Matmul — torch_matmul","text":"Matrix product two tensors. behavior depends dimensionality tensors follows: tensors 1-dimensional, dot product (scalar) returned. arguments 2-dimensional, matrix-matrix product returned. first argument 1-dimensional second argument 2-dimensional, 1 prepended dimension purpose matrix multiply. matrix multiply, prepended dimension removed. first argument 2-dimensional second argument 1-dimensional, matrix-vector product returned. arguments least 1-dimensional least one argument N-dimensional (N > 2), batched matrix multiply returned.  first argument 1-dimensional, 1 prepended dimension purpose batched matrix multiply removed .  second argument 1-dimensional, 1 appended dimension purpose batched matrix multiple removed . non-matrix (.e. batch) dimensions broadcasted  (thus must broadcastable).  example, input \\((j \\times 1 \\times n \\times m)\\) tensor \\((k \\times m \\times p)\\) tensor, \\((j \\times k \\times n \\times p)\\) tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matmul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matmul — torch_matmul","text":"","code":"if (torch_is_installed()) {  # vector x vector tensor1 = torch_randn(c(3)) tensor2 = torch_randn(c(3)) torch_matmul(tensor1, tensor2) # matrix x vector tensor1 = torch_randn(c(3, 4)) tensor2 = torch_randn(c(4)) torch_matmul(tensor1, tensor2) # batched matrix x broadcasted vector tensor1 = torch_randn(c(10, 3, 4)) tensor2 = torch_randn(c(4)) torch_matmul(tensor1, tensor2) # batched matrix x batched matrix tensor1 = torch_randn(c(10, 3, 4)) tensor2 = torch_randn(c(10, 4, 5)) torch_matmul(tensor1, tensor2) # batched matrix x broadcasted matrix tensor1 = torch_randn(c(10, 3, 4)) tensor2 = torch_randn(c(4, 5)) torch_matmul(tensor1, tensor2) } #> torch_tensor #> (1,.,.) =  #>  -0.6703  0.1748  0.1019  2.1782 -1.9164 #>   3.4863  0.7423 -0.8082  1.5387 -0.2886 #>   2.2476  0.9486  1.8962 -1.2999  1.4790 #>  #> (2,.,.) =  #>   0.9446  1.0571  1.4544 -0.2813  0.9670 #>   1.4007 -0.4533  0.5070 -0.2281 -0.8250 #>  -0.2017  0.3509  0.6494  0.0332  0.1461 #>  #> (3,.,.) =  #>  -3.4653 -1.6867 -0.8829 -0.4846 -1.2331 #>  -0.6890  0.2529  1.7228 -0.7841  0.2751 #>  -4.6621  0.6449  0.9571  2.8237 -2.0121 #>  #> (4,.,.) =  #>  -0.3645 -0.8249  0.9828 -2.5264  0.8061 #>  -5.7000 -0.6100 -0.2068  0.9414 -1.2617 #>   1.9504  1.7264  2.3723 -1.4703  2.5558 #>  #> (5,.,.) =  #>  -0.3427  0.8398  1.4759 -0.6493  1.1072 #>   2.5539 -1.2103 -1.4570 -0.5723 -0.6212 #>   2.2649 -0.9920 -2.4079  0.2779 -0.6104 #>  #> (6,.,.) =  #>  -1.8022  0.1544 -0.5616  0.9548 -0.2760 #>  -0.6957 -2.7108 -2.1812 -1.5212 -1.2216 #>   2.8840 -0.3510 -1.7105 -1.5380  1.7126 #>  #> ... [the output was truncated (use n=-1 to disable)] #> [ CPUFloatType{10,3,5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix_exp — torch_matrix_exp","title":"Matrix_exp — torch_matrix_exp","text":"Matrix_exp","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix_exp — torch_matrix_exp","text":"","code":"torch_matrix_exp(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix_exp — torch_matrix_exp","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_exp.html","id":"matrix-power-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"matrix_power(input) -> Tensor","title":"Matrix_exp — torch_matrix_exp","text":"Returns matrix exponential. Supports batched input. matrix , matrix exponential defined $$     \\exp^= \\sum_{k=0}^\\infty ^k / k!. $$ implementation based : Bader, P.; Blanes, S.; Casas, F. Computing Matrix Exponential Optimized Taylor Polynomial Approximation. Mathematics 2019, 7, 1174.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix_exp — torch_matrix_exp","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(2, 2, 2)) a[1, , ] <- torch_eye(2, 2) a[2, , ] <- 2 * torch_eye(2, 2) a torch_matrix_exp(a)  x <- torch_tensor(rbind(c(0, pi/3), c(-pi/3, 0))) x$matrix_exp() # should be [[cos(pi/3), sin(pi/3)], [-sin(pi/3), cos(pi/3)]] } #> torch_tensor #>  0.5000  0.8660 #> -0.8660  0.5000 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_power.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix_power — torch_matrix_power","title":"Matrix_power — torch_matrix_power","text":"Matrix_power","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_power.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrix_power — torch_matrix_power","text":"","code":"torch_matrix_power(self, n)"},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_power.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix_power — torch_matrix_power","text":"self (Tensor) input tensor. n (int) power raise matrix ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_power.html","id":"matrix-power-input-n-gt-tensor-","dir":"Reference","previous_headings":"","what":"matrix_power(input, n) -> Tensor","title":"Matrix_power — torch_matrix_power","text":"Returns matrix raised power n square matrices. batch matrices, individual matrix raised power n. n negative, inverse matrix (invertible) raised power n.  batch matrices, batched inverse (invertible) raised power n. n 0, identity matrix returned.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_power.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Matrix_power — torch_matrix_power","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(2, 2, 2)) a torch_matrix_power(a, 3) } #> torch_tensor #> (1,.,.) =  #>  -1.8053 -0.0262 #>   0.1418 -1.8350 #>  #> (2,.,.) =  #>   0.3966 -0.3756 #>  -0.3245  0.3026 #> [ CPUFloatType{2,2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrix_rank — torch_matrix_rank","title":"Matrix_rank — torch_matrix_rank","text":"Matrix_rank","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrix_rank — torch_matrix_rank","text":"self (Tensor) input 2-D tensor tol (float, optional) tolerance value. Default: NULL symmetric (bool, optional) indicates whether input symmetric.                               Default: FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_matrix_rank.html","id":"matrix-rank-input-tol-null-symmetric-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"matrix_rank(input, tol=NULL, symmetric=False) -> Tensor","title":"Matrix_rank — torch_matrix_rank","text":"Returns numerical rank 2-D tensor. method compute matrix rank done using SVD default. symmetric TRUE, input assumed symmetric, computation rank done obtaining eigenvalues. tol threshold singular values (eigenvalues symmetric TRUE) considered 0. tol specified, tol set S.max() * max(S.size()) * eps S singular values (eigenvalues symmetric TRUE), eps epsilon value datatype input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":null,"dir":"Reference","previous_headings":"","what":"Max — torch_max","title":"Max — torch_max","text":"Max","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Max — torch_max","text":"self (Tensor) input tensor. dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained . Default: FALSE. (tuple, optional) result tuple two output tensors (max, max_indices) (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Max — torch_max","text":"shapes match, shape returned output tensor follows broadcasting rules .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"max-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"max(input) -> Tensor","title":"Max — torch_max","text":"Returns maximum value elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"max-input-dim-keepdim-false-out-null-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"max(input, dim, keepdim=False, out=NULL) -> (Tensor, LongTensor)","title":"Max — torch_max","text":"Returns namedtuple (values, indices) values maximum value row input tensor given dimension dim. indices index location maximum value found (argmax).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Max — torch_max","text":"indices necessarily contain first occurrence maximal value found, unless unique. exact implementation details device-specific. expect result run CPU GPU general. keepdim TRUE, output tensors size input except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensors 1 fewer dimension input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"max-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"max(input, other, out=NULL) -> Tensor","title":"Max — torch_max","text":"element tensor input compared corresponding element tensor element-wise maximum taken. shapes input need match, must broadcastable . $$     \\mbox{}_i = \\max(\\mbox{tensor}_i, \\mbox{}_i) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_max.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Max — torch_max","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_max(a)   a = torch_randn(c(4, 4)) a torch_max(a, dim = 1)   a = torch_randn(c(4)) a b = torch_randn(c(4)) b torch_max(a, other = b) } #> torch_tensor #> -1.1791 #>  0.9259 #>  0.0413 #>  0.1109 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum — torch_maximum","title":"Maximum — torch_maximum","text":"Maximum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum — torch_maximum","text":"","code":"torch_maximum(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum — torch_maximum","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Maximum — torch_maximum","text":"one elements compared NaN, element returned. torch_maximum() supported tensors complex dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":"maximum-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"maximum(input, other, *, out=None) -> Tensor","title":"Maximum — torch_maximum","text":"Computes element-wise maximum input .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_maximum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum — torch_maximum","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2, -1)) b <- torch_tensor(c(3, 0, 4)) torch_maximum(a, b) } #> torch_tensor #>  3 #>  2 #>  4 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean — torch_mean","title":"Mean — torch_mean","text":"Mean","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean — torch_mean","text":"","code":"torch_mean(self, dim, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean — torch_mean","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained . dtype resulting data type.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":"mean-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"mean(input) -> Tensor","title":"Mean — torch_mean","text":"Returns mean value elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":"mean-input-dim-keepdim-false-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"mean(input, dim, keepdim=False, out=NULL) -> Tensor","title":"Mean — torch_mean","text":"Returns mean value row input tensor given dimension dim. dim list dimensions, reduce . keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean — torch_mean","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_mean(a)   a = torch_randn(c(4, 4)) a torch_mean(a, 1) torch_mean(a, 1, TRUE) } #> torch_tensor #> -1.0464  0.1152  0.6736 -0.3284 #> [ CPUFloatType{1,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Median — torch_median","title":"Median — torch_median","text":"Median","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Median — torch_median","text":"","code":"torch_median(self, dim, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Median — torch_median","text":"self (Tensor) input tensor. dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":"median-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"median(input) -> Tensor","title":"Median — torch_median","text":"Returns median value elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":"median-input-dim-keepdim-false-out-null-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"median(input, dim=-1, keepdim=False, out=NULL) -> (Tensor, LongTensor)","title":"Median — torch_median","text":"Returns namedtuple (values, indices) values median value row input tensor given dimension dim. indices index location median value found. default, dim last dimension input tensor. keepdim TRUE, output tensors size input except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting outputs tensor 1 fewer dimension input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Median — torch_median","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_median(a)   a = torch_randn(c(4, 5)) a torch_median(a, 1) } #> [[1]] #> torch_tensor #>  0.0628 #> -0.7662 #> -0.1937 #>  0.2784 #> -0.7597 #> [ CPUFloatType{5} ] #>  #> [[2]] #> torch_tensor #>  2 #>  2 #>  1 #>  0 #>  1 #> [ CPULongType{5} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_memory_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Memory format — torch_memory_format","title":"Memory format — torch_memory_format","text":"Returns correspondent memory format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_memory_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Memory format — torch_memory_format","text":"","code":"torch_contiguous_format()  torch_preserve_format()  torch_channels_last_format()"},{"path":"https://torch.mlverse.org/docs/reference/torch_meshgrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Meshgrid — torch_meshgrid","title":"Meshgrid — torch_meshgrid","text":"Take \\(N\\) tensors, can either scalar 1-dimensional vector, create \\(N\\) N-dimensional grids, \\(\\) th grid defined expanding \\(\\) th input dimensions defined inputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_meshgrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Meshgrid — torch_meshgrid","text":"","code":"torch_meshgrid(tensors, indexing)"},{"path":"https://torch.mlverse.org/docs/reference/torch_meshgrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Meshgrid — torch_meshgrid","text":"tensors (list Tensor) list scalars 1 dimensional tensors. Scalars treated (1,). indexing (str, optional): indexing mode, either “xy” “ij”, defaults “ij”. See warning future changes. “xy” selected, first dimension corresponds cardinality second input second dimension corresponds cardinality first input. “ij” selected, dimensions order cardinality inputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_meshgrid.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Meshgrid — torch_meshgrid","text":"future torch_meshgrid transition indexing=’xy’ default. issue tracks issue goal migrating NumPy’s behavior.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_meshgrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Meshgrid — torch_meshgrid","text":"","code":"if (torch_is_installed()) {  x = torch_tensor(c(1, 2, 3)) y = torch_tensor(c(4, 5, 6)) out = torch_meshgrid(list(x, y)) out } #> [[1]] #> torch_tensor #>  1  1  1 #>  2  2  2 #>  3  3  3 #> [ CPUFloatType{3,3} ] #>  #> [[2]] #> torch_tensor #>  4  5  6 #>  4  5  6 #>  4  5  6 #> [ CPUFloatType{3,3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":null,"dir":"Reference","previous_headings":"","what":"Min — torch_min","title":"Min — torch_min","text":"Min","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Min — torch_min","text":"self (Tensor) input tensor. dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained . (tuple, optional) tuple two output tensors (min, min_indices) (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Min — torch_min","text":"shapes match, shape returned output tensor follows broadcasting rules .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"min-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"min(input) -> Tensor","title":"Min — torch_min","text":"Returns minimum value elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"min-input-dim-keepdim-false-out-null-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"min(input, dim, keepdim=False, out=NULL) -> (Tensor, LongTensor)","title":"Min — torch_min","text":"Returns namedtuple (values, indices) values minimum value row input tensor given dimension dim. indices index location minimum value found (argmin).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Min — torch_min","text":"indices necessarily contain first occurrence minimal value found, unless unique. exact implementation details device-specific. expect result run CPU GPU general. keepdim TRUE, output tensors size input except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensors 1 fewer dimension input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"min-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"min(input, other, out=NULL) -> Tensor","title":"Min — torch_min","text":"element tensor input compared corresponding element tensor element-wise minimum taken. resulting tensor returned. shapes input need match, must broadcastable . $$     \\mbox{}_i = \\min(\\mbox{tensor}_i, \\mbox{}_i) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_min.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Min — torch_min","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_min(a)   a = torch_randn(c(4, 4)) a torch_min(a, dim = 1)   a = torch_randn(c(4)) a b = torch_randn(c(4)) b torch_min(a, other = b) } #> torch_tensor #> -0.3243 #>  0.2041 #> -1.7173 #>  0.4610 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":null,"dir":"Reference","previous_headings":"","what":"Minimum — torch_minimum","title":"Minimum — torch_minimum","text":"Minimum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Minimum — torch_minimum","text":"","code":"torch_minimum(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Minimum — torch_minimum","text":"self (Tensor) input tensor. (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Minimum — torch_minimum","text":"one elements compared NaN, element returned. torch_minimum() supported tensors complex dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":"minimum-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"minimum(input, other, *, out=None) -> Tensor","title":"Minimum — torch_minimum","text":"Computes element-wise minimum input .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_minimum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Minimum — torch_minimum","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2, -1)) b <- torch_tensor(c(3, 0, 4)) torch_minimum(a, b) } #> torch_tensor #>  1 #>  0 #> -1 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":null,"dir":"Reference","previous_headings":"","what":"Mm — torch_mm","title":"Mm — torch_mm","text":"Mm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mm — torch_mm","text":"","code":"torch_mm(self, mat2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mm — torch_mm","text":"self (Tensor) first matrix multiplied mat2 (Tensor) second matrix multiplied","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Mm — torch_mm","text":"function broadcast . broadcasting matrix products, see torch_matmul.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":"mm-input-mat-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"mm(input, mat2, out=NULL) -> Tensor","title":"Mm — torch_mm","text":"Performs matrix multiplication matrices input mat2. input \\((n \\times m)\\) tensor, mat2 \\((m \\times p)\\) tensor, \\((n \\times p)\\) tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mm — torch_mm","text":"","code":"if (torch_is_installed()) {  mat1 = torch_randn(c(2, 3)) mat2 = torch_randn(c(3, 3)) torch_mm(mat1, mat2) } #> torch_tensor #> -0.5435 -0.2961  1.1167 #>  0.8410 -0.8920  0.1800 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":null,"dir":"Reference","previous_headings":"","what":"Mode — torch_mode","title":"Mode — torch_mode","text":"Mode","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mode — torch_mode","text":"","code":"torch_mode(self, dim = -1L, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mode — torch_mode","text":"self (Tensor) input tensor. dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Mode — torch_mode","text":"function defined torch_cuda.Tensor yet.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":"mode-input-dim-keepdim-false-out-null-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"mode(input, dim=-1, keepdim=False, out=NULL) -> (Tensor, LongTensor)","title":"Mode — torch_mode","text":"Returns namedtuple (values, indices) values mode value row input tensor given dimension dim, .e. value appears often row, indices index location mode value found. default, dim last dimension input tensor. keepdim TRUE, output tensors size input except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensors 1 fewer dimension input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mode — torch_mode","text":"","code":"if (torch_is_installed()) {  a = torch_randint(0, 50, size = list(5)) a torch_mode(a, 1) } #> [[1]] #> torch_tensor #> 5 #> [ CPUFloatType{} ] #>  #> [[2]] #> torch_tensor #> 2 #> [ CPULongType{} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_movedim.html","id":null,"dir":"Reference","previous_headings":"","what":"Movedim — torch_movedim","title":"Movedim — torch_movedim","text":"Movedim","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_movedim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Movedim — torch_movedim","text":"","code":"torch_movedim(self, source, destination)"},{"path":"https://torch.mlverse.org/docs/reference/torch_movedim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Movedim — torch_movedim","text":"self (Tensor) input tensor. source (int tuple ints) Original positions dims move. must unique. destination (int tuple ints) Destination positions original dims. must also unique.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_movedim.html","id":"movedim-input-source-destination-gt-tensor-","dir":"Reference","previous_headings":"","what":"movedim(input, source, destination) -> Tensor","title":"Movedim — torch_movedim","text":"Moves dimension(s) input position(s) source position(s) destination. dimensions input explicitly moved remain original order appear positions specified destination.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_movedim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Movedim — torch_movedim","text":"","code":"if (torch_is_installed()) {  t <- torch_randn(c(3,2,1)) t torch_movedim(t, 2, 1)$shape torch_movedim(t, 2, 1) torch_movedim(t, c(2, 3), c(1, 2))$shape torch_movedim(t, c(2, 3), c(1, 2)) } #> torch_tensor #> (1,.,.) =  #>   1.4197 -0.3672 -1.5816 #>  #> (2,.,.) =  #>  -0.3044 -0.3522  1.1081 #> [ CPUFloatType{2,1,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_mul.html","id":null,"dir":"Reference","previous_headings":"","what":"Mul — torch_mul","title":"Mul — torch_mul","text":"Mul","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mul.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mul — torch_mul","text":"","code":"torch_mul(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mul.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mul — torch_mul","text":"self (Tensor) first multiplicand tensor (Tensor) second multiplicand tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mul.html","id":"mul-input-other-out-null-","dir":"Reference","previous_headings":"","what":"mul(input, other, out=NULL)","title":"Mul — torch_mul","text":"Multiplies element input input scalar returns new resulting tensor. $$     \\mbox{}_i = \\mbox{} \\times \\mbox{input}_i $$ input type FloatTensor DoubleTensor, real number, otherwise integer element tensor input multiplied corresponding element Tensor . resulting tensor returned. shapes input must broadcastable . $$     \\mbox{}_i = \\mbox{input}_i \\times \\mbox{}_i $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mul.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mul — torch_mul","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3)) a torch_mul(a, 100)   a = torch_randn(c(4, 1)) a b = torch_randn(c(1, 4)) b torch_mul(a, b) } #> torch_tensor #>  1.1375 -1.3661  2.4762 -0.3392 #>  0.1289 -0.1549  0.2807 -0.0385 #>  0.1674 -0.2011  0.3645 -0.0499 #>  0.0937 -0.1126  0.2040 -0.0280 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial — torch_multinomial","title":"Multinomial — torch_multinomial","text":"Multinomial","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial — torch_multinomial","text":"","code":"torch_multinomial(self, num_samples, replacement = FALSE, generator = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial — torch_multinomial","text":"self (Tensor) input tensor containing probabilities num_samples (int) number samples draw replacement (bool, optional) whether draw replacement generator (torch.Generator, optional) pseudorandom number generator sampling","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Multinomial — torch_multinomial","text":"Indices ordered left right according sampled (first samples placed first column). input vector, vector size num_samples. input matrix m rows, matrix shape \\((m \\times \\mbox{num\\_samples})\\). replacement TRUE, samples drawn replacement. , drawn without replacement, means sample index drawn row, drawn row.","code":"The rows of `input` do not need to sum to one (in which case we use the values as weights), but must be non-negative, finite and have a non-zero sum. When drawn without replacement, `num_samples` must be lower than number of non-zero elements in `input` (or the min number of non-zero elements in each row of `input` if it is a matrix)."},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":"multinomial-input-num-samples-replacement-false-generator-null-out-null-gt-longtensor-","dir":"Reference","previous_headings":"","what":"multinomial(input, num_samples, replacement=False, *, generator=NULL, out=NULL) -> LongTensor","title":"Multinomial — torch_multinomial","text":"Returns tensor row contains num_samples indices sampled multinomial probability distribution located corresponding row tensor input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_multinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multinomial — torch_multinomial","text":"","code":"if (torch_is_installed()) {  weights = torch_tensor(c(0, 10, 3, 0), dtype=torch_float()) # create a tensor of weights torch_multinomial(weights, 2) torch_multinomial(weights, 4, replacement=TRUE) } #> torch_tensor #>  2 #>  2 #>  2 #>  2 #> [ CPULongType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_multiply.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply — torch_multiply","title":"Multiply — torch_multiply","text":"Multiply","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_multiply.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply — torch_multiply","text":"","code":"torch_multiply(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_multiply.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply — torch_multiply","text":"self (Tensor) first multiplicand tensor (Tensor) second multiplicand tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_multiply.html","id":"multiply-input-other-out-none-","dir":"Reference","previous_headings":"","what":"multiply(input, other, *, out=None)","title":"Multiply — torch_multiply","text":"Alias torch_mul().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":null,"dir":"Reference","previous_headings":"","what":"Mv — torch_mv","title":"Mv — torch_mv","text":"Mv","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mv — torch_mv","text":"","code":"torch_mv(self, vec)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mv — torch_mv","text":"self (Tensor) matrix multiplied vec (Tensor) vector multiplied","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Mv — torch_mv","text":"function broadcast .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":"mv-input-vec-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"mv(input, vec, out=NULL) -> Tensor","title":"Mv — torch_mv","text":"Performs matrix-vector product matrix input vector vec. input \\((n \\times m)\\) tensor, vec 1-D tensor size \\(m\\), 1-D size \\(n\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mv — torch_mv","text":"","code":"if (torch_is_installed()) {  mat = torch_randn(c(2, 3)) vec = torch_randn(c(3)) torch_mv(mat, vec) } #> torch_tensor #> -0.5089 #>  2.4542 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_mvlgamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Mvlgamma — torch_mvlgamma","title":"Mvlgamma — torch_mvlgamma","text":"Mvlgamma","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mvlgamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mvlgamma — torch_mvlgamma","text":"","code":"torch_mvlgamma(self, p)"},{"path":"https://torch.mlverse.org/docs/reference/torch_mvlgamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mvlgamma — torch_mvlgamma","text":"self (Tensor) tensor compute multivariate log-gamma function p (int) number dimensions","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mvlgamma.html","id":"mvlgamma-input-p-gt-tensor-","dir":"Reference","previous_headings":"","what":"mvlgamma(input, p) -> Tensor","title":"Mvlgamma — torch_mvlgamma","text":"Computes multivariate log-gamma function <https://en.wikipedia.org/wiki/Multivariate_gamma_function>_) dimension \\(p\\) element-wise, given $$     \\log(\\Gamma_{p}()) = C + \\displaystyle \\sum_{=1}^{p} \\log\\left(\\Gamma\\left(- \\frac{- 1}{2}\\right)\\right) $$ \\(C = \\log(\\pi) \\times \\frac{p (p - 1)}{4}\\) \\(\\Gamma(\\cdot)\\) Gamma function. elements must greater \\(\\frac{p - 1}{2}\\), otherwise error thrown.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_mvlgamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mvlgamma — torch_mvlgamma","text":"","code":"if (torch_is_installed()) {  a = torch_empty(c(2, 3))$uniform_(1, 2) a torch_mvlgamma(a, 2) } #> torch_tensor #>  0.3956  0.4255  0.3985 #>  0.4307  0.3940  0.4207 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_nanquantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Nanquantile — torch_nanquantile","title":"Nanquantile — torch_nanquantile","text":"Nanquantile","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nanquantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nanquantile — torch_nanquantile","text":"","code":"torch_nanquantile(   self,   q,   dim = NULL,   keepdim = FALSE,   interpolation = \"linear\" )"},{"path":"https://torch.mlverse.org/docs/reference/torch_nanquantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nanquantile — torch_nanquantile","text":"self (Tensor) input tensor. q (float Tensor) scalar 1D tensor quantile values range [0, 1] dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained . interpolation interpolation method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nanquantile.html","id":"nanquantile-input-q-dim-none-keepdim-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"nanquantile(input, q, dim=None, keepdim=FALSE, *, out=None) -> Tensor","title":"Nanquantile — torch_nanquantile","text":"variant torch_quantile() \"ignores\" NaN values, computing quantiles q NaN values input exist. values reduced row NaN quantiles reduction NaN. See documentation torch_quantile().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nanquantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nanquantile — torch_nanquantile","text":"","code":"if (torch_is_installed()) {  t <- torch_tensor(c(NaN, 1, 2)) t$quantile(0.5) t$nanquantile(0.5) t <- torch_tensor(rbind(c(NaN, NaN), c(1, 2))) t t$nanquantile(0.5, dim=1) t$nanquantile(0.5, dim=2) torch_nanquantile(t, 0.5, dim = 1) torch_nanquantile(t, 0.5, dim = 2) } #> torch_tensor #>     nan  1.5000 #> [ CPUFloatType{1,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":null,"dir":"Reference","previous_headings":"","what":"Nansum — torch_nansum","title":"Nansum — torch_nansum","text":"Nansum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nansum — torch_nansum","text":"","code":"torch_nansum(self, dim = NULL, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nansum — torch_nansum","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained . dtype desired data type returned tensor. specified, input tensor casted dtype operation performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":"nansum-input-dtype-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"nansum(input, *, dtype=None) -> Tensor","title":"Nansum — torch_nansum","text":"Returns sum elements, treating Numbers (NaNs) zero.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":"nansum-input-dim-keepdim-false-dtype-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"nansum(input, dim, keepdim=FALSE, *, dtype=None) -> Tensor","title":"Nansum — torch_nansum","text":"Returns sum row input tensor given dimension dim, treating Numbers (NaNs) zero. dim list dimensions, reduce . keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nansum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nansum — torch_nansum","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1., 2., NaN, 4.)) torch_nansum(a)   torch_nansum(torch_tensor(c(1., NaN))) a <- torch_tensor(rbind(c(1, 2), c(3., NaN))) torch_nansum(a) torch_nansum(a, dim=1) torch_nansum(a, dim=2) } #> torch_tensor #>  3 #>  3 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_narrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Narrow — torch_narrow","title":"Narrow — torch_narrow","text":"Narrow","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_narrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Narrow — torch_narrow","text":"","code":"torch_narrow(self, dim, start, length)"},{"path":"https://torch.mlverse.org/docs/reference/torch_narrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Narrow — torch_narrow","text":"self (Tensor) tensor narrow dim (int) dimension along narrow start (int) starting dimension length (int) distance ending dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_narrow.html","id":"narrow-input-dim-start-length-gt-tensor-","dir":"Reference","previous_headings":"","what":"narrow(input, dim, start, length) -> Tensor","title":"Narrow — torch_narrow","text":"Returns new tensor narrowed version input tensor. dimension dim input start start + length. returned tensor input tensor share underlying storage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_narrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Narrow — torch_narrow","text":"","code":"if (torch_is_installed()) {  x = torch_tensor(matrix(c(1:9), ncol = 3, byrow= TRUE)) torch_narrow(x, 1, 1, 2) torch_narrow(x, 2, 2, 2) } #> torch_tensor #>  2  3 #>  5  6 #>  8  9 #> [ CPULongType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_ne.html","id":null,"dir":"Reference","previous_headings":"","what":"Ne — torch_ne","title":"Ne — torch_ne","text":"Ne","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ne.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ne — torch_ne","text":"","code":"torch_ne(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_ne.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ne — torch_ne","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ne.html","id":"ne-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"ne(input, other, out=NULL) -> Tensor","title":"Ne — torch_ne","text":"Computes \\(input \\neq \\) element-wise. second argument can number tensor whose shape broadcastable  first argument.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ne.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ne — torch_ne","text":"","code":"if (torch_is_installed()) {  torch_ne(torch_tensor(matrix(1:4, ncol = 2, byrow=TRUE)),           torch_tensor(matrix(rep(c(1,4), each = 2), ncol = 2, byrow=TRUE))) } #> torch_tensor #>  0  1 #>  1  0 #> [ CPUBoolType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_neg.html","id":null,"dir":"Reference","previous_headings":"","what":"Neg — torch_neg","title":"Neg — torch_neg","text":"Neg","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_neg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Neg — torch_neg","text":"","code":"torch_neg(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_neg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Neg — torch_neg","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_neg.html","id":"neg-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"neg(input, out=NULL) -> Tensor","title":"Neg — torch_neg","text":"Returns new tensor negative elements input. $$     \\mbox{} = -1 \\times \\mbox{input} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_neg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Neg — torch_neg","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(5)) a torch_neg(a) } #> torch_tensor #> -0.3203 #> -1.2317 #>  1.3018 #> -0.2356 #>  0.0700 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_negative.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative — torch_negative","title":"Negative — torch_negative","text":"Negative","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_negative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative — torch_negative","text":"","code":"torch_negative(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_negative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative — torch_negative","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_negative.html","id":"negative-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"negative(input, *, out=None) -> Tensor","title":"Negative — torch_negative","text":"Alias torch_neg()","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nextafter.html","id":null,"dir":"Reference","previous_headings":"","what":"Nextafter — torch_nextafter","title":"Nextafter — torch_nextafter","text":"Nextafter","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nextafter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nextafter — torch_nextafter","text":"","code":"torch_nextafter(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_nextafter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nextafter — torch_nextafter","text":"self (Tensor) first input tensor (Tensor) second input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nextafter.html","id":"nextafter-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"nextafter(input, other, *, out=None) -> Tensor","title":"Nextafter — torch_nextafter","text":"Return next floating-point value input towards , elementwise. shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nextafter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nextafter — torch_nextafter","text":"","code":"if (torch_is_installed()) {  eps <- torch_finfo(torch_float32())$eps torch_nextafter(torch_tensor(c(1, 2)), torch_tensor(c(2, 1))) == torch_tensor(c(eps + 1, 2 - eps)) } #> torch_tensor #>  1 #>  1 #> [ CPUBoolType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonzero — torch_nonzero","title":"Nonzero — torch_nonzero","text":"Nonzero elements tensors.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonzero — torch_nonzero","text":"","code":"torch_nonzero(self, as_list = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonzero — torch_nonzero","text":"self (Tensor) input tensor. as_list FALSE, output tensor containing indices. TRUE, one 1-D tensor dimension, containing indices nonzero element along dimension. as_list FALSE (default): Returns tensor containing indices non-zero elements input.  row result contains indices non-zero element input. result sorted lexicographically, last index changing fastest (C-style). input \\(n\\) dimensions, resulting indices tensor size \\((z \\times n)\\), \\(z\\) total number non-zero elements input tensor. as_list TRUE: Returns tuple 1-D tensors, one dimension input, containing indices (dimension) non-zero elements input . input \\(n\\) dimensions, resulting tuple contains \\(n\\) tensors size \\(z\\), \\(z\\) total number non-zero elements input tensor. special case, input zero dimensions nonzero scalar value, treated one-dimensional tensor one element.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_nonzero.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonzero — torch_nonzero","text":"","code":"if (torch_is_installed()) {  torch_nonzero(torch_tensor(c(1, 1, 1, 0, 1))) } #> torch_tensor #>  1 #>  2 #>  3 #>  5 #> [ CPULongType{4,1} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Norm — torch_norm","title":"Norm — torch_norm","text":"Norm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Norm — torch_norm","text":"","code":"torch_norm(self, p = 2L, dim, keepdim = FALSE, dtype)"},{"path":"https://torch.mlverse.org/docs/reference/torch_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Norm — torch_norm","text":"self (Tensor) input tensor p (int, float, inf, -inf, 'fro', 'nuc', optional) order norm. Default: 'fro'        following norms can calculated:        =====  ============================  ==========================        ord    matrix norm                   vector norm        =====  ============================  ==========================        NULL   Frobenius norm                2-norm        'fro'  Frobenius norm                --        'nuc'  nuclear norm                  --         vec norm dim NULL  sum(abs(x)ord)(1./ord)        =====  ============================  ========================== dim (int, 2-tuple ints, 2-list ints, optional) int,        vector norm calculated, 2-tuple ints, matrix norm        calculated. value NULL, matrix norm calculated        input tensor two dimensions, vector norm        calculated input tensor one dimension. input        tensor two dimensions, vector norm applied        last dimension. keepdim (bool, optional) whether output tensors dim        retained . Ignored dim = NULL        = NULL. Default: FALSE Ignored        dim = NULL = NULL. dtype (torch.dtype, optional) desired data type        returned tensor. specified, input tensor casted        'dtype' performing operation. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_norm.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Norm — torch_norm","text":"Returns matrix norm vector norm given tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_norm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Norm — torch_norm","text":"","code":"if (torch_is_installed()) {  a <- torch_arange(1, 9, dtype = torch_float()) b <- a$reshape(list(3, 3)) torch_norm(a) torch_norm(b) torch_norm(a, Inf) torch_norm(b, Inf)  } #> torch_tensor #> 9 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal — torch_normal","title":"Normal — torch_normal","text":"Normal Normal distributed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal — torch_normal","text":"","code":"torch_normal(mean, std, size = NULL, generator = NULL, ...)"},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal — torch_normal","text":"mean (tensor scalar double) Mean normal distribution. torch_tensor() output dim mean represents per-element mean. scalar value, reused elements. std (tensor scalar double) standard deviation normal distribution. torch_tensor() output size std represents per-element standard deviation. scalar value, reused elements. size (integers, optional) used mean std scalars. generator random number generator created torch_generator(). NULL default generator used. ... Tensor option parameters like dtype, layout, device. Can used mean std scalar numerics.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Normal — torch_normal","text":"shapes match, shape mean used shape returned output tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"normal-mean-std-gt-tensor-","dir":"Reference","previous_headings":"","what":"normal(mean, std, *) -> Tensor","title":"Normal — torch_normal","text":"Returns tensor random numbers drawn separate normal distributions whose mean standard deviation given. mean tensor mean output element's normal distribution std tensor standard deviation output element's normal distribution shapes mean std need match, total number elements tensor need .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"normal-mean-std-gt-tensor--1","dir":"Reference","previous_headings":"","what":"normal(mean=0.0, std) -> Tensor","title":"Normal — torch_normal","text":"Similar function , means shared among drawn elements.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"normal-mean-std-gt-tensor--2","dir":"Reference","previous_headings":"","what":"normal(mean, std=1.0) -> Tensor","title":"Normal — torch_normal","text":"Similar function , standard-deviations shared among drawn elements.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"normal-mean-std-size-gt-tensor-","dir":"Reference","previous_headings":"","what":"normal(mean, std, size, *) -> Tensor","title":"Normal — torch_normal","text":"Similar function , means standard deviations shared among drawn elements. resulting tensor size given size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_normal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal — torch_normal","text":"","code":"if (torch_is_installed()) {  torch_normal(mean=0, std=torch_arange(1, 0, -0.1) + 1e-6) torch_normal(mean=0.5, std=torch_arange(1., 6.)) torch_normal(mean=torch_arange(1., 6.)) torch_normal(2, 3, size=c(1, 4))  } #> torch_tensor #>  0.0455  2.4500  3.9270  5.6783 #> [ CPUFloatType{1,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_not_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Not_equal — torch_not_equal","title":"Not_equal — torch_not_equal","text":"Not_equal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_not_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Not_equal — torch_not_equal","text":"","code":"torch_not_equal(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_not_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Not_equal — torch_not_equal","text":"self (Tensor) tensor compare (Tensor float) tensor value compare","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_not_equal.html","id":"not-equal-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"not_equal(input, other, *, out=None) -> Tensor","title":"Not_equal — torch_not_equal","text":"Alias torch_ne().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones.html","id":null,"dir":"Reference","previous_headings":"","what":"Ones — torch_ones","title":"Ones — torch_ones","text":"Ones","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ones — torch_ones","text":"","code":"torch_ones(   ...,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_ones.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ones — torch_ones","text":"... (int...) sequence integers defining shape output tensor.        Can variable number arguments collection like list tuple. names optional names dimensions dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones.html","id":"ones-size-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"ones(*size, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Ones — torch_ones","text":"Returns tensor filled scalar value 1, shape defined variable argument size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ones — torch_ones","text":"","code":"if (torch_is_installed()) {  torch_ones(c(2, 3)) torch_ones(c(5)) } #> torch_tensor #>  1 #>  1 #>  1 #>  1 #>  1 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Ones_like — torch_ones_like","title":"Ones_like — torch_ones_like","text":"Ones_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ones_like — torch_ones_like","text":"","code":"torch_ones_like(   input,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ones_like — torch_ones_like","text":"input (Tensor) size input determine size output tensor. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":"ones-like-input-dtype-null-layout-null-device-null-requires-grad-false-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"ones_like(input, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, memory_format=torch.preserve_format) -> Tensor","title":"Ones_like — torch_ones_like","text":"Returns tensor filled scalar value 1, size input. torch_ones_like(input) equivalent torch_ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Ones_like — torch_ones_like","text":"0.4, function support keyword. alternative, old torch_ones_like(input, =output) equivalent torch_ones(input.size(), =output).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ones_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ones_like — torch_ones_like","text":"","code":"if (torch_is_installed()) {  input = torch_empty(c(2, 3)) torch_ones_like(input) } #> torch_tensor #>  1  1  1 #>  1  1  1 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_orgqr.html","id":null,"dir":"Reference","previous_headings":"","what":"Orgqr — torch_orgqr","title":"Orgqr — torch_orgqr","text":"Orgqr","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_orgqr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orgqr — torch_orgqr","text":"","code":"torch_orgqr(self, input2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_orgqr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orgqr — torch_orgqr","text":"self (Tensor) torch_geqrf. input2 (Tensor) tau torch_geqrf.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_orgqr.html","id":"orgqr-input-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"orgqr(input, input2) -> Tensor","title":"Orgqr — torch_orgqr","text":"Computes orthogonal matrix Q QR factorization, (input, input2) tuple returned torch_geqrf. directly calls underlying LAPACK function ?orgqr. See LAPACK documentation orgqr_ details.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ormqr.html","id":null,"dir":"Reference","previous_headings":"","what":"Ormqr — torch_ormqr","title":"Ormqr — torch_ormqr","text":"Ormqr","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ormqr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ormqr — torch_ormqr","text":"","code":"torch_ormqr(self, input2, input3, left = TRUE, transpose = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_ormqr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ormqr — torch_ormqr","text":"self (Tensor) torch_geqrf. input2 (Tensor) tau torch_geqrf. input3 (Tensor) matrix multiplied. left see LAPACK documentation transpose see LAPACK documentation","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_ormqr.html","id":"ormqr-input-input-input-left-true-transpose-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"ormqr(input, input2, input3, left=TRUE, transpose=False) -> Tensor","title":"Ormqr — torch_ormqr","text":"Multiplies mat (given input3) orthogonal Q matrix QR factorization formed torch_geqrf() represented (, tau) (given (input, input2)). directly calls underlying LAPACK function ?ormqr.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":null,"dir":"Reference","previous_headings":"","what":"Outer — torch_outer","title":"Outer — torch_outer","text":"Outer","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outer — torch_outer","text":"","code":"torch_outer(self, vec2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outer — torch_outer","text":"self (Tensor) 1-D input vector vec2 (Tensor) 1-D input vector","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Outer — torch_outer","text":"function broadcast.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":"outer-input-vec-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"outer(input, vec2, *, out=None) -> Tensor","title":"Outer — torch_outer","text":"Outer product input vec2. input vector size \\(n\\) vec2 vector size \\(m\\), must matrix size \\((n \\times m)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_outer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outer — torch_outer","text":"","code":"if (torch_is_installed()) {  v1 <- torch_arange(1., 5.) v2 <- torch_arange(1., 4.) torch_outer(v1, v2) } #> torch_tensor #>   1   2   3   4 #>   2   4   6   8 #>   3   6   9  12 #>   4   8  12  16 #>   5  10  15  20 #> [ CPUFloatType{5,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_pdist.html","id":null,"dir":"Reference","previous_headings":"","what":"Pdist — torch_pdist","title":"Pdist — torch_pdist","text":"Pdist","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pdist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pdist — torch_pdist","text":"","code":"torch_pdist(self, p = 2L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_pdist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pdist — torch_pdist","text":"self NA input tensor shape \\(N \\times M\\). p NA p value p-norm distance calculate vector pair        \\(\\[0, \\infty]\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pdist.html","id":"pdist-input-p-gt-tensor-","dir":"Reference","previous_headings":"","what":"pdist(input, p=2) -> Tensor","title":"Pdist — torch_pdist","text":"Computes p-norm distance every pair row vectors input. identical upper triangular portion, excluding diagonal, torch_norm(input[:, NULL] - input, dim=2, p=p). function faster rows contiguous. input shape \\(N \\times M\\) output shape \\(\\frac{1}{2} N (N - 1)\\). function equivalent scipy.spatial.distance.pdist(input, 'minkowski', p=p) \\(p \\(0, \\infty)\\). \\(p = 0\\) equivalent scipy.spatial.distance.pdist(input, 'hamming') * M. \\(p = \\infty\\), closest scipy function scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max()).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":null,"dir":"Reference","previous_headings":"","what":"Pinverse — torch_pinverse","title":"Pinverse — torch_pinverse","text":"Pinverse","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pinverse — torch_pinverse","text":"","code":"torch_pinverse(self, rcond = 1e-15)"},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pinverse — torch_pinverse","text":"self (Tensor) input tensor size \\((*, m, n)\\) \\(*\\) zero batch dimensions rcond (float) floating point value determine cutoff small singular values.                   Default: 1e-15","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Pinverse — torch_pinverse","text":"","code":"This method is implemented using the Singular Value Decomposition. The pseudo-inverse is not necessarily a continuous function in the elements of the matrix `[1]`_. Therefore, derivatives are not always existent, and exist for a constant rank only `[2]`_. However, this method is backprop-able due to the implementation by using SVD results, and could be unstable. Double-backward will also be unstable due to the usage of SVD internally. See `~torch.svd` for more details."},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":"pinverse-input-rcond-e-gt-tensor-","dir":"Reference","previous_headings":"","what":"pinverse(input, rcond=1e-15) -> Tensor","title":"Pinverse — torch_pinverse","text":"Calculates pseudo-inverse (also known Moore-Penrose inverse) 2D tensor. Please look Moore-Penrose inverse_ details","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pinverse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pinverse — torch_pinverse","text":"","code":"if (torch_is_installed()) {  input = torch_randn(c(3, 5)) input torch_pinverse(input) # Batched pinverse example a = torch_randn(c(2,6,3)) b = torch_pinverse(a) torch_matmul(b, a) } #> torch_tensor #> (1,.,.) =  #>   1.0000e+00 -4.2841e-08 -8.9407e-08 #>  -8.3819e-09  1.0000e+00 -1.3411e-07 #>  -1.0245e-07 -9.6858e-08  1.0000e+00 #>  #> (2,.,.) =  #>   1.0000e+00 -3.4459e-07  9.6858e-08 #>  -1.7881e-07  1.0000e+00 -2.4587e-07 #>   1.4901e-07  1.7043e-07  1.0000e+00 #> [ CPUFloatType{2,3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_pixel_shuffle.html","id":null,"dir":"Reference","previous_headings":"","what":"Pixel_shuffle — torch_pixel_shuffle","title":"Pixel_shuffle — torch_pixel_shuffle","text":"Pixel_shuffle","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pixel_shuffle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pixel_shuffle — torch_pixel_shuffle","text":"","code":"torch_pixel_shuffle(self, upscale_factor)"},{"path":"https://torch.mlverse.org/docs/reference/torch_pixel_shuffle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pixel_shuffle — torch_pixel_shuffle","text":"self (Tensor) input tensor upscale_factor (int) factor increase spatial resolution ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pixel_shuffle.html","id":"rearranges-elements-in-a-tensor-of-shape-","dir":"Reference","previous_headings":"","what":"Rearranges elements in a tensor of shape","title":"Pixel_shuffle — torch_pixel_shuffle","text":"math:(*, C \\times r^2, H, W) : Rearranges elements tensor shape \\((*, C \\times r^2, H, W)\\) tensor shape \\((*, C, H \\times r, W \\times r)\\). See ~torch.nn.PixelShuffle details.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pixel_shuffle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pixel_shuffle — torch_pixel_shuffle","text":"","code":"if (torch_is_installed()) {  input = torch_randn(c(1, 9, 4, 4)) output = nnf_pixel_shuffle(input, 3) print(output$size()) } #> [1]  1  1 12 12"},{"path":"https://torch.mlverse.org/docs/reference/torch_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson — torch_poisson","title":"Poisson — torch_poisson","text":"Poisson","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson — torch_poisson","text":"","code":"torch_poisson(self, generator = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson — torch_poisson","text":"self (Tensor) input tensor containing rates Poisson distribution generator (torch.Generator, optional) pseudorandom number generator sampling","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_poisson.html","id":"poisson-input-generator-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"poisson(input *, generator=NULL) -> Tensor","title":"Poisson — torch_poisson","text":"Returns tensor size input element sampled Poisson distribution rate parameter given corresponding element input .e., $$     \\mbox{}_i \\sim \\mbox{Poisson}(\\mbox{input}_i) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson — torch_poisson","text":"","code":"if (torch_is_installed()) {  rates = torch_rand(c(4, 4)) * 5  # rate parameter between 0 and 5 torch_poisson(rates) } #> torch_tensor #>  3  0  2  2 #>  7  0  3  3 #>  3  4  4  0 #>  2  5  2  4 #> [ CPUFloatType{4,4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_polar.html","id":null,"dir":"Reference","previous_headings":"","what":"Polar — torch_polar","title":"Polar — torch_polar","text":"Polar","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polar — torch_polar","text":"","code":"torch_polar(abs, angle)"},{"path":"https://torch.mlverse.org/docs/reference/torch_polar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polar — torch_polar","text":"abs (Tensor) absolute value complex tensor. Must float double. angle (Tensor) angle complex tensor. Must dtype abs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polar.html","id":"polar-abs-angle-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"polar(abs, angle, *, out=None) -> Tensor","title":"Polar — torch_polar","text":"Constructs complex tensor whose elements Cartesian coordinates corresponding polar coordinates absolute value abs angle angle. $$     \\mbox{} = \\mbox{abs} \\cdot \\cos(\\mbox{angle}) + \\mbox{abs} \\cdot \\sin(\\mbox{angle}) \\cdot j $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polar — torch_polar","text":"","code":"if (torch_is_installed()) {  abs <- torch_tensor(c(1, 2), dtype=torch_float64()) angle <- torch_tensor(c(pi / 2, 5 * pi / 4), dtype=torch_float64()) z <- torch_polar(abs, angle) z } #> torch_tensor #> ℹ Use `$real` or `$imag` to print the contents of this tensor. #> [ CPUComplexDoubleType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":null,"dir":"Reference","previous_headings":"","what":"Polygamma — torch_polygamma","title":"Polygamma — torch_polygamma","text":"Polygamma","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polygamma — torch_polygamma","text":"","code":"torch_polygamma(n, input)"},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polygamma — torch_polygamma","text":"n (int) order polygamma function input (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Polygamma — torch_polygamma","text":"","code":"This function is not implemented for \\eqn{n \\geq 2}."},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":"polygamma-n-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"polygamma(n, input, out=NULL) -> Tensor","title":"Polygamma — torch_polygamma","text":"Computes \\(n^{th}\\) derivative digamma function input. \\(n \\geq 0\\) called order polygamma function. $$     \\psi^{(n)}(x) = \\frac{d^{(n)}}{dx^{(n)}} \\psi(x) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_polygamma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polygamma — torch_polygamma","text":"","code":"if (torch_is_installed()) { if (FALSE) { a = torch_tensor(c(1, 0.5)) torch_polygamma(1, a) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":null,"dir":"Reference","previous_headings":"","what":"Pow — torch_pow","title":"Pow — torch_pow","text":"Pow","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pow — torch_pow","text":"","code":"torch_pow(self, exponent)"},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pow — torch_pow","text":"self (float) scalar base value power operation exponent (float tensor) exponent value","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":"pow-input-exponent-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"pow(input, exponent, out=NULL) -> Tensor","title":"Pow — torch_pow","text":"Takes power element input exponent returns tensor result. exponent can either single float number Tensor number elements input. exponent scalar value, operation applied : $$     \\mbox{}_i = x_i^{\\mbox{exponent}} $$ exponent tensor, operation applied : $$     \\mbox{}_i = x_i^{\\mbox{exponent}_i} $$ exponent tensor, shapes input exponent must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":"pow-self-exponent-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"pow(self, exponent, out=NULL) -> Tensor","title":"Pow — torch_pow","text":"self scalar float value, exponent tensor. returned tensor shape exponent operation applied : $$     \\mbox{}_i = \\mbox{self} ^ {\\mbox{exponent}_i} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_pow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pow — torch_pow","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_pow(a, 2) exp <- torch_arange(1, 5) a <- torch_arange(1, 5) a exp torch_pow(a, exp)   exp <- torch_arange(1, 5) base <- 2 torch_pow(base, exp) } #> torch_tensor #>   2 #>   4 #>   8 #>  16 #>  32 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":null,"dir":"Reference","previous_headings":"","what":"Prod — torch_prod","title":"Prod — torch_prod","text":"Prod","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prod — torch_prod","text":"","code":"torch_prod(self, dim, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prod — torch_prod","text":"self (Tensor) input tensor. dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained . dtype (torch.dtype, optional) desired data type returned tensor.        specified, input tensor casted dtype operation        performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":"prod-input-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"prod(input, dtype=NULL) -> Tensor","title":"Prod — torch_prod","text":"Returns product elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":"prod-input-dim-keepdim-false-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"prod(input, dim, keepdim=False, dtype=NULL) -> Tensor","title":"Prod — torch_prod","text":"Returns product row input tensor given dimension dim. keepdim TRUE, output tensor size input except dimension dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 fewer dimension input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_prod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prod — torch_prod","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_prod(a)   a = torch_randn(c(4, 2)) a torch_prod(a, 1) } #> torch_tensor #>  1.0789 #>  0.6899 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_promote_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Promote_types — torch_promote_types","title":"Promote_types — torch_promote_types","text":"Promote_types","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_promote_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Promote_types — torch_promote_types","text":"","code":"torch_promote_types(type1, type2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_promote_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Promote_types — torch_promote_types","text":"type1 (torch.dtype) type2 (torch.dtype)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_promote_types.html","id":"promote-types-type-type-gt-dtype-","dir":"Reference","previous_headings":"","what":"promote_types(type1, type2) -> dtype","title":"Promote_types — torch_promote_types","text":"Returns torch_dtype smallest size scalar kind smaller lower kind either type1 type2. See type promotion documentation  information type promotion logic.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_promote_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Promote_types — torch_promote_types","text":"","code":"if (torch_is_installed()) {  torch_promote_types(torch_int32(), torch_float32()) torch_promote_types(torch_uint8(), torch_long()) } #> torch_Long"},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":null,"dir":"Reference","previous_headings":"","what":"Qr — torch_qr","title":"Qr — torch_qr","text":"Qr","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Qr — torch_qr","text":"","code":"torch_qr(self, some = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Qr — torch_qr","text":"self (Tensor) input tensor size \\((*, m, n)\\) * zero                batch dimensions consisting matrices dimension \\(m \\times n\\). (bool, optional) Set TRUE reduced QR decomposition FALSE                complete QR decomposition.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Qr — torch_qr","text":"precision may lost magnitudes elements input large always give valid decomposition, may give one across platforms - depend LAPACK implementation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":"qr-input-some-true-out-null-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"qr(input, some=TRUE, out=NULL) -> (Tensor, Tensor)","title":"Qr — torch_qr","text":"Computes QR decomposition matrix batch matrices input, returns namedtuple (Q, R) tensors \\(\\mbox{input} = Q R\\) \\(Q\\) orthogonal matrix batch orthogonal matrices \\(R\\) upper triangular matrix batch upper triangular matrices. TRUE, function returns thin (reduced) QR factorization. Otherwise, FALSE, function returns complete QR factorization.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_qr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Qr — torch_qr","text":"","code":"if (torch_is_installed()) {  a = torch_tensor(matrix(c(12., -51, 4, 6, 167, -68, -4, 24, -41), ncol = 3, byrow = TRUE)) out = torch_qr(a) q = out[[1]] r = out[[2]] torch_mm(q, r)$round() torch_mm(q$t(), q)$round() } #> torch_tensor #>  1  0  0 #>  0  1  0 #>  0  0  1 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_qscheme.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates the corresponding Scheme object — torch_qscheme","title":"Creates the corresponding Scheme object — torch_qscheme","text":"Creates corresponding Scheme object","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_qscheme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates the corresponding Scheme object — torch_qscheme","text":"","code":"torch_per_channel_affine()  torch_per_tensor_affine()  torch_per_channel_symmetric()  torch_per_tensor_symmetric()"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile — torch_quantile","title":"Quantile — torch_quantile","text":"Quantile","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile — torch_quantile","text":"","code":"torch_quantile(self, q, dim = NULL, keepdim = FALSE, interpolation = \"linear\")"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile — torch_quantile","text":"self (Tensor) input tensor. q (float Tensor) scalar 1D tensor quantile values range [0, 1] dim (int) dimension reduce. keepdim (bool) whether output tensor dim retained . interpolation interpolation method.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":"quantile-input-q-gt-tensor-","dir":"Reference","previous_headings":"","what":"quantile(input, q) -> Tensor","title":"Quantile — torch_quantile","text":"Returns q-th quantiles elements input tensor, linear interpolation q-th quantile lies two data points.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":"quantile-input-q-dim-none-keepdim-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"quantile(input, q, dim=None, keepdim=FALSE, *, out=None) -> Tensor","title":"Quantile — torch_quantile","text":"Returns q-th quantiles row input tensor along dimension dim, linear interpolation q-th quantile lies two data points. default, dim None resulting input tensor flattened computation. keepdim TRUE, output dimensions size input except dimensions reduced (dim dim NULL) size 1. Otherwise, dimensions reduced squeezed (see torch_squeeze). q 1D tensor, extra dimension prepended output tensor size q represents quantiles.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile — torch_quantile","text":"","code":"if (torch_is_installed()) {  a <- torch_randn(c(1, 3)) a q <- torch_tensor(c(0, 0.5, 1)) torch_quantile(a, q)   a <- torch_randn(c(2, 3)) a q <- torch_tensor(c(0.25, 0.5, 0.75)) torch_quantile(a, q, dim=1, keepdim=TRUE) torch_quantile(a, q, dim=1, keepdim=TRUE)$shape } #> [1] 3 1 3"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_channel.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantize_per_channel — torch_quantize_per_channel","title":"Quantize_per_channel — torch_quantize_per_channel","text":"Quantize_per_channel","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_channel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantize_per_channel — torch_quantize_per_channel","text":"","code":"torch_quantize_per_channel(self, scales, zero_points, axis, dtype)"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_channel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantize_per_channel — torch_quantize_per_channel","text":"self (Tensor) float tensor quantize scales (Tensor) float 1D tensor scales use, size match input.size(axis) zero_points (int) integer 1D tensor offset use, size match input.size(axis) axis (int) dimension apply per-channel quantization dtype (torch.dtype) desired data type returned tensor.        one quantized dtypes: torch_quint8, torch.qint8, torch.qint32","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_channel.html","id":"quantize-per-channel-input-scales-zero-points-axis-dtype-gt-tensor-","dir":"Reference","previous_headings":"","what":"quantize_per_channel(input, scales, zero_points, axis, dtype) -> Tensor","title":"Quantize_per_channel — torch_quantize_per_channel","text":"Converts float tensor per-channel quantized tensor given scales zero points.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_channel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantize_per_channel — torch_quantize_per_channel","text":"","code":"if (torch_is_installed()) { x = torch_tensor(matrix(c(-1.0, 0.0, 1.0, 2.0), ncol = 2, byrow = TRUE)) torch_quantize_per_channel(x, torch_tensor(c(0.1, 0.01)),                             torch_tensor(c(10L, 0L)), 0, torch_quint8()) torch_quantize_per_channel(x, torch_tensor(c(0.1, 0.01)),                             torch_tensor(c(10L, 0L)), 0, torch_quint8())$int_repr() } #> torch_tensor #>    0   10 #>  100  200 #> [ CPUByteType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantize_per_tensor — torch_quantize_per_tensor","title":"Quantize_per_tensor — torch_quantize_per_tensor","text":"Quantize_per_tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantize_per_tensor — torch_quantize_per_tensor","text":"","code":"torch_quantize_per_tensor(self, scale, zero_point, dtype)"},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantize_per_tensor — torch_quantize_per_tensor","text":"self (Tensor) float tensor quantize scale (float) scale apply quantization formula zero_point (int) offset integer value maps float zero dtype (torch.dtype) desired data type returned tensor.        one quantized dtypes: torch_quint8, torch.qint8, torch.qint32","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_tensor.html","id":"quantize-per-tensor-input-scale-zero-point-dtype-gt-tensor-","dir":"Reference","previous_headings":"","what":"quantize_per_tensor(input, scale, zero_point, dtype) -> Tensor","title":"Quantize_per_tensor — torch_quantize_per_tensor","text":"Converts float tensor quantized tensor given scale zero point.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_quantize_per_tensor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantize_per_tensor — torch_quantize_per_tensor","text":"","code":"if (torch_is_installed()) { torch_quantize_per_tensor(torch_tensor(c(-1.0, 0.0, 1.0, 2.0)), 0.1, 10, torch_quint8()) torch_quantize_per_tensor(torch_tensor(c(-1.0, 0.0, 1.0, 2.0)), 0.1, 10, torch_quint8())$int_repr() } #> torch_tensor #>   0 #>  10 #>  20 #>  30 #> [ CPUByteType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_rad2deg.html","id":null,"dir":"Reference","previous_headings":"","what":"Rad2deg — torch_rad2deg","title":"Rad2deg — torch_rad2deg","text":"Rad2deg","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rad2deg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rad2deg — torch_rad2deg","text":"","code":"torch_rad2deg(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_rad2deg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rad2deg — torch_rad2deg","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rad2deg.html","id":"rad-deg-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"rad2deg(input, *, out=None) -> Tensor","title":"Rad2deg — torch_rad2deg","text":"Returns new tensor elements input converted angles radians degrees.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rad2deg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rad2deg — torch_rad2deg","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(rbind(c(3.142, -3.142), c(6.283, -6.283), c(1.570, -1.570))) torch_rad2deg(a) } #> torch_tensor #>  180.0233 -180.0233 #>  359.9894 -359.9894 #>   89.9544  -89.9544 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_rand.html","id":null,"dir":"Reference","previous_headings":"","what":"Rand — torch_rand","title":"Rand — torch_rand","text":"Rand","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rand.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rand — torch_rand","text":"","code":"torch_rand(   ...,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_rand.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rand — torch_rand","text":"... (int...) sequence integers defining shape output tensor.        Can variable number arguments collection like list tuple. names optional dimension names dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rand.html","id":"rand-size-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"rand(*size, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Rand — torch_rand","text":"Returns tensor filled random numbers uniform distribution interval \\([0, 1)\\) shape tensor defined variable argument size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rand.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rand — torch_rand","text":"","code":"if (torch_is_installed()) {  torch_rand(4) torch_rand(c(2, 3)) } #> torch_tensor #>  0.8802  0.0500  0.8957 #>  0.2329  0.6650  0.5580 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_rand_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Rand_like — torch_rand_like","title":"Rand_like — torch_rand_like","text":"Rand_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rand_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rand_like — torch_rand_like","text":"","code":"torch_rand_like(   input,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_rand_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rand_like — torch_rand_like","text":"input (Tensor) size input determine size output tensor. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rand_like.html","id":"rand-like-input-dtype-null-layout-null-device-null-requires-grad-false-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"rand_like(input, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, memory_format=torch.preserve_format) -> Tensor","title":"Rand_like — torch_rand_like","text":"Returns tensor size input filled random numbers uniform distribution interval \\([0, 1)\\). torch_rand_like(input) equivalent torch_rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint.html","id":null,"dir":"Reference","previous_headings":"","what":"Randint — torch_randint","title":"Randint — torch_randint","text":"Randint","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randint — torch_randint","text":"","code":"torch_randint(   low,   high,   size,   generator = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_randint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randint — torch_randint","text":"low (int, optional) Lowest integer drawn distribution. Default: 0. high (int) One highest integer drawn distribution. size (tuple) tuple defining shape output tensor. generator (torch.Generator, optional) pseudorandom number generator sampling dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format memory format resulting tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint.html","id":"randint-low-high-size-generator-null-out-null-","dir":"Reference","previous_headings":"","what":"randint(low=0, high, size, *, generator=NULL, out=NULL, \\","title":"Randint — torch_randint","text":"dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor Returns tensor filled random integers generated uniformly low (inclusive) high (exclusive). shape tensor defined variable argument size. .. note: global dtype default (torch_float32), function returns tensor dtype torch_int64.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randint — torch_randint","text":"","code":"if (torch_is_installed()) {  torch_randint(3, 5, list(3)) torch_randint(0, 10, size = list(2, 2)) torch_randint(3, 10, list(2, 2)) } #> torch_tensor #>  6  8 #>  5  7 #> [ CPUFloatType{2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_randint_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Randint_like — torch_randint_like","title":"Randint_like — torch_randint_like","text":"Randint_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randint_like — torch_randint_like","text":"","code":"torch_randint_like(   input,   low,   high,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_randint_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randint_like — torch_randint_like","text":"input (Tensor) size input determine size output tensor. low (int, optional) Lowest integer drawn distribution. Default: 0. high (int) One highest integer drawn distribution. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randint_like.html","id":"randint-like-input-low-high-dtype-null-layout-torch-strided-device-null-requires-grad-false-","dir":"Reference","previous_headings":"","what":"randint_like(input, low=0, high, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False,","title":"Randint_like — torch_randint_like","text":"memory_format=torch.preserve_format) -> Tensor Returns tensor shape Tensor input filled random integers generated uniformly low (inclusive) high (exclusive). .. note: global dtype default (torch_float32), function returns tensor dtype torch_int64.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn.html","id":null,"dir":"Reference","previous_headings":"","what":"Randn — torch_randn","title":"Randn — torch_randn","text":"Randn","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randn — torch_randn","text":"","code":"torch_randn(   ...,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_randn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randn — torch_randn","text":"... (int...) sequence integers defining shape output tensor.        Can variable number arguments collection like list tuple. names optional names dimensions dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn.html","id":"randn-size-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"randn(*size, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Randn — torch_randn","text":"Returns tensor filled random numbers normal distribution mean 0 variance 1 (also called standard normal distribution). $$     \\mbox{}_{} \\sim \\mathcal{N}(0, 1) $$ shape tensor defined variable argument size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randn — torch_randn","text":"","code":"if (torch_is_installed()) {  torch_randn(c(4)) torch_randn(c(2, 3)) } #> torch_tensor #> -0.8321  0.3774 -1.2515 #>  1.1037  2.6689  0.0240 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_randn_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Randn_like — torch_randn_like","title":"Randn_like — torch_randn_like","text":"Randn_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randn_like — torch_randn_like","text":"","code":"torch_randn_like(   input,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_randn_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randn_like — torch_randn_like","text":"input (Tensor) size input determine size output tensor. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randn_like.html","id":"randn-like-input-dtype-null-layout-null-device-null-requires-grad-false-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"randn_like(input, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, memory_format=torch.preserve_format) -> Tensor","title":"Randn_like — torch_randn_like","text":"Returns tensor size input filled random numbers normal distribution mean 0 variance 1. torch_randn_like(input) equivalent torch_randn(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randperm.html","id":null,"dir":"Reference","previous_headings":"","what":"Randperm — torch_randperm","title":"Randperm — torch_randperm","text":"Randperm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randperm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Randperm — torch_randperm","text":"","code":"torch_randperm(   n,   dtype = torch_int64(),   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_randperm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Randperm — torch_randperm","text":"n (int) upper bound (exclusive) dtype (torch.dtype, optional) desired data type returned tensor.        Default: torch_int64. layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randperm.html","id":"randperm-n-out-null-dtype-torch-int-layout-torch-strided-device-null-requires-grad-false-gt-longtensor-","dir":"Reference","previous_headings":"","what":"randperm(n, out=NULL, dtype=torch.int64, layout=torch.strided, device=NULL, requires_grad=False) -> LongTensor","title":"Randperm — torch_randperm","text":"Returns random permutation integers 0 n - 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_randperm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Randperm — torch_randperm","text":"","code":"if (torch_is_installed()) {  torch_randperm(4) } #> torch_tensor #>  1 #>  2 #>  0 #>  3 #> [ CPULongType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":null,"dir":"Reference","previous_headings":"","what":"Range — torch_range","title":"Range — torch_range","text":"Range","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Range — torch_range","text":"","code":"torch_range(   start,   end,   step = 1,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Range — torch_range","text":"start (float) starting value set points. Default: 0. end (float) ending value set points step (float) gap pair adjacent points. Default: 1. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). dtype given, infer data type input        arguments. start, end, stop floating-point,        dtype inferred default dtype, see        ~torch.get_default_dtype. Otherwise, dtype inferred        torch.int64. layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":"range-start-end-step-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"range(start=0, end, step=1, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Range — torch_range","text":"Returns 1-D tensor size \\(\\left\\lfloor \\frac{\\mbox{end} - \\mbox{start}}{\\mbox{step}} \\right\\rfloor + 1\\) values start end step step. Step gap two values tensor. $$     \\mbox{}_{+1} = \\mbox{}_i + \\mbox{step}. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Range — torch_range","text":"function deprecated favor torch_arange.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_range.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Range — torch_range","text":"","code":"if (torch_is_installed()) {  torch_range(1, 4) torch_range(1, 4, 0.5) } #> Warning: This function is deprecated in favor of torch_arange. #> Warning: This function is deprecated in favor of torch_arange. #> torch_tensor #>  1.0000 #>  1.5000 #>  2.0000 #>  2.5000 #>  3.0000 #>  3.5000 #>  4.0000 #> [ CPUFloatType{7} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":null,"dir":"Reference","previous_headings":"","what":"Real — torch_real","title":"Real — torch_real","text":"Real","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Real — torch_real","text":"","code":"torch_real(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Real — torch_real","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":"real-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"real(input) -> Tensor","title":"Real — torch_real","text":"Returns real part input tensor. input real (non-complex) tensor, function just returns .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Real — torch_real","text":"yet implemented complex tensors. $$     \\mbox{}_{} = real(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_real.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Real — torch_real","text":"","code":"if (torch_is_installed()) { if (FALSE) { torch_real(torch_tensor(c(-1 + 1i, -2 + 2i, 3 - 3i))) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_reciprocal.html","id":null,"dir":"Reference","previous_headings":"","what":"Reciprocal — torch_reciprocal","title":"Reciprocal — torch_reciprocal","text":"Reciprocal","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reciprocal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reciprocal — torch_reciprocal","text":"","code":"torch_reciprocal(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_reciprocal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reciprocal — torch_reciprocal","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reciprocal.html","id":"reciprocal-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"reciprocal(input, out=NULL) -> Tensor","title":"Reciprocal — torch_reciprocal","text":"Returns new tensor reciprocal elements input $$     \\mbox{}_{} = \\frac{1}{\\mbox{input}_{}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reciprocal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reciprocal — torch_reciprocal","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_reciprocal(a) } #> torch_tensor #>  -12.5890 #>    1.9890 #>  162.2891 #>    1.2674 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_reduction.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates the reduction objet — torch_reduction","title":"Creates the reduction objet — torch_reduction","text":"Creates reduction objet","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reduction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates the reduction objet — torch_reduction","text":"","code":"torch_reduction_sum()  torch_reduction_mean()  torch_reduction_none()"},{"path":"https://torch.mlverse.org/docs/reference/torch_relu.html","id":null,"dir":"Reference","previous_headings":"","what":"Relu — torch_relu","title":"Relu — torch_relu","text":"Relu","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_relu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relu — torch_relu","text":"","code":"torch_relu(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_relu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relu — torch_relu","text":"self input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_relu.html","id":"relu-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"relu(input) -> Tensor","title":"Relu — torch_relu","text":"Computes relu tranformation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_relu_.html","id":null,"dir":"Reference","previous_headings":"","what":"Relu_ — torch_relu_","title":"Relu_ — torch_relu_","text":"Relu_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_relu_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Relu_ — torch_relu_","text":"","code":"torch_relu_(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_relu_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Relu_ — torch_relu_","text":"self input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_relu_.html","id":"relu-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"relu_(input) -> Tensor","title":"Relu_ — torch_relu_","text":"-place version torch_relu().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_remainder.html","id":null,"dir":"Reference","previous_headings":"","what":"Remainder — torch_remainder","title":"Remainder — torch_remainder","text":"Remainder","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_remainder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remainder — torch_remainder","text":"","code":"torch_remainder(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_remainder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remainder — torch_remainder","text":"self (Tensor) dividend (Tensor float) divisor may either number                               Tensor shape dividend","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_remainder.html","id":"remainder-input-other-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"remainder(input, other, out=NULL) -> Tensor","title":"Remainder — torch_remainder","text":"Computes element-wise remainder division. divisor dividend may contain integer floating point numbers. remainder sign divisor. tensor, shapes input must broadcastable .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_remainder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remainder — torch_remainder","text":"","code":"if (torch_is_installed()) {  torch_remainder(torch_tensor(c(-3., -2, -1, 1, 2, 3)), 2) torch_remainder(torch_tensor(c(1., 2, 3, 4, 5)), 1.5) } #> torch_tensor #>  1.0000 #>  0.5000 #>  0.0000 #>  1.0000 #>  0.5000 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Renorm — torch_renorm","title":"Renorm — torch_renorm","text":"Renorm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Renorm — torch_renorm","text":"","code":"torch_renorm(self, p, dim, maxnorm)"},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Renorm — torch_renorm","text":"self (Tensor) input tensor. p (float) power norm computation dim (int) dimension slice get sub-tensors maxnorm (float) maximum norm keep sub-tensor ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Renorm — torch_renorm","text":"norm row lower maxnorm, row unchanged","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":"renorm-input-p-dim-maxnorm-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"renorm(input, p, dim, maxnorm, out=NULL) -> Tensor","title":"Renorm — torch_renorm","text":"Returns tensor sub-tensor input along dimension dim normalized p-norm sub-tensor lower value maxnorm","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_renorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Renorm — torch_renorm","text":"","code":"if (torch_is_installed()) { x = torch_ones(c(3, 3)) x[2,]$fill_(2) x[3,]$fill_(3) x torch_renorm(x, 1, 1, 5) } #> torch_tensor #>  1.0000  1.0000  1.0000 #>  1.6667  1.6667  1.6667 #>  1.6667  1.6667  1.6667 #> [ CPUFloatType{3,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeat_interleave — torch_repeat_interleave","title":"Repeat_interleave — torch_repeat_interleave","text":"Repeat_interleave","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeat_interleave — torch_repeat_interleave","text":"","code":"torch_repeat_interleave(self, repeats, dim = NULL, output_size = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Repeat_interleave — torch_repeat_interleave","text":"self (Tensor) input tensor. repeats (Tensor int) number repetitions element.        repeats broadcasted fit shape given axis. dim (int, optional) dimension along repeat values.        default, use flattened input array, return flat output        array. output_size (int, optional) – Total output size given axis ( e.g. sum repeats). given, avoid stream syncronization needed calculate output shape tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"repeat-interleave-input-repeats-dim-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"repeat_interleave(input, repeats, dim=NULL) -> Tensor","title":"Repeat_interleave — torch_repeat_interleave","text":"Repeat elements tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Repeat_interleave — torch_repeat_interleave","text":"","code":"This is different from `torch_Tensor.repeat` but similar to `numpy.repeat`."},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"repeat-interleave-repeats-gt-tensor-","dir":"Reference","previous_headings":"","what":"repeat_interleave(repeats) -> Tensor","title":"Repeat_interleave — torch_repeat_interleave","text":"repeats tensor([n1, n2, n3, ...]), output tensor([0, 0, ..., 1, 1, ..., 2, 2, ..., ...]) 0 appears n1 times, 1 appears n2 times, 2 appears n3 times, etc.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_repeat_interleave.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Repeat_interleave — torch_repeat_interleave","text":"","code":"if (torch_is_installed()) { if (FALSE) { x = torch_tensor(c(1, 2, 3)) x$repeat_interleave(2) y = torch_tensor(matrix(c(1, 2, 3, 4), ncol = 2, byrow=TRUE)) torch_repeat_interleave(y, 2) torch_repeat_interleave(y, 3, dim=1) torch_repeat_interleave(y, torch_tensor(c(1, 2)), dim=1) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_reshape.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape — torch_reshape","title":"Reshape — torch_reshape","text":"Reshape","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reshape.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape — torch_reshape","text":"","code":"torch_reshape(self, shape)"},{"path":"https://torch.mlverse.org/docs/reference/torch_reshape.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape — torch_reshape","text":"self (Tensor) tensor reshaped shape (tuple ints) new shape","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reshape.html","id":"reshape-input-shape-gt-tensor-","dir":"Reference","previous_headings":"","what":"reshape(input, shape) -> Tensor","title":"Reshape — torch_reshape","text":"Returns tensor data number elements input, specified shape. possible, returned tensor view input. Otherwise, copy. Contiguous inputs inputs compatible strides can reshaped without copying, depend copying vs. viewing behavior. See torch_Tensor.view possible return view. single dimension may -1, case inferred remaining dimensions number elements input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_reshape.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape — torch_reshape","text":"","code":"if (torch_is_installed()) {  a <- torch_arange(0, 3) torch_reshape(a, list(2, 2)) b <- torch_tensor(matrix(c(0, 1, 2, 3), ncol = 2, byrow=TRUE)) torch_reshape(b, list(-1)) } #> torch_tensor #>  0 #>  1 #>  2 #>  3 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_result_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Result_type — torch_result_type","title":"Result_type — torch_result_type","text":"Result_type","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_result_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Result_type — torch_result_type","text":"","code":"torch_result_type(tensor1, tensor2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_result_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Result_type — torch_result_type","text":"tensor1 (Tensor Number) input tensor number tensor2 (Tensor Number) input tensor number","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_result_type.html","id":"result-type-tensor-tensor-gt-dtype-","dir":"Reference","previous_headings":"","what":"result_type(tensor1, tensor2) -> dtype","title":"Result_type — torch_result_type","text":"Returns torch_dtype result performing arithmetic operation provided input tensors. See type promotion documentation information type promotion logic.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_result_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Result_type — torch_result_type","text":"","code":"if (torch_is_installed()) {  torch_result_type(tensor1 = torch_tensor(c(1, 2), dtype=torch_int()), tensor2 = 1) } #> torch_Float"},{"path":"https://torch.mlverse.org/docs/reference/torch_roll.html","id":null,"dir":"Reference","previous_headings":"","what":"Roll — torch_roll","title":"Roll — torch_roll","text":"Roll","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_roll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Roll — torch_roll","text":"","code":"torch_roll(self, shifts, dims = list())"},{"path":"https://torch.mlverse.org/docs/reference/torch_roll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Roll — torch_roll","text":"self (Tensor) input tensor. shifts (int tuple ints) number places elements        tensor shifted. shifts tuple, dims must tuple        size, dimension rolled corresponding        value dims (int tuple ints) Axis along roll","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_roll.html","id":"roll-input-shifts-dims-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"roll(input, shifts, dims=NULL) -> Tensor","title":"Roll — torch_roll","text":"Roll tensor along given dimension(s). Elements shifted beyond last position re-introduced first position. dimension specified, tensor flattened rolling restored original shape.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_roll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Roll — torch_roll","text":"","code":"if (torch_is_installed()) {  x = torch_tensor(c(1, 2, 3, 4, 5, 6, 7, 8))$view(c(4, 2)) x torch_roll(x, 1, 1) torch_roll(x, -1, 1) torch_roll(x, shifts=list(2, 1), dims=list(1, 2)) } #> torch_tensor #>  6  5 #>  8  7 #>  2  1 #>  4  3 #> [ CPUFloatType{4,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_rot90.html","id":null,"dir":"Reference","previous_headings":"","what":"Rot90 — torch_rot90","title":"Rot90 — torch_rot90","text":"Rot90","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rot90.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rot90 — torch_rot90","text":"","code":"torch_rot90(self, k = 1L, dims = c(0, 1))"},{"path":"https://torch.mlverse.org/docs/reference/torch_rot90.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rot90 — torch_rot90","text":"self (Tensor) input tensor. k (int) number times rotate dims (list tuple) axis rotate","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rot90.html","id":"rot-input-k-dims-gt-tensor-","dir":"Reference","previous_headings":"","what":"rot90(input, k, dims) -> Tensor","title":"Rot90 — torch_rot90","text":"Rotate n-D tensor 90 degrees plane specified dims axis. Rotation direction first towards second axis k > 0, second towards first k < 0.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rot90.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rot90 — torch_rot90","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(1, 4)$view(c(2, 2)) x torch_rot90(x, 1, c(1, 2)) x <- torch_arange(1, 8)$view(c(2, 2, 2)) x torch_rot90(x, 1, c(1, 2)) } #> torch_tensor #> (1,.,.) =  #>   3  4 #>   7  8 #>  #> (2,.,.) =  #>   1  2 #>   5  6 #> [ CPUFloatType{2,2,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_round.html","id":null,"dir":"Reference","previous_headings":"","what":"Round — torch_round","title":"Round — torch_round","text":"Round","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_round.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Round — torch_round","text":"","code":"torch_round(self, decimals)"},{"path":"https://torch.mlverse.org/docs/reference/torch_round.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Round — torch_round","text":"self (Tensor) input tensor. decimals Number decimal places round (default: 0). decimals negative, specifies number positions left decimal point.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_round.html","id":"round-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"round(input, out=NULL) -> Tensor","title":"Round — torch_round","text":"Returns new tensor elements input rounded closest integer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_round.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Round — torch_round","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_round(a) } #> torch_tensor #> -1 #> -1 #>  0 #>  1 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_rrelu_.html","id":null,"dir":"Reference","previous_headings":"","what":"Rrelu_ — torch_rrelu_","title":"Rrelu_ — torch_rrelu_","text":"Rrelu_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rrelu_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rrelu_ — torch_rrelu_","text":"","code":"torch_rrelu_(   self,   lower = 0.125,   upper = 0.333333333333333,   training = FALSE,   generator = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_rrelu_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rrelu_ — torch_rrelu_","text":"self input tensor lower lower bound uniform distribution. Default: 1/8 upper upper bound uniform distribution. Default: 1/3 training bool wether training pass. DEfault: FALSE generator random number generator","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rrelu_.html","id":"rrelu-input-lower-upper-training-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"rrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor","title":"Rrelu_ — torch_rrelu_","text":"-place version torch_rrelu.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rsqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Rsqrt — torch_rsqrt","title":"Rsqrt — torch_rsqrt","text":"Rsqrt","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rsqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rsqrt — torch_rsqrt","text":"","code":"torch_rsqrt(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_rsqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rsqrt — torch_rsqrt","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rsqrt.html","id":"rsqrt-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"rsqrt(input, out=NULL) -> Tensor","title":"Rsqrt — torch_rsqrt","text":"Returns new tensor reciprocal square-root elements input. $$     \\mbox{}_{} = \\frac{1}{\\sqrt{\\mbox{input}_{}}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_rsqrt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rsqrt — torch_rsqrt","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_rsqrt(a) } #> torch_tensor #>     nan #>  3.2777 #>  1.3045 #>     nan #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves an object to a disk file. — torch_save","title":"Saves an object to a disk file. — torch_save","text":"function experimental, use long term storage.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves an object to a disk file. — torch_save","text":"","code":"torch_save(obj, path, ..., compress = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves an object to a disk file. — torch_save","text":"obj saved object path connection name file save. ... currently used. compress logical specifying whether saving named file use \"gzip\" compression, one \"gzip\", \"bzip2\" \"xz\" indicate type compression used. Ignored file connection.","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/torch_scalar_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Scalar tensor — torch_scalar_tensor","title":"Scalar tensor — torch_scalar_tensor","text":"Creates singleton dimension tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_scalar_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scalar tensor — torch_scalar_tensor","text":"","code":"torch_scalar_tensor(value, dtype = NULL, device = NULL, requires_grad = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_scalar_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scalar tensor — torch_scalar_tensor","text":"value value want use dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_searchsorted.html","id":null,"dir":"Reference","previous_headings":"","what":"Searchsorted — torch_searchsorted","title":"Searchsorted — torch_searchsorted","text":"Searchsorted","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_searchsorted.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Searchsorted — torch_searchsorted","text":"","code":"torch_searchsorted(   sorted_sequence,   self,   out_int32 = FALSE,   right = FALSE,   side = NULL,   sorter = list() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_searchsorted.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Searchsorted — torch_searchsorted","text":"sorted_sequence (Tensor) N-D 1-D tensor, containing monotonically increasing sequence innermost dimension. self (Tensor Scalar) N-D tensor Scalar containing search value(s). out_int32 (bool, optional) – indicate output data type. torch_int32() True, torch_int64() otherwise. Default value FALSE, .e. default output data type torch_int64(). right (bool, optional) – False, return first suitable location found. True, return last index. suitable index found, return 0 non-numerical value (eg. nan, inf) size boundaries (one pass last index). words, False, gets lower bound index value input boundaries. True, gets upper bound index instead. Default value False. side right preferred. “left” corresponds FALSE right “right” corresponds TRUE right. error set “left” right TRUE. sorter provided, tensor matching shape unsorted sorted_sequence containing sequence indices sort ascending order innermost dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_searchsorted.html","id":"searchsorted-sorted-sequence-values-out-int-false-right-false-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"searchsorted(sorted_sequence, values, *, out_int32=FALSE, right=FALSE, out=None) -> Tensor","title":"Searchsorted — torch_searchsorted","text":"Find indices innermost dimension sorted_sequence , corresponding values values inserted indices, order corresponding innermost dimension within sorted_sequence preserved. Return new tensor size values. right FALSE (default), left boundary sorted_sequence closed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_searchsorted.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Searchsorted — torch_searchsorted","text":"","code":"if (torch_is_installed()) {  sorted_sequence <- torch_tensor(rbind(c(1, 3, 5, 7, 9), c(2, 4, 6, 8, 10))) sorted_sequence values <- torch_tensor(rbind(c(3, 6, 9), c(3, 6, 9))) values torch_searchsorted(sorted_sequence, values) torch_searchsorted(sorted_sequence, values, right=TRUE) sorted_sequence_1d <- torch_tensor(c(1, 3, 5, 7, 9)) sorted_sequence_1d torch_searchsorted(sorted_sequence_1d, values) } #> torch_tensor #>  1  3  4 #>  1  3  4 #> [ CPULongType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_selu.html","id":null,"dir":"Reference","previous_headings":"","what":"Selu — torch_selu","title":"Selu — torch_selu","text":"Selu","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_selu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selu — torch_selu","text":"","code":"torch_selu(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_selu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selu — torch_selu","text":"self input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_selu.html","id":"selu-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"selu(input) -> Tensor","title":"Selu — torch_selu","text":"Computes selu transformation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_selu_.html","id":null,"dir":"Reference","previous_headings":"","what":"Selu_ — torch_selu_","title":"Selu_ — torch_selu_","text":"Selu_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_selu_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Selu_ — torch_selu_","text":"","code":"torch_selu_(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_selu_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Selu_ — torch_selu_","text":"self input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_selu_.html","id":"selu-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"selu_(input) -> Tensor","title":"Selu_ — torch_selu_","text":"-place version torch_selu().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_serialize.html","id":null,"dir":"Reference","previous_headings":"","what":"Serialize a torch object returning a raw object — torch_serialize","title":"Serialize a torch object returning a raw object — torch_serialize","text":"just wraper around torch_save().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_serialize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Serialize a torch object returning a raw object — torch_serialize","text":"","code":"torch_serialize(obj, ...)"},{"path":"https://torch.mlverse.org/docs/reference/torch_serialize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Serialize a torch object returning a raw object — torch_serialize","text":"obj saved object ... Additional arguments passed torch_save(). obj path accepted set torch_serialize().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_serialize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Serialize a torch object returning a raw object — torch_serialize","text":"raw vector containing serialized object. Can reloaded using torch_load().","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/torch_sgn.html","id":null,"dir":"Reference","previous_headings":"","what":"Sgn — torch_sgn","title":"Sgn — torch_sgn","text":"Sgn","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sgn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sgn — torch_sgn","text":"","code":"torch_sgn(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sgn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sgn — torch_sgn","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sgn.html","id":"sgn-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"sgn(input, *, out=None) -> Tensor","title":"Sgn — torch_sgn","text":"complex tensors, function returns new tensor whose elemants angle elements input absolute value 1. non-complex tensor, function returns signs elements input (see torch_sign). \\(\\mbox{}_{} = 0\\), \\(|{\\mbox{{input}}_i}| == 0\\) \\(\\mbox{}_{} = \\frac{{\\mbox{{input}}_i}}{|{\\mbox{{input}}_i}|}\\), otherwise","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sgn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sgn — torch_sgn","text":"","code":"if (torch_is_installed()) { if (FALSE) { x <- torch_tensor(c(3+4i, 7-24i, 0, 1+2i)) x$sgn() torch_sgn(x) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_sigmoid.html","id":null,"dir":"Reference","previous_headings":"","what":"Sigmoid — torch_sigmoid","title":"Sigmoid — torch_sigmoid","text":"Sigmoid","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sigmoid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sigmoid — torch_sigmoid","text":"","code":"torch_sigmoid(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sigmoid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sigmoid — torch_sigmoid","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sigmoid.html","id":"sigmoid-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sigmoid(input, out=NULL) -> Tensor","title":"Sigmoid — torch_sigmoid","text":"Returns new tensor sigmoid elements input. $$     \\mbox{}_{} = \\frac{1}{1 + e^{-\\mbox{input}_{}}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sigmoid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sigmoid — torch_sigmoid","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_sigmoid(a) } #> torch_tensor #>  0.3561 #>  0.6325 #>  0.5406 #>  0.2522 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_sign.html","id":null,"dir":"Reference","previous_headings":"","what":"Sign — torch_sign","title":"Sign — torch_sign","text":"Sign","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sign — torch_sign","text":"","code":"torch_sign(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sign — torch_sign","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sign.html","id":"sign-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sign(input, out=NULL) -> Tensor","title":"Sign — torch_sign","text":"Returns new tensor signs elements input. $$     \\mbox{}_{} = \\mbox{sgn}(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sign — torch_sign","text":"","code":"if (torch_is_installed()) {  a = torch_tensor(c(0.7, -1.2, 0., 2.3)) a torch_sign(a) } #> torch_tensor #>  1 #> -1 #>  0 #>  1 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_signbit.html","id":null,"dir":"Reference","previous_headings":"","what":"Signbit — torch_signbit","title":"Signbit — torch_signbit","text":"Signbit","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_signbit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Signbit — torch_signbit","text":"","code":"torch_signbit(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_signbit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Signbit — torch_signbit","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_signbit.html","id":"signbit-input-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"signbit(input, *, out=None) -> Tensor","title":"Signbit — torch_signbit","text":"Tests element input sign bit set (less zero) .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_signbit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Signbit — torch_signbit","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(0.7, -1.2, 0., 2.3)) torch_signbit(a) } #> torch_tensor #>  0 #>  1 #>  0 #>  0 #> [ CPUBoolType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_sin.html","id":null,"dir":"Reference","previous_headings":"","what":"Sin — torch_sin","title":"Sin — torch_sin","text":"Sin","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sin — torch_sin","text":"","code":"torch_sin(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sin — torch_sin","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sin.html","id":"sin-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sin(input, out=NULL) -> Tensor","title":"Sin — torch_sin","text":"Returns new tensor sine elements input. $$     \\mbox{}_{} = \\sin(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sin — torch_sin","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_sin(a) } #> torch_tensor #>  0.6204 #> -0.8166 #>  0.9796 #> -0.9412 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_sinh.html","id":null,"dir":"Reference","previous_headings":"","what":"Sinh — torch_sinh","title":"Sinh — torch_sinh","text":"Sinh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sinh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sinh — torch_sinh","text":"","code":"torch_sinh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sinh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sinh — torch_sinh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sinh.html","id":"sinh-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sinh(input, out=NULL) -> Tensor","title":"Sinh — torch_sinh","text":"Returns new tensor hyperbolic sine elements input. $$     \\mbox{}_{} = \\sinh(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sinh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sinh — torch_sinh","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_sinh(a) } #> torch_tensor #> -2.4683 #>  0.7364 #> -1.0255 #>  1.5774 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":null,"dir":"Reference","previous_headings":"","what":"Slogdet — torch_slogdet","title":"Slogdet — torch_slogdet","text":"Slogdet","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Slogdet — torch_slogdet","text":"","code":"torch_slogdet(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Slogdet — torch_slogdet","text":"self (Tensor) input tensor size (*, n, n) * zero                batch dimensions.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Slogdet — torch_slogdet","text":"","code":"If `input` has zero determinant, this returns `(0, -inf)`. Backward through `slogdet` internally uses SVD results when `input` is not invertible. In this case, double backward through `slogdet` will be unstable in when `input` doesn't have distinct singular values. See `~torch.svd` for details."},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":"slogdet-input-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"slogdet(input) -> (Tensor, Tensor)","title":"Slogdet — torch_slogdet","text":"Calculates sign log absolute value determinant(s) square matrix batches square matrices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_slogdet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Slogdet — torch_slogdet","text":"","code":"if (torch_is_installed()) {  A = torch_randn(c(3, 3)) A torch_det(A) torch_logdet(A) torch_slogdet(A) } #> [[1]] #> torch_tensor #> 1 #> [ CPUFloatType{} ] #>  #> [[2]] #> torch_tensor #> 0.240458 #> [ CPUFloatType{} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_sort.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort — torch_sort","title":"Sort — torch_sort","text":"Sort","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort — torch_sort","text":"self (Tensor) input tensor. dim (int, optional) dimension sort along descending (bool, optional) controls sorting order (ascending descending) stable (bool, optional) – makes sorting routine stable, guarantees order equivalent elements preserved.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sort.html","id":"sort-input-dim-descending-false-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"sort(input, dim=-1, descending=FALSE) -> (Tensor, LongTensor)","title":"Sort — torch_sort","text":"Sorts elements input tensor along given dimension ascending order value. dim given, last dimension input chosen. descending TRUE elements sorted descending order value. namedtuple (values, indices) returned, values sorted values indices indices elements original input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sort.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sort — torch_sort","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(3, 4)) out = torch_sort(x) out out = torch_sort(x, 1) out } #> [[1]] #> torch_tensor #> -0.7761 -2.0850 -0.6274 -0.7934 #> -0.5297 -1.2828 -0.2581  0.2248 #>  1.0347 -0.2183  0.0451  0.8375 #> [ CPUFloatType{3,4} ] #>  #> [[2]] #> torch_tensor #>  3  2  2  3 #>  1  1  1  1 #>  2  3  3  2 #> [ CPULongType{3,4} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_sparse_coo_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Sparse_coo_tensor — torch_sparse_coo_tensor","title":"Sparse_coo_tensor — torch_sparse_coo_tensor","text":"Sparse_coo_tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sparse_coo_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sparse_coo_tensor — torch_sparse_coo_tensor","text":"","code":"torch_sparse_coo_tensor(   indices,   values,   size = NULL,   dtype = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_sparse_coo_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sparse_coo_tensor — torch_sparse_coo_tensor","text":"indices (array_like) Initial data tensor. Can list, tuple,        NumPy ndarray, scalar, types. cast torch_LongTensor        internally. indices coordinates non-zero values matrix, thus        two-dimensional first dimension number tensor dimensions        second dimension number non-zero values. values (array_like) Initial values tensor. Can list, tuple,        NumPy ndarray, scalar, types. size (list, tuple, torch.Size, optional) Size sparse tensor.        provided size inferred minimum size big enough hold non-zero        elements. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, infers data type values. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sparse_coo_tensor.html","id":"sparse-coo-tensor-indices-values-size-null-dtype-null-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"sparse_coo_tensor(indices, values, size=NULL, dtype=NULL, device=NULL, requires_grad=False) -> Tensor","title":"Sparse_coo_tensor — torch_sparse_coo_tensor","text":"Constructs sparse tensors COO(rdinate) format non-zero elements given indices given values. sparse tensor can uncoalesced, case, duplicate coordinates indices, value index sum duplicate value entries: torch_sparse_.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sparse_coo_tensor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sparse_coo_tensor — torch_sparse_coo_tensor","text":"","code":"if (torch_is_installed()) {  i = torch_tensor(matrix(c(1, 2, 2, 3, 1, 3), ncol = 3, byrow = TRUE), dtype=torch_int64()) v = torch_tensor(c(3, 4, 5), dtype=torch_float32()) torch_sparse_coo_tensor(i, v) torch_sparse_coo_tensor(i, v, c(2, 4))  # create empty sparse tensors S = torch_sparse_coo_tensor(   torch_empty(c(1, 0), dtype = torch_int64()),    torch_tensor(numeric(), dtype = torch_float32()),    c(1) ) S = torch_sparse_coo_tensor(   torch_empty(c(1, 0), dtype = torch_int64()),    torch_empty(c(0, 2)),    c(1, 2) ) }"},{"path":"https://torch.mlverse.org/docs/reference/torch_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split — torch_split","title":"Split — torch_split","text":"Splits tensor chunks. chunk view original tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split — torch_split","text":"","code":"torch_split(self, split_size, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split — torch_split","text":"self (Tensor) tensor split. split_size (int) size single chunk list sizes chunk dim (int) dimension along split tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_split.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split — torch_split","text":"split_size integer type, tensor split equally sized chunks (possible). Last chunk smaller tensor size along given dimension dim divisible split_size. split_size list, tensor split length(split_size) chunks sizes dim according split_size_or_sections.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sqrt.html","id":null,"dir":"Reference","previous_headings":"","what":"Sqrt — torch_sqrt","title":"Sqrt — torch_sqrt","text":"Sqrt","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sqrt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sqrt — torch_sqrt","text":"","code":"torch_sqrt(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sqrt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sqrt — torch_sqrt","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sqrt.html","id":"sqrt-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sqrt(input, out=NULL) -> Tensor","title":"Sqrt — torch_sqrt","text":"Returns new tensor square-root elements input. $$     \\mbox{}_{} = \\sqrt{\\mbox{input}_{}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sqrt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sqrt — torch_sqrt","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_sqrt(a) } #> torch_tensor #>     nan #>  1.1726 #>  1.0350 #>  1.0000 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_square.html","id":null,"dir":"Reference","previous_headings":"","what":"Square — torch_square","title":"Square — torch_square","text":"Square","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_square.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Square — torch_square","text":"","code":"torch_square(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_square.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Square — torch_square","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_square.html","id":"square-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"square(input, out=NULL) -> Tensor","title":"Square — torch_square","text":"Returns new tensor square elements input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_square.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Square — torch_square","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_square(a) } #> torch_tensor #>  0.1155 #>  0.0852 #>  6.8488 #>  0.0022 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":null,"dir":"Reference","previous_headings":"","what":"Squeeze — torch_squeeze","title":"Squeeze — torch_squeeze","text":"Squeeze","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Squeeze — torch_squeeze","text":"","code":"torch_squeeze(self, dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Squeeze — torch_squeeze","text":"self (Tensor) input tensor. dim (int, optional) given, input squeezed           dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Squeeze — torch_squeeze","text":"returned tensor shares storage input tensor, changing contents one change contents .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":"squeeze-input-dim-null-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"squeeze(input, dim=NULL, out=NULL) -> Tensor","title":"Squeeze — torch_squeeze","text":"Returns tensor dimensions input size 1 removed. example, input shape: \\((\\times 1 \\times B \\times C \\times 1 \\times D)\\) tensor shape: \\((\\times B \\times C \\times D)\\). dim given, squeeze operation done given dimension. input shape: \\((\\times 1 \\times B)\\), squeeze(input, 0) leaves tensor unchanged, squeeze(input, 1) squeeze tensor shape \\((\\times B)\\).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_squeeze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Squeeze — torch_squeeze","text":"","code":"if (torch_is_installed()) {  x = torch_zeros(c(2, 1, 2, 1, 2)) x y = torch_squeeze(x) y y = torch_squeeze(x, 1) y y = torch_squeeze(x, 2) y } #> torch_tensor #> (1,1,.,.) =  #>   0  0 #>  #> (2,1,.,.) =  #>   0  0 #>  #> (1,2,.,.) =  #>   0  0 #>  #> (2,2,.,.) =  #>   0  0 #> [ CPUFloatType{2,2,1,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Stack — torch_stack","title":"Stack — torch_stack","text":"Stack","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stack — torch_stack","text":"","code":"torch_stack(tensors, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stack — torch_stack","text":"tensors (sequence Tensors) sequence tensors concatenate dim (int) dimension insert. 0 number        dimensions concatenated tensors (inclusive)","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_stack.html","id":"stack-tensors-dim-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"stack(tensors, dim=0, out=NULL) -> Tensor","title":"Stack — torch_stack","text":"Concatenates sequence tensors along new dimension. tensors need size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":null,"dir":"Reference","previous_headings":"","what":"Std — torch_std","title":"Std — torch_std","text":"Std","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Std — torch_std","text":"","code":"torch_std(self, dim, unbiased = TRUE, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Std — torch_std","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. unbiased (bool) whether use unbiased estimation keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":"std-input-unbiased-true-gt-tensor-","dir":"Reference","previous_headings":"","what":"std(input, unbiased=TRUE) -> Tensor","title":"Std — torch_std","text":"Returns standard-deviation elements input tensor. unbiased FALSE, standard-deviation calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":"std-input-dim-unbiased-true-keepdim-false-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"std(input, dim, unbiased=TRUE, keepdim=False, out=NULL) -> Tensor","title":"Std — torch_std","text":"Returns standard-deviation row input tensor dimension dim. dim list dimensions, reduce . keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s). unbiased FALSE, standard-deviation calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Std — torch_std","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_std(a)   a = torch_randn(c(4, 4)) a torch_std(a, dim=1) } #> torch_tensor #>  1.1563 #>  0.3994 #>  0.5251 #>  1.2504 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Std_mean — torch_std_mean","title":"Std_mean — torch_std_mean","text":"Std_mean","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Std_mean — torch_std_mean","text":"","code":"torch_std_mean(self, dim, unbiased = TRUE, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Std_mean — torch_std_mean","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. unbiased (bool) whether use unbiased estimation keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":"std-mean-input-unbiased-true-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"std_mean(input, unbiased=TRUE) -> (Tensor, Tensor)","title":"Std_mean — torch_std_mean","text":"Returns standard-deviation mean elements input tensor. unbiased FALSE, standard-deviation calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":"std-mean-input-dim-unbiased-true-keepdim-false-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"std_mean(input, dim, unbiased=TRUE, keepdim=False) -> (Tensor, Tensor)","title":"Std_mean — torch_std_mean","text":"Returns standard-deviation mean row input tensor dimension dim. dim list dimensions, reduce . keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s). unbiased FALSE, standard-deviation calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_std_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Std_mean — torch_std_mean","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_std_mean(a)   a = torch_randn(c(4, 4)) a torch_std_mean(a, 1) } #> [[1]] #> torch_tensor #>  0.3698 #>  0.3130 #>  0.6728 #>  1.1034 #> [ CPUFloatType{4} ] #>  #> [[2]] #> torch_tensor #> -0.1066 #>  0.0862 #>  0.1781 #>  0.1767 #> [ CPUFloatType{4} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_stft.html","id":null,"dir":"Reference","previous_headings":"","what":"Stft — torch_stft","title":"Stft — torch_stft","text":"Stft","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_stft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stft — torch_stft","text":"","code":"torch_stft(   input,   n_fft,   hop_length = NULL,   win_length = NULL,   window = NULL,   center = TRUE,   pad_mode = \"reflect\",   normalized = FALSE,   onesided = NULL,   return_complex = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_stft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stft — torch_stft","text":"input (Tensor) input tensor n_fft (int) size Fourier transform hop_length (int, optional) distance neighboring sliding window frames. Default: NULL (treated equal floor(n_fft / 4)) win_length (int, optional) size window frame STFT filter. Default: NULL  (treated equal n_fft) window (Tensor, optional) optional window function. Default: NULL (treated window \\(1\\) s) center (bool, optional) whether pad input sides \\(t\\)-th frame centered time \\(t \\times \\mbox{hop\\_length}\\). Default: TRUE pad_mode (string, optional) controls padding method used center TRUE. Default: \"reflect\" normalized (bool, optional) controls whether return normalized STFT results Default: FALSE onesided (bool, optional) controls whether return half results avoid redundancy Default: TRUE return_complex (bool, optional) controls whether return complex tensors .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_stft.html","id":"short-time-fourier-transform-stft-","dir":"Reference","previous_headings":"","what":"Short-time Fourier transform (STFT).","title":"Stft — torch_stft","text":"Short-time Fourier transform (STFT).   $$         X[m, \\omega] = \\sum_{k = 0}^{\\mbox{win\\_length-1}}%                             \\mbox{window}[k]\\ \\mbox{input}[m \\times \\mbox{hop\\_length} + k]\\ %                             \\exp\\left(- j \\frac{2 \\pi \\cdot \\omega k}{\\mbox{win\\_length}}\\right), $$ \\(m\\) index sliding window, \\(\\omega\\) frequency \\(0 \\leq \\omega < \\mbox{n\\_fft}\\). onesided default value TRUE,","code":"Ignoring the optional batch dimension, this method computes the following expression: * `input` must be either a 1-D time sequence or a 2-D batch of time   sequences.  * If `hop_length` is `NULL` (default), it is treated as equal to   `floor(n_fft / 4)`.  * If `win_length` is `NULL` (default), it is treated as equal to   `n_fft`.  * `window` can be a 1-D tensor of size `win_length`, e.g., from   `torch_hann_window`. If `window` is `NULL` (default), it is   treated as if having \\eqn{1} everywhere in the window. If   \\eqn{\\mbox{win\\_length} < \\mbox{n\\_fft}}, `window` will be padded on   both sides to length `n_fft` before being applied.  * If `center` is `TRUE` (default), `input` will be padded on   both sides so that the \\eqn{t}-th frame is centered at time   \\eqn{t \\times \\mbox{hop\\_length}}. Otherwise, the \\eqn{t}-th frame   begins at time  \\eqn{t \\times \\mbox{hop\\_length}}.  * `pad_mode` determines the padding method used on `input` when   `center` is `TRUE`. See `torch_nn.functional.pad` for   all available options. Default is `\"reflect\"`.  * If `onesided` is `TRUE` (default), only values for \\eqn{\\omega}   in \\eqn{\\left[0, 1, 2, \\dots, \\left\\lfloor \\frac{\\mbox{n\\_fft}}{2} \\right\\rfloor + 1\\right]}   are returned because the real-to-complex Fourier transform satisfies the   conjugate symmetry, i.e., \\eqn{X[m, \\omega] = X[m, \\mbox{n\\_fft} - \\omega]^*}.  * If `normalized` is `TRUE` (default is `FALSE`), the function   returns the normalized STFT results, i.e., multiplied by \\eqn{(\\mbox{frame\\_length})^{-0.5}}.  Returns the real and the imaginary parts together as one tensor of size \\eqn{(* \\times N \\times T \\times 2)}, where \\eqn{*} is the optional batch size of `input`, \\eqn{N} is the number of frequencies where STFT is applied, \\eqn{T} is the total number of frames used, and each pair in the last dimension represents a complex number as the real part and the imaginary part."},{"path":"https://torch.mlverse.org/docs/reference/torch_stft.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Stft — torch_stft","text":"function changed signature version 0.4.1. Calling previous signature may cause error return incorrect result.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sub.html","id":null,"dir":"Reference","previous_headings":"","what":"Sub — torch_sub","title":"Sub — torch_sub","text":"Sub","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sub.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sub — torch_sub","text":"","code":"torch_sub(self, other, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sub.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sub — torch_sub","text":"self (Tensor) input tensor. (Tensor Scalar) tensor scalar subtract input alpha scalar multiplier ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sub.html","id":"sub-input-other-alpha-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"sub(input, other, *, alpha=1, out=None) -> Tensor","title":"Sub — torch_sub","text":"Subtracts , scaled alpha, input. $$     \\mbox{{}}_i = \\mbox{{input}}_i - \\mbox{{alpha}} \\times \\mbox{{}}_i $$ Supports broadcasting common shape , type promotion , integer, float, complex inputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sub.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sub — torch_sub","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2)) b <- torch_tensor(c(0, 1)) torch_sub(a, b, alpha=2) } #> torch_tensor #>  1 #>  0 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_subtract.html","id":null,"dir":"Reference","previous_headings":"","what":"Subtract — torch_subtract","title":"Subtract — torch_subtract","text":"Subtract","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_subtract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Subtract — torch_subtract","text":"","code":"torch_subtract(self, other, alpha = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_subtract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Subtract — torch_subtract","text":"self (Tensor) input tensor. (Tensor Scalar) tensor scalar subtract input alpha scalar multiplier ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_subtract.html","id":"subtract-input-other-alpha-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"subtract(input, other, *, alpha=1, out=None) -> Tensor","title":"Subtract — torch_subtract","text":"Alias torch_sub().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"Sum — torch_sum","title":"Sum — torch_sum","text":"Sum","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sum — torch_sum","text":"","code":"torch_sum(self, dim, keepdim = FALSE, dtype = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sum — torch_sum","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. keepdim (bool) whether output tensor dim retained . dtype (torch.dtype, optional) desired data type returned tensor.        specified, input tensor casted dtype operation        performed. useful preventing data type overflows. Default: NULL.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":"sum-input-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sum(input, dtype=NULL) -> Tensor","title":"Sum — torch_sum","text":"Returns sum elements input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":"sum-input-dim-keepdim-false-dtype-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"sum(input, dim, keepdim=False, dtype=NULL) -> Tensor","title":"Sum — torch_sum","text":"Returns sum row input tensor given dimension dim. dim list dimensions, reduce . keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_sum.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sum — torch_sum","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_sum(a)   a <- torch_randn(c(4, 4)) a torch_sum(a, 1) b <- torch_arange(1, 4 * 5 * 6)$view(c(4, 5, 6)) torch_sum(b, list(2, 1)) } #> torch_tensor #>  1160 #>  1180 #>  1200 #>  1220 #>  1240 #>  1260 #> [ CPUFloatType{6} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Svd — torch_svd","title":"Svd — torch_svd","text":"Svd","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Svd — torch_svd","text":"","code":"torch_svd(self, some = TRUE, compute_uv = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Svd — torch_svd","text":"self (Tensor) input tensor size \\((*, m, n)\\) * zero                    batch dimensions consisting \\(m \\times n\\) matrices. (bool, optional) controls shape returned U V compute_uv (bool, optional) option whether compute U V ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Svd — torch_svd","text":"singular values returned descending order. input batch matrices, singular values matrix batch returned descending order. implementation SVD CPU uses LAPACK routine ?gesdd (divide--conquer algorithm) instead ?gesvd speed. Analogously, SVD GPU uses MAGMA routine gesdd well. Irrespective original strides, returned matrix U transposed, .e. strides U.contiguous().transpose(-2, -1).stride() Extra care needs taken backward U V outputs. operation really stable input full rank distinct singular values. Otherwise, NaN can appear gradients properly defined. Also, notice double backward usually additional backward U V even original backward S. = FALSE, gradients U[..., :, min(m, n):] V[..., :, min(m, n):] ignored backward vectors can arbitrary bases subspaces. compute_uv = FALSE, backward performed since U V forward pass required backward operation.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":"svd-input-some-true-compute-uv-true-gt-tensor-tensor-tensor-","dir":"Reference","previous_headings":"","what":"svd(input, some=TRUE, compute_uv=TRUE) -> (Tensor, Tensor, Tensor)","title":"Svd — torch_svd","text":"function returns namedtuple (U, S, V) singular value decomposition input real matrix batches real matrices input \\(input = U \\times diag(S) \\times V^T\\). TRUE (default), method returns reduced singular value decomposition .e., last two dimensions input m n, returned U V matrices contain \\(min(n, m)\\) orthonormal columns. compute_uv FALSE, returned U V matrices zero matrices shape \\((m \\times m)\\) \\((n \\times n)\\) respectively. ignored .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_svd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Svd — torch_svd","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(5, 3)) a out = torch_svd(a) u = out[[1]] s = out[[2]] v = out[[3]] torch_dist(a, torch_mm(torch_mm(u, torch_diag(s)), v$t())) a_big = torch_randn(c(7, 5, 3)) out = torch_svd(a_big) u = out[[1]] s = out[[2]] v = out[[3]] torch_dist(a_big, torch_matmul(torch_matmul(u, torch_diag_embed(s)), v$transpose(-2, -1))) } #> torch_tensor #> 2.91169e-06 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_t.html","id":null,"dir":"Reference","previous_headings":"","what":"T — torch_t","title":"T — torch_t","text":"T","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"T — torch_t","text":"","code":"torch_t(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"T — torch_t","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_t.html","id":"t-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"t(input) -> Tensor","title":"T — torch_t","text":"Expects input <= 2-D tensor transposes dimensions 0 1. 0-D 1-D tensors returned . input 2-D tensor equivalent transpose(input, 0, 1).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_t.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"T — torch_t","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(2,3)) x torch_t(x) x = torch_randn(c(3)) x torch_t(x) x = torch_randn(c(2, 3)) x torch_t(x) } #> torch_tensor #> -0.8600  0.5891 #> -0.0482 -1.9269 #>  1.6084  0.3332 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_take.html","id":null,"dir":"Reference","previous_headings":"","what":"Take — torch_take","title":"Take — torch_take","text":"Take","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_take.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take — torch_take","text":"","code":"torch_take(self, index)"},{"path":"https://torch.mlverse.org/docs/reference/torch_take.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Take — torch_take","text":"self (Tensor) input tensor. index (LongTensor) indices tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_take.html","id":"take-input-index-gt-tensor-","dir":"Reference","previous_headings":"","what":"take(input, index) -> Tensor","title":"Take — torch_take","text":"Returns new tensor elements input given indices. input tensor treated viewed 1-D tensor. result takes shape indices.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_take.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Take — torch_take","text":"","code":"if (torch_is_installed()) {  src = torch_tensor(matrix(c(4,3,5,6,7,8), ncol = 3, byrow = TRUE)) torch_take(src, torch_tensor(c(1, 2, 5), dtype = torch_int64())) } #> torch_tensor #>  4 #>  3 #>  7 #> [ CPUFloatType{3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_tan.html","id":null,"dir":"Reference","previous_headings":"","what":"Tan — torch_tan","title":"Tan — torch_tan","text":"Tan","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tan.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tan — torch_tan","text":"","code":"torch_tan(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_tan.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tan — torch_tan","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tan.html","id":"tan-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"tan(input, out=NULL) -> Tensor","title":"Tan — torch_tan","text":"Returns new tensor tangent elements input. $$     \\mbox{}_{} = \\tan(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tan.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tan — torch_tan","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_tan(a) } #> torch_tensor #>  0.6133 #>  0.6518 #>  0.1024 #>  0.6123 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_tanh.html","id":null,"dir":"Reference","previous_headings":"","what":"Tanh — torch_tanh","title":"Tanh — torch_tanh","text":"Tanh","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tanh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tanh — torch_tanh","text":"","code":"torch_tanh(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_tanh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tanh — torch_tanh","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tanh.html","id":"tanh-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"tanh(input, out=NULL) -> Tensor","title":"Tanh — torch_tanh","text":"Returns new tensor hyperbolic tangent elements input. $$     \\mbox{}_{} = \\tanh(\\mbox{input}_{}) $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tanh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tanh — torch_tanh","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_tanh(a) } #> torch_tensor #> -0.2279 #>  0.1029 #>  0.8538 #>  0.8189 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts R objects to a torch tensor — torch_tensor","title":"Converts R objects to a torch tensor — torch_tensor","text":"Converts R objects torch tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts R objects to a torch tensor — torch_tensor","text":"","code":"torch_tensor(   data,   dtype = NULL,   device = NULL,   requires_grad = FALSE,   pin_memory = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts R objects to a torch tensor — torch_tensor","text":"data R atomic vector, matrix array dtype torch_dtype instance device device creted torch_device() requires_grad autograd record operations returned tensor. pin_memory set, returned tensor allocated pinned memory.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts R objects to a torch tensor — torch_tensor","text":"","code":"if (torch_is_installed()) { torch_tensor(c(1, 2, 3, 4)) torch_tensor(c(1, 2, 3, 4), dtype = torch_int()) } #> torch_tensor #>  1 #>  2 #>  3 #>  4 #> [ CPUIntType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor_from_buffer.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a tensor from a buffer of memory — torch_tensor_from_buffer","title":"Creates a tensor from a buffer of memory — torch_tensor_from_buffer","text":"creates tensor without taking ownership memory points . must call clone want copy memory new tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor_from_buffer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a tensor from a buffer of memory — torch_tensor_from_buffer","text":"","code":"torch_tensor_from_buffer(buffer, shape, dtype = \"float\")  buffer_from_torch_tensor(tensor)"},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor_from_buffer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a tensor from a buffer of memory — torch_tensor_from_buffer","text":"buffer R atomic object containing data contiguous array. shape shape resulting tensor. dtype torch data type tresulting tensor. tensor Tensor object converted buffer.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensor_from_buffer.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Creates a tensor from a buffer of memory — torch_tensor_from_buffer","text":"buffer_from_torch_tensor(): Creates raw vector containing tensor data. Causes data copy.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensordot.html","id":null,"dir":"Reference","previous_headings":"","what":"Tensordot — torch_tensordot","title":"Tensordot — torch_tensordot","text":"Returns contraction b multiple dimensions. tensordot implements generalized matrix product.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensordot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tensordot — torch_tensordot","text":"","code":"torch_tensordot(a, b, dims = 2)"},{"path":"https://torch.mlverse.org/docs/reference/torch_tensordot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tensordot — torch_tensordot","text":"(Tensor) Left tensor contract b (Tensor) Right tensor contract dims (int tuple two lists integers) number dimensions     contract explicit lists dimensions     b respectively","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tensordot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tensordot — torch_tensordot","text":"","code":"if (torch_is_installed()) {  a <- torch_arange(start = 1, end = 60)$reshape(c(3, 4, 5)) b <- torch_arange(start = 1, end = 24)$reshape(c(4, 3, 2)) torch_tensordot(a, b, dims = list(c(2, 1), c(1, 2))) if (FALSE) { a = torch_randn(3, 4, 5, device='cuda') b = torch_randn(4, 5, 6, device='cuda') c = torch_tensordot(a, b, dims=2)$cpu() } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_threshold_.html","id":null,"dir":"Reference","previous_headings":"","what":"Threshold_ — torch_threshold_","title":"Threshold_ — torch_threshold_","text":"Threshold_","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_threshold_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Threshold_ — torch_threshold_","text":"","code":"torch_threshold_(self, threshold, value)"},{"path":"https://torch.mlverse.org/docs/reference/torch_threshold_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Threshold_ — torch_threshold_","text":"self input tensor threshold value threshold value value replace ","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_threshold_.html","id":"threshold-input-threshold-value-gt-tensor-","dir":"Reference","previous_headings":"","what":"threshold_(input, threshold, value) -> Tensor","title":"Threshold_ — torch_threshold_","text":"-place version torch_threshold.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_topk.html","id":null,"dir":"Reference","previous_headings":"","what":"Topk — torch_topk","title":"Topk — torch_topk","text":"Topk","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_topk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Topk — torch_topk","text":"","code":"torch_topk(self, k, dim = -1L, largest = TRUE, sorted = TRUE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_topk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Topk — torch_topk","text":"self (Tensor) input tensor. k (int) k \"top-k\" dim (int, optional) dimension sort along largest (bool, optional) controls whether return largest           smallest elements sorted (bool, optional) controls whether return elements           sorted order","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_topk.html","id":"topk-input-k-dim-null-largest-true-sorted-true-gt-tensor-longtensor-","dir":"Reference","previous_headings":"","what":"topk(input, k, dim=NULL, largest=TRUE, sorted=TRUE) -> (Tensor, LongTensor)","title":"Topk — torch_topk","text":"Returns k largest elements given input tensor along given dimension. dim given, last dimension input chosen. largest FALSE k smallest elements returned. namedtuple (values, indices) returned, indices indices elements original input tensor. boolean option sorted TRUE, make sure returned k elements sorted","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_topk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Topk — torch_topk","text":"","code":"if (torch_is_installed()) {  x = torch_arange(1., 6.) x torch_topk(x, 3) } #> [[1]] #> torch_tensor #>  6 #>  5 #>  4 #> [ CPUFloatType{3} ] #>  #> [[2]] #> torch_tensor #>  6 #>  5 #>  4 #> [ CPULongType{3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Trace — torch_trace","title":"Trace — torch_trace","text":"Trace","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trace — torch_trace","text":"","code":"torch_trace(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trace — torch_trace","text":"self input tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trace.html","id":"trace-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"trace(input) -> Tensor","title":"Trace — torch_trace","text":"Returns sum elements diagonal input 2-D matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trace — torch_trace","text":"","code":"if (torch_is_installed()) {  x <- torch_arange(1, 9)$view(c(3, 3)) x torch_trace(x) } #> torch_tensor #> 15 #> [ CPUFloatType{} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_transpose.html","id":null,"dir":"Reference","previous_headings":"","what":"Transpose — torch_transpose","title":"Transpose — torch_transpose","text":"Transpose","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_transpose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transpose — torch_transpose","text":"","code":"torch_transpose(self, dim0, dim1)"},{"path":"https://torch.mlverse.org/docs/reference/torch_transpose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transpose — torch_transpose","text":"self (Tensor) input tensor. dim0 (int) first dimension transposed dim1 (int) second dimension transposed","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_transpose.html","id":"transpose-input-dim-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"transpose(input, dim0, dim1) -> Tensor","title":"Transpose — torch_transpose","text":"Returns tensor transposed version input. given dimensions dim0 dim1 swapped. resulting tensor shares underlying storage input tensor, changing content one change content .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_transpose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transpose — torch_transpose","text":"","code":"if (torch_is_installed()) {  x = torch_randn(c(2, 3)) x torch_transpose(x, 1, 2) } #> torch_tensor #> -1.2440 -0.3130 #>  0.0556  0.1887 #>  0.2138 -1.4054 #> [ CPUFloatType{3,2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":null,"dir":"Reference","previous_headings":"","what":"Trapz — torch_trapz","title":"Trapz — torch_trapz","text":"Trapz","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trapz — torch_trapz","text":"","code":"torch_trapz(y, dx = 1L, x, dim = -1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trapz — torch_trapz","text":"y (Tensor) values function integrate dx (float) distance points y sampled. x (Tensor) points function y sampled.        x ascending order, intervals decreasing        contribute negatively estimated integral (.e., convention        \\(\\int_a^b f = -\\int_b^f\\) followed). dim (int) dimension along integrate.        default, use last dimension.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":"trapz-y-x-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"trapz(y, x, *, dim=-1) -> Tensor","title":"Trapz — torch_trapz","text":"Estimate \\(\\int y\\,dx\\) along dim, using trapezoid rule.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":"trapz-y-dx-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"trapz(y, *, dx=1, dim=-1) -> Tensor","title":"Trapz — torch_trapz","text":", sample points spaced uniformly distance dx.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trapz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trapz — torch_trapz","text":"","code":"if (torch_is_installed()) {  y = torch_randn(list(2, 3)) y x = torch_tensor(matrix(c(1, 3, 4, 1, 2, 3), ncol = 3, byrow=TRUE)) torch_trapz(y, x = x)  } #> torch_tensor #> -3.0178 #> -0.8236 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_triangular_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"Triangular_solve — torch_triangular_solve","title":"Triangular_solve — torch_triangular_solve","text":"Triangular_solve","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triangular_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triangular_solve — torch_triangular_solve","text":"","code":"torch_triangular_solve(   self,   A,   upper = TRUE,   transpose = FALSE,   unitriangular = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_triangular_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triangular_solve — torch_triangular_solve","text":"self (Tensor) multiple right-hand sides size \\((*, m, k)\\)                \\(*\\) zero batch dimensions (\\(b\\)) (Tensor) input triangular coefficient matrix size \\((*, m, m)\\)                \\(*\\) zero batch dimensions upper (bool, optional) whether solve upper-triangular system        equations (default) lower-triangular system equations. Default: TRUE. transpose (bool, optional) whether \\(\\) transposed        sent solver. Default: FALSE. unitriangular (bool, optional) whether \\(\\) unit triangular.        TRUE, diagonal elements \\(\\) assumed        1 referenced \\(\\). Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triangular_solve.html","id":"triangular-solve-input-a-upper-true-transpose-false-unitriangular-false-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"triangular_solve(input, A, upper=TRUE, transpose=False, unitriangular=False) -> (Tensor, Tensor)","title":"Triangular_solve — torch_triangular_solve","text":"Solves system equations triangular coefficient matrix \\(\\) multiple right-hand sides \\(b\\). particular, solves \\(AX = b\\) assumes \\(\\) upper-triangular default keyword arguments. torch_triangular_solve(b, ) can take 2D inputs b, inputs batches 2D matrices. inputs batches, returns batched outputs X","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triangular_solve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triangular_solve — torch_triangular_solve","text":"","code":"if (torch_is_installed()) {  A = torch_randn(c(2, 2))$triu() A b = torch_randn(c(2, 3)) b torch_triangular_solve(b, A) } #> [[1]] #> torch_tensor #> -2.0220 -2.1697  0.2369 #>  0.5612 -0.8687  0.3310 #> [ CPUFloatType{2,3} ] #>  #> [[2]] #> torch_tensor #>  0.5262  0.6967 #>  0.0000  0.7233 #> [ CPUFloatType{2,2} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_tril.html","id":null,"dir":"Reference","previous_headings":"","what":"Tril — torch_tril","title":"Tril — torch_tril","text":"Tril","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tril — torch_tril","text":"","code":"torch_tril(self, diagonal = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_tril.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tril — torch_tril","text":"self (Tensor) input tensor. diagonal (int, optional) diagonal consider","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril.html","id":"tril-input-diagonal-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"tril(input, diagonal=0, out=NULL) -> Tensor","title":"Tril — torch_tril","text":"Returns lower triangular part matrix (2-D tensor) batch matrices input, elements result tensor set 0. lower triangular part matrix defined elements diagonal. argument diagonal controls diagonal consider. diagonal = 0, elements main diagonal retained. positive value includes just many diagonals main diagonal, similarly negative value excludes just many diagonals main diagonal. main diagonal set indices \\(\\lbrace (, ) \\rbrace\\) \\(\\[0, \\min\\{d_{1}, d_{2}\\} - 1]\\) \\(d_{1}, d_{2}\\) dimensions matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tril — torch_tril","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) a torch_tril(a) b = torch_randn(c(4, 6)) b torch_tril(b, diagonal=1) torch_tril(b, diagonal=-1) } #> torch_tensor #>  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000 #>  1.8172  0.0000  0.0000  0.0000  0.0000  0.0000 #> -0.2900 -0.3578  0.0000  0.0000  0.0000  0.0000 #>  0.8494 -0.3954  0.7822  0.0000  0.0000  0.0000 #> [ CPUFloatType{4,6} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Tril_indices — torch_tril_indices","title":"Tril_indices — torch_tril_indices","text":"Tril_indices","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tril_indices — torch_tril_indices","text":"","code":"torch_tril_indices(   row,   col,   offset = 0,   dtype = NULL,   device = NULL,   layout = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tril_indices — torch_tril_indices","text":"row (int) number rows 2-D matrix. col (int) number columns 2-D matrix. offset (int) diagonal offset main diagonal.        Default: provided, 0. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, torch_long. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. layout (torch.layout, optional) currently support torch_strided.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Tril_indices — torch_tril_indices","text":"","code":"When running on CUDA, `row * col` must be less than \\eqn{2^{59}} to prevent overflow during calculation."},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":"tril-indices-row-col-offset-dtype-torch-long-device-cpu-layout-torch-strided-gt-tensor-","dir":"Reference","previous_headings":"","what":"tril_indices(row, col, offset=0, dtype=torch.long, device='cpu', layout=torch.strided) -> Tensor","title":"Tril_indices — torch_tril_indices","text":"Returns indices lower triangular part row-- col matrix 2--N Tensor, first row contains row coordinates indices second row contains column coordinates. Indices ordered based rows columns. lower triangular part matrix defined elements diagonal. argument offset controls diagonal consider. offset = 0, elements main diagonal retained. positive value includes just many diagonals main diagonal, similarly negative value excludes just many diagonals main diagonal. main diagonal set indices \\(\\lbrace (, ) \\rbrace\\) \\(\\[0, \\min\\{d_{1}, d_{2}\\} - 1]\\) \\(d_{1}, d_{2}\\) dimensions matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_tril_indices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tril_indices — torch_tril_indices","text":"","code":"if (torch_is_installed()) { if (FALSE) { a = torch_tril_indices(3, 3) a a = torch_tril_indices(4, 3, -1) a a = torch_tril_indices(4, 3, 1) a } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_triu.html","id":null,"dir":"Reference","previous_headings":"","what":"Triu — torch_triu","title":"Triu — torch_triu","text":"Triu","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triu — torch_triu","text":"","code":"torch_triu(self, diagonal = 0L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_triu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triu — torch_triu","text":"self (Tensor) input tensor. diagonal (int, optional) diagonal consider","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu.html","id":"triu-input-diagonal-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"triu(input, diagonal=0, out=NULL) -> Tensor","title":"Triu — torch_triu","text":"Returns upper triangular part matrix (2-D tensor) batch matrices input, elements result tensor set 0. upper triangular part matrix defined elements diagonal. argument diagonal controls diagonal consider. diagonal = 0, elements main diagonal retained. positive value excludes just many diagonals main diagonal, similarly negative value includes just many diagonals main diagonal. main diagonal set indices \\(\\lbrace (, ) \\rbrace\\) \\(\\[0, \\min\\{d_{1}, d_{2}\\} - 1]\\) \\(d_{1}, d_{2}\\) dimensions matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triu — torch_triu","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(3, 3)) a torch_triu(a) torch_triu(a, diagonal=1) torch_triu(a, diagonal=-1) b = torch_randn(c(4, 6)) b torch_triu(b, diagonal=1) torch_triu(b, diagonal=-1) } #> torch_tensor #> -0.4660 -0.2273 -0.6166 -1.9900 -0.7221 -0.9500 #>  1.1051 -0.7226 -0.2677  0.6145 -2.1794  0.7118 #>  0.0000 -0.8139  1.0528 -0.1026  1.3411 -0.7295 #>  0.0000  0.0000  0.2327 -0.4739 -0.6007 -0.3636 #> [ CPUFloatType{4,6} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Triu_indices — torch_triu_indices","title":"Triu_indices — torch_triu_indices","text":"Triu_indices","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triu_indices — torch_triu_indices","text":"","code":"torch_triu_indices(   row,   col,   offset = 0,   dtype = NULL,   device = NULL,   layout = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Triu_indices — torch_triu_indices","text":"row (int) number rows 2-D matrix. col (int) number columns 2-D matrix. offset (int) diagonal offset main diagonal.        Default: provided, 0. dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, torch_long. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. layout (torch.layout, optional) currently support torch_strided.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Triu_indices — torch_triu_indices","text":"","code":"When running on CUDA, `row * col` must be less than \\eqn{2^{59}} to prevent overflow during calculation."},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":"triu-indices-row-col-offset-dtype-torch-long-device-cpu-layout-torch-strided-gt-tensor-","dir":"Reference","previous_headings":"","what":"triu_indices(row, col, offset=0, dtype=torch.long, device='cpu', layout=torch.strided) -> Tensor","title":"Triu_indices — torch_triu_indices","text":"Returns indices upper triangular part row col matrix 2--N Tensor, first row contains row coordinates indices second row contains column coordinates. Indices ordered based rows columns. upper triangular part matrix defined elements diagonal. argument offset controls diagonal consider. offset = 0, elements main diagonal retained. positive value excludes just many diagonals main diagonal, similarly negative value includes just many diagonals main diagonal. main diagonal set indices \\(\\lbrace (, ) \\rbrace\\) \\(\\[0, \\min\\{d_{1}, d_{2}\\} - 1]\\) \\(d_{1}, d_{2}\\) dimensions matrix.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_triu_indices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Triu_indices — torch_triu_indices","text":"","code":"if (torch_is_installed()) { if (FALSE) { a = torch_triu_indices(3, 3) a a = torch_triu_indices(4, 3, -1) a a = torch_triu_indices(4, 3, 1) a } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_true_divide.html","id":null,"dir":"Reference","previous_headings":"","what":"TRUE_divide — torch_true_divide","title":"TRUE_divide — torch_true_divide","text":"TRUE_divide","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_true_divide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"TRUE_divide — torch_true_divide","text":"","code":"torch_true_divide(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_true_divide.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"TRUE_divide — torch_true_divide","text":"self (Tensor) dividend (Tensor Scalar) divisor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_true_divide.html","id":"true-divide-dividend-divisor-gt-tensor-","dir":"Reference","previous_headings":"","what":"true_divide(dividend, divisor) -> Tensor","title":"TRUE_divide — torch_true_divide","text":"Performs \"true division\" always computes division floating point. Analogous division Python 3 equivalent torch_div except inputs bool integer scalar types, case cast default (floating) scalar type division. $$     \\mbox{}_i = \\frac{\\mbox{dividend}_i}{\\mbox{divisor}} $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_true_divide.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"TRUE_divide — torch_true_divide","text":"","code":"if (torch_is_installed()) {  dividend = torch_tensor(c(5, 3), dtype=torch_int()) divisor = torch_tensor(c(3, 2), dtype=torch_int()) torch_true_divide(dividend, divisor) torch_true_divide(dividend, 2) } #> torch_tensor #>  2.5000 #>  1.5000 #> [ CPUFloatType{2} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_trunc.html","id":null,"dir":"Reference","previous_headings":"","what":"Trunc — torch_trunc","title":"Trunc — torch_trunc","text":"Trunc","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trunc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trunc — torch_trunc","text":"","code":"torch_trunc(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_trunc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trunc — torch_trunc","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trunc.html","id":"trunc-input-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"trunc(input, out=NULL) -> Tensor","title":"Trunc — torch_trunc","text":"Returns new tensor truncated integer values elements input.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_trunc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trunc — torch_trunc","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(4)) a torch_trunc(a) } #> torch_tensor #> -0 #> -0 #>  0 #>  0 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_unbind.html","id":null,"dir":"Reference","previous_headings":"","what":"Unbind — torch_unbind","title":"Unbind — torch_unbind","text":"Unbind","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unbind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unbind — torch_unbind","text":"","code":"torch_unbind(self, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_unbind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unbind — torch_unbind","text":"self (Tensor) tensor unbind dim (int) dimension remove","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unbind.html","id":"unbind-input-dim-gt-seq-","dir":"Reference","previous_headings":"","what":"unbind(input, dim=0) -> seq","title":"Unbind — torch_unbind","text":"Removes tensor dimension. Returns tuple slices along given dimension, already without .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unbind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unbind — torch_unbind","text":"","code":"if (torch_is_installed()) {  torch_unbind(torch_tensor(matrix(1:9, ncol = 3, byrow=TRUE))) } #> [[1]] #> torch_tensor #>  1 #>  2 #>  3 #> [ CPULongType{3} ] #>  #> [[2]] #> torch_tensor #>  4 #>  5 #>  6 #> [ CPULongType{3} ] #>  #> [[3]] #> torch_tensor #>  7 #>  8 #>  9 #> [ CPULongType{3} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_unique_consecutive.html","id":null,"dir":"Reference","previous_headings":"","what":"Unique_consecutive — torch_unique_consecutive","title":"Unique_consecutive — torch_unique_consecutive","text":"Unique_consecutive","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unique_consecutive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unique_consecutive — torch_unique_consecutive","text":"","code":"torch_unique_consecutive(   self,   return_inverse = FALSE,   return_counts = FALSE,   dim = NULL )"},{"path":"https://torch.mlverse.org/docs/reference/torch_unique_consecutive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unique_consecutive — torch_unique_consecutive","text":"self (Tensor) input tensor return_inverse (bool) Whether also return indices        elements original input ended returned unique list. return_counts (bool) Whether also return counts unique        element. dim (int) dimension apply unique. NULL, unique        flattened input returned. default: NULL","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unique_consecutive.html","id":"test-","dir":"Reference","previous_headings":"","what":"TEST","title":"Unique_consecutive — torch_unique_consecutive","text":"Eliminates first element every consecutive group equivalent elements.","code":".. note:: This function is different from [`torch_unique`] in the sense that this function     only eliminates consecutive duplicate values. This semantics is similar to `std::unique`     in C++."},{"path":"https://torch.mlverse.org/docs/reference/torch_unique_consecutive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unique_consecutive — torch_unique_consecutive","text":"","code":"if (torch_is_installed()) { x = torch_tensor(c(1, 1, 2, 2, 3, 1, 1, 2)) output = torch_unique_consecutive(x) output torch_unique_consecutive(x, return_inverse=TRUE) torch_unique_consecutive(x, return_counts=TRUE) } #> [[1]] #> torch_tensor #>  1 #>  2 #>  3 #>  1 #>  2 #> [ CPUFloatType{5} ] #>  #> [[2]] #> torch_tensor #> [ CPULongType{0} ] #>  #> [[3]] #> torch_tensor #>  2 #>  2 #>  1 #>  2 #>  1 #> [ CPULongType{5} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_chunk.html","id":null,"dir":"Reference","previous_headings":"","what":"Unsafe_chunk — torch_unsafe_chunk","title":"Unsafe_chunk — torch_unsafe_chunk","text":"Unsafe_chunk","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_chunk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unsafe_chunk — torch_unsafe_chunk","text":"","code":"torch_unsafe_chunk(self, chunks, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_chunk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unsafe_chunk — torch_unsafe_chunk","text":"self (Tensor) tensor split chunks (int) number chunks return dim (int) dimension along split tensor","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_chunk.html","id":"unsafe-chunk-input-chunks-dim-gt-list-of-tensors-","dir":"Reference","previous_headings":"","what":"unsafe_chunk(input, chunks, dim=0) -> List of Tensors","title":"Unsafe_chunk — torch_unsafe_chunk","text":"Works like torch_chunk() without enforcing autograd restrictions inplace modification outputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_chunk.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Unsafe_chunk — torch_unsafe_chunk","text":"function safe use long input, outputs modified inplace calling function. user's responsibility ensure case. input one outputs modified inplace, gradients computed autograd silently incorrect.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Unsafe_split — torch_unsafe_split","title":"Unsafe_split — torch_unsafe_split","text":"Unsafe_split","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unsafe_split — torch_unsafe_split","text":"","code":"torch_unsafe_split(self, split_size, dim = 1L)"},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unsafe_split — torch_unsafe_split","text":"self (Tensor) tensor split. split_size (int) size single chunk list sizes chunk dim (int) dimension along split tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_split.html","id":"unsafe-split-tensor-split-size-or-sections-dim-gt-list-of-tensors-","dir":"Reference","previous_headings":"","what":"unsafe_split(tensor, split_size_or_sections, dim=0) -> List of Tensors","title":"Unsafe_split — torch_unsafe_split","text":"Works like torch_split() without enforcing autograd restrictions inplace modification outputs.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsafe_split.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Unsafe_split — torch_unsafe_split","text":"function safe use long input, outputs modified inplace calling function. user's responsibility ensure case. input one outputs modified inplace, gradients computed autograd silently incorrect.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsqueeze.html","id":null,"dir":"Reference","previous_headings":"","what":"Unsqueeze — torch_unsqueeze","title":"Unsqueeze — torch_unsqueeze","text":"Unsqueeze","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsqueeze.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unsqueeze — torch_unsqueeze","text":"","code":"torch_unsqueeze(self, dim)"},{"path":"https://torch.mlverse.org/docs/reference/torch_unsqueeze.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unsqueeze — torch_unsqueeze","text":"self (Tensor) input tensor. dim (int) index insert singleton dimension","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsqueeze.html","id":"unsqueeze-input-dim-gt-tensor-","dir":"Reference","previous_headings":"","what":"unsqueeze(input, dim) -> Tensor","title":"Unsqueeze — torch_unsqueeze","text":"Returns new tensor dimension size one inserted specified position. returned tensor shares underlying data tensor. dim value within range [-input.dim() - 1, input.dim() + 1) can used. Negative dim correspond unsqueeze applied dim = dim + input.dim() + 1.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_unsqueeze.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unsqueeze — torch_unsqueeze","text":"","code":"if (torch_is_installed()) {  x = torch_tensor(c(1, 2, 3, 4)) torch_unsqueeze(x, 1) torch_unsqueeze(x, 2) } #> torch_tensor #>  1 #>  2 #>  3 #>  4 #> [ CPUFloatType{4,1} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_vander.html","id":null,"dir":"Reference","previous_headings":"","what":"Vander — torch_vander","title":"Vander — torch_vander","text":"Vander","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vander.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vander — torch_vander","text":"","code":"torch_vander(x, N = NULL, increasing = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_vander.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vander — torch_vander","text":"x (Tensor) 1-D input tensor. N (int, optional) Number columns output. N specified, square array returned \\((N = len(x))\\). increasing (bool, optional) Order powers columns. TRUE, powers increase left right, FALSE (default) reversed.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vander.html","id":"vander-x-n-none-increasing-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"vander(x, N=None, increasing=FALSE) -> Tensor","title":"Vander — torch_vander","text":"Generates Vandermonde matrix. columns output matrix elementwise powers input vector \\(x^{(N-1)}, x^{(N-2)}, ..., x^0\\). increasing TRUE, order columns reversed \\(x^0, x^1, ..., x^{(N-1)}\\). matrix geometric progression row named Alexandre-Theophile Vandermonde.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vander.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vander — torch_vander","text":"","code":"if (torch_is_installed()) {  x <- torch_tensor(c(1, 2, 3, 5)) torch_vander(x) torch_vander(x, N=3) torch_vander(x, N=3, increasing=TRUE) } #> torch_tensor #>   1   1   1 #>   1   2   4 #>   1   3   9 #>   1   5  25 #> [ CPUFloatType{4,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":null,"dir":"Reference","previous_headings":"","what":"Var — torch_var","title":"Var — torch_var","text":"Var","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Var — torch_var","text":"","code":"torch_var(self, dim, unbiased = TRUE, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Var — torch_var","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. unbiased (bool) whether use unbiased estimation keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":"var-input-unbiased-true-gt-tensor-","dir":"Reference","previous_headings":"","what":"var(input, unbiased=TRUE) -> Tensor","title":"Var — torch_var","text":"Returns variance elements input tensor. unbiased FALSE, variance calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":"var-input-dim-keepdim-false-unbiased-true-out-null-gt-tensor-","dir":"Reference","previous_headings":"","what":"var(input, dim, keepdim=False, unbiased=TRUE, out=NULL) -> Tensor","title":"Var — torch_var","text":"Returns variance row input tensor given dimension dim. keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s). unbiased FALSE, variance calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Var — torch_var","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_var(a)   a = torch_randn(c(4, 4)) a torch_var(a, 1) } #> torch_tensor #>  0.1741 #>  0.8066 #>  0.8044 #>  0.2940 #> [ CPUFloatType{4} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Var_mean — torch_var_mean","title":"Var_mean — torch_var_mean","text":"Var_mean","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Var_mean — torch_var_mean","text":"","code":"torch_var_mean(self, dim, unbiased = TRUE, keepdim = FALSE)"},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Var_mean — torch_var_mean","text":"self (Tensor) input tensor. dim (int tuple ints) dimension dimensions reduce. unbiased (bool) whether use unbiased estimation keepdim (bool) whether output tensor dim retained .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":"var-mean-input-unbiased-true-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"var_mean(input, unbiased=TRUE) -> (Tensor, Tensor)","title":"Var_mean — torch_var_mean","text":"Returns variance mean elements input tensor. unbiased FALSE, variance calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":"var-mean-input-dim-keepdim-false-unbiased-true-gt-tensor-tensor-","dir":"Reference","previous_headings":"","what":"var_mean(input, dim, keepdim=False, unbiased=TRUE) -> (Tensor, Tensor)","title":"Var_mean — torch_var_mean","text":"Returns variance mean row input tensor given dimension dim. keepdim TRUE, output tensor size input except dimension(s) dim size 1. Otherwise, dim squeezed (see torch_squeeze), resulting output tensor 1 (len(dim)) fewer dimension(s). unbiased FALSE, variance calculated via biased estimator. Otherwise, Bessel's correction used.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_var_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Var_mean — torch_var_mean","text":"","code":"if (torch_is_installed()) {  a = torch_randn(c(1, 3)) a torch_var_mean(a)   a = torch_randn(c(4, 4)) a torch_var_mean(a, 1) } #> [[1]] #> torch_tensor #>  0.2780 #>  1.6386 #>  0.5056 #>  1.7292 #> [ CPUFloatType{4} ] #>  #> [[2]] #> torch_tensor #>  0.0747 #> -0.1032 #> -0.7452 #>  0.3950 #> [ CPUFloatType{4} ] #>"},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":null,"dir":"Reference","previous_headings":"","what":"Vdot — torch_vdot","title":"Vdot — torch_vdot","text":"Vdot","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vdot — torch_vdot","text":"","code":"torch_vdot(self, other)"},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vdot — torch_vdot","text":"self (Tensor) first tensor dot product. conjugate used complex. (Tensor) second tensor dot product.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Vdot — torch_vdot","text":"function broadcast .","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":"vdot-input-other-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"vdot(input, other, *, out=None) -> Tensor","title":"Vdot — torch_vdot","text":"Computes dot product (inner product) two tensors. vdot(, b) function handles complex numbers differently dot(, b). first argument complex, complex conjugate first argument used calculation dot product.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vdot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vdot — torch_vdot","text":"","code":"if (torch_is_installed()) {  torch_vdot(torch_tensor(c(2, 3)), torch_tensor(c(2, 1))) if (FALSE) { a <- torch_tensor(list(1 +2i, 3 - 1i)) b <- torch_tensor(list(2 +1i, 4 - 0i)) torch_vdot(a, b) torch_vdot(b, a) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":null,"dir":"Reference","previous_headings":"","what":"View_as_complex — torch_view_as_complex","title":"View_as_complex — torch_view_as_complex","text":"View_as_complex","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View_as_complex — torch_view_as_complex","text":"","code":"torch_view_as_complex(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View_as_complex — torch_view_as_complex","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":"view-as-complex-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"view_as_complex(input) -> Tensor","title":"View_as_complex — torch_view_as_complex","text":"Returns view input complex tensor. input complex tensor size \\(m1, m2, \\dots, mi, 2\\), function returns new complex tensor size \\(m1, m2, \\dots, mi\\) last dimension input tensor expected represent real imaginary components complex numbers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"View_as_complex — torch_view_as_complex","text":"torch_view_as_complex supported tensors torch_dtype torch_float64() torch_float32().  input expected last dimension size 2. addition, tensor must stride 1 last dimension. strides dimensions must even numbers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_complex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View_as_complex — torch_view_as_complex","text":"","code":"if (torch_is_installed()) { if (FALSE) { x=torch_randn(c(4, 2)) x torch_view_as_complex(x) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":null,"dir":"Reference","previous_headings":"","what":"View_as_real — torch_view_as_real","title":"View_as_real — torch_view_as_real","text":"View_as_real","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"View_as_real — torch_view_as_real","text":"","code":"torch_view_as_real(self)"},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"View_as_real — torch_view_as_real","text":"self (Tensor) input tensor.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":"view-as-real-input-gt-tensor-","dir":"Reference","previous_headings":"","what":"view_as_real(input) -> Tensor","title":"View_as_real — torch_view_as_real","text":"Returns view input real tensor. input complex tensor size \\(m1, m2, \\dots, mi\\), function returns new real tensor size \\(m1, m2, \\dots, mi, 2\\), last dimension size 2 represents real imaginary components complex numbers.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"View_as_real — torch_view_as_real","text":"torch_view_as_real() supported tensors complex dtypes.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_view_as_real.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"View_as_real — torch_view_as_real","text":"","code":"if (torch_is_installed()) {  if (FALSE) { x <- torch_randn(4, dtype=torch_cfloat()) x torch_view_as_real(x) } }"},{"path":"https://torch.mlverse.org/docs/reference/torch_vstack.html","id":null,"dir":"Reference","previous_headings":"","what":"Vstack — torch_vstack","title":"Vstack — torch_vstack","text":"Vstack","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vstack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vstack — torch_vstack","text":"","code":"torch_vstack(tensors)"},{"path":"https://torch.mlverse.org/docs/reference/torch_vstack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vstack — torch_vstack","text":"tensors (sequence Tensors) sequence tensors concatenate","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vstack.html","id":"vstack-tensors-out-none-gt-tensor-","dir":"Reference","previous_headings":"","what":"vstack(tensors, *, out=None) -> Tensor","title":"Vstack — torch_vstack","text":"Stack tensors sequence vertically (row wise). equivalent concatenation along first axis 1-D tensors reshaped torch_atleast_2d().","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_vstack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vstack — torch_vstack","text":"","code":"if (torch_is_installed()) {  a <- torch_tensor(c(1, 2, 3)) b <- torch_tensor(c(4, 5, 6)) torch_vstack(list(a,b)) a <- torch_tensor(rbind(1,2,3)) b <- torch_tensor(rbind(4,5,6)) torch_vstack(list(a,b)) } #> torch_tensor #>  1 #>  2 #>  3 #>  4 #>  5 #>  6 #> [ CPUFloatType{6,1} ]"},{"path":[]},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Where — torch_where","text":"","code":"torch_where(condition, self = NULL, other = NULL)"},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Where — torch_where","text":"condition (BoolTensor) TRUE (nonzero), yield x, otherwise yield y self (Tensor) values selected indices condition TRUE (Tensor) values selected indices condition FALSE","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Where — torch_where","text":"See also torch_nonzero().","code":"The tensors `condition`, `x`, `y` must be broadcastable ."},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"where-condition-x-y-gt-tensor-","dir":"Reference","previous_headings":"","what":"where(condition, x, y) -> Tensor","title":"Where — torch_where","text":"Return tensor elements selected either x y, depending condition. operation defined : $$     \\mbox{}_i = \\left\\{ \\begin{array}{ll}         \\mbox{x}_i & \\mbox{} \\mbox{condition}_i \\\\         \\mbox{y}_i & \\mbox{otherwise} \\\\     \\end{array}     \\right. $$","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"where-condition-gt-tuple-of-longtensor-","dir":"Reference","previous_headings":"","what":"where(condition) -> tuple of LongTensor","title":"Where — torch_where","text":"torch_where(condition) identical torch_nonzero(condition, as_tuple=TRUE).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_where.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Where — torch_where","text":"","code":"if (torch_is_installed()) {  if (FALSE) { x = torch_randn(c(3, 2)) y = torch_ones(c(3, 2)) x torch_where(x > 0, x, y) }    }"},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros.html","id":null,"dir":"Reference","previous_headings":"","what":"Zeros — torch_zeros","title":"Zeros — torch_zeros","text":"Zeros","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zeros — torch_zeros","text":"","code":"torch_zeros(   ...,   names = NULL,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE )"},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zeros — torch_zeros","text":"... sequence integers defining shape output tensor.        Can variable number arguments collection like list tuple. names optional dimension names dtype (torch.dtype, optional) desired data type returned tensor.        Default: NULL, uses global default (see torch_set_default_tensor_type). layout (torch.layout, optional) desired layout returned Tensor.        Default: torch_strided. device (torch.device, optional) desired device returned tensor.        Default: NULL, uses current device default tensor type        (see torch_set_default_tensor_type). device CPU        CPU tensor types current CUDA device CUDA tensor types. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros.html","id":"zeros-size-out-null-dtype-null-layout-torch-strided-device-null-requires-grad-false-gt-tensor-","dir":"Reference","previous_headings":"","what":"zeros(*size, out=NULL, dtype=NULL, layout=torch.strided, device=NULL, requires_grad=False) -> Tensor","title":"Zeros — torch_zeros","text":"Returns tensor filled scalar value 0, shape defined variable argument size.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zeros — torch_zeros","text":"","code":"if (torch_is_installed()) {  torch_zeros(c(2, 3)) torch_zeros(c(5)) } #> torch_tensor #>  0 #>  0 #>  0 #>  0 #>  0 #> [ CPUFloatType{5} ]"},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":null,"dir":"Reference","previous_headings":"","what":"Zeros_like — torch_zeros_like","title":"Zeros_like — torch_zeros_like","text":"Zeros_like","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Zeros_like — torch_zeros_like","text":"","code":"torch_zeros_like(   input,   dtype = NULL,   layout = NULL,   device = NULL,   requires_grad = FALSE,   memory_format = torch_preserve_format() )"},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Zeros_like — torch_zeros_like","text":"input (Tensor) size input determine size output tensor. dtype (torch.dtype, optional) desired data type returned Tensor.        Default: NULL, defaults dtype input. layout (torch.layout, optional) desired layout returned tensor.        Default: NULL, defaults layout input. device (torch.device, optional) desired device returned tensor.        Default: NULL, defaults device input. requires_grad (bool, optional) autograd record operations        returned tensor. Default: FALSE. memory_format (torch.memory_format, optional) desired memory format        returned Tensor. Default: torch_preserve_format.","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":"zeros-like-input-dtype-null-layout-null-device-null-requires-grad-false-memory-format-torch-preserve-format-gt-tensor-","dir":"Reference","previous_headings":"","what":"zeros_like(input, dtype=NULL, layout=NULL, device=NULL, requires_grad=False, memory_format=torch.preserve_format) -> Tensor","title":"Zeros_like — torch_zeros_like","text":"Returns tensor filled scalar value 0, size input. torch_zeros_like(input) equivalent torch_zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Zeros_like — torch_zeros_like","text":"0.4, function support keyword. alternative, old torch_zeros_like(input, =output) equivalent torch_zeros(input.size(), =output).","code":""},{"path":"https://torch.mlverse.org/docs/reference/torch_zeros_like.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Zeros_like — torch_zeros_like","text":"","code":"if (torch_is_installed()) {  input = torch_empty(c(2, 3)) torch_zeros_like(input) } #> torch_tensor #>  0  0  0 #>  0  0  0 #> [ CPUFloatType{2,3} ]"},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":null,"dir":"Reference","previous_headings":"","what":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"two things:","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"","code":"with_detect_anomaly(code)"},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"code Code executed detect anomaly context.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"Running forward pass detection enabled allow backward pass print traceback forward operation created failing backward function. backward computation generate \"nan\" value raise error.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":"warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"mode enabled debugging different tests slow program execution.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_detect_anomaly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Context-manager that enable anomaly detection for the autograd engine. — with_detect_anomaly","text":"","code":"if (torch_is_installed()) { x <- torch_randn(2, requires_grad = TRUE) y <- torch_randn(1) b <- (x^y)$sum() y$add_(1)  try({   b$backward()    with_detect_anomaly({     b$backward()   }) }) } #> Error in (function (self, inputs, gradient, retain_graph, create_graph)  :  #>   one of the variables needed for gradient computation has been modified by an inplace operation: [CPUFloatType [1]] is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True). #> Exception raised from unpack at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/saved_variable.cpp:194 (most recent call first): #> frame #0: c10::Error::Error(c10::SourceLocation, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>) + 81 (0x10404eca1 in libc10.dylib) #> frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 98 (0x10404d342 in libc10.dylib) #> frame #2: torch::autograd::SavedVariable::unpack(std::__1::shared_ptr<torch::autograd::Node>) const + 2815 (0x124574d0f in libtorch_cpu.dylib) #> frame #3: torch::autograd::generated::PowBackward1::apply(std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>>&&) + 168 (0x1236c7488 in libtorch_cpu.dylib) #> frame #4: torch::autograd::Node::operator()(std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>>&&) + 99 (0x1245456c3 in libtorch_cpu.dylib) #> frame #5: torch::autograd::Engine::evaluate_function(std::__1::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::__1::shared_ptr<torch::autograd::ReadyQueue> const&) + 3401 (0x12453ba89 in libtorch_cpu.dylib) #> frame #6: torch::autograd::Engine::thread_main(std::__1::shared_ptr<torch::autograd::GraphTask> const&) + 954 (0x12453a6da in libtorch_cpu.dylib) #> frame #7: torch::autograd::Engine::execute_with_graph_task(std::__1::shared_ptr<torch::autograd::GraphTask> const&, std::__1::shared_ptr<torch::autograd::Node>, torch::autograd::InputBuffer&&) + 374 (0x124544646 in libtorch_cpu.dylib) #> frame #8: torch::autograd::Engine::execute(std::__1::vector<torch::autograd::Edge, std::__1::allocator<torch::autograd::Edge>> const&, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, bool, bool, bool, std::__1::vector<torch::autograd::Edge, std::__1::allocator<torch::autograd::Edge>> const&) + 2605 (0x12454268d in libtorch_cpu.dylib) #> frame #9: torch::autograd::run_backward(std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, bool, bool, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, bool, bool) + 2129 (0x124528df1 in libtorch_cpu.dylib) #> frame #10: torch::autograd::backward(std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&, c10::optional<bool>, bool, std::__1::vector<at::Tensor, std::__1::allocator<at::Tensor>> const&) + 104 (0x124529408 in libtorch_cpu.dylib) #> frame #11: torch::autograd::VariableHooks::_backward(at::Tensor const&, c10::ArrayRef<at::Tensor>, c10::optional<at::Tensor> const&, c10::optional<bool>, bool) const + 435 (0x12457a9f3 in libtorch_cpu.dylib) #> frame #12: at::Tensor::_backward(c10::ArrayRef<at::Tensor>, c10::optional<at::Tensor> const&, c10::optional<bool>, bool) const + 75 (0x120ebbeab in libtorch_cpu.dylib) #> frame #13: _lantern_Tensor__backward_tensor_tensorlist_tensor_bool_bool + 427 (0x1068a3b2b in liblantern.dylib) #> frame #14: std::__1::__function::__func<cpp_torch_method__backward_self_Tensor_inputs_TensorList(XPtrTorchTensor, XPtrTorchTensorList, XPtrTorchOptionalTensor, XPtrTorchoptional_bool, XPtrTorchbool)::$_1, std::__1::allocator<cpp_torch_method__backward_self_Tensor_inputs_TensorList(XPtrTorchTensor, XPtrTorchTensorList, XPtrTorchOptionalTensor, XPtrTorchoptional_bool, XPtrTorchbool)::$_1>, void ()>::operator()() + 54 (0x10513fbf6 in torchpkg.so) #> frame #15: std::__1::packaged_task<void ()>::operator()() + 72 (0x10513df88 in torchpkg.so) #> frame #16: EventLoop<void>::run() + 379 (0x10513ddbb in torchpkg.so) #> frame #17: void* std::__1::__thread_proxy[abi:v160006]<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct>>, ThreadPool<void>::ThreadPool(int)::'lambda'()>>(void*) + 50 (0x10513db32 in torchpkg.so) #> frame #18: _pthread_start + 125 (0x7ff805e541d3 in libsystem_pthread.dylib) #> frame #19: thread_start + 15 (0x7ff805e4fbd3 in libsystem_pthread.dylib) #>"},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Enable grad — with_enable_grad","title":"Enable grad — with_enable_grad","text":"Context-manager enables gradient calculation. Enables gradient calculation, disabled via with_no_grad.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enable grad — with_enable_grad","text":"","code":"with_enable_grad(code)  local_enable_grad(.env = parent.frame())"},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enable grad — with_enable_grad","text":"code code executed gradient recording. .env environment use scoping.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Enable grad — with_enable_grad","text":"context manager thread local; affect computation threads.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Enable grad — with_enable_grad","text":"local_enable_grad(): Locally enable gradient computations.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_enable_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enable grad — with_enable_grad","text":"","code":"if (torch_is_installed()) {  x <- torch_tensor(1, requires_grad = TRUE) with_no_grad({   with_enable_grad({     y <- x * 2   }) }) y$backward() x$grad } #> torch_tensor #>  2 #> [ CPUFloatType{1} ]"},{"path":"https://torch.mlverse.org/docs/reference/with_no_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporarily modify gradient recording. — with_no_grad","title":"Temporarily modify gradient recording. — with_no_grad","text":"Temporarily modify gradient recording.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_no_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporarily modify gradient recording. — with_no_grad","text":"","code":"with_no_grad(code)  local_no_grad(.env = parent.frame())"},{"path":"https://torch.mlverse.org/docs/reference/with_no_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporarily modify gradient recording. — with_no_grad","text":"code code executed gradient recording. .env environment use scoping.","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_no_grad.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Temporarily modify gradient recording. — with_no_grad","text":"local_no_grad(): Disable autograd goes scope","code":""},{"path":"https://torch.mlverse.org/docs/reference/with_no_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporarily modify gradient recording. — with_no_grad","text":"","code":"if (torch_is_installed()) { x <- torch_tensor(runif(5), requires_grad = TRUE) with_no_grad({   x$sub_(torch_tensor(as.numeric(1:5))) }) x x$grad } #> torch_tensor #> [ Tensor (undefined) ]"},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-0130","dir":"Changelog","previous_headings":"","what":"torch 0.13.0","title":"torch 0.13.0","text":"CRAN release: 2024-05-21","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-13-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.13.0","text":"lantern now distributed different URL (https://torch-cdn.mlverse.org). users shouldn’t effect, unless need special authorization access URL’s. (#1162)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-13-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.13.0","text":"Added support private $finalize_deep_clone() method nn_module allows run code cloning module. compare_proxy method torch_tensor type added allows compare torch tensors using testthat::expect_equal(). Converting torch tensor R array works tensor ‘cuda’ device (#1130)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-13-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.13.0","text":"Fix bug using input projection initialization bias nnf_multi_head_attention_forward (#1154 @cregouby) Bugfix: calling $detach() tensor now preserves attributes (#1136) Make sure deep cloning tensor nn_module preserves class attributes requires_grad field. (#1129) Fixed parameters buffers children nn_modules cloned Cloned objects longer reference object cloned Fixed bug nn_module’s patched clone method invalid call internal create_nn_module_callable() Printing grad_fn now appends new line end. Make sure deep cloning preserve state dict attributes. (#1129) Added separate setter unsetter autocast context instead allowing local_autocast(). (#1142) Fixed bug torch_arange() causing return 1:(n-1) values specific request dtype = torch_int64() (#1160)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-0120","dir":"Changelog","previous_headings":"","what":"torch 0.12.0","title":"torch 0.12.0","text":"CRAN release: 2023-12-15","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-12-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.12.0","text":"New torch_save serialization format. ’s ~10x faster since ’s based safetensors, files can read safetensors implementation. (#1071) Updated LibTorch 2.0.1. (#1085) torch_load longer supports device=NULL load weights device saved. (#1085) Lantern binaries torch pre-built binaries now built Ubuntu 20.04. (#1124)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-12-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.12.0","text":"Added support CUDA 11.8. (#1089) Added support iterable datasets. (#1095)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-12-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.12.0","text":"fix printer torch device (add new line end) .array now moves tensors cpu copying data R. (#1080) Fixed segfault caused comparing dtype NULL. (#1090) Fixed incorrect naming complex data type names, torch_cfloat64. (#1091) Fixed name out_features attribute nn_linear module. (#1097) Fixed issues loading state dict optimizers learning rate schedulers. (#1100) Fixed bug cloning nn_modules empty state dicts. (#1108) distr_multivariate_normal now correctly handles precision matrix’s. (#1110) Moved length.torch_tensor implementation R7 avoid problems torch dataset torch_tensor class. (#1111) Fixed problem deep cloning nn_module. (#1123)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-0110","dir":"Changelog","previous_headings":"","what":"torch 0.11.0","title":"torch 0.11.0","text":"CRAN release: 2023-06-06","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-11-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.11.0","text":"load_state_dict() optimizers now default cloning tensors state dict, don’t keep references objects dict. (#1041)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-11-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.11.0","text":"Added nn_utils_weight_norm (#1025) Added support reading ordered state dicts serialized PyTorch. (#1031) Added jit_ops allowing access JIT operators. (#1023) Added with_device local_device allow temporarily modify default device tensors get initialized. (#1034) nnf_gelu() nn_gelu() gained approximate argument. (#1043) Implemented != torch devices. (#1042) Allows setting dtype string. (#1045) can now create named list modules using nn_module_dict(). (#1046) Faster load_state_dict(), also using less memory. ’ possible use legacy implementation required, see PR. (#1051) Export helpers handling RNG state, temprarily modifying . (#1057) Added support converting half tensors R .numeric(). (#1056) Added new torch_tensor_from_buffer() buffer_from_torch_tensor() allow low level creation torch tensors. (#1061, #1062)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-11-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.11.0","text":"Improved documentation LBFGS optimizer. (#1035) Added message asking user restart session manual installation install_torch(). (#1055)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-11-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.11.0","text":"Fixed bug related handling non-persistent buffers. get added state_dict() even . (#1036) Fixed typo optim_adamw class name. Fixed nn_cross_entropy_loss class name. (#1043) Fixed bug LBFGS w/ line search. (#1048) Correctly handle installation RemoteSha package version. (#1058)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-11-0","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.11.0","text":"Started building LibLantern macOS 11 instead macOS12 maximum compatibility. (#1026) Added CXXSTD Makevars enable C+11 compilation options. Refactored codepath TensorOptions now tensors initialization handled codepath. (#1033) Added internal argument .refer_to_state_dict load_state_dict() nn_module() method. Allows loading state dict model keeping parmaters references state dict. (#1036)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-0100","dir":"Changelog","previous_headings":"","what":"torch 0.10.0","title":"torch 0.10.0","text":"CRAN release: 2023-04-13","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-10-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.10.0","text":"Updated LibTorch v1.13.1 (#977)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-10-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.10.0","text":"Provide pre-built binaries torch using GH Action workflow. (#975) Added nn_silu() nnf_silu(). (#985) Added support deep cloning nn_modules. (#986) Added local_no_grad() local_enable_grad() alternatives with_ functions. (#990) Added optim_adamw optimizer. (#991) Added support automatic mixed precision (#996) Added functionality temporarily modify torch seed. (#999) Support creating torch tensors raw vectors back. (#1003)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-10-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.10.0","text":"Dataloaders now preserve batch dimension batch_size=1 used. (#994)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-10-0","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.10.0","text":"Large refactoring build system. (#964) Use native symbol registration instead dynamic lookup. (#976) Returning lists tensors R now much faster. (#993)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-091","dir":"Changelog","previous_headings":"","what":"torch 0.9.1","title":"torch 0.9.1","text":"CRAN release: 2023-01-23","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-9-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.9.1","text":"torch_where now returns 1-based indices ’s called condition argument . (#951, @skeydan)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-9-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.9.1","text":"Added support nonABI builds CUDA 11.6. (#919) torch_fft_fftfreq() function now exported. (#950, @skeydan)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-9-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.9.1","text":"Fixed bug caused distr_normal$sample() able generate reproducible results setting seeds. (#938) torch_cat error message now correctly reflects 1-based indexing. (#952, @skeydan)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-9-1","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.9.1","text":"Fixed warnings R CMD Check generated unsafe use sprintf. (#959, @shikokuchuo) Import, suggest glue (#960)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-090","dir":"Changelog","previous_headings":"","what":"torch 0.9.0","title":"torch 0.9.0","text":"CRAN release: 2022-10-24","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-9-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.9.0","text":"Updated LibTorch v1.12.1. (#889, #893, #899) torch_bincount now 1-based indexed. (#896) torch_movedim() $movedim() now 1-based indexed. (#905)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-9-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.9.0","text":"Added cuda_synchronize() allow synchronization CUDA operations. (#887) Added support M1 Macs, including creating Tensors MPS device. (#890) Added support CUDA 11.6 Linux. (#902) Added cuda_empty_cache() allow freeing memory caching allocator system. (#903) Added $is_sparse() method check wether Tensor sparse . (#903) dataset_subset now adds class modified dataset original dataset classes postfixed _subset. (#904) Added torch_serialize() allow creating raw vector torch objects. (#908)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.9.0","text":"Fixed bug torch_arange causing end value getting included result. (#885, @skeydan) Fixed bug window functions setting default dtype. (#886, @skeydan) Fixed bug using install_torch(reinstall = TRUE). (#883) dims argument torch_tile() longer modified, ’s meant 1-based dimension. (#905) nn_module$state_diict() now detaches output tensors default. (#916)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-9-0","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.9.0","text":"Re-implemented $ method R7 classes C/C++ improve speed calling methods. (#873) Re-implemented garbage collection logic calling inside backward() call. improves speed longer need call GC everytime backward called. (#873) now use thread pool instead launching new thread backward calls. (#883) Implemented options allow configuring activation garbage collection allocating CUDA memory. (#883) nnf_ functions updated use single torch_ kernel instead custom implementation. (#896) Improved performance dataloaders. (#900) now let LibTorch query default generator, allows one use torch_bernoulli() device=\"gpu\". (#906)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-081","dir":"Changelog","previous_headings":"","what":"torch 0.8.1","title":"torch 0.8.1","text":"CRAN release: 2022-08-19","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-8-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.8.1","text":"now prompt user installing torch additional dependencies interactive environments. requested CRAN maintainers. (#864)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-8-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.8.1","text":"Dataloaders can now handle logical values. (#858, @ryan-heslin) now provide builds Pre CXX11 ABI version LibTorch. can used setting environment variable PRECXX11ABI=1. can useful environments older versions GLIBC. (#870)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-8-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.8.1","text":"Fixed way errors passed dataloaders workers main process. Now using new rlang error chaining. (#864)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-8-1","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.8.1","text":"can now call GC even backward call (ie, different thread) allows better memory management. (#853) Fix HTML5 Manual information resquested CRAN (#869)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-080","dir":"Changelog","previous_headings":"","what":"torch 0.8.0","title":"torch 0.8.0","text":"CRAN release: 2022-06-09","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-8-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.8.0","text":"Serialization now much faster avoid base64 encoding serialized tensors. result, files serialized newer versions torch can’t opened older versions torch. Set options(torch.serialization_version = 1) want file readable older versions. (#803) Deprecated support CUDA 10.2 Windows. (#835) linalg_matrix_rank linalg_pinv gained atol rtol arguments deprecating tol rcond. (#835)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.8.0","text":"Improved auto-detection CUDA version Windows. (#798, @SvenVw) Improved parallel dataloaders performance using socket conection transfer data workers main process. (#803) keep_graph now defaults value create_graph calling $backward(). also renamed retain_graph match PyTorch. (#811) Optimizers created optimizer now carry classname generator instances. Optimizer generators now class torch_optimizer_generator. class torch optimizers renamed torch_Optimizer torch_optimizer. (#814) New utility function nn_prune_head() prune top layer(s) network (#819 @cregouby) torch_kron() now exported (#818). Added nn_embedding_bag. (#827, @egillax) nn_multihead_attention now supports batch_first option. (#828, @jonthegeek) ’s now possible modify gradient tensor using syntax x$grad <- new_grad. (#832) sampler() now exported allowing create custom samplers can passed dataloader(). (#833) Creating nn_modules without initialize method now supported. (#834) Added lr_reduce_on_plateau learning rate scheduler. (#836, @egillax) torch_tensor(NULL) longer fails. now returns tensor dimensions data. (#839) Improved complex numbers handling, including better printing support casting R. (#844)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-8-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.8.0","text":"Fixed bug weight decay handling Adam optimizer. (#824, @egillax) Fixed bug nn_l1_loss. (#825, @sebffischer)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-8-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.8.0","text":"Nice error message embed_dim divisible num_heads nn_multihead_attention. (#828)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-8-0","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.8.0","text":"Updated LibTorch v1.11.0. (#835) Moved error message translations R, makes easier add new ones update existing. (#841)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-072","dir":"Changelog","previous_headings":"","what":"torch 0.7.2","title":"torch 0.7.2","text":"CRAN release: 2022-02-25","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fix-0-7-2","dir":"Changelog","previous_headings":"","what":"Bug fix","title":"torch 0.7.2","text":"Fixed vignette building Windows.","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-071","dir":"Changelog","previous_headings":"","what":"torch 0.7.1","title":"torch 0.7.1","text":"CRAN release: 2022-02-25","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-7-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.7.1","text":"Added cuda_runtime_version() query CUDA Tolkit version torch using. (#790)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-070","dir":"Changelog","previous_headings":"","what":"torch 0.7.0","title":"torch 0.7.0","text":"CRAN release: 2022-02-18","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-7-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.7.0","text":"torch_sort Tensor$sort now return 1-indexed results. (#709, @mohamed-180) Support LibTorch 1.10.2. See also release notes PyTorch v1.10. (#758, #763, #775, @hsbadr). Changed default dim 1 2 nnf_cosine_similarity. (#769) default value arguments various functions changed. bug code generation truncating default values specially float values needed 6 digit precision. (#770)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.7.0","text":"jit_save_for_mobile allows save traced model bytecode form, loaded LiteModuleLoader. (#713) Exported is_torch_tensor check wether object tensor . (#730, @rdinnager) Adds cuda_get_device_properties(device) allows one query device capability properties. (#734, @rdinnager) Implemented call_torch_function() allow calling potentially unexported torch core functions. (#743, @rdinnager) Now installing torch LibTorch Lantern headers installed within inst directory. allow packages extending torch bind directly C++ library. (#718) dataset_subset use .getbatch method wrapped dataset one available. (#742, @egillax) Added nn_flatten nn_unflatten modules. (#773) Added cuda_memory_stats() cuda_memory_summary() verify amount memory torch using GPU. (#774) Added backends_cudnn_version() query CuDNN version found torch. (#774)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.7.0","text":"Fixed bug .validate_sample Distribution class incorrectly check tensors. (#739, @hsbadr) Fixed memory leak applying custom autograd_functions. (#750) Fixed bug caused autograd_grad deadlock used custom autograd functions. (#771) Fixed bug torch_max torch_min fail length=2 Tensors. (#772)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-7-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.7.0","text":"Improved ‘Loading data’ vignette datasets documentation. (#780, @jnolis)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-0-7-0","dir":"Changelog","previous_headings":"","what":"Internal","title":"torch 0.7.0","text":"Refactored internal Lantern types Rcpp types made clearer exported types can used C++ extensions. (#718) Simplified concurrency related constructs autograd. (#755, @yitao-li) R C++ code cleanup, styling, formatting. (#753, @hsbadr) Dataloaders slightly faster new transpose function. (#783) torch_tensor now C++ function slighly increasing performance situations. (#784)","code":""},{"path":[]},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-6-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.6.1","text":"Fixed valgrind errors CRAN requiring recent version knitr. Updated LibTorch version 1.9.1 (#725 @hsbadr) now check lantern DLL’s loaded calling lantern function. avoids segfaults Lantern installed. (#723).","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-060","dir":"Changelog","previous_headings":"","what":"torch 0.6.0","title":"torch 0.6.0","text":"CRAN release: 2021-10-07","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.6.0","text":"nn_sequential now bare nn_module, allowing easily inherit . breaking change used name argument. name behavior can achieved subclassing; see tests PR. (#699)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.6.0","text":"Additional info showed printing tensors like requires grad grad fn. (#668, #669, #673, @mohamed-180) can now subset nn_sequential modules using [. (#678, @mohamed-180) now allow padding='' padding='valid' using convolutions. (#679) nnf_cross_entropy now uses ATen cross_entropy operation directly instead logsoftmax + NLLLoss. (#680) Inherited classes now persisted subclasses. specially useful subclass nn_sequential still want specific S3 methods still work. (#701)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.6.0","text":"Fixed bug indexing numeric vectors. (#693, @mohamed-180) Fixed bug indexing tensors ellipsis tensor. (#696)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-6-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.6.0","text":"Improved optimizer documentation adding ‘Warning’ regarding creation usage order. (#698)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-050","dir":"Changelog","previous_headings":"","what":"torch 0.5.0","title":"torch 0.5.0","text":"CRAN release: 2021-08-17","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.5.0","text":"Droped support CUDA 10.1 (#610) torch_manual_seed() now matches PyTorch’s behavior can easily compare implementations. Since breaking change added torch.old_seed_behavior=TRUE option users can stick old behavior. (#639) Indexing vectors now behavior R indexing, making easier understand. Users can still use old behavior using torch_index torch_index_put. (#649)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-5-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.5.0","text":"Added support ScriptModule. Loaded JIT modules now operate nn_modules. (#593) Added jit_compile function allows compiling arbitrary TorchScript code script function can serialized executed. (#601) Added jit_trace support nn_module created R. (#604) Updated LibTorch version 1.9.0 (#610) Added Linear Algebra functions (#612) Added contrib_sort_vertices efficiently sort vertices CUDA. (#619) Allows querying graph traced modules. (#623) Added with_detect_anomaly debug autograd errors. (#628) Implemented traced_module$graph_for() allow inspecting optimized jit graph. (#643) Added slc allow dynamically creating slices indexing tensors. (#648)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.5.0","text":"Fixed bug using .getbatch method didn’t return torch_tensor. (#615) Fixed warning using %/% caused call deprecated torch_floor_divide (#616) Improved CUDA version auto-detection (#644)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-changes-0-5-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"torch 0.5.0","text":"Improved R <-> JIT types conversion. (#593) Added Dockerfiles CUDA 11.1 (#597) warning raised incompatible dataset passed parallel dataloader. (#626) Additionally calling gc CUDA memory exhausted now call R_RunPendingFinalizers. improve memory usage, now delete tensors earlier. (#654) Fix rchk issues (#667)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-040","dir":"Changelog","previous_headings":"","what":"torch 0.4.0","title":"torch 0.4.0","text":"CRAN release: 2021-06-10","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.4.0","text":"torch_multinomial now returns 1-based indexes comply 1-based indexing across torch. (#588)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.4.0","text":"Added parameter multihead attention module allow output unaveraged attention weights. (@jonathanbratt #542) now allow jit_trace functions 1 argument. (#544) Added Multivariate normal distribution (#552) Export torch_diff function added docs . (#565) Added device argument torch_load() allowing one select device parameters loaded. (#578) Added distr_categorical() (#576) Added distr_mixture_same_family() (#576) Improve handling optimizers state implement load_state_dict() state_dict() optimizers. (#585) Added ability save R lists containing torch_tensors using torch_save. allows us save state optimizers modules using torch_save(). (#586)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.4.0","text":"Fixed bug nn_multihead_attention q,k,v inputs . (@jonathanbratt #540) Fixed $copy_ correctly respects src requires_grad() reloading saved models torch_load(). (#545) Fixed nn_init_xavier_normal_() nn_init_xavier_uniform_() standard deviation calculation. (#557) Fixed bug torch_tensordot() called infering dimensions. (#563) Dataset’s .getbatch now takes integer vector input instead list(). (#572) Fixed bug tensor$size() indexing negative numbers. (#570) Fixed bug log_prob distr_bernoulli() (#581)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"torch 0.4.0","text":"Better handling optional Tensor arguments using explicit XPtrTorchOptionalTensor class. (#565) Tensors R side point C++ Tensor now guaranteed object. allows easily determine unique model parameters. (#582)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-030","dir":"Changelog","previous_headings":"","what":"torch 0.3.0","title":"torch 0.3.0","text":"CRAN release: 2021-04-28","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.3.0","text":"torch_nonzero tensor$nonzero() now return 1-based indexes. (#432) Breaking change: torch_arange returns closed interval [start, end] instead half open [start, end). makes behave similar R’s seq. (#506)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.3.0","text":"torch_split now accepts list sizes well fixed size. (#429) Added nn_layer_norm. (#435) Allow timeout=360 install_torch() parameter large file download (@cregouby #438) Added install_torch_from_file() get_install_libs_url()setup cases direct download possible (@cregouby #439) Added mean.torch_tensor (#448) New arguments worker_globals worker_packages allowing easily pass objects workers parallel dataloaders (#449). now call R garbage collector ’s memory available GPU, can help cases laziness garbage collector allows many tensors memory even though longer referenced R. (#456) Implemented nn_group_norm fixed bug nnf_group_norm (#474) Added backend functions allowing us query optimizations LibTorch compiled (#476) Added normal distribution (#462) Added bernoulli distribution (#484) .list nn_modules (#492) Enumerate support Bernoulli distribution (#490) Added Poisson Distriibution (#495) Allow optional .getbatch datasets/dataloaders (#498) nn_lstm, nn_gru nn_gru can now use cudnn accelerations available (#503). Added Gamma distribution (#489) now respect TORCH_HOME env var automatically install torch. (#522) Implement comparison operator != torch dtypes. (#524) Added Chi-square distribution. (#518) Added optimizer function allowing easily implement custom optimizers. (#527)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.3.0","text":"Fixed bug optim_lbfgs make model objects exponentially big. (#431) Correctly handle NaNs L-BFGS optimizer (#433) default collate function now respects data type converting tensor (dataset returns R object) (#434) Fixed torch_normal. (#450) Fixed backward compatibility issue loading models saved older versions torch. bug introduced #452 now fixed also added regression test. (#458) Fixed bug using RNN’s GPU (#460) Found fixed memory leaks, specially creating datatypes strings saving models torch_save. (#454) Fixed bug nnf_pad using mode='circular'. (#471) Bugfixes nn_multihead_attention (#496) Fixed bug using packed sequences nn_lstm (#500) Fixed bug method nn_module reset requires_grad attribute parameters. (#501) Added strong_wolfe option optim_lbfgs. (#517) Fixed default argument nn_init_trunc_normal_ initializer function. (#535)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-3-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.3.0","text":"Added vignette reading models Python (#469)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"internal-changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Internal changes","title":"torch 0.3.0","text":"Removed PerformanceReporter tests get easier read stack traces. (#449) Internal change R7 classes R7 objects simple external pointer instead environments. might cause breaking change relied saving kind state Tensor object. (#452) Internal refactoring making Rcpp aware XPtrTorch* types making simpler return Rcpp code. might cause breaking change relying torch_dtype() R6 class. (#451) Internal changes auto unwrap arguments SEXP’s Rcpp. make easier move dispatcher system C++ future, already allows us gain ~30% speedups small operations. (#454) Added Windows GPU CI workflow (#508). Update LibTorch v1.8 (#513) Moved parts dispatcher C++ make faster. (#520)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-021","dir":"Changelog","previous_headings":"","what":"torch 0.2.1","title":"torch 0.2.1","text":"CRAN release: 2021-01-05","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-2-1","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.2.1","text":"Made torch_one_hot nnf_one_hot use 1-based indexing. (#410) nn_module$eval() nn_module$train() now return callable nn_module instead nn_Module. (#425)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-2-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.2.1","text":"Added custom CPU allocator call gc torch might need memory (#402) Updated LibTorch 1.7.1 (#412) Allow listing nested modules nn_module (#417) Allow modifying requires_grad attribute using $<- operator (#419) Added length method nn_sequential container. (#423) Added support CUDA 11 linux (#424)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-2-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.2.1","text":"Fix support cuda 9.2 (#398) Fixed GPU CI skipping tests. (#398) Fixed memory leak printing tensors (#402) Fixed memory leak passing integer vectors lantern. (#402) Fixed memory leaks related autograd context (#405) Fixed nnf_normalize x$norm() able called (#409)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"documentation-0-2-1","dir":"Changelog","previous_headings":"","what":"Documentation","title":"torch 0.2.1","text":"Small improvement nn_module documentation (#399). getting started section removed pkgdown website favor new guide landing page (#401) Updated landing page include getting started tutorial (#400)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-020","dir":"Changelog","previous_headings":"","what":"torch 0.2.0","title":"torch 0.2.0","text":"CRAN release: 2020-12-15","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"breaking-changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"torch 0.2.0","text":"Dataloaders now returns coro::exhausted intead raising stop_iteration_error dataloader exceeds. (#366) Fixed bug happen functions need transform tensors 0-based 1-based GPU. (#317) Fixed torch_argsort x$argsort return 1-based indexes (#342) Fixed torch_argmax, torch_argmin, x$argmax() x$argmin() return 1-based indexes. (#389)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.2.0","text":"Added $element_size() method (@dirkschumacher #322) Added $bool() method (@dirkschumacher #323) torch__addr torch__addr_ removed longer available LibTorch 1.7. now check MD5 hashes downloaded LibTorch binaries. (@dirkschumacher #325) Added Distribution abstract class (@krzjoa #333) Updated LibTorch 1.7 (#337) now warn converting long tensors R ’s chance integer overflow. (#347) Allow private active methods nn_module’s dataset’s. (#349) Added nn_batch_norm3d (@mattwarkentin #354) Added nn_lstm nn_gru modules. (#362) Added distribution constraints (@krzjoa #364) Dataloaders now use num_workers argument load data parallel (#366) Added Exponential Family classs distributions (#373) Added Dockerfile docker compose file GPU support, -guide. (#380 #386) Added R 3.6 CI system fixed compilation source Windows (#387) Initial support JIT tracing (#377) Added LBFGS optimizer (#392) Improved nn_module UI improving autocomplete support adding print method (#391)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.2.0","text":"Fixed bug trying print grad_fn Tensor doesn’t one. See (#321) Refactored optimizers code avoid duplication parameter checks, etc. (@dirkschumacher #328) Fixed torch_norm can called dim argument. (#345) Fixed crash calling torch_hann_window invalid NULL window_length. (#351) Fixed torch_stft calls LibTorch 1.7 (added return_complex argument) (#355) Fixed bug strides NULL pooling operations. (#361) Use nvcc --version instead nvidia-smi find CUDA version nvidia-smi reports latest supported version installed one. (#363) Corrected URL download LibTorch Linux CUDA 10.2 (#367) Fixed handling integer tensors indexing tensors (#385) Fixed bug passing length zero vectors lantern/libtorch. (#388)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-011","dir":"Changelog","previous_headings":"","what":"torch 0.1.1","title":"torch 0.1.1","text":"CRAN release: 2020-10-20","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"bug-fixes-0-1-1","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"torch 0.1.1","text":"Fixed bug made RandomSampler(replacement = TRUE) never take last element dataset. (84861fa) Fixed torch_topk x$topk returned indexes 1-based (#280) Fixed bug (#275) cause 1 - torch_tensor(1, device = \"cuda\") fail 1 created CPU. (#279) now preserve names dataloader output (#286) torch_narrow, Tensor$narrow() Tensor$narrow_copy now indexed starting 1. (#294) Tensor$is_leaf now active method. (#295) Fixed bug passing equations torch_einsum. (#296) Fixed nn_module_list() correctly name added modules, otherwise returned state_dict() . (#300) Fixed bug related random number seeds using -place methods. (#303) Fixed nn_batchnorm* returns results PyTorch (#302) Fixed bug made nn_module$parameter shared parameters layers. (#306) Fixed $max $min return 1-based indexes. (#315)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"torch 0.1.1","text":"Expanded utils_data_default_collate support converting R objects torch tensors needed. (#269) Added .matrix method torch Tensors. (#282) default now truncate output print(totrch_tensor(1:40)) spans 30 lines. useful spamming console taking long print print large tensor. (#283) Added Adadelta optimizer (@krzjoa #284) Added support GPU’s Windows (#281) Added Adagrad optimizer (@krzjoa #289) Added RMSprop optimizer (@krzjoa #290) Added Rprop optimizer (@krzjoa #297) Added gradient clipping utilities (#299) Added nnf_contrib_sparsemax nn_contrib_sparsemax. (#309) Added ASGD optimizer (@krzjoa #307) Getters setters number threads used torch (#311)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-010","dir":"Changelog","previous_headings":"","what":"torch 0.1.0","title":"torch 0.1.0","text":"CRAN release: 2020-09-28 Added many missing losses (#252) Implemented $<- [[<- operators nn_module class. (#253) Export nn_parameter, nn_buffer, is_* auxiliary functions. Added new serialization vignette. Added learning rate schedulers (#258)","code":""},{"path":"https://torch.mlverse.org/docs/news/index.html","id":"torch-002","dir":"Changelog","previous_headings":"","what":"torch 0.0.2","title":"torch 0.0.2","text":"CRAN release: 2020-08-31 Added NEWS.md file track changes package. Auto install loading package first time.","code":""}]
