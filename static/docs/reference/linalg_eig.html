<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="Letting  be  or ,
the eigenvalue decomposition of a square matrix
 (if it exists) is defined as"><title>Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig • torch</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><meta property="og:title" content="Computes the eigenvalue decomposition of a square matrix if it exists. — linalg_eig"><meta property="og:description" content="Letting  be  or ,
the eigenvalue decomposition of a square matrix
 (if it exists) is defined as"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZJSKW3L0N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9ZJSKW3L0N');
</script></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary" data-bs-theme="dark"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">torch</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.13.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/installation.html">Installation</a>
    <h6 class="dropdown-header" data-toc-skip>Tensors</h6>
    <a class="dropdown-item" href="../articles/tensor-creation.html">Creating tensors</a>
    <a class="dropdown-item" href="../articles/indexing.html">Indexing</a>
    <a class="dropdown-item" href="../articles/tensor/index.html">Tensor class</a>
    <a class="dropdown-item" href="../articles/serialization.html">Serialization</a>
    <h6 class="dropdown-header" data-toc-skip>Datasets</h6>
    <a class="dropdown-item" href="../articles/loading-data.html">Loading Data</a>
    <h6 class="dropdown-header" data-toc-skip>Autograd</h6>
    <a class="dropdown-item" href="../articles/using-autograd.html">Using autograd</a>
    <a class="dropdown-item" href="../articles/extending-autograd.html">Extending autograd</a>
    <a class="dropdown-item" href="../articles/python-to-r.html">Python models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-examples">Examples</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-examples">
    <a class="dropdown-item" href="../articles/examples/basic-autograd.html">basic-autograd</a>
    <a class="dropdown-item" href="../articles/examples/basic-nn-module.html">basic-nn-module</a>
    <a class="dropdown-item" href="../articles/examples/dataset.html">dataset</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-advanced">Advanced</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-advanced">
    <a class="dropdown-item" href="../articles/memory-management.html">Memory management</a>
    <a class="dropdown-item" href="../articles/modifying-source-code.html">Building locally</a>
    <a class="dropdown-item" href="../articles/amp.html">Automatic Mixed Precision</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlverse/torch/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Computes the eigenvalue decomposition of a square matrix if it exists.</h1>
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/HEAD/R/linalg.R" class="external-link"><code>R/linalg.R</code></a></small>
      <div class="d-none name"><code>linalg_eig.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Letting  be  or ,
the <strong>eigenvalue decomposition</strong> of a square matrix
 (if it exists) is defined as</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">linalg_eig</span><span class="op">(</span><span class="va">A</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>
    <dl><dt>A</dt>
<dd><p>(Tensor): tensor of shape <code>(*, n, n)</code> where <code>*</code> is zero or more batch dimensions
consisting of diagonalizable matrices.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    

<p>A list <code>(eigenvalues, eigenvectors)</code> which corresponds to  and  above.
<code>eigenvalues</code> and <code>eigenvectors</code> will always be complex-valued, even when <code>A</code> is real. The eigenvectors
will be given by the columns of <code>eigenvectors</code>.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" data-external="1"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>V</mi><mi mathvariant="normal">diag</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">Λ</mi><mo stretchy="false">)</mo><msup><mi>V</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mpadded width="0px"><mrow><mspace width="2em"></mspace><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">C</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup><mo separator="true">,</mo><mi mathvariant="normal">Λ</mi><mo>∈</mo><msup><mi mathvariant="double-struck">C</mi><mi>n</mi></msup></mrow></mpadded></mrow><annotation encoding="application/x-tex">
A = V \operatorname{diag}(\Lambda) V^{-1}\mathrlap{\qquad V \in \mathbb{C}^{n \times n}, \Lambda \in \mathbb{C}^n}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em;">diag</span></span><span class="mopen">(</span><span class="mord">Λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:1.0158em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mspace" style="margin-right:2em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8213em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Λ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span><span class="fix"></span></span></span></span></span></span></span></span></p>
<p>This decomposition exists if and only if  is <code>diagonalizable</code>_.
This is the case when all its eigenvalues are different.
Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if <code>A</code> is a batch of matrices then
the output has the same batch dimensions.</p>
    </div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>The eigenvalues and eigenvectors of a real matrix may be complex.</p>
    </div>
    <div class="section level2">
    <h2 id="warning">Warning<a class="anchor" aria-label="anchor" href="#warning"></a></h2>
    

<ul><li><p>This function assumes that <code>A</code> is <code>diagonalizable</code>_ (for example, when all the
eigenvalues are different). If it is not diagonalizable, the returned
eigenvalues will be correct but .</p></li>
<li><p>The eigenvectors of a matrix are not unique, nor are they continuous with respect to
<code>A</code>. Due to this lack of uniqueness, different hardware and software may compute
different eigenvectors.
This non-uniqueness is caused by the fact that multiplying an eigenvector by a
non-zero number produces another set of valid eigenvectors of the matrix.
In this implmentation, the returned eigenvectors are normalized to have norm
<code>1</code> and largest real component.</p></li>
<li><p>Gradients computed using <code>V</code> will only be finite when <code>A</code> does not have repeated eigenvalues.
Furthermore, if the distance between any two eigenvalues is close to zero,
the gradient will be numerically unstable, as it depends on the eigenvalues
 through the computation of
.</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index">
<ul><li><p><code><a href="linalg_eigvals.html">linalg_eigvals()</a></code> computes only the eigenvalues. Unlike <code>linalg_eig()</code>, the gradients of
<code><a href="linalg_eigvals.html">linalg_eigvals()</a></code> are always numerically stable.</p></li>
<li><p><code><a href="linalg_eigh.html">linalg_eigh()</a></code> for a (faster) function that computes the eigenvalue decomposition
for Hermitian and symmetric matrices.</p></li>
<li><p><code><a href="linalg_svd.html">linalg_svd()</a></code> for a function that computes another type of spectral
decomposition that works on matrices of any shape.</p></li>
<li><p><code><a href="linalg_qr.html">linalg_qr()</a></code> for another (much faster) decomposition that works on matrices of
any shape.</p></li>
</ul><p>Other linalg: 
<code><a href="linalg_cholesky_ex.html">linalg_cholesky_ex</a>()</code>,
<code><a href="linalg_cholesky.html">linalg_cholesky</a>()</code>,
<code><a href="linalg_det.html">linalg_det</a>()</code>,
<code><a href="linalg_eigh.html">linalg_eigh</a>()</code>,
<code><a href="linalg_eigvalsh.html">linalg_eigvalsh</a>()</code>,
<code><a href="linalg_eigvals.html">linalg_eigvals</a>()</code>,
<code><a href="linalg_householder_product.html">linalg_householder_product</a>()</code>,
<code><a href="linalg_inv_ex.html">linalg_inv_ex</a>()</code>,
<code><a href="linalg_inv.html">linalg_inv</a>()</code>,
<code><a href="linalg_lstsq.html">linalg_lstsq</a>()</code>,
<code><a href="linalg_matrix_norm.html">linalg_matrix_norm</a>()</code>,
<code><a href="linalg_matrix_power.html">linalg_matrix_power</a>()</code>,
<code><a href="linalg_matrix_rank.html">linalg_matrix_rank</a>()</code>,
<code><a href="linalg_multi_dot.html">linalg_multi_dot</a>()</code>,
<code><a href="linalg_norm.html">linalg_norm</a>()</code>,
<code><a href="linalg_pinv.html">linalg_pinv</a>()</code>,
<code><a href="linalg_qr.html">linalg_qr</a>()</code>,
<code><a href="linalg_slogdet.html">linalg_slogdet</a>()</code>,
<code><a href="linalg_solve_triangular.html">linalg_solve_triangular</a>()</code>,
<code><a href="linalg_solve.html">linalg_solve</a>()</code>,
<code><a href="linalg_svdvals.html">linalg_svdvals</a>()</code>,
<code><a href="linalg_svd.html">linalg_svd</a>()</code>,
<code><a href="linalg_tensorinv.html">linalg_tensorinv</a>()</code>,
<code><a href="linalg_tensorsolve.html">linalg_tensorsolve</a>()</code>,
<code><a href="linalg_vector_norm.html">linalg_vector_norm</a>()</code></p></div>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="torch_is_installed.html">torch_is_installed</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fu"><a href="torch_randn.html">torch_randn</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">wv</span> <span class="op">&lt;-</span> <span class="fu">linalg_eig</span><span class="op">(</span><span class="va">a</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer></div>

  

  

  </body></html>

