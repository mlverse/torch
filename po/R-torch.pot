msgid ""
msgstr ""
"Project-Id-Version: torch 0.11.0.9002\n"
"POT-Creation-Date: 2023-10-04 00:23+0200\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=CHARSET\n"
"Content-Transfer-Encoding: 8bit\n"

#: R7.R:46
msgid "can only set to public, private and active"
msgstr ""

#: autograd.R:167
msgid "<torch_hook>"
msgstr ""

#: call_torch_function.R:39
msgid ""
"Because this function allows access to unexported functions, please use with "
"caution, and\n"
"            only if you are sure know what you are doing. Unexported "
"functions will expect inputs that\n"
"            are more C++-like than R-like. For example, they will expect all "
"indexes to be 0-based instead\n"
"            of 1-based. In addition unexported functions may be subject to "
"removal from the API without\n"
"            warning. Set quiet = TRUE to silence this warning."
msgstr ""

#: call_torch_function.R:47
msgid "Only functions prefixed with 'torch_' are available from this function."
msgstr ""

#: call_torch_function.R:54
msgid ""
"A function of name %s was not found. Please check your spelling and that the "
"desired function exists."
msgstr ""

#: codegen-utils.R:5
msgid "Dimension is 1-based, but found 0."
msgstr ""

#: codegen-utils.R:40
msgid "%s does not exist"
msgstr ""

#: compilation_unit.R:9
msgid "<torch_compilation_unit>"
msgstr ""

#: creation-ops.R:6 creation-ops.R:12
msgid "You should specify a single size argument."
msgstr ""

#: creation-ops.R:260
msgid "This function is deprecated in favor of torch_arange."
msgstr ""

#: creation-ops.R:380
msgid "values must be length 1"
msgstr ""

#: creation-ops.R:384
msgid "value must be a length 1 vector"
msgstr ""

#: cuda.R:42
msgid "device must be an integer between 0 and the number of devices minus 1"
msgstr ""

#: device.R:12
#, c-format
msgid ""
"type '%s' should not include an index because index was passed explicitly."
msgstr ""

#: device.R:31 jit-execute.R:8 jit-execute.R:10 jit-execute.R:13
#, c-format
msgid "%s"
msgstr ""

#: device.R:110
msgid "y is not a torch_device"
msgstr ""

#: distributions-bernoulli.R:21
msgid "Either `probs` or `logits` must be specified, but not both."
msgstr ""

#: distributions-categorical.R:18
msgid "Either `probs` or `logits` must be specified but not both."
msgstr ""

#: distributions-categorical.R:23
msgid "`probs` must be at least one-dimensional."
msgstr ""

#: distributions-categorical.R:29
msgid "`logits` must be at least one-dimensional."
msgstr ""

#: distributions-constraints.R:38
msgid "Cannot determine validity of dependent constraint"
msgstr ""

#: distributions-constraints.R:60
msgid "Expected value$dim() >= %s but got %s"
msgstr ""

#: distributions-mixture_same_family.R:20
msgid "Mixture distribution must be distr_categorical."
msgstr ""

#: distributions-mixture_same_family.R:24
msgid "Component distribution must be an instance of torch_Distribution."
msgstr ""

#: distributions-mixture_same_family.R:32
msgid ""
"Mixture distribution component (%s) does not equal "
"component_distribution$batch_shape[-1] (%s)."
msgstr ""

#: distributions-multivariate_normal.R:81
msgid "loc must be at least one-dimensional."
msgstr ""

#: distributions-multivariate_normal.R:86
msgid ""
"Exactly one of covariance_matrix or precision_matrix or scale_tril may be "
"specified."
msgstr ""

#: distributions-multivariate_normal.R:93
msgid "scale_tril matrix must be at least two-dimensional"
msgstr ""

#: distributions-multivariate_normal.R:94 distributions-multivariate_normal.R:104 distributions-multivariate_normal.R:116
msgid "with optional leading batch dimensions"
msgstr ""

#: distributions-multivariate_normal.R:103
msgid "covariance_matrix matrix must be at least two-dimensional"
msgstr ""

#: distributions-multivariate_normal.R:115
msgid "precision_matrix matrix must be at least two-dimensional"
msgstr ""

#: distributions.R:169
msgid "The value argument to log_prob must be a Tensor"
msgstr ""

#: distributions.R:176
msgid "The right-most size of value must match event_shape: %s vs %s."
msgstr ""

#: distributions.R:192
msgid "Value is not broadcastable with batch_shape+event_shape: %s vs %s."
msgstr ""

#: distributions.R:199
msgid "The value argument must be within the support"
msgstr ""

#: distributions.R:275
msgid ""
"Subclass %s of %s that defines a custom `initialize()` method must also "
"define a custom `expand()` method."
msgstr ""

#: dtype.R:9 layout.R:9 qscheme.R:9
#, c-format
msgid "torch_%s"
msgstr ""

#: dtype.R:162
msgid "One of the objects is not a dtype. Comparison is not possible."
msgstr ""

#: generator.R:13
msgid "torch_generator()"
msgstr ""

#: generator.R:17
msgid "bit64 is required to correctly show the seed."
msgstr ""

#: generator.R:24
msgid "Seed must an integer or integer64."
msgstr ""

#: indexing.R:38
msgid "<slice>"
msgstr ""

#: install.R:542
msgid "Unexpected value"
msgstr ""

#: ivalue.R:12
msgid "Argument 'x' must be a list."
msgstr ""

#: ivalue.R:29
msgid "Argument 'x' must be scalar atomic."
msgstr ""

#: jit-execute.R:6
msgid "arguments:"
msgstr ""

#: jit-execute.R:12
msgid "returns:"
msgstr ""

#: jit-ops.R:57
#, c-format
msgid "<torch_ops>: Handle to namespace  %s"
msgstr ""

#: jit-ops.R:60
msgid "Object of class <torch_ops>"
msgstr ""

#: lantern_load.R:6
msgid "Torch is not installed, please run 'install_torch()'."
msgstr ""

#: memory_format.R:9
#, c-format
msgid "torch_%s_format"
msgstr ""

#: nn-activation.R:760
msgid "embed_dim must be divisible by num_heads"
msgstr ""

#: nn-batchnorm.R:42 nn-init.R:229 nn-init.R:421
msgid "not implemented"
msgstr ""

#: nn-batchnorm.R:177
msgid "expected 2D or 3D input (got %sD input)"
msgstr ""

#: nn-batchnorm.R:250
msgid "expected 4D input (got %sD input)"
msgstr ""

#: nn-batchnorm.R:329
msgid "expected 5D input (got %sD input)"
msgstr ""

#: nn-conv.R:10
msgid "in_channels must be divisable by groups"
msgstr ""

#: nn-conv.R:14
msgid "out_channels must be divisable by groups"
msgstr ""

#: nn-conv.R:21
msgid "padding_mode must be one of [%s], but got padding_mode='%s'."
msgstr ""

#: nn-conv.R:22
msgid ","
msgstr ""

#: nn-conv.R:509
msgid "Only 'zeros' padding is supported."
msgstr ""

#: nn-conv.R:529
msgid "output_size must have %s or %s elements (got %s)"
msgstr ""

#: nn-conv.R:551
msgid "requested an output of size %s, but valid"
msgstr ""

#: nn-conv.R:552
msgid "sizes range from %s to %s (for an input of size %s)"
msgstr ""

#: nn-conv.R:687
msgid "Only `zeros` padding mode is supported for ConvTranspose1d"
msgstr ""

#: nn-conv.R:844
msgid "Only `zeros` padding mode is supported for ConvTranspose2d"
msgstr ""

#: nn-conv.R:998
msgid "Only `zeros` padding mode is supported for ConvTranspose3d"
msgstr ""

#: nn-dropout.R:8
msgid "dropout probability has to be between 0 and 1 but got %s"
msgstr ""

#: nn-init.R:89
msgid "Unsupported nonlinearity: %s"
msgstr ""

#: nn-loss.R:998
msgid "only p == 1 or p == 2 are supported."
msgstr ""

#: nn-loss.R:1001
msgid "weight must be NULL or 1-dimensional"
msgstr ""

#: nn-pooling.R:685
msgid "both output_size and output_ratio are NULL"
msgstr ""

#: nn-pooling.R:689
msgid "both output_size and output_ratio are not NULL"
msgstr ""

#: nn-pooling.R:694
msgid "output_ratio must be between 0 and 1."
msgstr ""

#: nn-rnn.R:53
msgid "Unrecognized RNN mode: %s"
msgstr ""

#: nn-rnn.R:273
msgid "No cudnn backend for mode '%s'"
msgstr ""

#: nn-rnn.R:395
msgid "Unknown nonlinearity '%s'"
msgstr ""

#: nn-sparse.R:67 nn-sparse.R:70 nn-sparse.R:167 nn-sparse.R:170
msgid "'padding_idx' must be within num_embeddings"
msgstr ""

#: nn-sparse.R:87 nn-sparse.R:187
msgid "Shape of '.weight' does not match num_embeddings and embedding_dim"
msgstr ""

#: nn-utils.R:7
msgid "Input dimension should be at least %s."
msgstr ""

#: nn.R:22
msgid "Forward method is not implemented"
msgstr ""

#: nn.R:106
msgid ""
"nn.Module.to only accepts floating point '\n"
"                      'dtypes, but got desired dtype %s"
msgstr ""

#: nn.R:192
msgid "Could not find %s in the state_dict."
msgstr ""

#: nn.R:278
msgid "It's not possible to modify the parameters list."
msgstr ""

#: nn.R:279 nn.R:295
msgid "You can modify the parameter in-place or use"
msgstr ""

#: nn.R:280 nn.R:296
msgid "`module$parameter_name <- new_value`"
msgstr ""

#: nn.R:294
msgid "It's not possible to modify the buffers list."
msgstr ""

#: nn.R:310
msgid "It's not possible to modify the modules list."
msgstr ""

#: nn.R:311 nn.R:331
msgid "You can modify the modules in-place"
msgstr ""

#: nn.R:330
msgid "It's not possible to modify the children list."
msgstr ""

#: nn.R:351
msgid "`x` must be a tensor."
msgstr ""

#: nn_adaptive.R:108
msgid "not yet implemented"
msgstr ""

#: nnf-activation.R:81
msgid "not yet implemented."
msgstr ""

#: nnf-activation.R:798
msgid "Input should be a tensor and got '%s'."
msgstr ""

#: nnf-embedding.R:83
msgid "if input is 2D, then offsets has to be NULL"
msgstr ""

#: nnf-loss.R:216
msgid "reduction is not valid."
msgstr ""

#: nnf-pooling.R:278
msgid ""
"output_size should be a sequence containing %s or %s elements but it has a "
"length of '%s'"
msgstr ""

#: nnf-pooling.R:451
msgid "output_ratio should not be NULL if output_size is NULL"
msgstr ""

#: nnf-upsampling.R:60
msgid "only one of size or scale_factor should be defined"
msgstr ""

#: nnf-upsampling.R:67
msgid "size shape must match input shape. Input is %sD, size is %s"
msgstr ""

#: nnf-upsampling.R:77
msgid "scale_factor shape must match input shape. Input is %sD, size is %s"
msgstr ""

#: nnf-upsampling.R:82
msgid "either size or scale_factor should be defined"
msgstr ""

#: nnf-upsampling.R:144
msgid "Got 3D input, but bilinear mode needs 4D input"
msgstr ""

#: nnf-upsampling.R:148
msgid "Got 3D input, but trilinear mode needs 5D input"
msgstr ""

#: nnf-upsampling.R:152
msgid "Got 4D input, but trilinear mode needs 3D input"
msgstr ""

#: nnf-upsampling.R:164
msgid "Got 4D input, but trilinear mode needs 5D input"
msgstr ""

#: nnf-upsampling.R:168
msgid "Got 5D input, but trilinear mode needs 3D input"
msgstr ""

#: nnf-upsampling.R:172
msgid "Got 5D input, but bilinear mode needs 4D input"
msgstr ""

#: nnf-vision.R:97
msgid "Unknown mode name '%s'. Supported modes are 'bilinear'"
msgstr ""

#: nnf-vision.R:98
msgid "and 'nearest'."
msgstr ""

#: nnf-vision.R:111
msgid "Unknown padding mode name '%s'. Supported modes are"
msgstr ""

#: nnf-vision.R:112
msgid "'zeros', 'border' and 'reflection'."
msgstr ""

#: operators.R:331 operators.R:339 operators.R:347 operators.R:363 operators.R:379
msgid "Torch tensors do not have NAs!"
msgstr ""

#: optim-adadelta.R:51 optim-adagrad.R:38 optim-adam.R:36 optim-asgd.R:32 optim-rmsprop.R:40 optim-rprop.R:30 optim-sgd.R:61
msgid "Invalid learning rate: %s"
msgstr ""

#: optim-adadelta.R:55
msgid "Invalid rho value: %s"
msgstr ""

#: optim-adadelta.R:63 optim-adagrad.R:46 optim-rmsprop.R:49 optim-sgd.R:69
msgid "Invalid weight_decay value: %s"
msgstr ""

#: optim-adagrad.R:42
msgid "Invalid lr_decay value: %s"
msgstr ""

#: optim-adagrad.R:50
msgid "Invalid initial_accumulator_value value: %s"
msgstr ""

#: optim-adagrad.R:54 optim-rmsprop.R:43
msgid "Invalid epsilon value: %s"
msgstr ""

#: optim-adam.R:40
msgid "Invalid eps: %s"
msgstr ""

#: optim-adam.R:44
msgid "Invalid beta parameter at index 1"
msgstr ""

#: optim-adam.R:48
msgid "Invalid beta parameter at index 2"
msgstr ""

#: optim-adam.R:52 optim-asgd.R:36
msgid "Invalid weight decay value: %s"
msgstr ""

#: optim-lbfgs.R:371
msgid "LBFGS doesn't support per-parameter options"
msgstr ""

#: optim-lbfgs.R:372
msgid "(parameter groups)"
msgstr ""

#: optim-lbfgs.R:527
msgid "only strong_wolfe is supported"
msgstr ""

#: optim-lr_scheduler.R:35
msgid "parameter 'inital_lr' is not specified."
msgstr ""

#: optim-lr_scheduler.R:75
msgid "Adjusting learning rate of group %s to %.4f"
msgstr ""

#: optim-lr_scheduler.R:179 optim-lr_scheduler.R:237
msgid "lr_lambda length (%s) is different from the number of"
msgstr ""

#: optim-lr_scheduler.R:180 optim-lr_scheduler.R:238
msgid "optimizer$param_grpups (%s)"
msgstr ""

#: optim-lr_scheduler.R:425
msgid "You must define either total_steps OR (epochs AND steps_per_epoch)"
msgstr ""

#: optim-lr_scheduler.R:428
msgid "Expected positive integer total_steps, but got %s"
msgstr ""

#: optim-lr_scheduler.R:434
msgid "Expected positive integer epochs, but got %s"
msgstr ""

#: optim-lr_scheduler.R:438
msgid "Expected positive integer steps_per_epoch, but got %s"
msgstr ""

#: optim-lr_scheduler.R:449
msgid "Expected float between 0 and 1 pct_start, but got %s"
msgstr ""

#: optim-lr_scheduler.R:454
msgid "anneal_strategy must by one of 'cos' or 'linear', instead got %s"
msgstr ""

#: optim-lr_scheduler.R:478
msgid "optimizer must support momentum with `cycle momentum` enabled"
msgstr ""

#: optim-lr_scheduler.R:506
msgid "expected %s values for %s but got %s"
msgstr ""

#: optim-lr_scheduler.R:721
msgid "mode %s is unknown!"
msgstr ""

#: optim-lr_scheduler.R:724
msgid "threshold mode %s is unknown!"
msgstr ""

#: optim-rmsprop.R:46 optim-sgd.R:65
msgid "Invalid momentum value: %s"
msgstr ""

#: optim-rmsprop.R:52
msgid "Invalid alpha value: %s"
msgstr ""

#: optim-rprop.R:33
msgid "Invalid eta values: %s, %s"
msgstr ""

#: optim-sgd.R:73
msgid "Nesterov momentum requires a momentum and zero dampening"
msgstr ""

#: optim.R:37
msgid "Wrong parameters specification."
msgstr ""

#: optim.R:48
msgid "param group is not named"
msgstr ""

#: optim.R:59
msgid "optimizer can only optimize Tensors,"
msgstr ""

#: optim.R:60
msgid "but one of the params is %s"
msgstr ""

#: optim.R:65
msgid "can't optimize a non-leaf Tensor"
msgstr ""

#: optim.R:73
msgid "parameter group didn't specify a value of required"
msgstr ""

#: optim.R:74
msgid "optimization parameter %s"
msgstr ""

#: optim.R:113
msgid "Loaded state dict has a different number of parameter groups"
msgstr ""

#: optim.R:118
msgid ""
"Loaded state dict has contains a parameter group that doesn't match the size "
"of optimizers group."
msgstr ""

#: package.R:103
msgid "Aborted."
msgstr ""

#: save.R:304
msgid "currently unsuported"
msgstr ""

#: scalar.R:30
msgid "torch_scalar"
msgstr ""

#: script_module.R:18
msgid "ScriptModule does not support non persistent buffers."
msgstr ""

#: script_module.R:29
msgid "Script modules can only register Script modules children."
msgstr ""

#: script_module.R:173
msgid ""
"Forward is not defined. Methods from submodules of traced modules are not "
"traced. Are you trying to call from a submodule?"
msgstr ""

#: script_module.R:194
msgid "<script_method>"
msgstr ""

#: tensor.R:55
msgid "Indexing starts at 1 and got a 0."
msgstr ""

#: tensor.R:115
msgid "You must pass a cuda device."
msgstr ""

#: tensor.R:180 tensor.R:187
msgid "start indexing starts at 1"
msgstr ""

#: tensor.R:198 tensor.R:216
msgid "Can't set other and dim arguments."
msgstr ""

#: tensor.R:333
msgid "The tensor doesn't have names so you can't rename a dimension."
msgstr ""

#: tensor.R:413
msgid "Can't convert cuda tensor to R. Convert to cpu tensor before."
msgstr ""

#: trace.R:70
msgid "You must initialize the nn_module before tracing."
msgstr ""

#: trace.R:82
msgid "jit_trace needs a function or nn_module."
msgstr ""

#: trace.R:126 trace.R:343
msgid "Only `script_function` or `script_module` can be saved with `jit_save`."
msgstr ""

#: trace.R:185
msgid "<script_function>"
msgstr ""

#: trace.R:281
msgid "`mod` must be a `nn_module()`."
msgstr ""

#: trace.R:285
msgid "Arguments passed trough `...` must be named."
msgstr ""

#: trace.R:292
msgid "Method '%s' does not exist in `mod` and therefore can't be traced."
msgstr ""

#: utils-data-dataloader.R:121
msgid "Could not find an object with name '%s'."
msgstr ""

#: utils-data-dataloader.R:441
msgid "Failed starting the worker."
msgstr ""

#: utils-data-dataloader.R:488 utils-data-dataloader.R:531
msgid "dataloader worker timed out."
msgstr ""

#: wrapers.R:25
msgid "argument 'out' must be a list of Tensors."
msgstr ""

#: wrapers.R:30
#, c-format
msgid "expected tuple of %s elements but got %s"
msgstr ""

#: wrapers.R:184
msgid "tensordot expects dims >= 1, but got %s"
msgstr ""
