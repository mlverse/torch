<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Extending Autograd • torch</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Extending Autograd">
<meta property="og:description" content="torch">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-178883486-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178883486-1');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torch</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.1.1.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Getting started
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Beginers guide</li>
    <li>
      <a href="../articles/getting-started/warmup.html">Warm-up</a>
    </li>
    <li>
      <a href="../articles/getting-started/tensors.html">Tensors</a>
    </li>
    <li>
      <a href="../articles/getting-started/tensors-and-autograd.html">Tensors and autograd</a>
    </li>
    <li>
      <a href="../articles/getting-started/new-autograd-functions.html">Defining new autograd functions</a>
    </li>
    <li>
      <a href="../articles/getting-started/nn.html">nn: neural networks with torch</a>
    </li>
    <li>
      <a href="../articles/getting-started/optim.html">optim: optimizers in torch</a>
    </li>
    <li>
      <a href="../articles/getting-started/custom-nn.html">Custom nn modules</a>
    </li>
    <li>
      <a href="../articles/getting-started/control-flow-and-weight-sharing.html">Control flow &amp; Weight sharing</a>
    </li>
    <li class="dropdown-header">Torch Mechanics</li>
    <li>
      <a href="../articles/getting-started/what-is-torch.html">What's torch?</a>
    </li>
    <li>
      <a href="../articles/getting-started/autograd.html">Autograd: automatic differentiation</a>
    </li>
    <li>
      <a href="../articles/getting-started/neural-networks.html">Neural networks</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/installation.html">Installation</a>
    </li>
    <li class="dropdown-header">Tensors</li>
    <li>
      <a href="../articles/tensor-creation.html">Creating tensors</a>
    </li>
    <li>
      <a href="../articles/indexing.html">Indexing</a>
    </li>
    <li>
      <a href="../articles/tensor/index.html">Tensor class</a>
    </li>
    <li>
      <a href="../articles/serialization.html">Serialization</a>
    </li>
    <li class="dropdown-header">Datasets</li>
    <li>
      <a href="../articles/loading-data.html">Loading Data</a>
    </li>
    <li class="dropdown-header">Autograd</li>
    <li>
      <a href="../articles/using-autograd.html">Using autograd</a>
    </li>
    <li>
      <a href="../articles/extending-autograd.html">Extending autograd</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/examples/basic-autograd.html">basic-autograd</a>
    </li>
    <li>
      <a href="../articles/examples/basic-nn-module.html">basic-nn-module</a>
    </li>
    <li>
      <a href="../articles/examples/dataset.html">dataset</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlverse/torch/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="extending-autograd_files/accessible-code-block-0.0.1/empty-anchor.js"></script><link href="extending-autograd_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet">
<script src="extending-autograd_files/anchor-sections-1.0/anchor-sections.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Extending Autograd</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/master/vignettes/extending-autograd.Rmd"><code>vignettes/extending-autograd.Rmd</code></a></small>
      <div class="hidden name"><code>extending-autograd.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs">torch</a></span><span class="op">)</span></code></pre></div>
<p>Adding operations to autograd requires implementing a new <code>autograd_function</code> for each operation. Recall that <code>autograd_functions</code>s are what <code>autograd</code> uses to compute the results and gradients, and encode the operation history. Every new function requires you to implement 2 methods:</p>
<ul>
<li><p><code>forward()</code> - the code that performs the operation. It can take as many arguments as you want, with some of them being optional, if you specify the default values. All kinds of R objects are accepted here. Tensor arguments that track history (i.e., with <code>requires_grad=TRUE</code>) will be converted to ones that don’t track history before the call, and their use will be registered in the graph. Note that this logic won’t traverse lists or any other data structures and will only consider Tensor’s that are direct arguments to the call. You can return either a single Tensor output, or a list of <code>Tensor</code>s if there are multiple outputs. Also, please refer to the docs of <code>autograd_function</code> to find descriptions of useful methods that can be called only from <code>forward()</code>.</p></li>
<li><p><code>backward()</code> - gradient formula. It will be given as many Tensor arguments as there were outputs, with each of them representing gradient w.r.t. that output. It should return as many <code>Tensor</code>s as there were <code>Tensor's</code> that required gradients in <code>forward</code>, with each of them containing the gradient w.r.t. its corresponding input.</p></li>
</ul>
<div id="note" class="section level2">
<h2 class="hasAnchor">
<a href="#note" class="anchor"></a>Note</h2>
<p>It’s the user’s responsibility to use the special functions in the forward’s <code>ctx</code> properly in order to ensure that the new <code>autograd_function</code> works properly with the autograd engine.</p>
<ul>
<li><p><code>save_for_backward()</code> must be used when saving input or ouput of the forward to be used later in the backward.</p></li>
<li><p><code>mark_dirty()</code> must be used to mark any input that is modified inplace by the forward function.</p></li>
<li><p><code>mark_non_differentiable()</code> must be used to tell the engine if an output is not differentiable.</p></li>
</ul>
</div>
<div id="examples" class="section level2">
<h2 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h2>
<p>Below you can find code for a linear function:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span>
  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">input</span>, <span class="va">weight</span>, <span class="va">bias</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>input <span class="op">=</span> <span class="va">input</span>, weight <span class="op">=</span> <span class="va">weight</span>, bias <span class="op">=</span> <span class="va">bias</span><span class="op">)</span>
    <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">input</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">weight</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">bias</span><span class="op">)</span><span class="op">)</span>
      <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">output</span> <span class="op">+</span> <span class="va">bias</span><span class="op">$</span><span class="fu">unsqueeze</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span><span class="op">$</span><span class="fu">expand_as</span><span class="op">(</span><span class="va">output</span><span class="op">)</span>
    
    <span class="va">output</span>
  <span class="op">}</span>,
  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span>
    
    <span class="va">s</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span>
    
    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      input <span class="op">=</span> <span class="cn">NULL</span>,
      weight <span class="op">=</span> <span class="cn">NULL</span>,
      bias <span class="op">=</span> <span class="cn">NULL</span>
    <span class="op">)</span>
    
    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">input</span><span class="op">)</span>
      <span class="va">grads</span><span class="op">$</span><span class="va">input</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span>
    
    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span>
      <span class="va">grads</span><span class="op">$</span><span class="va">weight</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">input</span><span class="op">)</span>
    
    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html">is.null</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span>
      <span class="va">grads</span><span class="op">$</span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">sum</span><span class="op">(</span>dim <span class="op">=</span> <span class="fl">0</span><span class="op">)</span>
    
    <span class="va">grads</span>
  <span class="op">}</span>
<span class="op">)</span></code></pre></div>
<p>Here, we give an additional example of a function that is parametrized by non-Tensor arguments:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mul_constant</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span>
  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">tensor</span>, <span class="va">constant</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>constant <span class="op">=</span> <span class="va">constant</span><span class="op">)</span>
    <span class="va">tensor</span> <span class="op">*</span> <span class="va">constant</span>
  <span class="op">}</span>,
  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">v</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>
      tensor <span class="op">=</span> <span class="va">grad_output</span> <span class="op">*</span> <span class="va">v</span><span class="op">$</span><span class="va">constant</span>
    <span class="op">)</span>
  <span class="op">}</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_tensor.html">torch_tensor</a></span><span class="op">(</span><span class="fl">1</span>, requires_grad <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">o</span> <span class="op">&lt;-</span> <span class="fu">mul_constant</span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span>
<span class="va">o</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span>
<span class="va">x</span><span class="op">$</span><span class="va">grad</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  2</span>
<span class="co">#&gt; [ CPUFloatType{1} ]</span></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
