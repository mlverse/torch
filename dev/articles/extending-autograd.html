<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Extending Autograd • torch</title>
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Extending Autograd">
<meta name="robots" content="noindex">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZJSKW3L0N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9ZJSKW3L0N');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">torch</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.16.3.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/installation.html">Installation</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Tensors</h6></li>
    <li><a class="dropdown-item" href="../articles/tensor-creation.html">Creating tensors</a></li>
    <li><a class="dropdown-item" href="../articles/indexing.html">Indexing</a></li>
    <li><a class="dropdown-item" href="../articles/tensor/index.html">Tensor class</a></li>
    <li><a class="dropdown-item" href="../articles/serialization.html">Serialization</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Datasets</h6></li>
    <li><a class="dropdown-item" href="../articles/loading-data.html">Loading Data</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Autograd</h6></li>
    <li><a class="dropdown-item" href="../articles/using-autograd.html">Using autograd</a></li>
    <li><a class="dropdown-item" href="../articles/extending-autograd.html">Extending autograd</a></li>
    <li><a class="dropdown-item" href="../articles/python-to-r.html">Python models</a></li>
    <li><a class="dropdown-item" href="../articles/torchscript.html">Jit Compilation</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="../articles/examples/basic-autograd.html">basic-autograd</a></li>
    <li><a class="dropdown-item" href="../articles/examples/basic-nn-module.html">basic-nn-module</a></li>
    <li><a class="dropdown-item" href="../articles/examples/dataset.html">dataset</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-advanced" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Advanced</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-advanced">
<li><a class="dropdown-item" href="../articles/memory-management.html">Memory management</a></li>
    <li><a class="dropdown-item" href="../articles/compatibility-matrix.html">CUDA compatibility matrix</a></li>
    <li><a class="dropdown-item" href="../articles/modifying-source-code.html">Building locally</a></li>
    <li><a class="dropdown-item" href="../articles/amp.html">Automatic Mixed Precision</a></li>
    <li><a class="dropdown-item" href="../articles/modifying-source-code.html">Modifying source code</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/torch/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Extending Autograd</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/main/vignettes/extending-autograd.Rmd" class="external-link"><code>vignettes/extending-autograd.Rmd</code></a></small>
      <div class="d-none name"><code>extending-autograd.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs">torch</a></span><span class="op">)</span></span></code></pre></div>
<p>Adding operations to autograd requires implementing a new
<code>autograd_function</code> for each operation. Recall that
<code>autograd_functions</code>s are what <code>autograd</code> uses to
compute the results and gradients, and encode the operation history.
Every new function requires you to implement 2 methods:</p>
<ul>
<li><p><code>forward()</code> - the code that performs the operation. It
can take as many arguments as you want, with some of them being
optional, if you specify the default values. All kinds of R objects are
accepted here. Tensor arguments that track history (i.e., with
<code>requires_grad=TRUE</code>) will be converted to ones that don’t
track history before the call, and their use will be registered in the
graph. Note that this logic won’t traverse lists or any other data
structures and will only consider Tensor’s that are direct arguments to
the call. You can return either a single Tensor output, or a list of
<code>Tensor</code>s if there are multiple outputs. Also, please refer
to the docs of <code>autograd_function</code> to find descriptions of
useful methods that can be called only from
<code>forward()</code>.</p></li>
<li><p><code>backward()</code> - gradient formula. It will be given as
many Tensor arguments as there were outputs, with each of them
representing gradient w.r.t. that output. It should return as many
<code>Tensor</code>s as there were <code>Tensor's</code> that required
gradients in <code>forward</code>, with each of them containing the
gradient w.r.t. its corresponding input.</p></li>
</ul>
<div class="section level2">
<h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a>
</h2>
<p>It’s the user’s responsibility to use the special functions in the
forward’s <code>ctx</code> properly in order to ensure that the new
<code>autograd_function</code> works properly with the autograd
engine.</p>
<ul>
<li><p><code>save_for_backward()</code> must be used when saving input
or ouput of the forward to be used later in the backward.</p></li>
<li><p><code>mark_dirty()</code> must be used to mark any input that is
modified inplace by the forward function.</p></li>
<li><p><code>mark_non_differentiable()</code> must be used to tell the
engine if an output is not differentiable.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h2>
<p>Below you can find code for a linear function:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span></span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">input</span>, <span class="va">weight</span>, <span class="va">bias</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>input <span class="op">=</span> <span class="va">input</span>, weight <span class="op">=</span> <span class="va">weight</span>, bias <span class="op">=</span> <span class="va">bias</span><span class="op">)</span></span>
<span>    <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">input</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">weight</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">bias</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">output</span> <span class="op">+</span> <span class="va">bias</span><span class="op">$</span><span class="fu">unsqueeze</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span><span class="op">$</span><span class="fu">expand_as</span><span class="op">(</span><span class="va">output</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="va">output</span></span>
<span>  <span class="op">}</span>,</span>
<span>  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="va">s</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span></span>
<span>    </span>
<span>    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      input <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>      weight <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>      bias <span class="op">=</span> <span class="cn">NULL</span></span>
<span>    <span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">input</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">input</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">weight</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">input</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">sum</span><span class="op">(</span>dim <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="va">grads</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Here, we give an additional example of a function that is
parametrized by non-Tensor arguments:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mul_constant</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span></span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">tensor</span>, <span class="va">constant</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>constant <span class="op">=</span> <span class="va">constant</span><span class="op">)</span></span>
<span>    <span class="va">tensor</span> <span class="op">*</span> <span class="va">constant</span></span>
<span>  <span class="op">}</span>,</span>
<span>  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">v</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      tensor <span class="op">=</span> <span class="va">grad_output</span> <span class="op">*</span> <span class="va">v</span><span class="op">$</span><span class="va">constant</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_tensor.html">torch_tensor</a></span><span class="op">(</span><span class="fl">1</span>, requires_grad <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">o</span> <span class="op">&lt;-</span> <span class="fu">mul_constant</span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">o</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">$</span><span class="va">grad</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  2</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ]</span></span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
