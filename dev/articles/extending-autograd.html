<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="torch">
<title>Extending Autograd • torch</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Extending Autograd">
<meta property="og:description" content="torch">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZJSKW3L0N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9ZJSKW3L0N');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">torch</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.11.0.9002</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/installation.html">Installation</a>
    <h6 class="dropdown-header" data-toc-skip>Tensors</h6>
    <a class="dropdown-item" href="../articles/tensor-creation.html">Creating tensors</a>
    <a class="dropdown-item" href="../articles/indexing.html">Indexing</a>
    <a class="dropdown-item" href="../articles/tensor/index.html">Tensor class</a>
    <a class="dropdown-item" href="../articles/serialization.html">Serialization</a>
    <h6 class="dropdown-header" data-toc-skip>Datasets</h6>
    <a class="dropdown-item" href="../articles/loading-data.html">Loading Data</a>
    <h6 class="dropdown-header" data-toc-skip>Autograd</h6>
    <a class="dropdown-item" href="../articles/using-autograd.html">Using autograd</a>
    <a class="dropdown-item" href="../articles/extending-autograd.html">Extending autograd</a>
    <a class="dropdown-item" href="../articles/python-to-r.html">Python models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-examples">Examples</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-examples">
    <a class="dropdown-item" href="../articles/examples/basic-autograd.html">basic-autograd</a>
    <a class="dropdown-item" href="../articles/examples/basic-nn-module.html">basic-nn-module</a>
    <a class="dropdown-item" href="../articles/examples/dataset.html">dataset</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-advanced">Advanced</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-advanced">
    <a class="dropdown-item" href="../articles/memory-management.html">Memory management</a>
    <a class="dropdown-item" href="../articles/modifying-source-code.html">Building locally</a>
    <a class="dropdown-item" href="../articles/amp.html">Automatic Mixed Precision</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlverse/torch/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Extending Autograd</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/HEAD/vignettes/extending-autograd.Rmd" class="external-link"><code>vignettes/extending-autograd.Rmd</code></a></small>
      <div class="d-none name"><code>extending-autograd.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs">torch</a></span><span class="op">)</span></span></code></pre></div>
<p>Adding operations to autograd requires implementing a new
<code>autograd_function</code> for each operation. Recall that
<code>autograd_functions</code>s are what <code>autograd</code> uses to
compute the results and gradients, and encode the operation history.
Every new function requires you to implement 2 methods:</p>
<ul>
<li><p><code>forward()</code> - the code that performs the operation. It
can take as many arguments as you want, with some of them being
optional, if you specify the default values. All kinds of R objects are
accepted here. Tensor arguments that track history (i.e., with
<code>requires_grad=TRUE</code>) will be converted to ones that don’t
track history before the call, and their use will be registered in the
graph. Note that this logic won’t traverse lists or any other data
structures and will only consider Tensor’s that are direct arguments to
the call. You can return either a single Tensor output, or a list of
<code>Tensor</code>s if there are multiple outputs. Also, please refer
to the docs of <code>autograd_function</code> to find descriptions of
useful methods that can be called only from
<code>forward()</code>.</p></li>
<li><p><code>backward()</code> - gradient formula. It will be given as
many Tensor arguments as there were outputs, with each of them
representing gradient w.r.t. that output. It should return as many
<code>Tensor</code>s as there were <code>Tensor's</code> that required
gradients in <code>forward</code>, with each of them containing the
gradient w.r.t. its corresponding input.</p></li>
</ul>
<div class="section level2">
<h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a>
</h2>
<p>It’s the user’s responsibility to use the special functions in the
forward’s <code>ctx</code> properly in order to ensure that the new
<code>autograd_function</code> works properly with the autograd
engine.</p>
<ul>
<li><p><code>save_for_backward()</code> must be used when saving input
or ouput of the forward to be used later in the backward.</p></li>
<li><p><code>mark_dirty()</code> must be used to mark any input that is
modified inplace by the forward function.</p></li>
<li><p><code>mark_non_differentiable()</code> must be used to tell the
engine if an output is not differentiable.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h2>
<p>Below you can find code for a linear function:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span></span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">input</span>, <span class="va">weight</span>, <span class="va">bias</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>input <span class="op">=</span> <span class="va">input</span>, weight <span class="op">=</span> <span class="va">weight</span>, bias <span class="op">=</span> <span class="va">bias</span><span class="op">)</span></span>
<span>    <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">input</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">weight</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">bias</span><span class="op">)</span><span class="op">)</span></span>
<span>      <span class="va">output</span> <span class="op">&lt;-</span> <span class="va">output</span> <span class="op">+</span> <span class="va">bias</span><span class="op">$</span><span class="fu">unsqueeze</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span><span class="op">$</span><span class="fu">expand_as</span><span class="op">(</span><span class="va">output</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="va">output</span></span>
<span>  <span class="op">}</span>,</span>
<span>  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="va">s</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span></span>
<span>    </span>
<span>    <span class="va">grads</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      input <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>      weight <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>      bias <span class="op">=</span> <span class="cn">NULL</span></span>
<span>    <span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">input</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">input</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">weight</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">weight</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">t</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="fu">mm</span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">input</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">s</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="va">ctx</span><span class="op">$</span><span class="va">needs_input_grad</span><span class="op">$</span><span class="va">bias</span><span class="op">)</span></span>
<span>      <span class="va">grads</span><span class="op">$</span><span class="va">bias</span> <span class="op">&lt;-</span> <span class="va">grad_output</span><span class="op">$</span><span class="fu">sum</span><span class="op">(</span>dim <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span>    </span>
<span>    <span class="va">grads</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Here, we give an additional example of a function that is
parametrized by non-Tensor arguments:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mul_constant</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/autograd_function.html">autograd_function</a></span><span class="op">(</span></span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">tensor</span>, <span class="va">constant</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ctx</span><span class="op">$</span><span class="fu">save_for_backward</span><span class="op">(</span>constant <span class="op">=</span> <span class="va">constant</span><span class="op">)</span></span>
<span>    <span class="va">tensor</span> <span class="op">*</span> <span class="va">constant</span></span>
<span>  <span class="op">}</span>,</span>
<span>  backward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">ctx</span>, <span class="va">grad_output</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">v</span> <span class="op">&lt;-</span> <span class="va">ctx</span><span class="op">$</span><span class="va">saved_variables</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      tensor <span class="op">=</span> <span class="va">grad_output</span> <span class="op">*</span> <span class="va">v</span><span class="op">$</span><span class="va">constant</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_tensor.html">torch_tensor</a></span><span class="op">(</span><span class="fl">1</span>, requires_grad <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">o</span> <span class="op">&lt;-</span> <span class="fu">mul_constant</span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">o</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">$</span><span class="va">grad</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  2</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ]</span></span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
