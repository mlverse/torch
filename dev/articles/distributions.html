<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Distributions • torch</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Distributions">
<meta property="og:description" content="torch">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-178883486-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178883486-1');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torch</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.5.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/installation.html">Installation</a>
    </li>
    <li class="dropdown-header">Tensors</li>
    <li>
      <a href="../articles/tensor-creation.html">Creating tensors</a>
    </li>
    <li>
      <a href="../articles/indexing.html">Indexing</a>
    </li>
    <li>
      <a href="../articles/tensor/index.html">Tensor class</a>
    </li>
    <li>
      <a href="../articles/serialization.html">Serialization</a>
    </li>
    <li class="dropdown-header">Datasets</li>
    <li>
      <a href="../articles/loading-data.html">Loading Data</a>
    </li>
    <li class="dropdown-header">Autograd</li>
    <li>
      <a href="../articles/using-autograd.html">Using autograd</a>
    </li>
    <li>
      <a href="../articles/extending-autograd.html">Extending autograd</a>
    </li>
    <li>
      <a href="../articles/python-to-r.html">Python models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/examples/basic-autograd.html">basic-autograd</a>
    </li>
    <li>
      <a href="../articles/examples/basic-nn-module.html">basic-nn-module</a>
    </li>
    <li>
      <a href="../articles/examples/dataset.html">dataset</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlverse/torch/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="distributions_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Distributions</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/master/vignettes/distributions.Rmd"><code>vignettes/distributions.Rmd</code></a></small>
      <div class="hidden name"><code>distributions.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs">torch</a></span><span class="op">)</span>
<span class="fu"><a href="../reference/torch_manual_seed.html">torch_manual_seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># setting seed for reproducibility</span></code></pre></div>
<p>This vignette showcases the basic functionality of distributions in torch. Currently the distributions modules are considered ‘work in progress’ and are still experimental features in the torch package. You can see the progress in this <a href="https://github.com/mlverse/torch/issues/479">link</a>.</p>
<p>The distributions modules in torch are modelled after PyTorch’s <a href="https://pytorch.org/docs/stable/distributions.html#">distributions module</a> which in turn is based on the TensorFlow <a href="https://arxiv.org/abs/1711.10604">Distributions package</a>.</p>
<p>This vignette is based in the TensorFlow’s distributions <a href="https://www.tensorflow.org/probability/examples/TensorFlow_Distributions_Tutorial#basic_univariate_distributions">tutorial</a>.</p>
<div id="basic-univariate-distributions" class="section level2">
<h2 class="hasAnchor">
<a href="#basic-univariate-distributions" class="anchor"></a>Basic univariate distributions</h2>
<p>Let’s start and create a new instance of a normal distribution:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distr_normal.html">distr_normal</a></span><span class="op">(</span>loc <span class="op">=</span> <span class="fl">0</span>, scale <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">n</span>
<span class="co">#&gt; torch_Normal ()</span></code></pre></div>
<p>We can draw samples from it with:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  1.0759</span>
<span class="co">#&gt; [ CPUFloatType{1} ]</span></code></pre></div>
<p>or, draw multiple samples:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt; -0.8603</span>
<span class="co">#&gt;  0.0332</span>
<span class="co">#&gt; -0.3031</span>
<span class="co">#&gt; [ CPUFloatType{3,1} ]</span></code></pre></div>
<p>We can evaluate the log probability of values:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt; -0.9189</span>
<span class="co">#&gt; [ CPUFloatType{1} ]</span>
<span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="co"># equivalent R code</span>
<span class="co">#&gt; [1] -0.9189385</span></code></pre></div>
<p>or, evaluate multiple log probabilities:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt; -0.9189</span>
<span class="co">#&gt; -2.9189</span>
<span class="co">#&gt; -8.9189</span>
<span class="co">#&gt; [ CPUFloatType{3} ]</span></code></pre></div>
</div>
<div id="multiple-distributions" class="section level2">
<h2 class="hasAnchor">
<a href="#multiple-distributions" class="anchor"></a>Multiple distributions</h2>
<p>A distribution can take a tensor as it’s parameters:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distr_bernoulli.html">distr_bernoulli</a></span><span class="op">(</span>probs <span class="op">=</span> <span class="fu"><a href="../reference/torch_tensor.html">torch_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">b</span>
<span class="co">#&gt; torch_Bernoulli ()</span></code></pre></div>
<p>This object represents 3 independent Bernoulli distributions, one for each element of the tensor.</p>
<p>We can sample a single observation:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">b</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  0</span>
<span class="co">#&gt;  1</span>
<span class="co">#&gt;  1</span>
<span class="co">#&gt; [ CPUFloatType{3} ]</span></code></pre></div>
<p>or, a batch of <code>n</code> observations:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">b</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">6</span><span class="op">)</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  0  1  0</span>
<span class="co">#&gt;  0  0  1</span>
<span class="co">#&gt;  0  0  1</span>
<span class="co">#&gt;  0  1  1</span>
<span class="co">#&gt;  0  0  1</span>
<span class="co">#&gt;  0  0  1</span>
<span class="co">#&gt; [ CPUFloatType{6,3} ]</span></code></pre></div>
</div>
<div id="using-distributions-within-models" class="section level2">
<h2 class="hasAnchor">
<a href="#using-distributions-within-models" class="anchor"></a>Using distributions within models</h2>
<p>The <code>log_prob</code> method of distributions can be differentiated, thus, distributions can be used to train models in torch.</p>
<p>Let’s implement a Gaussian linear model, but first let’s simulate some data</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_randn.html">torch_randn</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="va">x</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="../reference/torch_randn.html">torch_randn</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">1</span><span class="op">)</span></code></pre></div>
<p>and plot:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="distributions_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
<p>We can now define our model:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">GaussianLinear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_module.html">nn_module</a></span><span class="op">(</span>
  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># this linear predictor will estimate the mean of the normal distribution</span>
    <span class="va">self</span><span class="op">$</span><span class="va">linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_linear.html">nn_linear</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>
    <span class="co"># this parameter will hold the estimate of the variability</span>
    <span class="va">self</span><span class="op">$</span><span class="va">scale</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_parameter.html">nn_parameter</a></span><span class="op">(</span><span class="fu"><a href="../reference/torch_ones.html">torch_ones</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>,
  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># we estimate the mean</span>
    <span class="va">loc</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">linear</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="co"># return a normal distribution</span>
    <span class="fu"><a href="../reference/distr_normal.html">distr_normal</a></span><span class="op">(</span><span class="va">loc</span>, <span class="va">self</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">)</span>

<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">GaussianLinear</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p>We can now train our model with:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">opt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optim_sgd.html">optim_sgd</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>

<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">opt</span><span class="op">$</span><span class="fu">zero_grad</span><span class="op">(</span><span class="op">)</span>
  <span class="va">d</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_mean.html">torch_mean</a></span><span class="op">(</span><span class="op">-</span><span class="va">d</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>
  <span class="va">loss</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span>
  <span class="va">opt</span><span class="op">$</span><span class="fu">step</span><span class="op">(</span><span class="op">)</span>
  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op">%%</span> <span class="fl">10</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"iter: "</span>, <span class="va">i</span>, <span class="st">" loss: "</span>, <span class="va">loss</span><span class="op">$</span><span class="fu">item</span><span class="op">(</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span>
<span class="op">}</span>
<span class="co">#&gt; iter:  10  loss:  1.809854 </span>
<span class="co">#&gt; iter:  20  loss:  1.606322 </span>
<span class="co">#&gt; iter:  30  loss:  1.46065 </span>
<span class="co">#&gt; iter:  40  loss:  1.399433 </span>
<span class="co">#&gt; iter:  50  loss:  1.39078 </span>
<span class="co">#&gt; iter:  60  loss:  1.390136 </span>
<span class="co">#&gt; iter:  70  loss:  1.390089 </span>
<span class="co">#&gt; iter:  80  loss:  1.390086 </span>
<span class="co">#&gt; iter:  90  loss:  1.390085 </span>
<span class="co">#&gt; iter:  100  loss:  1.390085</span></code></pre></div>
<p>We can see the parameter estimates with:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model</span><span class="op">$</span><span class="va">parameters</span>
<span class="co">#&gt; $linear.weight</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  1.9772</span>
<span class="co">#&gt; [ CPUFloatType{1,1} ]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $linear.bias</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  1.0390</span>
<span class="co">#&gt; [ CPUFloatType{1} ]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $scale</span>
<span class="co">#&gt; torch_tensor</span>
<span class="co">#&gt;  0.9716</span>
<span class="co">#&gt; [ CPUFloatType{1} ]</span></code></pre></div>
<p>and quickly compare with the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = as.numeric(y) ~ as.numeric(x))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -2.5311  -0.6277  -0.1177   0.5544   3.3037  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)    1.03900    0.09844   10.55   &lt;2e-16 ***</span>
<span class="co">#&gt; as.numeric(x)  1.97723    0.09392   21.05   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.963191)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 521.260  on 99  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:  94.393  on 98  degrees of freedom</span>
<span class="co">#&gt; AIC: 284.02</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
