<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Distributions • torch</title>
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Distributions">
<meta name="robots" content="noindex">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-9ZJSKW3L0N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9ZJSKW3L0N');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">torch</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">0.16.3.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/installation.html">Installation</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Tensors</h6></li>
    <li><a class="dropdown-item" href="../articles/tensor-creation.html">Creating tensors</a></li>
    <li><a class="dropdown-item" href="../articles/indexing.html">Indexing</a></li>
    <li><a class="dropdown-item" href="../articles/tensor/index.html">Tensor class</a></li>
    <li><a class="dropdown-item" href="../articles/serialization.html">Serialization</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Datasets</h6></li>
    <li><a class="dropdown-item" href="../articles/loading-data.html">Loading Data</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Autograd</h6></li>
    <li><a class="dropdown-item" href="../articles/using-autograd.html">Using autograd</a></li>
    <li><a class="dropdown-item" href="../articles/extending-autograd.html">Extending autograd</a></li>
    <li><a class="dropdown-item" href="../articles/python-to-r.html">Python models</a></li>
    <li><a class="dropdown-item" href="../articles/torchscript.html">Jit Compilation</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="../articles/examples/basic-autograd.html">basic-autograd</a></li>
    <li><a class="dropdown-item" href="../articles/examples/basic-nn-module.html">basic-nn-module</a></li>
    <li><a class="dropdown-item" href="../articles/examples/dataset.html">dataset</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-advanced" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Advanced</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-advanced">
<li><a class="dropdown-item" href="../articles/memory-management.html">Memory management</a></li>
    <li><a class="dropdown-item" href="../articles/compatibility-matrix.html">CUDA compatibility matrix</a></li>
    <li><a class="dropdown-item" href="../articles/modifying-source-code.html">Building locally</a></li>
    <li><a class="dropdown-item" href="../articles/amp.html">Automatic Mixed Precision</a></li>
    <li><a class="dropdown-item" href="../articles/modifying-source-code.html">Modifying source code</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/torch/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Distributions</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torch/blob/main/vignettes/distributions.Rmd" class="external-link"><code>vignettes/distributions.Rmd</code></a></small>
      <div class="d-none name"><code>distributions.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs">torch</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/torch_manual_seed.html">torch_manual_seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span> <span class="co"># setting seed for reproducibility</span></span></code></pre></div>
<p>This vignette showcases the basic functionality of distributions in
torch. Currently the distributions modules are considered ‘work in
progress’ and are still experimental features in the torch package. You
can see the progress in this <a href="https://github.com/mlverse/torch/issues/479" class="external-link">link</a>.</p>
<p>The distributions modules in torch are modelled after PyTorch’s <a href="https://docs.pytorch.org/docs/stable/distributions.html#" class="external-link">distributions
module</a> which in turn is based on the TensorFlow <a href="https://arxiv.org/abs/1711.10604" class="external-link">Distributions package</a>.</p>
<p>This vignette is based in the TensorFlow’s distributions <a href="https://www.tensorflow.org/probability/examples/TensorFlow_Distributions_Tutorial#basic_univariate_distributions" class="external-link">tutorial</a>.</p>
<div class="section level2">
<h2 id="basic-univariate-distributions">Basic univariate distributions<a class="anchor" aria-label="anchor" href="#basic-univariate-distributions"></a>
</h2>
<p>Let’s start and create a new instance of a normal distribution:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distr_normal.html">distr_normal</a></span><span class="op">(</span>loc <span class="op">=</span> <span class="fl">0</span>, scale <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">n</span></span>
<span><span class="co">#&gt; torch_Normal ()</span></span></code></pre></div>
<p>We can draw samples from it with:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  0.6614</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ]</span></span></code></pre></div>
<p>or, draw multiple samples:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  0.2669</span></span>
<span><span class="co">#&gt;  0.0617</span></span>
<span><span class="co">#&gt;  0.6213</span></span>
<span><span class="co">#&gt; [ CPUFloatType{3,1} ]</span></span></code></pre></div>
<p>We can evaluate the log probability of values:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt; -0.9189</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="co"># equivalent R code</span></span>
<span><span class="co">#&gt; [1] -0.9189385</span></span></code></pre></div>
<p>or, evaluate multiple log probabilities:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt; -0.9189</span></span>
<span><span class="co">#&gt; -2.9189</span></span>
<span><span class="co">#&gt; -8.9189</span></span>
<span><span class="co">#&gt; [ CPUFloatType{3} ]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="multiple-distributions">Multiple distributions<a class="anchor" aria-label="anchor" href="#multiple-distributions"></a>
</h2>
<p>A distribution can take a tensor as it’s parameters:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/distr_bernoulli.html">distr_bernoulli</a></span><span class="op">(</span>probs <span class="op">=</span> <span class="fu"><a href="../reference/torch_tensor.html">torch_tensor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">b</span></span>
<span><span class="co">#&gt; torch_Bernoulli ()</span></span></code></pre></div>
<p>This object represents 3 independent Bernoulli distributions, one for
each element of the tensor.</p>
<p>We can sample a single observation:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  0</span></span>
<span><span class="co">#&gt;  1</span></span>
<span><span class="co">#&gt;  1</span></span>
<span><span class="co">#&gt; [ CPUFloatType{3} ]</span></span></code></pre></div>
<p>or, a batch of <code>n</code> observations:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">b</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">6</span><span class="op">)</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  0  0  1</span></span>
<span><span class="co">#&gt;  0  1  1</span></span>
<span><span class="co">#&gt;  0  0  1</span></span>
<span><span class="co">#&gt;  0  1  1</span></span>
<span><span class="co">#&gt;  0  1  1</span></span>
<span><span class="co">#&gt;  0  0  1</span></span>
<span><span class="co">#&gt; [ CPUFloatType{6,3} ]</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="using-distributions-within-models">Using distributions within models<a class="anchor" aria-label="anchor" href="#using-distributions-within-models"></a>
</h2>
<p>The <code>log_prob</code> method of distributions can be
differentiated, thus, distributions can be used to train models in
torch.</p>
<p>Let’s implement a Gaussian linear model, but first let’s simulate
some data</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_randn.html">torch_randn</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="va">x</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="../reference/torch_randn.html">torch_randn</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>and plot:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="distributions_files/figure-html/unnamed-chunk-11-1.png" class="r-plt" width="700"></p>
<p>We can now define our model:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">GaussianLinear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_module.html">nn_module</a></span><span class="op">(</span></span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># this linear predictor will estimate the mean of the normal distribution</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_linear.html">nn_linear</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span></span>
<span>    <span class="co"># this parameter will hold the estimate of the variability</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">scale</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/nn_parameter.html">nn_parameter</a></span><span class="op">(</span><span class="fu"><a href="../reference/torch_ones.html">torch_ones</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># we estimate the mean</span></span>
<span>    <span class="va">loc</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">linear</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>    <span class="co"># return a normal distribution</span></span>
<span>    <span class="fu"><a href="../reference/distr_normal.html">distr_normal</a></span><span class="op">(</span><span class="va">loc</span>, <span class="va">self</span><span class="op">$</span><span class="va">scale</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">GaussianLinear</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>We can now train our model with:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">opt</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/optim_sgd.html">optim_sgd</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">parameters</span>, lr <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">opt</span><span class="op">$</span><span class="fu">zero_grad</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">d</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/torch_mean.html">torch_mean</a></span><span class="op">(</span><span class="op">-</span><span class="va">d</span><span class="op">$</span><span class="fu">log_prob</span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">loss</span><span class="op">$</span><span class="fu">backward</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">opt</span><span class="op">$</span><span class="fu">step</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op"><a href="https://rdrr.io/r/base/Arithmetic.html" class="external-link">%%</a></span> <span class="fl">10</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"iter: "</span>, <span class="va">i</span>, <span class="st">" loss: "</span>, <span class="va">loss</span><span class="op">$</span><span class="fu">item</span><span class="op">(</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="co">#&gt; iter:  10  loss:  1.975727 </span></span>
<span><span class="co">#&gt; iter:  20  loss:  1.790831 </span></span>
<span><span class="co">#&gt; iter:  30  loss:  1.64495 </span></span>
<span><span class="co">#&gt; iter:  40  loss:  1.532009 </span></span>
<span><span class="co">#&gt; iter:  50  loss:  1.478054 </span></span>
<span><span class="co">#&gt; iter:  60  loss:  1.465937 </span></span>
<span><span class="co">#&gt; iter:  70  loss:  1.464229 </span></span>
<span><span class="co">#&gt; iter:  80  loss:  1.464002 </span></span>
<span><span class="co">#&gt; iter:  90  loss:  1.463971 </span></span>
<span><span class="co">#&gt; iter:  100  loss:  1.463967</span></span></code></pre></div>
<p>We can see the parameter estimates with:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span><span class="op">$</span><span class="va">parameters</span></span>
<span><span class="co">#&gt; $linear.weight</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  2.1256</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1,1} ][ requires_grad = TRUE ]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $linear.bias</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  1.1215</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ][ requires_grad = TRUE ]</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $scale</span></span>
<span><span class="co">#&gt; torch_tensor</span></span>
<span><span class="co">#&gt;  1.0461</span></span>
<span><span class="co">#&gt; [ CPUFloatType{1} ][ requires_grad = TRUE ]</span></span></code></pre></div>
<p>and quickly compare with the <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code> function:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = as.numeric(y) ~ as.numeric(x))</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)     1.1226     0.1057   10.62   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; as.numeric(x)   2.1259     0.1009   21.08   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 1.116565)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 605.56  on 99  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 109.42  on 98  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 298.79</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel Falbel, Javier Luraschi.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
