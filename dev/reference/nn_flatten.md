# Flattens a contiguous range of dims into a tensor.

For use with
[nn_sequential](https://torch.mlverse.org/docs/dev/reference/nn_sequential.md).

## Usage

``` r
nn_flatten(start_dim = 2, end_dim = -1)
```

## Arguments

- start_dim:

  first dim to flatten (default = 2).

- end_dim:

  last dim to flatten (default = -1).

## Shape

- Input: `(*, S_start,..., S_i, ..., S_end, *)`, where `S_i` is the size
  at dimension `i` and `*` means any number of dimensions including
  none.

- Output: `(*, S_start*...*S_i*...S_end, *)`.

## See also

[nn_unflatten](https://torch.mlverse.org/docs/dev/reference/nn_unflatten.md)

## Examples

``` r
if (torch_is_installed()) {
input <- torch_randn(32, 1, 5, 5)
m <- nn_flatten()
m(input)
}
#> torch_tensor
#> Columns 1 to 10-0.6429 -0.5294 -0.4247 -0.0484 -0.4897 -1.1153  0.0505 -1.5148 -0.1747 -0.1347
#> -0.1646 -1.5854  1.4758 -0.6681 -1.2645 -0.8804 -0.0436  0.0190 -0.3135 -0.5915
#>  0.1070  0.9739 -1.0158  1.8865  0.6655 -0.4395 -0.7636  0.3178 -0.2334 -1.1048
#> -0.7868  1.9052 -0.9302  0.5628  1.2051 -1.3437  1.5161 -1.7542  0.9931 -1.5291
#>  1.9660  0.0230 -0.8242  0.6373  0.6375  0.4988 -0.3707  0.3691 -0.5110 -1.1121
#> -1.5463 -1.1067 -1.0029  0.0735  0.8916 -0.8892  0.9048 -1.4451 -1.7605  1.0588
#> -0.7127 -1.1931  0.4038 -0.5458  0.0635 -1.0604 -0.2159 -0.9745  1.0466  1.2605
#>  0.1315  0.6056  1.1179  0.3201  0.2743  0.0387  1.1648  0.0098 -0.5288  0.0537
#>  1.2207 -0.7391  1.1145 -0.0647 -1.1427  1.1837 -0.9709 -1.0754  0.2381  0.5544
#> -0.0300  1.0742 -0.2844  0.3491  0.2348  0.3587 -0.4330 -0.3230 -1.2334 -0.3282
#>  1.0476 -0.3145  0.7863  0.9906  0.0753 -1.4879  0.4844 -0.3041  0.3961 -0.2763
#> -0.7196  0.5712  0.2582  0.1950  0.4715 -0.5995  0.3805 -1.0940  0.3576  0.7134
#> -0.6694  0.8962  0.8689 -1.2329 -0.4567 -0.7133 -0.0236 -1.6728  0.6380  2.4079
#> -0.9598  0.3578  1.5662  1.2720  1.1613  0.4847  0.6251 -0.4267 -0.5745 -0.4699
#> -1.6793  0.6375  0.1103  0.4225 -1.0364  0.2404 -0.6739 -1.1686 -0.3891 -0.4651
#> -1.4087 -0.2563 -0.9943 -0.2683  1.4697 -1.0659  2.7913  0.8647  0.4448 -0.5497
#>  0.6839  0.3895  0.5475  0.4859  1.1967 -0.4233  0.3568 -0.5458 -0.8901 -0.7622
#> -1.6098  0.4886  0.3612  1.4765 -1.7792 -0.1514  0.1944 -0.1485 -0.4847  0.1902
#> -0.6571  0.3277  0.0468 -1.7028  1.2138 -0.2619 -0.1426 -0.0162 -0.6235 -1.0341
#>  0.2046 -0.1437 -0.5475  0.6729 -0.5890  0.3135 -0.5039 -0.9780  0.9577 -1.3205
#>  0.2873 -1.3708 -1.0415  0.8238  1.2388 -0.4261  0.0820  0.1078 -0.8140  1.7176
#> -0.9600  0.5031  1.0972 -0.6251  0.0808  1.2449 -1.8682  1.3527  0.8382 -0.5810
#> -0.0160 -0.6524 -0.6736 -0.8595  0.6583  1.4212  0.4011 -0.9488  1.2831 -1.5084
#> -1.1344 -1.4641 -1.0579  0.2389 -0.9691 -0.0097  0.4247  1.5109 -0.3584 -1.9691
#> -0.2624  0.9898 -0.8464 -1.4630  0.1665 -0.1574  0.3735 -0.2013 -0.1473  1.6818
#> -1.3414  0.2565  0.0558 -2.2440 -1.5408 -0.1393  0.0891  0.5273  1.3971 -0.5531
#> -0.3387 -0.7813 -0.1816  0.0246  1.4359  0.9427  0.4985 -0.3603 -0.3519  0.0100
#>  0.3563 -0.2717  0.8112 -1.3431  1.5576 -0.8859 -0.2877 -0.1507  0.2368  0.8163
#> -0.4022  0.3349 -0.2928  0.8134  1.5050  0.0244  0.8674 -0.1797 -0.0051  1.5898
#>  0.3749 -0.5531 -0.1117  0.2847 -0.3812  0.1535 -0.5357 -1.2727  0.4833 -0.4878
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{32,25} ]
```
