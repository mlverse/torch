# Flattens a contiguous range of dims into a tensor.

For use with
[nn_sequential](https://torch.mlverse.org/docs/dev/reference/nn_sequential.md).

## Usage

``` r
nn_flatten(start_dim = 2, end_dim = -1)
```

## Arguments

- start_dim:

  first dim to flatten (default = 2).

- end_dim:

  last dim to flatten (default = -1).

## Shape

- Input: `(*, S_start,..., S_i, ..., S_end, *)`, where `S_i` is the size
  at dimension `i` and `*` means any number of dimensions including
  none.

- Output: `(*, S_start*...*S_i*...S_end, *)`.

## See also

[nn_unflatten](https://torch.mlverse.org/docs/dev/reference/nn_unflatten.md)

## Examples

``` r
if (torch_is_installed()) {
input <- torch_randn(32, 1, 5, 5)
m <- nn_flatten()
m(input)
}
#> torch_tensor
#> Columns 1 to 10-2.4549  0.4013  1.0134  0.0602  1.5341 -0.6632 -1.4958  0.6551 -1.3792  0.0114
#> -0.6747  1.3312  0.7555 -2.5813 -0.7115  0.9597  0.4947  1.6389 -0.0619 -0.7485
#> -0.2543 -0.3317 -0.5540 -0.1980  1.0988  0.8276 -0.6155  3.0057  0.1517  0.8010
#> -0.1017  0.1609 -0.1576  2.2308 -1.2295 -0.0915  1.4866 -1.6887 -0.7022 -0.2444
#> -0.2202 -0.1597  0.7498 -0.6021 -0.0398  0.0530 -0.2982 -0.0196  1.6901  0.4197
#>  0.3301 -0.9736  0.9182 -0.3712  1.4233  0.1615 -1.0642 -0.3637  0.4485 -2.0036
#>  0.1894 -0.5645 -0.4172 -1.4549  2.2844 -1.0154  0.1047  0.7648  0.6262  0.4992
#> -0.1113  0.3835  2.2667  0.9083  0.5725  1.2227 -1.4900 -1.0725 -1.1362  0.5607
#>  0.5695  0.4654 -0.5077 -0.7506  0.9828 -0.3920 -1.0323 -0.4742 -0.0870 -0.5669
#>  0.4738 -1.6645 -0.3757 -0.8253  0.2710 -0.9409  0.6492  0.6847  0.7076  0.0584
#>  1.2029  0.9101 -1.4574  0.5544 -0.7882 -0.4017  0.8556  2.4344  0.0653 -0.7629
#>  0.9073 -0.5049 -0.7639  0.1851  1.1858 -1.3678  0.4335 -0.6644 -0.4690  0.0853
#>  0.9610  0.3703 -0.6223 -1.6260  0.8962  0.0740 -1.3993 -0.1245 -0.9057  0.6285
#>  0.4600 -1.6133 -0.5556 -1.1827  0.1376 -0.4903  0.6346  1.3657  1.3797 -0.8985
#> -2.4224  0.3884 -0.4919  0.6594 -1.7518 -0.4340  0.5140  0.6817  1.6388  1.8202
#> -0.4055  1.9108 -1.9309  1.1398  0.2602  0.8713 -0.3817  0.3444 -0.4844 -0.9412
#> -0.3716 -0.0375  0.7613 -0.0770  1.7014 -1.8043  0.7900 -0.1694 -0.8825 -2.3083
#> -1.4394 -0.9209  1.2836 -0.9393  1.3980  0.5578  0.5069  1.4112  0.2872 -0.0617
#>  0.3905  0.2466  1.7325  0.1055 -0.2058  0.3224 -0.1402 -0.3017  2.1861 -0.4345
#>  0.0107  0.4230  0.1817 -0.5522 -0.4804 -0.3245 -0.4032  0.5649 -0.3969  2.0258
#>  0.4985  0.9555 -0.1069  0.6812  0.2762  0.4414 -1.7138  0.8141 -0.9742  0.5986
#>  1.5362  0.1557 -0.3390 -1.7683 -0.6204 -1.3186  1.0852 -0.0955  1.5929 -1.9387
#>  1.3678 -0.9504  1.2215  0.2460 -0.7110  0.2074  0.1032  1.6091  0.7421 -0.2418
#>  1.2229  1.2746  0.7991  1.0467 -0.3662 -1.1073 -0.0673  0.7385 -1.2777 -0.5684
#>  1.2138  0.3925 -1.0068  0.2445  0.6461 -0.1079  0.4425 -0.6063 -0.4986 -0.3574
#> -0.2273  0.9334 -0.3193  1.1631  0.4420  0.8371 -0.3849  0.2681 -0.0929 -1.5755
#> -0.1345  0.1293 -0.1587 -1.2787 -0.4366  0.0876  1.2436  0.2132 -0.1087  0.5102
#> -0.9964 -0.1590  0.6447 -1.0211  2.3020  1.2431 -0.8013 -0.9320 -1.2582  0.0192
#> -2.8226 -0.5840 -2.0978 -1.2291  0.2043 -1.6496  1.3698 -0.2805  1.2176 -0.6865
#> -0.8723 -1.1440  0.1791  0.4198 -1.8630 -1.5977 -0.9127 -0.6998  0.7491 -0.2661
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{32,25} ]
```
