# Flattens a contiguous range of dims into a tensor.

For use with
[nn_sequential](https://torch.mlverse.org/docs/dev/reference/nn_sequential.md).

## Usage

``` r
nn_flatten(start_dim = 2, end_dim = -1)
```

## Arguments

- start_dim:

  first dim to flatten (default = 2).

- end_dim:

  last dim to flatten (default = -1).

## Shape

- Input: `(*, S_start,..., S_i, ..., S_end, *)`, where `S_i` is the size
  at dimension `i` and `*` means any number of dimensions including
  none.

- Output: `(*, S_start*...*S_i*...S_end, *)`.

## See also

[nn_unflatten](https://torch.mlverse.org/docs/dev/reference/nn_unflatten.md)

## Examples

``` r
if (torch_is_installed()) {
input <- torch_randn(32, 1, 5, 5)
m <- nn_flatten()
m(input)
}
#> torch_tensor
#> Columns 1 to 10-0.2879  1.0857  1.1421  2.0051 -0.8920  0.4806  0.1803  0.0536  0.7339  0.1522
#> -0.6643 -1.6263  0.2830  0.0271 -0.1124  1.2257 -0.7173  0.5444 -0.5379  1.1295
#>  0.5850  0.1536 -0.8098  0.0027 -1.3573  1.5025 -0.6358  0.5033  0.3658  0.2724
#> -0.4004  0.4682 -0.7473 -0.5438 -0.9876 -0.1160  0.3290  0.6996 -0.2561 -0.1812
#>  0.6660 -0.9020 -0.3557  1.3314 -0.0283 -2.7460 -0.0801 -0.6302 -0.2721 -0.7815
#> -1.3375 -2.0762 -0.0323 -2.1726 -0.9487 -0.0069 -1.6902 -2.0822 -0.6499  0.9678
#> -0.7587 -0.0593  0.8936 -1.0430  1.5229 -2.2734  0.3323 -1.8080  0.1969 -0.2306
#>  0.4582  0.6567 -1.2501  0.4458 -0.9909 -0.1246 -0.2044  1.7067 -0.7837 -0.1927
#>  0.9883 -0.4007  0.1832  1.3134  1.5797 -0.3633 -0.4823 -1.9284 -0.2429 -1.5872
#> -0.5327  0.2433 -0.6703  0.5405  0.4248 -2.3634 -1.9442  0.2214 -1.1406 -0.6084
#> -0.9887 -0.7686 -0.7965 -0.6882  1.3470 -0.2123 -0.8140  1.8476 -0.4841 -0.4612
#> -0.6951 -1.8790  0.8560 -0.2981  0.7996 -2.7875  0.0479 -2.1306 -0.5581  1.4178
#>  0.8523 -0.5317  0.2138  0.6160 -0.4384  0.3414 -1.3159  0.6415 -0.0504 -0.6991
#>  0.9553 -1.8614 -1.1130 -1.8501  1.6772  1.1812 -0.3041 -1.5784  1.0521 -0.5584
#> -0.5570  0.3603  0.7013 -1.0181 -0.4478  0.5740 -0.3519  0.3426  0.8334 -0.4560
#> -0.1862 -0.1368  0.4164  1.2308 -0.5031  0.0936 -1.5715  1.9664  0.0353  1.1405
#>  0.1625  0.1197 -0.0365 -2.0634  0.3255 -0.4414  0.0923  0.0350 -0.1782 -1.5388
#>  1.0615 -0.4814  0.0656 -1.6176 -1.0481  1.2279  0.2570  0.1983 -1.9153 -0.9330
#> -0.1309  2.5150  0.4293 -2.0588 -1.3176  1.2487  0.8852 -2.3048  0.5284 -0.7464
#>  2.0407  0.2196 -1.9889 -1.2277  0.6642 -0.7602 -1.4655 -0.4414 -1.2683 -0.1808
#> -0.8789  0.4577  0.1177  0.0738  0.1585  0.5479 -0.5578  1.1805 -0.9187  0.5909
#>  0.7579 -0.7160 -0.0423  1.8826 -0.5798  0.9789  0.4386 -0.1539  0.8558 -0.5838
#>  0.2343  2.3821 -0.4940 -0.8256  0.4193 -1.3120  1.5176 -0.8924  1.2255  0.1502
#> -0.0537 -1.2555  0.7199 -0.2022  1.1247 -0.0818 -0.7919 -0.7325  1.3165  0.0115
#> -0.1213 -0.2344  0.4477  0.0511  1.0341 -0.0517 -0.6830 -0.2824 -1.0327 -0.5594
#>  0.7254 -2.4463 -0.8820 -0.5048 -0.9270  0.1116 -1.3447 -0.5599 -0.1562  0.5459
#>  0.8376 -0.2303 -0.5410  0.3666  0.8907 -1.7603 -1.2233 -0.2761  0.3099  0.2256
#> -0.9230  0.7375  0.0107 -0.2386 -0.4234 -0.2056 -1.5137 -0.3263  1.5548  0.9153
#> -0.5024 -0.7025 -0.7561  2.6669  1.4289 -0.9276  1.0851 -1.6811  0.0269  0.6112
#> -1.0960 -0.6534  0.3056  0.0882  0.7044 -0.9972  1.7549  0.1353  1.3174 -1.7008
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{32,25} ]
```
