# Flattens a contiguous range of dims into a tensor.

For use with
[nn_sequential](https://torch.mlverse.org/docs/dev/reference/nn_sequential.md).

## Usage

``` r
nn_flatten(start_dim = 2, end_dim = -1)
```

## Arguments

- start_dim:

  first dim to flatten (default = 2).

- end_dim:

  last dim to flatten (default = -1).

## Shape

- Input: `(*, S_start,..., S_i, ..., S_end, *)`, where `S_i` is the size
  at dimension `i` and `*` means any number of dimensions including
  none.

- Output: `(*, S_start*...*S_i*...S_end, *)`.

## See also

[nn_unflatten](https://torch.mlverse.org/docs/dev/reference/nn_unflatten.md)

## Examples

``` r
if (torch_is_installed()) {
input <- torch_randn(32, 1, 5, 5)
m <- nn_flatten()
m(input)
}
#> torch_tensor
#> Columns 1 to 10-1.2062 -0.4613  1.1736  0.8215 -0.1089 -1.4105  1.2042  0.7010 -1.0807  0.6485
#>  0.3510 -0.0583  1.1993  0.6907 -0.8407 -0.3374  0.6922  1.8904 -0.6172 -0.6707
#>  0.6576  1.7383 -0.3484  1.7551  0.3148 -0.6031  0.2097 -1.3932 -1.5176 -0.8795
#>  1.0475  2.5805 -0.0954  1.2217  0.8922  0.4964  0.5440  1.3353  0.7980  1.1140
#> -0.3164  0.3172  0.7927  1.2752  0.4780 -0.9397  0.7167  0.6124  0.8124 -0.6525
#> -1.3695  0.0346 -0.6929  2.0919 -0.3476  0.5969 -0.8693  2.0620  0.5065 -0.6065
#> -1.7238  1.1159 -0.7562  1.0540  0.6447 -1.0320 -0.8712 -0.3132  0.1948  0.9127
#> -0.8457  0.3542 -0.8769 -0.5323  0.7530  1.9568  0.2815  0.2926  0.8796  0.6181
#>  1.0910 -2.2792  1.4817 -0.1344  0.9252 -0.0230 -0.8030  2.2428  0.6950 -2.3363
#> -1.4273 -0.7164  1.1004 -0.6161  0.0797 -0.6660 -0.7452 -0.8027 -0.3005 -1.1161
#>  0.3230  0.3261 -1.5440 -0.1058  0.7954 -1.0121  2.0411 -0.1660  2.3759  0.3065
#>  0.5625 -2.3857 -0.9865  0.2509  0.0851  1.2295  1.3973  1.4264 -0.2943  0.5984
#> -0.7570 -0.5243 -0.4466  0.0450 -0.0655  0.1826 -0.7790 -0.4434  0.3983 -0.2846
#> -0.5121  0.3316  0.8336 -0.7967 -0.1155  0.1192 -0.8265  0.1107  0.7355  0.9017
#> -0.2547 -0.1134  1.3741  0.4596 -0.8559  1.4444 -0.4028 -0.0313 -0.3772  0.1292
#>  2.6138 -0.8450 -0.3277  0.0987 -0.4166  0.3672 -1.4296 -1.1782 -0.3658 -0.1017
#>  0.2215  1.1602  1.2634  0.8786  0.6154  1.2892 -1.4283 -0.6019  0.7514  0.0929
#>  0.3509 -0.5748 -0.7533 -2.0060  0.4488  0.3336 -0.3519  0.9375  0.5085 -0.2463
#> -1.7490 -1.2092  0.6293  1.6541  1.8429  1.5471 -1.4586 -0.9489 -0.4349 -1.6478
#> -0.0407 -0.6166 -0.5516  0.1415 -0.0713  2.3086  0.5320  0.4056 -2.3272  0.8661
#>  0.8213  0.0741 -0.0771 -0.2421 -0.1436 -0.2442  0.7895 -0.0323  0.9340 -0.0207
#> -0.7678 -0.6380  0.0571 -0.3422  0.2272 -0.1936  0.2971  0.4957 -0.8483 -0.0647
#> -0.1441 -0.6428 -0.5444 -0.5843  2.4096 -0.3130  0.4313 -0.8290  0.3022 -0.0069
#> -0.7960 -0.0650 -1.4183 -0.5436 -0.5309 -1.1127  2.1209  0.2478  0.3116  0.8017
#> -2.1498  1.8202  1.1601 -0.1710 -1.9070  1.6412  0.1844 -0.6013  2.2322  0.3437
#>  1.0679 -0.9392 -0.4291  0.2464  1.3136 -0.4672 -0.2182  0.5867  0.2184 -0.0451
#> -1.3320  0.1588  0.0109  0.3753 -1.1300 -0.9850 -0.9668  0.3771  2.0076  0.6872
#>  0.6311  0.4802  0.0228 -0.5359 -1.0043  0.0192  1.1011 -0.4730  0.9443  0.9967
#>  1.4004  0.9884  0.0307  1.0725  1.0406  0.4483 -0.7271 -0.7569 -1.4478 -2.1057
#>  1.3485  0.6007 -1.4765  1.9133  0.2516  0.2782  0.6908 -1.3841 -1.4074  0.8325
#> ... [the output was truncated (use n=-1 to disable)]
#> [ CPUFloatType{32,25} ]
```
